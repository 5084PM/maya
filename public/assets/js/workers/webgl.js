var WEBGL = (function () {
	'use strict';

	/**
	 * @license
	 * Copyright 2010-2025 Three.js Authors
	 * SPDX-License-Identifier: MIT
	 */
	const REVISION = '177';

	/**
	 * Represents mouse buttons and interaction types in context of controls.
	 *
	 * @type {ConstantsMouse}
	 * @constant
	 */
	const MOUSE = { LEFT: 0, MIDDLE: 1, RIGHT: 2, ROTATE: 0, DOLLY: 1, PAN: 2 };

	/**
	 * Represents touch interaction types in context of controls.
	 *
	 * @type {ConstantsTouch}
	 * @constant
	 */
	const TOUCH = { ROTATE: 0, PAN: 1, DOLLY_PAN: 2, DOLLY_ROTATE: 3 };

	/**
	 * Disables face culling.
	 *
	 * @type {number}
	 * @constant
	 */
	const CullFaceNone = 0;

	/**
	 * Culls back faces.
	 *
	 * @type {number}
	 * @constant
	 */
	const CullFaceBack = 1;

	/**
	 * Culls front faces.
	 *
	 * @type {number}
	 * @constant
	 */
	const CullFaceFront = 2;

	/**
	 * Filters shadow maps using the Percentage-Closer Filtering (PCF) algorithm.
	 *
	 * @type {number}
	 * @constant
	 */
	const PCFShadowMap = 1;

	/**
	 * Filters shadow maps using the Percentage-Closer Filtering (PCF) algorithm with
	 * better soft shadows especially when using low-resolution shadow maps.
	 *
	 * @type {number}
	 * @constant
	 */
	const PCFSoftShadowMap = 2;

	/**
	 * Filters shadow maps using the Variance Shadow Map (VSM) algorithm.
	 * When using VSMShadowMap all shadow receivers will also cast shadows.
	 *
	 * @type {number}
	 * @constant
	 */
	const VSMShadowMap = 3;

	/**
	 * Only front faces are rendered.
	 *
	 * @type {number}
	 * @constant
	 */
	const FrontSide = 0;

	/**
	 * Only back faces are rendered.
	 *
	 * @type {number}
	 * @constant
	 */
	const BackSide = 1;

	/**
	 * Both front and back faces are rendered.
	 *
	 * @type {number}
	 * @constant
	 */
	const DoubleSide = 2;

	/**
	 * No blending is performed which effectively disables
	 * alpha transparency.
	 *
	 * @type {number}
	 * @constant
	 */
	const NoBlending = 0;

	/**
	 * The default blending.
	 *
	 * @type {number}
	 * @constant
	 */
	const NormalBlending = 1;

	/**
	 * Represents additive blending.
	 *
	 * @type {number}
	 * @constant
	 */
	const AdditiveBlending = 2;

	/**
	 * Represents subtractive blending.
	 *
	 * @type {number}
	 * @constant
	 */
	const SubtractiveBlending = 3;

	/**
	 * Represents multiply blending.
	 *
	 * @type {number}
	 * @constant
	 */
	const MultiplyBlending = 4;

	/**
	 * Represents custom blending.
	 *
	 * @type {number}
	 * @constant
	 */
	const CustomBlending = 5;

	/**
	 * A `source + destination` blending equation.
	 *
	 * @type {number}
	 * @constant
	 */
	const AddEquation = 100;

	/**
	 * A `source - destination` blending equation.
	 *
	 * @type {number}
	 * @constant
	 */
	const SubtractEquation = 101;

	/**
	 * A `destination - source` blending equation.
	 *
	 * @type {number}
	 * @constant
	 */
	const ReverseSubtractEquation = 102;

	/**
	 * A blend equation that uses the minimum of source and destination.
	 *
	 * @type {number}
	 * @constant
	 */
	const MinEquation = 103;

	/**
	 * A blend equation that uses the maximum of source and destination.
	 *
	 * @type {number}
	 * @constant
	 */
	const MaxEquation = 104;

	/**
	 * Multiplies all colors by `0`.
	 *
	 * @type {number}
	 * @constant
	 */
	const ZeroFactor = 200;

	/**
	 * Multiplies all colors by `1`.
	 *
	 * @type {number}
	 * @constant
	 */
	const OneFactor = 201;

	/**
	 * Multiplies all colors by the source colors.
	 *
	 * @type {number}
	 * @constant
	 */
	const SrcColorFactor = 202;

	/**
	 * Multiplies all colors by `1` minus each source color.
	 *
	 * @type {number}
	 * @constant
	 */
	const OneMinusSrcColorFactor = 203;

	/**
	 * Multiplies all colors by the source alpha value.
	 *
	 * @type {number}
	 * @constant
	 */
	const SrcAlphaFactor = 204;

	/**
	 * Multiplies all colors by 1 minus the source alpha value.
	 *
	 * @type {number}
	 * @constant
	 */
	const OneMinusSrcAlphaFactor = 205;

	/**
	 * Multiplies all colors by the destination alpha value.
	 *
	 * @type {number}
	 * @constant
	 */
	const DstAlphaFactor = 206;

	/**
	 * Multiplies all colors by `1` minus the destination alpha value.
	 *
	 * @type {number}
	 * @constant
	 */
	const OneMinusDstAlphaFactor = 207;

	/**
	 * Multiplies all colors by the destination color.
	 *
	 * @type {number}
	 * @constant
	 */
	const DstColorFactor = 208;

	/**
	 * Multiplies all colors by `1` minus each destination color.
	 *
	 * @type {number}
	 * @constant
	 */
	const OneMinusDstColorFactor = 209;

	/**
	 * Multiplies the RGB colors by the smaller of either the source alpha
	 * value or the value of `1` minus the destination alpha value. The alpha
	 * value is multiplied by `1`.
	 *
	 * @type {number}
	 * @constant
	 */
	const SrcAlphaSaturateFactor = 210;

	/**
	 * Multiplies all colors by a constant color.
	 *
	 * @type {number}
	 * @constant
	 */
	const ConstantColorFactor = 211;

	/**
	 * Multiplies all colors by `1` minus a constant color.
	 *
	 * @type {number}
	 * @constant
	 */
	const OneMinusConstantColorFactor = 212;

	/**
	 * Multiplies all colors by a constant alpha value.
	 *
	 * @type {number}
	 * @constant
	 */
	const ConstantAlphaFactor = 213;

	/**
	 * Multiplies all colors by 1 minus a constant alpha value.
	 *
	 * @type {number}
	 * @constant
	 */
	const OneMinusConstantAlphaFactor = 214;

	/**
	 * Never pass.
	 *
	 * @type {number}
	 * @constant
	 */
	const NeverDepth = 0;

	/**
	 * Always pass.
	 *
	 * @type {number}
	 * @constant
	 */
	const AlwaysDepth = 1;

	/**
	 * Pass if the incoming value is less than the depth buffer value.
	 *
	 * @type {number}
	 * @constant
	 */
	const LessDepth = 2;

	/**
	 * Pass if the incoming value is less than or equal to the depth buffer value.
	 *
	 * @type {number}
	 * @constant
	 */
	const LessEqualDepth = 3;

	/**
	 * Pass if the incoming value equals the depth buffer value.
	 *
	 * @type {number}
	 * @constant
	 */
	const EqualDepth = 4;

	/**
	 * Pass if the incoming value is greater than or equal to the depth buffer value.
	 *
	 * @type {number}
	 * @constant
	 */
	const GreaterEqualDepth = 5;

	/**
	 * Pass if the incoming value is greater than the depth buffer value.
	 *
	 * @type {number}
	 * @constant
	 */
	const GreaterDepth = 6;

	/**
	 * Pass if the incoming value is not equal to the depth buffer value.
	 *
	 * @type {number}
	 * @constant
	 */
	const NotEqualDepth = 7;

	/**
	 * Multiplies the environment map color with the surface color.
	 *
	 * @type {number}
	 * @constant
	 */
	const MultiplyOperation = 0;

	/**
	 * Uses reflectivity to blend between the two colors.
	 *
	 * @type {number}
	 * @constant
	 */
	const MixOperation = 1;

	/**
	 * Adds the two colors.
	 *
	 * @type {number}
	 * @constant
	 */
	const AddOperation = 2;

	/**
	 * No tone mapping is applied.
	 *
	 * @type {number}
	 * @constant
	 */
	const NoToneMapping = 0;

	/**
	 * Linear tone mapping.
	 *
	 * @type {number}
	 * @constant
	 */
	const LinearToneMapping = 1;

	/**
	 * Reinhard tone mapping.
	 *
	 * @type {number}
	 * @constant
	 */
	const ReinhardToneMapping = 2;

	/**
	 * Cineon tone mapping.
	 *
	 * @type {number}
	 * @constant
	 */
	const CineonToneMapping = 3;

	/**
	 * ACES Filmic tone mapping.
	 *
	 * @type {number}
	 * @constant
	 */
	const ACESFilmicToneMapping = 4;

	/**
	 * Custom tone mapping.
	 *
	 * Expects a custom implementation by modifying shader code of the material's fragment shader.
	 *
	 * @type {number}
	 * @constant
	 */
	const CustomToneMapping = 5;

	/**
	 * AgX tone mapping.
	 *
	 * @type {number}
	 * @constant
	 */
	const AgXToneMapping = 6;

	/**
	 * Neutral tone mapping.
	 *
	 * Implementation based on the Khronos 3D Commerce Group standard tone mapping.
	 *
	 * @type {number}
	 * @constant
	 */
	const NeutralToneMapping = 7;

	/**
	 * The skinned mesh shares the same world space as the skeleton.
	 *
	 * @type {string}
	 * @constant
	 */
	const AttachedBindMode = 'attached';

	/**
	 * The skinned mesh does not share the same world space as the skeleton.
	 * This is useful when a skeleton is shared across multiple skinned meshes.
	 *
	 * @type {string}
	 * @constant
	 */
	const DetachedBindMode = 'detached';

	/**
	 * Maps textures using the geometry's UV coordinates.
	 *
	 * @type {number}
	 * @constant
	 */
	const UVMapping = 300;

	/**
	 * Reflection mapping for cube textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const CubeReflectionMapping = 301;

	/**
	 * Refraction mapping for cube textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const CubeRefractionMapping = 302;

	/**
	 * Reflection mapping for equirectangular textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const EquirectangularReflectionMapping = 303;

	/**
	 * Refraction mapping for equirectangular textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const EquirectangularRefractionMapping = 304;

	/**
	 * Reflection mapping for PMREM textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const CubeUVReflectionMapping = 306;

	/**
	 * The texture will simply repeat to infinity.
	 *
	 * @type {number}
	 * @constant
	 */
	const RepeatWrapping = 1000;

	/**
	 * The last pixel of the texture stretches to the edge of the mesh.
	 *
	 * @type {number}
	 * @constant
	 */
	const ClampToEdgeWrapping = 1001;

	/**
	 * The texture will repeats to infinity, mirroring on each repeat.
	 *
	 * @type {number}
	 * @constant
	 */
	const MirroredRepeatWrapping = 1002;

	/**
	 * Returns the value of the texture element that is nearest (in Manhattan distance)
	 * to the specified texture coordinates.
	 *
	 * @type {number}
	 * @constant
	 */
	const NearestFilter = 1003;

	/**
	 * Chooses the mipmap that most closely matches the size of the pixel being textured
	 * and uses the `NearestFilter` criterion (the texel nearest to the center of the pixel)
	 * to produce a texture value.
	 *
	 * @type {number}
	 * @constant
	 */
	const NearestMipmapNearestFilter = 1004;

	/**
	 * Chooses the two mipmaps that most closely match the size of the pixel being textured and
	 * uses the `NearestFilter` criterion to produce a texture value from each mipmap.
	 * The final texture value is a weighted average of those two values.
	 *
	 * @type {number}
	 * @constant
	 */
	const NearestMipmapLinearFilter = 1005;

	/**
	 * Returns the weighted average of the four texture elements that are closest to the specified
	 * texture coordinates, and can include items wrapped or repeated from other parts of a texture,
	 * depending on the values of `wrapS` and `wrapT`, and on the exact mapping.
	 *
	 * @type {number}
	 * @constant
	 */
	const LinearFilter = 1006;

	/**
	 * Chooses the mipmap that most closely matches the size of the pixel being textured and uses
	 * the `LinearFilter` criterion (a weighted average of the four texels that are closest to the
	 * center of the pixel) to produce a texture value.
	 *
	 * @type {number}
	 * @constant
	 */
	const LinearMipmapNearestFilter = 1007;

	/**
	 * Chooses the two mipmaps that most closely match the size of the pixel being textured and uses
	 * the `LinearFilter` criterion to produce a texture value from each mipmap. The final texture value
	 * is a weighted average of those two values.
	 *
	 * @type {number}
	 * @constant
	 */
	const LinearMipmapLinearFilter = 1008;

	/**
	 * An unsigned byte data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const UnsignedByteType = 1009;

	/**
	 * A byte data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const ByteType = 1010;

	/**
	 * A short data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const ShortType = 1011;

	/**
	 * An unsigned short data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const UnsignedShortType = 1012;

	/**
	 * An int data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const IntType = 1013;

	/**
	 * An unsigned int data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const UnsignedIntType = 1014;

	/**
	 * A float data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const FloatType = 1015;

	/**
	 * A half float data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const HalfFloatType = 1016;

	/**
	 * An unsigned short 4_4_4_4 (packed) data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const UnsignedShort4444Type = 1017;

	/**
	 * An unsigned short 5_5_5_1 (packed) data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const UnsignedShort5551Type = 1018;

	/**
	 * An unsigned int 24_8 data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const UnsignedInt248Type = 1020;

	/**
	 * An unsigned int 5_9_9_9 (packed) data type for textures.
	 *
	 * @type {number}
	 * @constant
	 */
	const UnsignedInt5999Type = 35902;

	/**
	 * Discards the red, green and blue components and reads just the alpha component.
	 *
	 * @type {number}
	 * @constant
	 */
	const AlphaFormat = 1021;

	/**
	 * Discards the alpha component and reads the red, green and blue component.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBFormat = 1022;

	/**
	 * Reads the red, green, blue and alpha components.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBAFormat = 1023;

	/**
	 * Reads each element as a single depth value, converts it to floating point, and clamps to the range `[0,1]`.
	 *
	 * @type {number}
	 * @constant
	 */
	const DepthFormat = 1026;

	/**
	 * Reads each element is a pair of depth and stencil values. The depth component of the pair is interpreted as
	 * in `DepthFormat`. The stencil component is interpreted based on the depth + stencil internal format.
	 *
	 * @type {number}
	 * @constant
	 */
	const DepthStencilFormat = 1027;

	/**
	 * Discards the green, blue and alpha components and reads just the red component.
	 *
	 * @type {number}
	 * @constant
	 */
	const RedFormat = 1028;

	/**
	 * Discards the green, blue and alpha components and reads just the red component. The texels are read as integers instead of floating point.
	 *
	 * @type {number}
	 * @constant
	 */
	const RedIntegerFormat = 1029;

	/**
	 * Discards the alpha, and blue components and reads the red, and green components.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGFormat = 1030;

	/**
	 * Discards the alpha, and blue components and reads the red, and green components. The texels are read as integers instead of floating point.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGIntegerFormat = 1031;

	/**
	 * Reads the red, green, blue and alpha components. The texels are read as integers instead of floating point.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBAIntegerFormat = 1033;

	/**
	 * A DXT1-compressed image in an RGB image format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGB_S3TC_DXT1_Format = 33776;

	/**
	 * A DXT1-compressed image in an RGB image format with a simple on/off alpha value.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_S3TC_DXT1_Format = 33777;

	/**
	 * A DXT3-compressed image in an RGBA image format. Compared to a 32-bit RGBA texture, it offers 4:1 compression.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_S3TC_DXT3_Format = 33778;

	/**
	 * A DXT5-compressed image in an RGBA image format. It also provides a 4:1 compression, but differs to the DXT3
	 * compression in how the alpha compression is done.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_S3TC_DXT5_Format = 33779;

	/**
	 * PVRTC RGB compression in 4-bit mode. One block for each 4×4 pixels.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGB_PVRTC_4BPPV1_Format = 35840;

	/**
	 * PVRTC RGB compression in 2-bit mode. One block for each 8×4 pixels.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGB_PVRTC_2BPPV1_Format = 35841;

	/**
	 * PVRTC RGBA compression in 4-bit mode. One block for each 4×4 pixels.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_PVRTC_4BPPV1_Format = 35842;

	/**
	 * PVRTC RGBA compression in 2-bit mode. One block for each 8×4 pixels.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_PVRTC_2BPPV1_Format = 35843;

	/**
	 * ETC1 RGB format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGB_ETC1_Format = 36196;

	/**
	 * ETC2 RGB format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGB_ETC2_Format = 37492;

	/**
	 * ETC2 RGBA format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ETC2_EAC_Format = 37496;

	/**
	 * ASTC RGBA 4x4 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_4x4_Format = 37808;

	/**
	 * ASTC RGBA 5x4 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_5x4_Format = 37809;

	/**
	 * ASTC RGBA 5x5 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_5x5_Format = 37810;

	/**
	 * ASTC RGBA 6x5 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_6x5_Format = 37811;

	/**
	 * ASTC RGBA 6x6 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_6x6_Format = 37812;

	/**
	 * ASTC RGBA 8x5 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_8x5_Format = 37813;

	/**
	 * ASTC RGBA 8x6 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_8x6_Format = 37814;

	/**
	 * ASTC RGBA 8x8 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_8x8_Format = 37815;

	/**
	 * ASTC RGBA 10x5 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_10x5_Format = 37816;

	/**
	 * ASTC RGBA 10x6 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_10x6_Format = 37817;

	/**
	 * ASTC RGBA 10x8 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_10x8_Format = 37818;

	/**
	 * ASTC RGBA 10x10 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_10x10_Format = 37819;

	/**
	 * ASTC RGBA 12x10 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_12x10_Format = 37820;

	/**
	 * ASTC RGBA 12x12 format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_ASTC_12x12_Format = 37821;

	/**
	 * BPTC RGBA format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBA_BPTC_Format = 36492;

	/**
	 * BPTC Signed RGB format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGB_BPTC_SIGNED_Format = 36494;

	/**
	 * BPTC Unsigned RGB format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGB_BPTC_UNSIGNED_Format = 36495;

	/**
	 * RGTC1 Red format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RED_RGTC1_Format = 36283;

	/**
	 * RGTC1 Signed Red format.
	 *
	 * @type {number}
	 * @constant
	 */
	const SIGNED_RED_RGTC1_Format = 36284;

	/**
	 * RGTC2 Red Green format.
	 *
	 * @type {number}
	 * @constant
	 */
	const RED_GREEN_RGTC2_Format = 36285;

	/**
	 * RGTC2 Signed Red Green format.
	 *
	 * @type {number}
	 * @constant
	 */
	const SIGNED_RED_GREEN_RGTC2_Format = 36286;

	/**
	 * Discrete interpolation mode for keyframe tracks.
	 *
	 * @type {number}
	 * @constant
	 */
	const InterpolateDiscrete = 2300;

	/**
	 * Linear interpolation mode for keyframe tracks.
	 *
	 * @type {number}
	 * @constant
	 */
	const InterpolateLinear = 2301;

	/**
	 * Smooth interpolation mode for keyframe tracks.
	 *
	 * @type {number}
	 * @constant
	 */
	const InterpolateSmooth = 2302;

	/**
	 * Zero curvature ending for animations.
	 *
	 * @type {number}
	 * @constant
	 */
	const ZeroCurvatureEnding = 2400;

	/**
	 * Zero slope ending for animations.
	 *
	 * @type {number}
	 * @constant
	 */
	const ZeroSlopeEnding = 2401;

	/**
	 * Wrap around ending for animations.
	 *
	 * @type {number}
	 * @constant
	 */
	const WrapAroundEnding = 2402;

	/**
	 * Default animation blend mode.
	 *
	 * @type {number}
	 * @constant
	 */
	const NormalAnimationBlendMode = 2500;

	/**
	 * For every three vertices draw a single triangle.
	 *
	 * @type {number}
	 * @constant
	 */
	const TrianglesDrawMode = 0;

	/**
	 * For each vertex draw a triangle from the last three vertices.
	 *
	 * @type {number}
	 * @constant
	 */
	const TriangleStripDrawMode = 1;

	/**
	 * For each vertex draw a triangle from the first vertex and the last two vertices.
	 *
	 * @type {number}
	 * @constant
	 */
	const TriangleFanDrawMode = 2;

	/**
	 * Basic depth packing.
	 *
	 * @type {number}
	 * @constant
	 */
	const BasicDepthPacking = 3200;

	/**
	 * A depth value is packed into 32 bit RGBA.
	 *
	 * @type {number}
	 * @constant
	 */
	const RGBADepthPacking = 3201;

	/**
	 * Normal information is relative to the underlying surface.
	 *
	 * @type {number}
	 * @constant
	 */
	const TangentSpaceNormalMap = 0;

	/**
	 * Normal information is relative to the object orientation.
	 *
	 * @type {number}
	 * @constant
	 */
	const ObjectSpaceNormalMap = 1;

	// Color space string identifiers, matching CSS Color Module Level 4 and WebGPU names where available.

	/**
	 * No color space.
	 *
	 * @type {string}
	 * @constant
	 */
	const NoColorSpace = '';

	/**
	 * sRGB color space.
	 *
	 * @type {string}
	 * @constant
	 */
	const SRGBColorSpace = 'srgb';

	/**
	 * sRGB-linear color space.
	 *
	 * @type {string}
	 * @constant
	 */
	const LinearSRGBColorSpace = 'srgb-linear';

	/**
	 * Linear transfer function.
	 *
	 * @type {string}
	 * @constant
	 */
	const LinearTransfer = 'linear';

	/**
	 * sRGB transfer function.
	 *
	 * @type {string}
	 * @constant
	 */
	const SRGBTransfer = 'srgb';

	/**
	 * Keeps the current value.
	 *
	 * @type {number}
	 * @constant
	 */
	const KeepStencilOp = 7680;

	/**
	 * Will always return true.
	 *
	 * @type {number}
	 * @constant
	 */
	const AlwaysStencilFunc = 519;

	/**
	 * Never pass.
	 *
	 * @type {number}
	 * @constant
	 */
	const NeverCompare = 512;

	/**
	 * Pass if the incoming value is less than the texture value.
	 *
	 * @type {number}
	 * @constant
	 */
	const LessCompare = 513;

	/**
	 * Pass if the incoming value equals the texture value.
	 *
	 * @type {number}
	 * @constant
	 */
	const EqualCompare = 514;

	/**
	 * Pass if the incoming value is less than or equal to the texture value.
	 *
	 * @type {number}
	 * @constant
	 */
	const LessEqualCompare = 515;

	/**
	 * Pass if the incoming value is greater than the texture value.
	 *
	 * @type {number}
	 * @constant
	 */
	const GreaterCompare = 516;

	/**
	 * Pass if the incoming value is not equal to the texture value.
	 *
	 * @type {number}
	 * @constant
	 */
	const NotEqualCompare = 517;

	/**
	 * Pass if the incoming value is greater than or equal to the texture value.
	 *
	 * @type {number}
	 * @constant
	 */
	const GreaterEqualCompare = 518;

	/**
	 * Always pass.
	 *
	 * @type {number}
	 * @constant
	 */
	const AlwaysCompare = 519;

	/**
	 * The contents are intended to be specified once by the application, and used many
	 * times as the source for drawing and image specification commands.
	 *
	 * @type {number}
	 * @constant
	 */
	const StaticDrawUsage = 35044;

	/**
	 * The contents are intended to be respecified repeatedly by the application, and
	 * used many times as the source for drawing and image specification commands.
	 *
	 * @type {number}
	 * @constant
	 */
	const DynamicDrawUsage = 35048;

	/**
	 * GLSL 3 shader code.
	 *
	 * @type {string}
	 * @constant
	 */
	const GLSL3 = '300 es';

	/**
	 * WebGL coordinate system.
	 *
	 * @type {number}
	 * @constant
	 */
	const WebGLCoordinateSystem = 2000;

	/**
	 * WebGPU coordinate system.
	 *
	 * @type {number}
	 * @constant
	 */
	const WebGPUCoordinateSystem = 2001;

	/**
	 * This type represents mouse buttons and interaction types in context of controls.
	 *
	 * @typedef {Object} ConstantsMouse
	 * @property {number} MIDDLE - The left mouse button.
	 * @property {number} LEFT - The middle mouse button.
	 * @property {number} RIGHT - The right mouse button.
	 * @property {number} ROTATE - A rotate interaction.
	 * @property {number} DOLLY - A dolly interaction.
	 * @property {number} PAN - A pan interaction.
	 **/

	/**
	 * This type represents touch interaction types in context of controls.
	 *
	 * @typedef {Object} ConstantsTouch
	 * @property {number} ROTATE - A rotate interaction.
	 * @property {number} PAN - A pan interaction.
	 * @property {number} DOLLY_PAN - The dolly-pan interaction.
	 * @property {number} DOLLY_ROTATE - A dolly-rotate interaction.
	 **/

	/**
	 * This type represents the different timestamp query types.
	 *
	 * @typedef {Object} ConstantsTimestampQuery
	 * @property {string} COMPUTE - A `compute` timestamp query.
	 * @property {string} RENDER - A `render` timestamp query.
	 **/

	/**
	 * Represents the different interpolation sampling types.
	 *
	 * @typedef {Object} ConstantsInterpolationSamplingType
	 * @property {string} PERSPECTIVE - Perspective-correct interpolation.
	 * @property {string} LINEAR - Linear interpolation.
	 * @property {string} FLAT - Flat interpolation.
	 */

	/**
	 * Represents the different interpolation sampling modes.
	 *
	 * @typedef {Object} ConstantsInterpolationSamplingMode
	 * @property {string} NORMAL - Normal sampling mode.
	 * @property {string} CENTROID - Centroid sampling mode.
	 * @property {string} SAMPLE - Sample-specific sampling mode.
	 * @property {string} FLAT_FIRST - Flat interpolation using the first vertex.
	 * @property {string} FLAT_EITHER - Flat interpolation using either vertex.
	 */

	/**
	 * This modules allows to dispatch event objects on custom JavaScript objects.
	 *
	 * Main repository: [eventdispatcher.js]{@link https://github.com/mrdoob/eventdispatcher.js/}
	 *
	 * Code Example:
	 * ```js
	 * class Car extends EventDispatcher {
	 * 	start() {
	 *		this.dispatchEvent( { type: 'start', message: 'vroom vroom!' } );
	 *	}
	 *};
	 *
	 * // Using events with the custom object
	 * const car = new Car();
	 * car.addEventListener( 'start', function ( event ) {
	 * 	alert( event.message );
	 * } );
	 *
	 * car.start();
	 * ```
	 */
	class EventDispatcher {

		/**
		 * Adds the given event listener to the given event type.
		 *
		 * @param {string} type - The type of event to listen to.
		 * @param {Function} listener - The function that gets called when the event is fired.
		 */
		addEventListener( type, listener ) {

			if ( this._listeners === undefined ) this._listeners = {};

			const listeners = this._listeners;

			if ( listeners[ type ] === undefined ) {

				listeners[ type ] = [];

			}

			if ( listeners[ type ].indexOf( listener ) === -1 ) {

				listeners[ type ].push( listener );

			}

		}

		/**
		 * Returns `true` if the given event listener has been added to the given event type.
		 *
		 * @param {string} type - The type of event.
		 * @param {Function} listener - The listener to check.
		 * @return {boolean} Whether the given event listener has been added to the given event type.
		 */
		hasEventListener( type, listener ) {

			const listeners = this._listeners;

			if ( listeners === undefined ) return false;

			return listeners[ type ] !== undefined && listeners[ type ].indexOf( listener ) !== -1;

		}

		/**
		 * Removes the given event listener from the given event type.
		 *
		 * @param {string} type - The type of event.
		 * @param {Function} listener - The listener to remove.
		 */
		removeEventListener( type, listener ) {

			const listeners = this._listeners;

			if ( listeners === undefined ) return;

			const listenerArray = listeners[ type ];

			if ( listenerArray !== undefined ) {

				const index = listenerArray.indexOf( listener );

				if ( index !== -1 ) {

					listenerArray.splice( index, 1 );

				}

			}

		}

		/**
		 * Dispatches an event object.
		 *
		 * @param {Object} event - The event that gets fired.
		 */
		dispatchEvent( event ) {

			const listeners = this._listeners;

			if ( listeners === undefined ) return;

			const listenerArray = listeners[ event.type ];

			if ( listenerArray !== undefined ) {

				event.target = this;

				// Make a copy, in case listeners are removed while iterating.
				const array = listenerArray.slice( 0 );

				for ( let i = 0, l = array.length; i < l; i ++ ) {

					array[ i ].call( this, event );

				}

				event.target = null;

			}

		}

	}

	const _lut = [ '00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '0a', '0b', '0c', '0d', '0e', '0f', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1a', '1b', '1c', '1d', '1e', '1f', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '2a', '2b', '2c', '2d', '2e', '2f', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '3a', '3b', '3c', '3d', '3e', '3f', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '4a', '4b', '4c', '4d', '4e', '4f', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '5a', '5b', '5c', '5d', '5e', '5f', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '6a', '6b', '6c', '6d', '6e', '6f', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '7a', '7b', '7c', '7d', '7e', '7f', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '8a', '8b', '8c', '8d', '8e', '8f', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '9a', '9b', '9c', '9d', '9e', '9f', 'a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'aa', 'ab', 'ac', 'ad', 'ae', 'af', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9', 'ba', 'bb', 'bc', 'bd', 'be', 'bf', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'ca', 'cb', 'cc', 'cd', 'ce', 'cf', 'd0', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'da', 'db', 'dc', 'dd', 'de', 'df', 'e0', 'e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7', 'e8', 'e9', 'ea', 'eb', 'ec', 'ed', 'ee', 'ef', 'f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'fa', 'fb', 'fc', 'fd', 'fe', 'ff' ];

	let _seed = 1234567;


	const DEG2RAD = Math.PI / 180;
	const RAD2DEG = 180 / Math.PI;

	/**
	 * Generate a [UUID]{@link https://en.wikipedia.org/wiki/Universally_unique_identifier}
	 * (universally unique identifier).
	 *
	 * @return {string} The UUID.
	 */
	function generateUUID() {

		// http://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid-in-javascript/21963136#21963136

		const d0 = Math.random() * 0xffffffff | 0;
		const d1 = Math.random() * 0xffffffff | 0;
		const d2 = Math.random() * 0xffffffff | 0;
		const d3 = Math.random() * 0xffffffff | 0;
		const uuid = _lut[ d0 & 0xff ] + _lut[ d0 >> 8 & 0xff ] + _lut[ d0 >> 16 & 0xff ] + _lut[ d0 >> 24 & 0xff ] + '-' +
				_lut[ d1 & 0xff ] + _lut[ d1 >> 8 & 0xff ] + '-' + _lut[ d1 >> 16 & 0x0f | 0x40 ] + _lut[ d1 >> 24 & 0xff ] + '-' +
				_lut[ d2 & 0x3f | 0x80 ] + _lut[ d2 >> 8 & 0xff ] + '-' + _lut[ d2 >> 16 & 0xff ] + _lut[ d2 >> 24 & 0xff ] +
				_lut[ d3 & 0xff ] + _lut[ d3 >> 8 & 0xff ] + _lut[ d3 >> 16 & 0xff ] + _lut[ d3 >> 24 & 0xff ];

		// .toLowerCase() here flattens concatenated strings to save heap memory space.
		return uuid.toLowerCase();

	}

	/**
	 * Clamps the given value between min and max.
	 *
	 * @param {number} value - The value to clamp.
	 * @param {number} min - The min value.
	 * @param {number} max - The max value.
	 * @return {number} The clamped value.
	 */
	function clamp( value, min, max ) {

		return Math.max( min, Math.min( max, value ) );

	}

	/**
	 * Computes the Euclidean modulo of the given parameters that
	 * is `( ( n % m ) + m ) % m`.
	 *
	 * @param {number} n - The first parameter.
	 * @param {number} m - The second parameter.
	 * @return {number} The Euclidean modulo.
	 */
	function euclideanModulo( n, m ) {

		// https://en.wikipedia.org/wiki/Modulo_operation

		return ( ( n % m ) + m ) % m;

	}

	/**
	 * Performs a linear mapping from range `<a1, a2>` to range `<b1, b2>`
	 * for the given value.
	 *
	 * @param {number} x - The value to be mapped.
	 * @param {number} a1 - Minimum value for range A.
	 * @param {number} a2 - Maximum value for range A.
	 * @param {number} b1 - Minimum value for range B.
	 * @param {number} b2 - Maximum value for range B.
	 * @return {number} The mapped value.
	 */
	function mapLinear( x, a1, a2, b1, b2 ) {

		return b1 + ( x - a1 ) * ( b2 - b1 ) / ( a2 - a1 );

	}

	/**
	 * Returns the percentage in the closed interval `[0, 1]` of the given value
	 * between the start and end point.
	 *
	 * @param {number} x - The start point
	 * @param {number} y - The end point.
	 * @param {number} value - A value between start and end.
	 * @return {number} The interpolation factor.
	 */
	function inverseLerp( x, y, value ) {

		// https://www.gamedev.net/tutorials/programming/general-and-gameplay-programming/inverse-lerp-a-super-useful-yet-often-overlooked-function-r5230/

		if ( x !== y ) {

			return ( value - x ) / ( y - x );

		} else {

			return 0;

		}

	}

	/**
	 * Returns a value linearly interpolated from two known points based on the given interval -
	 * `t = 0` will return `x` and `t = 1` will return `y`.
	 *
	 * @param {number} x - The start point
	 * @param {number} y - The end point.
	 * @param {number} t - The interpolation factor in the closed interval `[0, 1]`.
	 * @return {number} The interpolated value.
	 */
	function lerp( x, y, t ) {

		return ( 1 - t ) * x + t * y;

	}

	/**
	 * Smoothly interpolate a number from `x` to `y` in  a spring-like manner using a delta
	 * time to maintain frame rate independent movement. For details, see
	 * [Frame rate independent damping using lerp]{@link http://www.rorydriscoll.com/2016/03/07/frame-rate-independent-damping-using-lerp/}.
	 *
	 * @param {number} x - The current point.
	 * @param {number} y - The target point.
	 * @param {number} lambda - A higher lambda value will make the movement more sudden,
	 * and a lower value will make the movement more gradual.
	 * @param {number} dt - Delta time in seconds.
	 * @return {number} The interpolated value.
	 */
	function damp( x, y, lambda, dt ) {

		return lerp( x, y, 1 - Math.exp( - lambda * dt ) );

	}

	/**
	 * Returns a value that alternates between `0` and the given `length` parameter.
	 *
	 * @param {number} x - The value to pingpong.
	 * @param {number} [length=1] - The positive value the function will pingpong to.
	 * @return {number} The alternated value.
	 */
	function pingpong( x, length = 1 ) {

		// https://www.desmos.com/calculator/vcsjnyz7x4

		return length - Math.abs( euclideanModulo( x, length * 2 ) - length );

	}

	/**
	 * Returns a value in the range `[0,1]` that represents the percentage that `x` has
	 * moved between `min` and `max`, but smoothed or slowed down the closer `x` is to
	 * the `min` and `max`.
	 *
	 * See [Smoothstep]{@link http://en.wikipedia.org/wiki/Smoothstep} for more details.
	 *
	 * @param {number} x - The value to evaluate based on its position between min and max.
	 * @param {number} min - The min value. Any x value below min will be `0`.
	 * @param {number} max - The max value. Any x value above max will be `1`.
	 * @return {number} The alternated value.
	 */
	function smoothstep( x, min, max ) {

		if ( x <= min ) return 0;
		if ( x >= max ) return 1;

		x = ( x - min ) / ( max - min );

		return x * x * ( 3 - 2 * x );

	}

	/**
	 * A [variation on smoothstep]{@link https://en.wikipedia.org/wiki/Smoothstep#Variations}
	 * that has zero 1st and 2nd order derivatives at x=0 and x=1.
	 *
	 * @param {number} x - The value to evaluate based on its position between min and max.
	 * @param {number} min - The min value. Any x value below min will be `0`.
	 * @param {number} max - The max value. Any x value above max will be `1`.
	 * @return {number} The alternated value.
	 */
	function smootherstep( x, min, max ) {

		if ( x <= min ) return 0;
		if ( x >= max ) return 1;

		x = ( x - min ) / ( max - min );

		return x * x * x * ( x * ( x * 6 - 15 ) + 10 );

	}

	/**
	 * Returns a random integer from `<low, high>` interval.
	 *
	 * @param {number} low - The lower value boundary.
	 * @param {number} high - The upper value boundary
	 * @return {number} A random integer.
	 */
	function randInt( low, high ) {

		return low + Math.floor( Math.random() * ( high - low + 1 ) );

	}

	/**
	 * Returns a random float from `<low, high>` interval.
	 *
	 * @param {number} low - The lower value boundary.
	 * @param {number} high - The upper value boundary
	 * @return {number} A random float.
	 */
	function randFloat( low, high ) {

		return low + Math.random() * ( high - low );

	}

	/**
	 * Returns a random integer from `<-range/2, range/2>` interval.
	 *
	 * @param {number} range - Defines the value range.
	 * @return {number} A random float.
	 */
	function randFloatSpread( range ) {

		return range * ( 0.5 - Math.random() );

	}

	/**
	 * Returns a deterministic pseudo-random float in the interval `[0, 1]`.
	 *
	 * @param {number} [s] - The integer seed.
	 * @return {number} A random float.
	 */
	function seededRandom( s ) {

		if ( s !== undefined ) _seed = s;

		// Mulberry32 generator

		let t = _seed += 0x6D2B79F5;

		t = Math.imul( t ^ t >>> 15, t | 1 );

		t ^= t + Math.imul( t ^ t >>> 7, t | 61 );

		return ( ( t ^ t >>> 14 ) >>> 0 ) / 4294967296;

	}

	/**
	 * Converts degrees to radians.
	 *
	 * @param {number} degrees - A value in degrees.
	 * @return {number} The converted value in radians.
	 */
	function degToRad( degrees ) {

		return degrees * DEG2RAD;

	}

	/**
	 * Converts radians to degrees.
	 *
	 * @param {number} radians - A value in radians.
	 * @return {number} The converted value in degrees.
	 */
	function radToDeg( radians ) {

		return radians * RAD2DEG;

	}

	/**
	 * Returns `true` if the given number is a power of two.
	 *
	 * @param {number} value - The value to check.
	 * @return {boolean} Whether the given number is a power of two or not.
	 */
	function isPowerOfTwo( value ) {

		return ( value & ( value - 1 ) ) === 0 && value !== 0;

	}

	/**
	 * Returns the smallest power of two that is greater than or equal to the given number.
	 *
	 * @param {number} value - The value to find a POT for.
	 * @return {number} The smallest power of two that is greater than or equal to the given number.
	 */
	function ceilPowerOfTwo( value ) {

		return Math.pow( 2, Math.ceil( Math.log( value ) / Math.LN2 ) );

	}

	/**
	 * Returns the largest power of two that is less than or equal to the given number.
	 *
	 * @param {number} value - The value to find a POT for.
	 * @return {number} The largest power of two that is less than or equal to the given number.
	 */
	function floorPowerOfTwo( value ) {

		return Math.pow( 2, Math.floor( Math.log( value ) / Math.LN2 ) );

	}

	/**
	 * Sets the given quaternion from the [Intrinsic Proper Euler Angles]{@link https://en.wikipedia.org/wiki/Euler_angles}
	 * defined by the given angles and order.
	 *
	 * Rotations are applied to the axes in the order specified by order:
	 * rotation by angle `a` is applied first, then by angle `b`, then by angle `c`.
	 *
	 * @param {Quaternion} q - The quaternion to set.
	 * @param {number} a - The rotation applied to the first axis, in radians.
	 * @param {number} b - The rotation applied to the second axis, in radians.
	 * @param {number} c - The rotation applied to the third axis, in radians.
	 * @param {('XYX'|'XZX'|'YXY'|'YZY'|'ZXZ'|'ZYZ')} order - A string specifying the axes order.
	 */
	function setQuaternionFromProperEuler( q, a, b, c, order ) {

		const cos = Math.cos;
		const sin = Math.sin;

		const c2 = cos( b / 2 );
		const s2 = sin( b / 2 );

		const c13 = cos( ( a + c ) / 2 );
		const s13 = sin( ( a + c ) / 2 );

		const c1_3 = cos( ( a - c ) / 2 );
		const s1_3 = sin( ( a - c ) / 2 );

		const c3_1 = cos( ( c - a ) / 2 );
		const s3_1 = sin( ( c - a ) / 2 );

		switch ( order ) {

			case 'XYX':
				q.set( c2 * s13, s2 * c1_3, s2 * s1_3, c2 * c13 );
				break;

			case 'YZY':
				q.set( s2 * s1_3, c2 * s13, s2 * c1_3, c2 * c13 );
				break;

			case 'ZXZ':
				q.set( s2 * c1_3, s2 * s1_3, c2 * s13, c2 * c13 );
				break;

			case 'XZX':
				q.set( c2 * s13, s2 * s3_1, s2 * c3_1, c2 * c13 );
				break;

			case 'YXY':
				q.set( s2 * c3_1, c2 * s13, s2 * s3_1, c2 * c13 );
				break;

			case 'ZYZ':
				q.set( s2 * s3_1, s2 * c3_1, c2 * s13, c2 * c13 );
				break;

			default:
				console.warn( 'THREE.MathUtils: .setQuaternionFromProperEuler() encountered an unknown order: ' + order );

		}

	}

	/**
	 * Denormalizes the given value according to the given typed array.
	 *
	 * @param {number} value - The value to denormalize.
	 * @param {TypedArray} array - The typed array that defines the data type of the value.
	 * @return {number} The denormalize (float) value in the range `[0,1]`.
	 */
	function denormalize( value, array ) {

		switch ( array.constructor ) {

			case Float32Array:

				return value;

			case Uint32Array:

				return value / 4294967295.0;

			case Uint16Array:

				return value / 65535.0;

			case Uint8Array:

				return value / 255.0;

			case Int32Array:

				return Math.max( value / 2147483647.0, -1 );

			case Int16Array:

				return Math.max( value / 32767.0, -1 );

			case Int8Array:

				return Math.max( value / 127.0, -1 );

			default:

				throw new Error( 'Invalid component type.' );

		}

	}

	/**
	 * Normalizes the given value according to the given typed array.
	 *
	 * @param {number} value - The float value in the range `[0,1]` to normalize.
	 * @param {TypedArray} array - The typed array that defines the data type of the value.
	 * @return {number} The normalize value.
	 */
	function normalize( value, array ) {

		switch ( array.constructor ) {

			case Float32Array:

				return value;

			case Uint32Array:

				return Math.round( value * 4294967295.0 );

			case Uint16Array:

				return Math.round( value * 65535.0 );

			case Uint8Array:

				return Math.round( value * 255.0 );

			case Int32Array:

				return Math.round( value * 2147483647.0 );

			case Int16Array:

				return Math.round( value * 32767.0 );

			case Int8Array:

				return Math.round( value * 127.0 );

			default:

				throw new Error( 'Invalid component type.' );

		}

	}

	/**
	 * @class
	 * @classdesc A collection of math utility functions.
	 * @hideconstructor
	 */
	const MathUtils = {
		DEG2RAD: DEG2RAD,
		RAD2DEG: RAD2DEG,
		/**
		 * Generate a [UUID]{@link https://en.wikipedia.org/wiki/Universally_unique_identifier}
		 * (universally unique identifier).
		 *
		 * @static
		 * @method
		 * @return {string} The UUID.
		 */
		generateUUID: generateUUID,
		/**
		 * Clamps the given value between min and max.
		 *
		 * @static
		 * @method
		 * @param {number} value - The value to clamp.
		 * @param {number} min - The min value.
		 * @param {number} max - The max value.
		 * @return {number} The clamped value.
		 */
		clamp: clamp,
		/**
		 * Computes the Euclidean modulo of the given parameters that
		 * is `( ( n % m ) + m ) % m`.
		 *
		 * @static
		 * @method
		 * @param {number} n - The first parameter.
		 * @param {number} m - The second parameter.
		 * @return {number} The Euclidean modulo.
		 */
		euclideanModulo: euclideanModulo,
		/**
		 * Performs a linear mapping from range `<a1, a2>` to range `<b1, b2>`
		 * for the given value.
		 *
		 * @static
		 * @method
		 * @param {number} x - The value to be mapped.
		 * @param {number} a1 - Minimum value for range A.
		 * @param {number} a2 - Maximum value for range A.
		 * @param {number} b1 - Minimum value for range B.
		 * @param {number} b2 - Maximum value for range B.
		 * @return {number} The mapped value.
		 */
		mapLinear: mapLinear,
		/**
		 * Returns the percentage in the closed interval `[0, 1]` of the given value
		 * between the start and end point.
		 *
		 * @static
		 * @method
		 * @param {number} x - The start point
		 * @param {number} y - The end point.
		 * @param {number} value - A value between start and end.
		 * @return {number} The interpolation factor.
		 */
		inverseLerp: inverseLerp,
		/**
		 * Returns a value linearly interpolated from two known points based on the given interval -
		 * `t = 0` will return `x` and `t = 1` will return `y`.
		 *
		 * @static
		 * @method
		 * @param {number} x - The start point
		 * @param {number} y - The end point.
		 * @param {number} t - The interpolation factor in the closed interval `[0, 1]`.
		 * @return {number} The interpolated value.
		 */
		lerp: lerp,
		/**
		 * Smoothly interpolate a number from `x` to `y` in  a spring-like manner using a delta
		 * time to maintain frame rate independent movement. For details, see
		 * [Frame rate independent damping using lerp]{@link http://www.rorydriscoll.com/2016/03/07/frame-rate-independent-damping-using-lerp/}.
		 *
		 * @static
		 * @method
		 * @param {number} x - The current point.
		 * @param {number} y - The target point.
		 * @param {number} lambda - A higher lambda value will make the movement more sudden,
		 * and a lower value will make the movement more gradual.
		 * @param {number} dt - Delta time in seconds.
		 * @return {number} The interpolated value.
		 */
		damp: damp,
		/**
		 * Returns a value that alternates between `0` and the given `length` parameter.
		 *
		 * @static
		 * @method
		 * @param {number} x - The value to pingpong.
		 * @param {number} [length=1] - The positive value the function will pingpong to.
		 * @return {number} The alternated value.
		 */
		pingpong: pingpong,
		/**
		 * Returns a value in the range `[0,1]` that represents the percentage that `x` has
		 * moved between `min` and `max`, but smoothed or slowed down the closer `x` is to
		 * the `min` and `max`.
		 *
		 * See [Smoothstep]{@link http://en.wikipedia.org/wiki/Smoothstep} for more details.
		 *
		 * @static
		 * @method
		 * @param {number} x - The value to evaluate based on its position between min and max.
		 * @param {number} min - The min value. Any x value below min will be `0`.
		 * @param {number} max - The max value. Any x value above max will be `1`.
		 * @return {number} The alternated value.
		 */
		smoothstep: smoothstep,
		/**
		 * A [variation on smoothstep]{@link https://en.wikipedia.org/wiki/Smoothstep#Variations}
		 * that has zero 1st and 2nd order derivatives at x=0 and x=1.
		 *
		 * @static
		 * @method
		 * @param {number} x - The value to evaluate based on its position between min and max.
		 * @param {number} min - The min value. Any x value below min will be `0`.
		 * @param {number} max - The max value. Any x value above max will be `1`.
		 * @return {number} The alternated value.
		 */
		smootherstep: smootherstep,
		/**
		 * Returns a random integer from `<low, high>` interval.
		 *
		 * @static
		 * @method
		 * @param {number} low - The lower value boundary.
		 * @param {number} high - The upper value boundary
		 * @return {number} A random integer.
		 */
		randInt: randInt,
		/**
		 * Returns a random float from `<low, high>` interval.
		 *
		 * @static
		 * @method
		 * @param {number} low - The lower value boundary.
		 * @param {number} high - The upper value boundary
		 * @return {number} A random float.
		 */
		randFloat: randFloat,
		/**
		 * Returns a random integer from `<-range/2, range/2>` interval.
		 *
		 * @static
		 * @method
		 * @param {number} range - Defines the value range.
		 * @return {number} A random float.
		 */
		randFloatSpread: randFloatSpread,
		/**
		 * Returns a deterministic pseudo-random float in the interval `[0, 1]`.
		 *
		 * @static
		 * @method
		 * @param {number} [s] - The integer seed.
		 * @return {number} A random float.
		 */
		seededRandom: seededRandom,
		/**
		 * Converts degrees to radians.
		 *
		 * @static
		 * @method
		 * @param {number} degrees - A value in degrees.
		 * @return {number} The converted value in radians.
		 */
		degToRad: degToRad,
		/**
		 * Converts radians to degrees.
		 *
		 * @static
		 * @method
		 * @param {number} radians - A value in radians.
		 * @return {number} The converted value in degrees.
		 */
		radToDeg: radToDeg,
		/**
		 * Returns `true` if the given number is a power of two.
		 *
		 * @static
		 * @method
		 * @param {number} value - The value to check.
		 * @return {boolean} Whether the given number is a power of two or not.
		 */
		isPowerOfTwo: isPowerOfTwo,
		/**
		 * Returns the smallest power of two that is greater than or equal to the given number.
		 *
		 * @static
		 * @method
		 * @param {number} value - The value to find a POT for.
		 * @return {number} The smallest power of two that is greater than or equal to the given number.
		 */
		ceilPowerOfTwo: ceilPowerOfTwo,
		/**
		 * Returns the largest power of two that is less than or equal to the given number.
		 *
		 * @static
		 * @method
		 * @param {number} value - The value to find a POT for.
		 * @return {number} The largest power of two that is less than or equal to the given number.
		 */
		floorPowerOfTwo: floorPowerOfTwo,
		/**
		 * Sets the given quaternion from the [Intrinsic Proper Euler Angles]{@link https://en.wikipedia.org/wiki/Euler_angles}
		 * defined by the given angles and order.
		 *
		 * Rotations are applied to the axes in the order specified by order:
		 * rotation by angle `a` is applied first, then by angle `b`, then by angle `c`.
		 *
		 * @static
		 * @method
		 * @param {Quaternion} q - The quaternion to set.
		 * @param {number} a - The rotation applied to the first axis, in radians.
		 * @param {number} b - The rotation applied to the second axis, in radians.
		 * @param {number} c - The rotation applied to the third axis, in radians.
		 * @param {('XYX'|'XZX'|'YXY'|'YZY'|'ZXZ'|'ZYZ')} order - A string specifying the axes order.
		 */
		setQuaternionFromProperEuler: setQuaternionFromProperEuler,
		/**
		 * Normalizes the given value according to the given typed array.
		 *
		 * @static
		 * @method
		 * @param {number} value - The float value in the range `[0,1]` to normalize.
		 * @param {TypedArray} array - The typed array that defines the data type of the value.
		 * @return {number} The normalize value.
		 */
		normalize: normalize,
		/**
		 * Denormalizes the given value according to the given typed array.
		 *
		 * @static
		 * @method
		 * @param {number} value - The value to denormalize.
		 * @param {TypedArray} array - The typed array that defines the data type of the value.
		 * @return {number} The denormalize (float) value in the range `[0,1]`.
		 */
		denormalize: denormalize
	};

	/**
	 * Class representing a 2D vector. A 2D vector is an ordered pair of numbers
	 * (labeled x and y), which can be used to represent a number of things, such as:
	 *
	 * - A point in 2D space (i.e. a position on a plane).
	 * - A direction and length across a plane. In three.js the length will
	 * always be the Euclidean distance(straight-line distance) from `(0, 0)` to `(x, y)`
	 * and the direction is also measured from `(0, 0)` towards `(x, y)`.
	 * - Any arbitrary ordered pair of numbers.
	 *
	 * There are other things a 2D vector can be used to represent, such as
	 * momentum vectors, complex numbers and so on, however these are the most
	 * common uses in three.js.
	 *
	 * Iterating through a vector instance will yield its components `(x, y)` in
	 * the corresponding order.
	 * ```js
	 * const a = new THREE.Vector2( 0, 1 );
	 *
	 * //no arguments; will be initialised to (0, 0)
	 * const b = new THREE.Vector2( );
	 *
	 * const d = a.distanceTo( b );
	 * ```
	 */
	class Vector2 {

		/**
		 * Constructs a new 2D vector.
		 *
		 * @param {number} [x=0] - The x value of this vector.
		 * @param {number} [y=0] - The y value of this vector.
		 */
		constructor( x = 0, y = 0 ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			Vector2.prototype.isVector2 = true;

			/**
			 * The x value of this vector.
			 *
			 * @type {number}
			 */
			this.x = x;

			/**
			 * The y value of this vector.
			 *
			 * @type {number}
			 */
			this.y = y;

		}

		/**
		 * Alias for {@link Vector2#x}.
		 *
		 * @type {number}
		 */
		get width() {

			return this.x;

		}

		set width( value ) {

			this.x = value;

		}

		/**
		 * Alias for {@link Vector2#y}.
		 *
		 * @type {number}
		 */
		get height() {

			return this.y;

		}

		set height( value ) {

			this.y = value;

		}

		/**
		 * Sets the vector components.
		 *
		 * @param {number} x - The value of the x component.
		 * @param {number} y - The value of the y component.
		 * @return {Vector2} A reference to this vector.
		 */
		set( x, y ) {

			this.x = x;
			this.y = y;

			return this;

		}

		/**
		 * Sets the vector components to the same value.
		 *
		 * @param {number} scalar - The value to set for all vector components.
		 * @return {Vector2} A reference to this vector.
		 */
		setScalar( scalar ) {

			this.x = scalar;
			this.y = scalar;

			return this;

		}

		/**
		 * Sets the vector's x component to the given value
		 *
		 * @param {number} x - The value to set.
		 * @return {Vector2} A reference to this vector.
		 */
		setX( x ) {

			this.x = x;

			return this;

		}

		/**
		 * Sets the vector's y component to the given value
		 *
		 * @param {number} y - The value to set.
		 * @return {Vector2} A reference to this vector.
		 */
		setY( y ) {

			this.y = y;

			return this;

		}

		/**
		 * Allows to set a vector component with an index.
		 *
		 * @param {number} index - The component index. `0` equals to x, `1` equals to y.
		 * @param {number} value - The value to set.
		 * @return {Vector2} A reference to this vector.
		 */
		setComponent( index, value ) {

			switch ( index ) {

				case 0: this.x = value; break;
				case 1: this.y = value; break;
				default: throw new Error( 'index is out of range: ' + index );

			}

			return this;

		}

		/**
		 * Returns the value of the vector component which matches the given index.
		 *
		 * @param {number} index - The component index. `0` equals to x, `1` equals to y.
		 * @return {number} A vector component value.
		 */
		getComponent( index ) {

			switch ( index ) {

				case 0: return this.x;
				case 1: return this.y;
				default: throw new Error( 'index is out of range: ' + index );

			}

		}

		/**
		 * Returns a new vector with copied values from this instance.
		 *
		 * @return {Vector2} A clone of this instance.
		 */
		clone() {

			return new this.constructor( this.x, this.y );

		}

		/**
		 * Copies the values of the given vector to this instance.
		 *
		 * @param {Vector2} v - The vector to copy.
		 * @return {Vector2} A reference to this vector.
		 */
		copy( v ) {

			this.x = v.x;
			this.y = v.y;

			return this;

		}

		/**
		 * Adds the given vector to this instance.
		 *
		 * @param {Vector2} v - The vector to add.
		 * @return {Vector2} A reference to this vector.
		 */
		add( v ) {

			this.x += v.x;
			this.y += v.y;

			return this;

		}

		/**
		 * Adds the given scalar value to all components of this instance.
		 *
		 * @param {number} s - The scalar to add.
		 * @return {Vector2} A reference to this vector.
		 */
		addScalar( s ) {

			this.x += s;
			this.y += s;

			return this;

		}

		/**
		 * Adds the given vectors and stores the result in this instance.
		 *
		 * @param {Vector2} a - The first vector.
		 * @param {Vector2} b - The second vector.
		 * @return {Vector2} A reference to this vector.
		 */
		addVectors( a, b ) {

			this.x = a.x + b.x;
			this.y = a.y + b.y;

			return this;

		}

		/**
		 * Adds the given vector scaled by the given factor to this instance.
		 *
		 * @param {Vector2} v - The vector.
		 * @param {number} s - The factor that scales `v`.
		 * @return {Vector2} A reference to this vector.
		 */
		addScaledVector( v, s ) {

			this.x += v.x * s;
			this.y += v.y * s;

			return this;

		}

		/**
		 * Subtracts the given vector from this instance.
		 *
		 * @param {Vector2} v - The vector to subtract.
		 * @return {Vector2} A reference to this vector.
		 */
		sub( v ) {

			this.x -= v.x;
			this.y -= v.y;

			return this;

		}

		/**
		 * Subtracts the given scalar value from all components of this instance.
		 *
		 * @param {number} s - The scalar to subtract.
		 * @return {Vector2} A reference to this vector.
		 */
		subScalar( s ) {

			this.x -= s;
			this.y -= s;

			return this;

		}

		/**
		 * Subtracts the given vectors and stores the result in this instance.
		 *
		 * @param {Vector2} a - The first vector.
		 * @param {Vector2} b - The second vector.
		 * @return {Vector2} A reference to this vector.
		 */
		subVectors( a, b ) {

			this.x = a.x - b.x;
			this.y = a.y - b.y;

			return this;

		}

		/**
		 * Multiplies the given vector with this instance.
		 *
		 * @param {Vector2} v - The vector to multiply.
		 * @return {Vector2} A reference to this vector.
		 */
		multiply( v ) {

			this.x *= v.x;
			this.y *= v.y;

			return this;

		}

		/**
		 * Multiplies the given scalar value with all components of this instance.
		 *
		 * @param {number} scalar - The scalar to multiply.
		 * @return {Vector2} A reference to this vector.
		 */
		multiplyScalar( scalar ) {

			this.x *= scalar;
			this.y *= scalar;

			return this;

		}

		/**
		 * Divides this instance by the given vector.
		 *
		 * @param {Vector2} v - The vector to divide.
		 * @return {Vector2} A reference to this vector.
		 */
		divide( v ) {

			this.x /= v.x;
			this.y /= v.y;

			return this;

		}

		/**
		 * Divides this vector by the given scalar.
		 *
		 * @param {number} scalar - The scalar to divide.
		 * @return {Vector2} A reference to this vector.
		 */
		divideScalar( scalar ) {

			return this.multiplyScalar( 1 / scalar );

		}

		/**
		 * Multiplies this vector (with an implicit 1 as the 3rd component) by
		 * the given 3x3 matrix.
		 *
		 * @param {Matrix3} m - The matrix to apply.
		 * @return {Vector2} A reference to this vector.
		 */
		applyMatrix3( m ) {

			const x = this.x, y = this.y;
			const e = m.elements;

			this.x = e[ 0 ] * x + e[ 3 ] * y + e[ 6 ];
			this.y = e[ 1 ] * x + e[ 4 ] * y + e[ 7 ];

			return this;

		}

		/**
		 * If this vector's x or y value is greater than the given vector's x or y
		 * value, replace that value with the corresponding min value.
		 *
		 * @param {Vector2} v - The vector.
		 * @return {Vector2} A reference to this vector.
		 */
		min( v ) {

			this.x = Math.min( this.x, v.x );
			this.y = Math.min( this.y, v.y );

			return this;

		}

		/**
		 * If this vector's x or y value is less than the given vector's x or y
		 * value, replace that value with the corresponding max value.
		 *
		 * @param {Vector2} v - The vector.
		 * @return {Vector2} A reference to this vector.
		 */
		max( v ) {

			this.x = Math.max( this.x, v.x );
			this.y = Math.max( this.y, v.y );

			return this;

		}

		/**
		 * If this vector's x or y value is greater than the max vector's x or y
		 * value, it is replaced by the corresponding value.
		 * If this vector's x or y value is less than the min vector's x or y value,
		 * it is replaced by the corresponding value.
		 *
		 * @param {Vector2} min - The minimum x and y values.
		 * @param {Vector2} max - The maximum x and y values in the desired range.
		 * @return {Vector2} A reference to this vector.
		 */
		clamp( min, max ) {

			// assumes min < max, componentwise

			this.x = clamp( this.x, min.x, max.x );
			this.y = clamp( this.y, min.y, max.y );

			return this;

		}

		/**
		 * If this vector's x or y values are greater than the max value, they are
		 * replaced by the max value.
		 * If this vector's x or y values are less than the min value, they are
		 * replaced by the min value.
		 *
		 * @param {number} minVal - The minimum value the components will be clamped to.
		 * @param {number} maxVal - The maximum value the components will be clamped to.
		 * @return {Vector2} A reference to this vector.
		 */
		clampScalar( minVal, maxVal ) {

			this.x = clamp( this.x, minVal, maxVal );
			this.y = clamp( this.y, minVal, maxVal );

			return this;

		}

		/**
		 * If this vector's length is greater than the max value, it is replaced by
		 * the max value.
		 * If this vector's length is less than the min value, it is replaced by the
		 * min value.
		 *
		 * @param {number} min - The minimum value the vector length will be clamped to.
		 * @param {number} max - The maximum value the vector length will be clamped to.
		 * @return {Vector2} A reference to this vector.
		 */
		clampLength( min, max ) {

			const length = this.length();

			return this.divideScalar( length || 1 ).multiplyScalar( clamp( length, min, max ) );

		}

		/**
		 * The components of this vector are rounded down to the nearest integer value.
		 *
		 * @return {Vector2} A reference to this vector.
		 */
		floor() {

			this.x = Math.floor( this.x );
			this.y = Math.floor( this.y );

			return this;

		}

		/**
		 * The components of this vector are rounded up to the nearest integer value.
		 *
		 * @return {Vector2} A reference to this vector.
		 */
		ceil() {

			this.x = Math.ceil( this.x );
			this.y = Math.ceil( this.y );

			return this;

		}

		/**
		 * The components of this vector are rounded to the nearest integer value
		 *
		 * @return {Vector2} A reference to this vector.
		 */
		round() {

			this.x = Math.round( this.x );
			this.y = Math.round( this.y );

			return this;

		}

		/**
		 * The components of this vector are rounded towards zero (up if negative,
		 * down if positive) to an integer value.
		 *
		 * @return {Vector2} A reference to this vector.
		 */
		roundToZero() {

			this.x = Math.trunc( this.x );
			this.y = Math.trunc( this.y );

			return this;

		}

		/**
		 * Inverts this vector - i.e. sets x = -x and y = -y.
		 *
		 * @return {Vector2} A reference to this vector.
		 */
		negate() {

			this.x = - this.x;
			this.y = - this.y;

			return this;

		}

		/**
		 * Calculates the dot product of the given vector with this instance.
		 *
		 * @param {Vector2} v - The vector to compute the dot product with.
		 * @return {number} The result of the dot product.
		 */
		dot( v ) {

			return this.x * v.x + this.y * v.y;

		}

		/**
		 * Calculates the cross product of the given vector with this instance.
		 *
		 * @param {Vector2} v - The vector to compute the cross product with.
		 * @return {number} The result of the cross product.
		 */
		cross( v ) {

			return this.x * v.y - this.y * v.x;

		}

		/**
		 * Computes the square of the Euclidean length (straight-line length) from
		 * (0, 0) to (x, y). If you are comparing the lengths of vectors, you should
		 * compare the length squared instead as it is slightly more efficient to calculate.
		 *
		 * @return {number} The square length of this vector.
		 */
		lengthSq() {

			return this.x * this.x + this.y * this.y;

		}

		/**
		 * Computes the  Euclidean length (straight-line length) from (0, 0) to (x, y).
		 *
		 * @return {number} The length of this vector.
		 */
		length() {

			return Math.sqrt( this.x * this.x + this.y * this.y );

		}

		/**
		 * Computes the Manhattan length of this vector.
		 *
		 * @return {number} The length of this vector.
		 */
		manhattanLength() {

			return Math.abs( this.x ) + Math.abs( this.y );

		}

		/**
		 * Converts this vector to a unit vector - that is, sets it equal to a vector
		 * with the same direction as this one, but with a vector length of `1`.
		 *
		 * @return {Vector2} A reference to this vector.
		 */
		normalize() {

			return this.divideScalar( this.length() || 1 );

		}

		/**
		 * Computes the angle in radians of this vector with respect to the positive x-axis.
		 *
		 * @return {number} The angle in radians.
		 */
		angle() {

			const angle = Math.atan2( - this.y, - this.x ) + Math.PI;

			return angle;

		}

		/**
		 * Returns the angle between the given vector and this instance in radians.
		 *
		 * @param {Vector2} v - The vector to compute the angle with.
		 * @return {number} The angle in radians.
		 */
		angleTo( v ) {

			const denominator = Math.sqrt( this.lengthSq() * v.lengthSq() );

			if ( denominator === 0 ) return Math.PI / 2;

			const theta = this.dot( v ) / denominator;

			// clamp, to handle numerical problems

			return Math.acos( clamp( theta, -1, 1 ) );

		}

		/**
		 * Computes the distance from the given vector to this instance.
		 *
		 * @param {Vector2} v - The vector to compute the distance to.
		 * @return {number} The distance.
		 */
		distanceTo( v ) {

			return Math.sqrt( this.distanceToSquared( v ) );

		}

		/**
		 * Computes the squared distance from the given vector to this instance.
		 * If you are just comparing the distance with another distance, you should compare
		 * the distance squared instead as it is slightly more efficient to calculate.
		 *
		 * @param {Vector2} v - The vector to compute the squared distance to.
		 * @return {number} The squared distance.
		 */
		distanceToSquared( v ) {

			const dx = this.x - v.x, dy = this.y - v.y;
			return dx * dx + dy * dy;

		}

		/**
		 * Computes the Manhattan distance from the given vector to this instance.
		 *
		 * @param {Vector2} v - The vector to compute the Manhattan distance to.
		 * @return {number} The Manhattan distance.
		 */
		manhattanDistanceTo( v ) {

			return Math.abs( this.x - v.x ) + Math.abs( this.y - v.y );

		}

		/**
		 * Sets this vector to a vector with the same direction as this one, but
		 * with the specified length.
		 *
		 * @param {number} length - The new length of this vector.
		 * @return {Vector2} A reference to this vector.
		 */
		setLength( length ) {

			return this.normalize().multiplyScalar( length );

		}

		/**
		 * Linearly interpolates between the given vector and this instance, where
		 * alpha is the percent distance along the line - alpha = 0 will be this
		 * vector, and alpha = 1 will be the given one.
		 *
		 * @param {Vector2} v - The vector to interpolate towards.
		 * @param {number} alpha - The interpolation factor, typically in the closed interval `[0, 1]`.
		 * @return {Vector2} A reference to this vector.
		 */
		lerp( v, alpha ) {

			this.x += ( v.x - this.x ) * alpha;
			this.y += ( v.y - this.y ) * alpha;

			return this;

		}

		/**
		 * Linearly interpolates between the given vectors, where alpha is the percent
		 * distance along the line - alpha = 0 will be first vector, and alpha = 1 will
		 * be the second one. The result is stored in this instance.
		 *
		 * @param {Vector2} v1 - The first vector.
		 * @param {Vector2} v2 - The second vector.
		 * @param {number} alpha - The interpolation factor, typically in the closed interval `[0, 1]`.
		 * @return {Vector2} A reference to this vector.
		 */
		lerpVectors( v1, v2, alpha ) {

			this.x = v1.x + ( v2.x - v1.x ) * alpha;
			this.y = v1.y + ( v2.y - v1.y ) * alpha;

			return this;

		}

		/**
		 * Returns `true` if this vector is equal with the given one.
		 *
		 * @param {Vector2} v - The vector to test for equality.
		 * @return {boolean} Whether this vector is equal with the given one.
		 */
		equals( v ) {

			return ( ( v.x === this.x ) && ( v.y === this.y ) );

		}

		/**
		 * Sets this vector's x value to be `array[ offset ]` and y
		 * value to be `array[ offset + 1 ]`.
		 *
		 * @param {Array<number>} array - An array holding the vector component values.
		 * @param {number} [offset=0] - The offset into the array.
		 * @return {Vector2} A reference to this vector.
		 */
		fromArray( array, offset = 0 ) {

			this.x = array[ offset ];
			this.y = array[ offset + 1 ];

			return this;

		}

		/**
		 * Writes the components of this vector to the given array. If no array is provided,
		 * the method returns a new instance.
		 *
		 * @param {Array<number>} [array=[]] - The target array holding the vector components.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Array<number>} The vector components.
		 */
		toArray( array = [], offset = 0 ) {

			array[ offset ] = this.x;
			array[ offset + 1 ] = this.y;

			return array;

		}

		/**
		 * Sets the components of this vector from the given buffer attribute.
		 *
		 * @param {BufferAttribute} attribute - The buffer attribute holding vector data.
		 * @param {number} index - The index into the attribute.
		 * @return {Vector2} A reference to this vector.
		 */
		fromBufferAttribute( attribute, index ) {

			this.x = attribute.getX( index );
			this.y = attribute.getY( index );

			return this;

		}

		/**
		 * Rotates this vector around the given center by the given angle.
		 *
		 * @param {Vector2} center - The point around which to rotate.
		 * @param {number} angle - The angle to rotate, in radians.
		 * @return {Vector2} A reference to this vector.
		 */
		rotateAround( center, angle ) {

			const c = Math.cos( angle ), s = Math.sin( angle );

			const x = this.x - center.x;
			const y = this.y - center.y;

			this.x = x * c - y * s + center.x;
			this.y = x * s + y * c + center.y;

			return this;

		}

		/**
		 * Sets each component of this vector to a pseudo-random value between `0` and
		 * `1`, excluding `1`.
		 *
		 * @return {Vector2} A reference to this vector.
		 */
		random() {

			this.x = Math.random();
			this.y = Math.random();

			return this;

		}

		*[ Symbol.iterator ]() {

			yield this.x;
			yield this.y;

		}

	}

	/**
	 * Class for representing a Quaternion. Quaternions are used in three.js to represent rotations.
	 *
	 * Iterating through a vector instance will yield its components `(x, y, z, w)` in
	 * the corresponding order.
	 *
	 * Note that three.js expects Quaternions to be normalized.
	 * ```js
	 * const quaternion = new THREE.Quaternion();
	 * quaternion.setFromAxisAngle( new THREE.Vector3( 0, 1, 0 ), Math.PI / 2 );
	 *
	 * const vector = new THREE.Vector3( 1, 0, 0 );
	 * vector.applyQuaternion( quaternion );
	 * ```
	 */
	class Quaternion {

		/**
		 * Constructs a new quaternion.
		 *
		 * @param {number} [x=0] - The x value of this quaternion.
		 * @param {number} [y=0] - The y value of this quaternion.
		 * @param {number} [z=0] - The z value of this quaternion.
		 * @param {number} [w=1] - The w value of this quaternion.
		 */
		constructor( x = 0, y = 0, z = 0, w = 1 ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isQuaternion = true;

			this._x = x;
			this._y = y;
			this._z = z;
			this._w = w;

		}

		/**
		 * Interpolates between two quaternions via SLERP. This implementation assumes the
		 * quaternion data are managed  in flat arrays.
		 *
		 * @param {Array<number>} dst - The destination array.
		 * @param {number} dstOffset - An offset into the destination array.
		 * @param {Array<number>} src0 - The source array of the first quaternion.
		 * @param {number} srcOffset0 - An offset into the first source array.
		 * @param {Array<number>} src1 -  The source array of the second quaternion.
		 * @param {number} srcOffset1 - An offset into the second source array.
		 * @param {number} t - The interpolation factor in the range `[0,1]`.
		 * @see {@link Quaternion#slerp}
		 */
		static slerpFlat( dst, dstOffset, src0, srcOffset0, src1, srcOffset1, t ) {

			// fuzz-free, array-based Quaternion SLERP operation

			let x0 = src0[ srcOffset0 + 0 ],
				y0 = src0[ srcOffset0 + 1 ],
				z0 = src0[ srcOffset0 + 2 ],
				w0 = src0[ srcOffset0 + 3 ];

			const x1 = src1[ srcOffset1 + 0 ],
				y1 = src1[ srcOffset1 + 1 ],
				z1 = src1[ srcOffset1 + 2 ],
				w1 = src1[ srcOffset1 + 3 ];

			if ( t === 0 ) {

				dst[ dstOffset + 0 ] = x0;
				dst[ dstOffset + 1 ] = y0;
				dst[ dstOffset + 2 ] = z0;
				dst[ dstOffset + 3 ] = w0;
				return;

			}

			if ( t === 1 ) {

				dst[ dstOffset + 0 ] = x1;
				dst[ dstOffset + 1 ] = y1;
				dst[ dstOffset + 2 ] = z1;
				dst[ dstOffset + 3 ] = w1;
				return;

			}

			if ( w0 !== w1 || x0 !== x1 || y0 !== y1 || z0 !== z1 ) {

				let s = 1 - t;
				const cos = x0 * x1 + y0 * y1 + z0 * z1 + w0 * w1,
					dir = ( cos >= 0 ? 1 : -1 ),
					sqrSin = 1 - cos * cos;

				// Skip the Slerp for tiny steps to avoid numeric problems:
				if ( sqrSin > Number.EPSILON ) {

					const sin = Math.sqrt( sqrSin ),
						len = Math.atan2( sin, cos * dir );

					s = Math.sin( s * len ) / sin;
					t = Math.sin( t * len ) / sin;

				}

				const tDir = t * dir;

				x0 = x0 * s + x1 * tDir;
				y0 = y0 * s + y1 * tDir;
				z0 = z0 * s + z1 * tDir;
				w0 = w0 * s + w1 * tDir;

				// Normalize in case we just did a lerp:
				if ( s === 1 - t ) {

					const f = 1 / Math.sqrt( x0 * x0 + y0 * y0 + z0 * z0 + w0 * w0 );

					x0 *= f;
					y0 *= f;
					z0 *= f;
					w0 *= f;

				}

			}

			dst[ dstOffset ] = x0;
			dst[ dstOffset + 1 ] = y0;
			dst[ dstOffset + 2 ] = z0;
			dst[ dstOffset + 3 ] = w0;

		}

		/**
		 * Multiplies two quaternions. This implementation assumes the quaternion data are managed
		 * in flat arrays.
		 *
		 * @param {Array<number>} dst - The destination array.
		 * @param {number} dstOffset - An offset into the destination array.
		 * @param {Array<number>} src0 - The source array of the first quaternion.
		 * @param {number} srcOffset0 - An offset into the first source array.
		 * @param {Array<number>} src1 -  The source array of the second quaternion.
		 * @param {number} srcOffset1 - An offset into the second source array.
		 * @return {Array<number>} The destination array.
		 * @see {@link Quaternion#multiplyQuaternions}.
		 */
		static multiplyQuaternionsFlat( dst, dstOffset, src0, srcOffset0, src1, srcOffset1 ) {

			const x0 = src0[ srcOffset0 ];
			const y0 = src0[ srcOffset0 + 1 ];
			const z0 = src0[ srcOffset0 + 2 ];
			const w0 = src0[ srcOffset0 + 3 ];

			const x1 = src1[ srcOffset1 ];
			const y1 = src1[ srcOffset1 + 1 ];
			const z1 = src1[ srcOffset1 + 2 ];
			const w1 = src1[ srcOffset1 + 3 ];

			dst[ dstOffset ] = x0 * w1 + w0 * x1 + y0 * z1 - z0 * y1;
			dst[ dstOffset + 1 ] = y0 * w1 + w0 * y1 + z0 * x1 - x0 * z1;
			dst[ dstOffset + 2 ] = z0 * w1 + w0 * z1 + x0 * y1 - y0 * x1;
			dst[ dstOffset + 3 ] = w0 * w1 - x0 * x1 - y0 * y1 - z0 * z1;

			return dst;

		}

		/**
		 * The x value of this quaternion.
		 *
		 * @type {number}
		 * @default 0
		 */
		get x() {

			return this._x;

		}

		set x( value ) {

			this._x = value;
			this._onChangeCallback();

		}

		/**
		 * The y value of this quaternion.
		 *
		 * @type {number}
		 * @default 0
		 */
		get y() {

			return this._y;

		}

		set y( value ) {

			this._y = value;
			this._onChangeCallback();

		}

		/**
		 * The z value of this quaternion.
		 *
		 * @type {number}
		 * @default 0
		 */
		get z() {

			return this._z;

		}

		set z( value ) {

			this._z = value;
			this._onChangeCallback();

		}

		/**
		 * The w value of this quaternion.
		 *
		 * @type {number}
		 * @default 1
		 */
		get w() {

			return this._w;

		}

		set w( value ) {

			this._w = value;
			this._onChangeCallback();

		}

		/**
		 * Sets the quaternion components.
		 *
		 * @param {number} x - The x value of this quaternion.
		 * @param {number} y - The y value of this quaternion.
		 * @param {number} z - The z value of this quaternion.
		 * @param {number} w - The w value of this quaternion.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		set( x, y, z, w ) {

			this._x = x;
			this._y = y;
			this._z = z;
			this._w = w;

			this._onChangeCallback();

			return this;

		}

		/**
		 * Returns a new quaternion with copied values from this instance.
		 *
		 * @return {Quaternion} A clone of this instance.
		 */
		clone() {

			return new this.constructor( this._x, this._y, this._z, this._w );

		}

		/**
		 * Copies the values of the given quaternion to this instance.
		 *
		 * @param {Quaternion} quaternion - The quaternion to copy.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		copy( quaternion ) {

			this._x = quaternion.x;
			this._y = quaternion.y;
			this._z = quaternion.z;
			this._w = quaternion.w;

			this._onChangeCallback();

			return this;

		}

		/**
		 * Sets this quaternion from the rotation specified by the given
		 * Euler angles.
		 *
		 * @param {Euler} euler - The Euler angles.
		 * @param {boolean} [update=true] - Whether the internal `onChange` callback should be executed or not.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		setFromEuler( euler, update = true ) {

			const x = euler._x, y = euler._y, z = euler._z, order = euler._order;

			// http://www.mathworks.com/matlabcentral/fileexchange/
			// 	20696-function-to-convert-between-dcm-euler-angles-quaternions-and-euler-vectors/
			//	content/SpinCalc.m

			const cos = Math.cos;
			const sin = Math.sin;

			const c1 = cos( x / 2 );
			const c2 = cos( y / 2 );
			const c3 = cos( z / 2 );

			const s1 = sin( x / 2 );
			const s2 = sin( y / 2 );
			const s3 = sin( z / 2 );

			switch ( order ) {

				case 'XYZ':
					this._x = s1 * c2 * c3 + c1 * s2 * s3;
					this._y = c1 * s2 * c3 - s1 * c2 * s3;
					this._z = c1 * c2 * s3 + s1 * s2 * c3;
					this._w = c1 * c2 * c3 - s1 * s2 * s3;
					break;

				case 'YXZ':
					this._x = s1 * c2 * c3 + c1 * s2 * s3;
					this._y = c1 * s2 * c3 - s1 * c2 * s3;
					this._z = c1 * c2 * s3 - s1 * s2 * c3;
					this._w = c1 * c2 * c3 + s1 * s2 * s3;
					break;

				case 'ZXY':
					this._x = s1 * c2 * c3 - c1 * s2 * s3;
					this._y = c1 * s2 * c3 + s1 * c2 * s3;
					this._z = c1 * c2 * s3 + s1 * s2 * c3;
					this._w = c1 * c2 * c3 - s1 * s2 * s3;
					break;

				case 'ZYX':
					this._x = s1 * c2 * c3 - c1 * s2 * s3;
					this._y = c1 * s2 * c3 + s1 * c2 * s3;
					this._z = c1 * c2 * s3 - s1 * s2 * c3;
					this._w = c1 * c2 * c3 + s1 * s2 * s3;
					break;

				case 'YZX':
					this._x = s1 * c2 * c3 + c1 * s2 * s3;
					this._y = c1 * s2 * c3 + s1 * c2 * s3;
					this._z = c1 * c2 * s3 - s1 * s2 * c3;
					this._w = c1 * c2 * c3 - s1 * s2 * s3;
					break;

				case 'XZY':
					this._x = s1 * c2 * c3 - c1 * s2 * s3;
					this._y = c1 * s2 * c3 - s1 * c2 * s3;
					this._z = c1 * c2 * s3 + s1 * s2 * c3;
					this._w = c1 * c2 * c3 + s1 * s2 * s3;
					break;

				default:
					console.warn( 'THREE.Quaternion: .setFromEuler() encountered an unknown order: ' + order );

			}

			if ( update === true ) this._onChangeCallback();

			return this;

		}

		/**
		 * Sets this quaternion from the given axis and angle.
		 *
		 * @param {Vector3} axis - The normalized axis.
		 * @param {number} angle - The angle in radians.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		setFromAxisAngle( axis, angle ) {

			// http://www.euclideanspace.com/maths/geometry/rotations/conversions/angleToQuaternion/index.htm

			const halfAngle = angle / 2, s = Math.sin( halfAngle );

			this._x = axis.x * s;
			this._y = axis.y * s;
			this._z = axis.z * s;
			this._w = Math.cos( halfAngle );

			this._onChangeCallback();

			return this;

		}

		/**
		 * Sets this quaternion from the given rotation matrix.
		 *
		 * @param {Matrix4} m - A 4x4 matrix of which the upper 3x3 of matrix is a pure rotation matrix (i.e. unscaled).
		 * @return {Quaternion} A reference to this quaternion.
		 */
		setFromRotationMatrix( m ) {

			// http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/index.htm

			// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)

			const te = m.elements,

				m11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ],
				m21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ],
				m31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ],

				trace = m11 + m22 + m33;

			if ( trace > 0 ) {

				const s = 0.5 / Math.sqrt( trace + 1.0 );

				this._w = 0.25 / s;
				this._x = ( m32 - m23 ) * s;
				this._y = ( m13 - m31 ) * s;
				this._z = ( m21 - m12 ) * s;

			} else if ( m11 > m22 && m11 > m33 ) {

				const s = 2.0 * Math.sqrt( 1.0 + m11 - m22 - m33 );

				this._w = ( m32 - m23 ) / s;
				this._x = 0.25 * s;
				this._y = ( m12 + m21 ) / s;
				this._z = ( m13 + m31 ) / s;

			} else if ( m22 > m33 ) {

				const s = 2.0 * Math.sqrt( 1.0 + m22 - m11 - m33 );

				this._w = ( m13 - m31 ) / s;
				this._x = ( m12 + m21 ) / s;
				this._y = 0.25 * s;
				this._z = ( m23 + m32 ) / s;

			} else {

				const s = 2.0 * Math.sqrt( 1.0 + m33 - m11 - m22 );

				this._w = ( m21 - m12 ) / s;
				this._x = ( m13 + m31 ) / s;
				this._y = ( m23 + m32 ) / s;
				this._z = 0.25 * s;

			}

			this._onChangeCallback();

			return this;

		}

		/**
		 * Sets this quaternion to the rotation required to rotate the direction vector
		 * `vFrom` to the direction vector `vTo`.
		 *
		 * @param {Vector3} vFrom - The first (normalized) direction vector.
		 * @param {Vector3} vTo - The second (normalized) direction vector.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		setFromUnitVectors( vFrom, vTo ) {

			// assumes direction vectors vFrom and vTo are normalized

			let r = vFrom.dot( vTo ) + 1;

			if ( r < Number.EPSILON ) {

				// vFrom and vTo point in opposite directions

				r = 0;

				if ( Math.abs( vFrom.x ) > Math.abs( vFrom.z ) ) {

					this._x = - vFrom.y;
					this._y = vFrom.x;
					this._z = 0;
					this._w = r;

				} else {

					this._x = 0;
					this._y = - vFrom.z;
					this._z = vFrom.y;
					this._w = r;

				}

			} else {

				// crossVectors( vFrom, vTo ); // inlined to avoid cyclic dependency on Vector3

				this._x = vFrom.y * vTo.z - vFrom.z * vTo.y;
				this._y = vFrom.z * vTo.x - vFrom.x * vTo.z;
				this._z = vFrom.x * vTo.y - vFrom.y * vTo.x;
				this._w = r;

			}

			return this.normalize();

		}

		/**
		 * Returns the angle between this quaternion and the given one in radians.
		 *
		 * @param {Quaternion} q - The quaternion to compute the angle with.
		 * @return {number} The angle in radians.
		 */
		angleTo( q ) {

			return 2 * Math.acos( Math.abs( clamp( this.dot( q ), -1, 1 ) ) );

		}

		/**
		 * Rotates this quaternion by a given angular step to the given quaternion.
		 * The method ensures that the final quaternion will not overshoot `q`.
		 *
		 * @param {Quaternion} q - The target quaternion.
		 * @param {number} step - The angular step in radians.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		rotateTowards( q, step ) {

			const angle = this.angleTo( q );

			if ( angle === 0 ) return this;

			const t = Math.min( 1, step / angle );

			this.slerp( q, t );

			return this;

		}

		/**
		 * Sets this quaternion to the identity quaternion; that is, to the
		 * quaternion that represents "no rotation".
		 *
		 * @return {Quaternion} A reference to this quaternion.
		 */
		identity() {

			return this.set( 0, 0, 0, 1 );

		}

		/**
		 * Inverts this quaternion via {@link Quaternion#conjugate}. The
		 * quaternion is assumed to have unit length.
		 *
		 * @return {Quaternion} A reference to this quaternion.
		 */
		invert() {

			return this.conjugate();

		}

		/**
		 * Returns the rotational conjugate of this quaternion. The conjugate of a
		 * quaternion represents the same rotation in the opposite direction about
		 * the rotational axis.
		 *
		 * @return {Quaternion} A reference to this quaternion.
		 */
		conjugate() {

			this._x *= -1;
			this._y *= -1;
			this._z *= -1;

			this._onChangeCallback();

			return this;

		}

		/**
		 * Calculates the dot product of this quaternion and the given one.
		 *
		 * @param {Quaternion} v - The quaternion to compute the dot product with.
		 * @return {number} The result of the dot product.
		 */
		dot( v ) {

			return this._x * v._x + this._y * v._y + this._z * v._z + this._w * v._w;

		}

		/**
		 * Computes the squared Euclidean length (straight-line length) of this quaternion,
		 * considered as a 4 dimensional vector. This can be useful if you are comparing the
		 * lengths of two quaternions, as this is a slightly more efficient calculation than
		 * {@link Quaternion#length}.
		 *
		 * @return {number} The squared Euclidean length.
		 */
		lengthSq() {

			return this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w;

		}

		/**
		 * Computes the Euclidean length (straight-line length) of this quaternion,
		 * considered as a 4 dimensional vector.
		 *
		 * @return {number} The Euclidean length.
		 */
		length() {

			return Math.sqrt( this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w );

		}

		/**
		 * Normalizes this quaternion - that is, calculated the quaternion that performs
		 * the same rotation as this one, but has a length equal to `1`.
		 *
		 * @return {Quaternion} A reference to this quaternion.
		 */
		normalize() {

			let l = this.length();

			if ( l === 0 ) {

				this._x = 0;
				this._y = 0;
				this._z = 0;
				this._w = 1;

			} else {

				l = 1 / l;

				this._x = this._x * l;
				this._y = this._y * l;
				this._z = this._z * l;
				this._w = this._w * l;

			}

			this._onChangeCallback();

			return this;

		}

		/**
		 * Multiplies this quaternion by the given one.
		 *
		 * @param {Quaternion} q - The quaternion.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		multiply( q ) {

			return this.multiplyQuaternions( this, q );

		}

		/**
		 * Pre-multiplies this quaternion by the given one.
		 *
		 * @param {Quaternion} q - The quaternion.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		premultiply( q ) {

			return this.multiplyQuaternions( q, this );

		}

		/**
		 * Multiplies the given quaternions and stores the result in this instance.
		 *
		 * @param {Quaternion} a - The first quaternion.
		 * @param {Quaternion} b - The second quaternion.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		multiplyQuaternions( a, b ) {

			// from http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/code/index.htm

			const qax = a._x, qay = a._y, qaz = a._z, qaw = a._w;
			const qbx = b._x, qby = b._y, qbz = b._z, qbw = b._w;

			this._x = qax * qbw + qaw * qbx + qay * qbz - qaz * qby;
			this._y = qay * qbw + qaw * qby + qaz * qbx - qax * qbz;
			this._z = qaz * qbw + qaw * qbz + qax * qby - qay * qbx;
			this._w = qaw * qbw - qax * qbx - qay * qby - qaz * qbz;

			this._onChangeCallback();

			return this;

		}

		/**
		 * Performs a spherical linear interpolation between quaternions.
		 *
		 * @param {Quaternion} qb - The target quaternion.
		 * @param {number} t - The interpolation factor in the closed interval `[0, 1]`.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		slerp( qb, t ) {

			if ( t === 0 ) return this;
			if ( t === 1 ) return this.copy( qb );

			const x = this._x, y = this._y, z = this._z, w = this._w;

			// http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/slerp/

			let cosHalfTheta = w * qb._w + x * qb._x + y * qb._y + z * qb._z;

			if ( cosHalfTheta < 0 ) {

				this._w = - qb._w;
				this._x = - qb._x;
				this._y = - qb._y;
				this._z = - qb._z;

				cosHalfTheta = - cosHalfTheta;

			} else {

				this.copy( qb );

			}

			if ( cosHalfTheta >= 1.0 ) {

				this._w = w;
				this._x = x;
				this._y = y;
				this._z = z;

				return this;

			}

			const sqrSinHalfTheta = 1.0 - cosHalfTheta * cosHalfTheta;

			if ( sqrSinHalfTheta <= Number.EPSILON ) {

				const s = 1 - t;
				this._w = s * w + t * this._w;
				this._x = s * x + t * this._x;
				this._y = s * y + t * this._y;
				this._z = s * z + t * this._z;

				this.normalize(); // normalize calls _onChangeCallback()

				return this;

			}

			const sinHalfTheta = Math.sqrt( sqrSinHalfTheta );
			const halfTheta = Math.atan2( sinHalfTheta, cosHalfTheta );
			const ratioA = Math.sin( ( 1 - t ) * halfTheta ) / sinHalfTheta,
				ratioB = Math.sin( t * halfTheta ) / sinHalfTheta;

			this._w = ( w * ratioA + this._w * ratioB );
			this._x = ( x * ratioA + this._x * ratioB );
			this._y = ( y * ratioA + this._y * ratioB );
			this._z = ( z * ratioA + this._z * ratioB );

			this._onChangeCallback();

			return this;

		}

		/**
		 * Performs a spherical linear interpolation between the given quaternions
		 * and stores the result in this quaternion.
		 *
		 * @param {Quaternion} qa - The source quaternion.
		 * @param {Quaternion} qb - The target quaternion.
		 * @param {number} t - The interpolation factor in the closed interval `[0, 1]`.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		slerpQuaternions( qa, qb, t ) {

			return this.copy( qa ).slerp( qb, t );

		}

		/**
		 * Sets this quaternion to a uniformly random, normalized quaternion.
		 *
		 * @return {Quaternion} A reference to this quaternion.
		 */
		random() {

			// Ken Shoemake
			// Uniform random rotations
			// D. Kirk, editor, Graphics Gems III, pages 124-132. Academic Press, New York, 1992.

			const theta1 = 2 * Math.PI * Math.random();
			const theta2 = 2 * Math.PI * Math.random();

			const x0 = Math.random();
			const r1 = Math.sqrt( 1 - x0 );
			const r2 = Math.sqrt( x0 );

			return this.set(
				r1 * Math.sin( theta1 ),
				r1 * Math.cos( theta1 ),
				r2 * Math.sin( theta2 ),
				r2 * Math.cos( theta2 ),
			);

		}

		/**
		 * Returns `true` if this quaternion is equal with the given one.
		 *
		 * @param {Quaternion} quaternion - The quaternion to test for equality.
		 * @return {boolean} Whether this quaternion is equal with the given one.
		 */
		equals( quaternion ) {

			return ( quaternion._x === this._x ) && ( quaternion._y === this._y ) && ( quaternion._z === this._z ) && ( quaternion._w === this._w );

		}

		/**
		 * Sets this quaternion's components from the given array.
		 *
		 * @param {Array<number>} array - An array holding the quaternion component values.
		 * @param {number} [offset=0] - The offset into the array.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		fromArray( array, offset = 0 ) {

			this._x = array[ offset ];
			this._y = array[ offset + 1 ];
			this._z = array[ offset + 2 ];
			this._w = array[ offset + 3 ];

			this._onChangeCallback();

			return this;

		}

		/**
		 * Writes the components of this quaternion to the given array. If no array is provided,
		 * the method returns a new instance.
		 *
		 * @param {Array<number>} [array=[]] - The target array holding the quaternion components.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Array<number>} The quaternion components.
		 */
		toArray( array = [], offset = 0 ) {

			array[ offset ] = this._x;
			array[ offset + 1 ] = this._y;
			array[ offset + 2 ] = this._z;
			array[ offset + 3 ] = this._w;

			return array;

		}

		/**
		 * Sets the components of this quaternion from the given buffer attribute.
		 *
		 * @param {BufferAttribute} attribute - The buffer attribute holding quaternion data.
		 * @param {number} index - The index into the attribute.
		 * @return {Quaternion} A reference to this quaternion.
		 */
		fromBufferAttribute( attribute, index ) {

			this._x = attribute.getX( index );
			this._y = attribute.getY( index );
			this._z = attribute.getZ( index );
			this._w = attribute.getW( index );

			this._onChangeCallback();

			return this;

		}

		/**
		 * This methods defines the serialization result of this class. Returns the
		 * numerical elements of this quaternion in an array of format `[x, y, z, w]`.
		 *
		 * @return {Array<number>} The serialized quaternion.
		 */
		toJSON() {

			return this.toArray();

		}

		_onChange( callback ) {

			this._onChangeCallback = callback;

			return this;

		}

		_onChangeCallback() {}

		*[ Symbol.iterator ]() {

			yield this._x;
			yield this._y;
			yield this._z;
			yield this._w;

		}

	}

	/**
	 * Class representing a 3D vector. A 3D vector is an ordered triplet of numbers
	 * (labeled x, y and z), which can be used to represent a number of things, such as:
	 *
	 * - A point in 3D space.
	 * - A direction and length in 3D space. In three.js the length will
	 * always be the Euclidean distance(straight-line distance) from `(0, 0, 0)` to `(x, y, z)`
	 * and the direction is also measured from `(0, 0, 0)` towards `(x, y, z)`.
	 * - Any arbitrary ordered triplet of numbers.
	 *
	 * There are other things a 3D vector can be used to represent, such as
	 * momentum vectors and so on, however these are the most
	 * common uses in three.js.
	 *
	 * Iterating through a vector instance will yield its components `(x, y, z)` in
	 * the corresponding order.
	 * ```js
	 * const a = new THREE.Vector3( 0, 1, 0 );
	 *
	 * //no arguments; will be initialised to (0, 0, 0)
	 * const b = new THREE.Vector3( );
	 *
	 * const d = a.distanceTo( b );
	 * ```
	 */
	class Vector3 {

		/**
		 * Constructs a new 3D vector.
		 *
		 * @param {number} [x=0] - The x value of this vector.
		 * @param {number} [y=0] - The y value of this vector.
		 * @param {number} [z=0] - The z value of this vector.
		 */
		constructor( x = 0, y = 0, z = 0 ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			Vector3.prototype.isVector3 = true;

			/**
			 * The x value of this vector.
			 *
			 * @type {number}
			 */
			this.x = x;

			/**
			 * The y value of this vector.
			 *
			 * @type {number}
			 */
			this.y = y;

			/**
			 * The z value of this vector.
			 *
			 * @type {number}
			 */
			this.z = z;

		}

		/**
		 * Sets the vector components.
		 *
		 * @param {number} x - The value of the x component.
		 * @param {number} y - The value of the y component.
		 * @param {number} z - The value of the z component.
		 * @return {Vector3} A reference to this vector.
		 */
		set( x, y, z ) {

			if ( z === undefined ) z = this.z; // sprite.scale.set(x,y)

			this.x = x;
			this.y = y;
			this.z = z;

			return this;

		}

		/**
		 * Sets the vector components to the same value.
		 *
		 * @param {number} scalar - The value to set for all vector components.
		 * @return {Vector3} A reference to this vector.
		 */
		setScalar( scalar ) {

			this.x = scalar;
			this.y = scalar;
			this.z = scalar;

			return this;

		}

		/**
		 * Sets the vector's x component to the given value
		 *
		 * @param {number} x - The value to set.
		 * @return {Vector3} A reference to this vector.
		 */
		setX( x ) {

			this.x = x;

			return this;

		}

		/**
		 * Sets the vector's y component to the given value
		 *
		 * @param {number} y - The value to set.
		 * @return {Vector3} A reference to this vector.
		 */
		setY( y ) {

			this.y = y;

			return this;

		}

		/**
		 * Sets the vector's z component to the given value
		 *
		 * @param {number} z - The value to set.
		 * @return {Vector3} A reference to this vector.
		 */
		setZ( z ) {

			this.z = z;

			return this;

		}

		/**
		 * Allows to set a vector component with an index.
		 *
		 * @param {number} index - The component index. `0` equals to x, `1` equals to y, `2` equals to z.
		 * @param {number} value - The value to set.
		 * @return {Vector3} A reference to this vector.
		 */
		setComponent( index, value ) {

			switch ( index ) {

				case 0: this.x = value; break;
				case 1: this.y = value; break;
				case 2: this.z = value; break;
				default: throw new Error( 'index is out of range: ' + index );

			}

			return this;

		}

		/**
		 * Returns the value of the vector component which matches the given index.
		 *
		 * @param {number} index - The component index. `0` equals to x, `1` equals to y, `2` equals to z.
		 * @return {number} A vector component value.
		 */
		getComponent( index ) {

			switch ( index ) {

				case 0: return this.x;
				case 1: return this.y;
				case 2: return this.z;
				default: throw new Error( 'index is out of range: ' + index );

			}

		}

		/**
		 * Returns a new vector with copied values from this instance.
		 *
		 * @return {Vector3} A clone of this instance.
		 */
		clone() {

			return new this.constructor( this.x, this.y, this.z );

		}

		/**
		 * Copies the values of the given vector to this instance.
		 *
		 * @param {Vector3} v - The vector to copy.
		 * @return {Vector3} A reference to this vector.
		 */
		copy( v ) {

			this.x = v.x;
			this.y = v.y;
			this.z = v.z;

			return this;

		}

		/**
		 * Adds the given vector to this instance.
		 *
		 * @param {Vector3} v - The vector to add.
		 * @return {Vector3} A reference to this vector.
		 */
		add( v ) {

			this.x += v.x;
			this.y += v.y;
			this.z += v.z;

			return this;

		}

		/**
		 * Adds the given scalar value to all components of this instance.
		 *
		 * @param {number} s - The scalar to add.
		 * @return {Vector3} A reference to this vector.
		 */
		addScalar( s ) {

			this.x += s;
			this.y += s;
			this.z += s;

			return this;

		}

		/**
		 * Adds the given vectors and stores the result in this instance.
		 *
		 * @param {Vector3} a - The first vector.
		 * @param {Vector3} b - The second vector.
		 * @return {Vector3} A reference to this vector.
		 */
		addVectors( a, b ) {

			this.x = a.x + b.x;
			this.y = a.y + b.y;
			this.z = a.z + b.z;

			return this;

		}

		/**
		 * Adds the given vector scaled by the given factor to this instance.
		 *
		 * @param {Vector3|Vector4} v - The vector.
		 * @param {number} s - The factor that scales `v`.
		 * @return {Vector3} A reference to this vector.
		 */
		addScaledVector( v, s ) {

			this.x += v.x * s;
			this.y += v.y * s;
			this.z += v.z * s;

			return this;

		}

		/**
		 * Subtracts the given vector from this instance.
		 *
		 * @param {Vector3} v - The vector to subtract.
		 * @return {Vector3} A reference to this vector.
		 */
		sub( v ) {

			this.x -= v.x;
			this.y -= v.y;
			this.z -= v.z;

			return this;

		}

		/**
		 * Subtracts the given scalar value from all components of this instance.
		 *
		 * @param {number} s - The scalar to subtract.
		 * @return {Vector3} A reference to this vector.
		 */
		subScalar( s ) {

			this.x -= s;
			this.y -= s;
			this.z -= s;

			return this;

		}

		/**
		 * Subtracts the given vectors and stores the result in this instance.
		 *
		 * @param {Vector3} a - The first vector.
		 * @param {Vector3} b - The second vector.
		 * @return {Vector3} A reference to this vector.
		 */
		subVectors( a, b ) {

			this.x = a.x - b.x;
			this.y = a.y - b.y;
			this.z = a.z - b.z;

			return this;

		}

		/**
		 * Multiplies the given vector with this instance.
		 *
		 * @param {Vector3} v - The vector to multiply.
		 * @return {Vector3} A reference to this vector.
		 */
		multiply( v ) {

			this.x *= v.x;
			this.y *= v.y;
			this.z *= v.z;

			return this;

		}

		/**
		 * Multiplies the given scalar value with all components of this instance.
		 *
		 * @param {number} scalar - The scalar to multiply.
		 * @return {Vector3} A reference to this vector.
		 */
		multiplyScalar( scalar ) {

			this.x *= scalar;
			this.y *= scalar;
			this.z *= scalar;

			return this;

		}

		/**
		 * Multiplies the given vectors and stores the result in this instance.
		 *
		 * @param {Vector3} a - The first vector.
		 * @param {Vector3} b - The second vector.
		 * @return {Vector3} A reference to this vector.
		 */
		multiplyVectors( a, b ) {

			this.x = a.x * b.x;
			this.y = a.y * b.y;
			this.z = a.z * b.z;

			return this;

		}

		/**
		 * Applies the given Euler rotation to this vector.
		 *
		 * @param {Euler} euler - The Euler angles.
		 * @return {Vector3} A reference to this vector.
		 */
		applyEuler( euler ) {

			return this.applyQuaternion( _quaternion$4.setFromEuler( euler ) );

		}

		/**
		 * Applies a rotation specified by an axis and an angle to this vector.
		 *
		 * @param {Vector3} axis - A normalized vector representing the rotation axis.
		 * @param {number} angle - The angle in radians.
		 * @return {Vector3} A reference to this vector.
		 */
		applyAxisAngle( axis, angle ) {

			return this.applyQuaternion( _quaternion$4.setFromAxisAngle( axis, angle ) );

		}

		/**
		 * Multiplies this vector with the given 3x3 matrix.
		 *
		 * @param {Matrix3} m - The 3x3 matrix.
		 * @return {Vector3} A reference to this vector.
		 */
		applyMatrix3( m ) {

			const x = this.x, y = this.y, z = this.z;
			const e = m.elements;

			this.x = e[ 0 ] * x + e[ 3 ] * y + e[ 6 ] * z;
			this.y = e[ 1 ] * x + e[ 4 ] * y + e[ 7 ] * z;
			this.z = e[ 2 ] * x + e[ 5 ] * y + e[ 8 ] * z;

			return this;

		}

		/**
		 * Multiplies this vector by the given normal matrix and normalizes
		 * the result.
		 *
		 * @param {Matrix3} m - The normal matrix.
		 * @return {Vector3} A reference to this vector.
		 */
		applyNormalMatrix( m ) {

			return this.applyMatrix3( m ).normalize();

		}

		/**
		 * Multiplies this vector (with an implicit 1 in the 4th dimension) by m, and
		 * divides by perspective.
		 *
		 * @param {Matrix4} m - The matrix to apply.
		 * @return {Vector3} A reference to this vector.
		 */
		applyMatrix4( m ) {

			const x = this.x, y = this.y, z = this.z;
			const e = m.elements;

			const w = 1 / ( e[ 3 ] * x + e[ 7 ] * y + e[ 11 ] * z + e[ 15 ] );

			this.x = ( e[ 0 ] * x + e[ 4 ] * y + e[ 8 ] * z + e[ 12 ] ) * w;
			this.y = ( e[ 1 ] * x + e[ 5 ] * y + e[ 9 ] * z + e[ 13 ] ) * w;
			this.z = ( e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] ) * w;

			return this;

		}

		/**
		 * Applies the given Quaternion to this vector.
		 *
		 * @param {Quaternion} q - The Quaternion.
		 * @return {Vector3} A reference to this vector.
		 */
		applyQuaternion( q ) {

			// quaternion q is assumed to have unit length

			const vx = this.x, vy = this.y, vz = this.z;
			const qx = q.x, qy = q.y, qz = q.z, qw = q.w;

			// t = 2 * cross( q.xyz, v );
			const tx = 2 * ( qy * vz - qz * vy );
			const ty = 2 * ( qz * vx - qx * vz );
			const tz = 2 * ( qx * vy - qy * vx );

			// v + q.w * t + cross( q.xyz, t );
			this.x = vx + qw * tx + qy * tz - qz * ty;
			this.y = vy + qw * ty + qz * tx - qx * tz;
			this.z = vz + qw * tz + qx * ty - qy * tx;

			return this;

		}

		/**
		 * Projects this vector from world space into the camera's normalized
		 * device coordinate (NDC) space.
		 *
		 * @param {Camera} camera - The camera.
		 * @return {Vector3} A reference to this vector.
		 */
		project( camera ) {

			return this.applyMatrix4( camera.matrixWorldInverse ).applyMatrix4( camera.projectionMatrix );

		}

		/**
		 * Unprojects this vector from the camera's normalized device coordinate (NDC)
		 * space into world space.
		 *
		 * @param {Camera} camera - The camera.
		 * @return {Vector3} A reference to this vector.
		 */
		unproject( camera ) {

			return this.applyMatrix4( camera.projectionMatrixInverse ).applyMatrix4( camera.matrixWorld );

		}

		/**
		 * Transforms the direction of this vector by a matrix (the upper left 3 x 3
		 * subset of the given 4x4 matrix and then normalizes the result.
		 *
		 * @param {Matrix4} m - The matrix.
		 * @return {Vector3} A reference to this vector.
		 */
		transformDirection( m ) {

			// input: THREE.Matrix4 affine matrix
			// vector interpreted as a direction

			const x = this.x, y = this.y, z = this.z;
			const e = m.elements;

			this.x = e[ 0 ] * x + e[ 4 ] * y + e[ 8 ] * z;
			this.y = e[ 1 ] * x + e[ 5 ] * y + e[ 9 ] * z;
			this.z = e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z;

			return this.normalize();

		}

		/**
		 * Divides this instance by the given vector.
		 *
		 * @param {Vector3} v - The vector to divide.
		 * @return {Vector3} A reference to this vector.
		 */
		divide( v ) {

			this.x /= v.x;
			this.y /= v.y;
			this.z /= v.z;

			return this;

		}

		/**
		 * Divides this vector by the given scalar.
		 *
		 * @param {number} scalar - The scalar to divide.
		 * @return {Vector3} A reference to this vector.
		 */
		divideScalar( scalar ) {

			return this.multiplyScalar( 1 / scalar );

		}

		/**
		 * If this vector's x, y or z value is greater than the given vector's x, y or z
		 * value, replace that value with the corresponding min value.
		 *
		 * @param {Vector3} v - The vector.
		 * @return {Vector3} A reference to this vector.
		 */
		min( v ) {

			this.x = Math.min( this.x, v.x );
			this.y = Math.min( this.y, v.y );
			this.z = Math.min( this.z, v.z );

			return this;

		}

		/**
		 * If this vector's x, y or z value is less than the given vector's x, y or z
		 * value, replace that value with the corresponding max value.
		 *
		 * @param {Vector3} v - The vector.
		 * @return {Vector3} A reference to this vector.
		 */
		max( v ) {

			this.x = Math.max( this.x, v.x );
			this.y = Math.max( this.y, v.y );
			this.z = Math.max( this.z, v.z );

			return this;

		}

		/**
		 * If this vector's x, y or z value is greater than the max vector's x, y or z
		 * value, it is replaced by the corresponding value.
		 * If this vector's x, y or z value is less than the min vector's x, y or z value,
		 * it is replaced by the corresponding value.
		 *
		 * @param {Vector3} min - The minimum x, y and z values.
		 * @param {Vector3} max - The maximum x, y and z values in the desired range.
		 * @return {Vector3} A reference to this vector.
		 */
		clamp( min, max ) {

			// assumes min < max, componentwise

			this.x = clamp( this.x, min.x, max.x );
			this.y = clamp( this.y, min.y, max.y );
			this.z = clamp( this.z, min.z, max.z );

			return this;

		}

		/**
		 * If this vector's x, y or z values are greater than the max value, they are
		 * replaced by the max value.
		 * If this vector's x, y or z values are less than the min value, they are
		 * replaced by the min value.
		 *
		 * @param {number} minVal - The minimum value the components will be clamped to.
		 * @param {number} maxVal - The maximum value the components will be clamped to.
		 * @return {Vector3} A reference to this vector.
		 */
		clampScalar( minVal, maxVal ) {

			this.x = clamp( this.x, minVal, maxVal );
			this.y = clamp( this.y, minVal, maxVal );
			this.z = clamp( this.z, minVal, maxVal );

			return this;

		}

		/**
		 * If this vector's length is greater than the max value, it is replaced by
		 * the max value.
		 * If this vector's length is less than the min value, it is replaced by the
		 * min value.
		 *
		 * @param {number} min - The minimum value the vector length will be clamped to.
		 * @param {number} max - The maximum value the vector length will be clamped to.
		 * @return {Vector3} A reference to this vector.
		 */
		clampLength( min, max ) {

			const length = this.length();

			return this.divideScalar( length || 1 ).multiplyScalar( clamp( length, min, max ) );

		}

		/**
		 * The components of this vector are rounded down to the nearest integer value.
		 *
		 * @return {Vector3} A reference to this vector.
		 */
		floor() {

			this.x = Math.floor( this.x );
			this.y = Math.floor( this.y );
			this.z = Math.floor( this.z );

			return this;

		}

		/**
		 * The components of this vector are rounded up to the nearest integer value.
		 *
		 * @return {Vector3} A reference to this vector.
		 */
		ceil() {

			this.x = Math.ceil( this.x );
			this.y = Math.ceil( this.y );
			this.z = Math.ceil( this.z );

			return this;

		}

		/**
		 * The components of this vector are rounded to the nearest integer value
		 *
		 * @return {Vector3} A reference to this vector.
		 */
		round() {

			this.x = Math.round( this.x );
			this.y = Math.round( this.y );
			this.z = Math.round( this.z );

			return this;

		}

		/**
		 * The components of this vector are rounded towards zero (up if negative,
		 * down if positive) to an integer value.
		 *
		 * @return {Vector3} A reference to this vector.
		 */
		roundToZero() {

			this.x = Math.trunc( this.x );
			this.y = Math.trunc( this.y );
			this.z = Math.trunc( this.z );

			return this;

		}

		/**
		 * Inverts this vector - i.e. sets x = -x, y = -y and z = -z.
		 *
		 * @return {Vector3} A reference to this vector.
		 */
		negate() {

			this.x = - this.x;
			this.y = - this.y;
			this.z = - this.z;

			return this;

		}

		/**
		 * Calculates the dot product of the given vector with this instance.
		 *
		 * @param {Vector3} v - The vector to compute the dot product with.
		 * @return {number} The result of the dot product.
		 */
		dot( v ) {

			return this.x * v.x + this.y * v.y + this.z * v.z;

		}

		// TODO lengthSquared?

		/**
		 * Computes the square of the Euclidean length (straight-line length) from
		 * (0, 0, 0) to (x, y, z). If you are comparing the lengths of vectors, you should
		 * compare the length squared instead as it is slightly more efficient to calculate.
		 *
		 * @return {number} The square length of this vector.
		 */
		lengthSq() {

			return this.x * this.x + this.y * this.y + this.z * this.z;

		}

		/**
		 * Computes the  Euclidean length (straight-line length) from (0, 0, 0) to (x, y, z).
		 *
		 * @return {number} The length of this vector.
		 */
		length() {

			return Math.sqrt( this.x * this.x + this.y * this.y + this.z * this.z );

		}

		/**
		 * Computes the Manhattan length of this vector.
		 *
		 * @return {number} The length of this vector.
		 */
		manhattanLength() {

			return Math.abs( this.x ) + Math.abs( this.y ) + Math.abs( this.z );

		}

		/**
		 * Converts this vector to a unit vector - that is, sets it equal to a vector
		 * with the same direction as this one, but with a vector length of `1`.
		 *
		 * @return {Vector3} A reference to this vector.
		 */
		normalize() {

			return this.divideScalar( this.length() || 1 );

		}

		/**
		 * Sets this vector to a vector with the same direction as this one, but
		 * with the specified length.
		 *
		 * @param {number} length - The new length of this vector.
		 * @return {Vector3} A reference to this vector.
		 */
		setLength( length ) {

			return this.normalize().multiplyScalar( length );

		}

		/**
		 * Linearly interpolates between the given vector and this instance, where
		 * alpha is the percent distance along the line - alpha = 0 will be this
		 * vector, and alpha = 1 will be the given one.
		 *
		 * @param {Vector3} v - The vector to interpolate towards.
		 * @param {number} alpha - The interpolation factor, typically in the closed interval `[0, 1]`.
		 * @return {Vector3} A reference to this vector.
		 */
		lerp( v, alpha ) {

			this.x += ( v.x - this.x ) * alpha;
			this.y += ( v.y - this.y ) * alpha;
			this.z += ( v.z - this.z ) * alpha;

			return this;

		}

		/**
		 * Linearly interpolates between the given vectors, where alpha is the percent
		 * distance along the line - alpha = 0 will be first vector, and alpha = 1 will
		 * be the second one. The result is stored in this instance.
		 *
		 * @param {Vector3} v1 - The first vector.
		 * @param {Vector3} v2 - The second vector.
		 * @param {number} alpha - The interpolation factor, typically in the closed interval `[0, 1]`.
		 * @return {Vector3} A reference to this vector.
		 */
		lerpVectors( v1, v2, alpha ) {

			this.x = v1.x + ( v2.x - v1.x ) * alpha;
			this.y = v1.y + ( v2.y - v1.y ) * alpha;
			this.z = v1.z + ( v2.z - v1.z ) * alpha;

			return this;

		}

		/**
		 * Calculates the cross product of the given vector with this instance.
		 *
		 * @param {Vector3} v - The vector to compute the cross product with.
		 * @return {Vector3} The result of the cross product.
		 */
		cross( v ) {

			return this.crossVectors( this, v );

		}

		/**
		 * Calculates the cross product of the given vectors and stores the result
		 * in this instance.
		 *
		 * @param {Vector3} a - The first vector.
		 * @param {Vector3} b - The second vector.
		 * @return {Vector3} A reference to this vector.
		 */
		crossVectors( a, b ) {

			const ax = a.x, ay = a.y, az = a.z;
			const bx = b.x, by = b.y, bz = b.z;

			this.x = ay * bz - az * by;
			this.y = az * bx - ax * bz;
			this.z = ax * by - ay * bx;

			return this;

		}

		/**
		 * Projects this vector onto the given one.
		 *
		 * @param {Vector3} v - The vector to project to.
		 * @return {Vector3} A reference to this vector.
		 */
		projectOnVector( v ) {

			const denominator = v.lengthSq();

			if ( denominator === 0 ) return this.set( 0, 0, 0 );

			const scalar = v.dot( this ) / denominator;

			return this.copy( v ).multiplyScalar( scalar );

		}

		/**
		 * Projects this vector onto a plane by subtracting this
		 * vector projected onto the plane's normal from this vector.
		 *
		 * @param {Vector3} planeNormal - The plane normal.
		 * @return {Vector3} A reference to this vector.
		 */
		projectOnPlane( planeNormal ) {

			_vector$c.copy( this ).projectOnVector( planeNormal );

			return this.sub( _vector$c );

		}

		/**
		 * Reflects this vector off a plane orthogonal to the given normal vector.
		 *
		 * @param {Vector3} normal - The (normalized) normal vector.
		 * @return {Vector3} A reference to this vector.
		 */
		reflect( normal ) {

			return this.sub( _vector$c.copy( normal ).multiplyScalar( 2 * this.dot( normal ) ) );

		}
		/**
		 * Returns the angle between the given vector and this instance in radians.
		 *
		 * @param {Vector3} v - The vector to compute the angle with.
		 * @return {number} The angle in radians.
		 */
		angleTo( v ) {

			const denominator = Math.sqrt( this.lengthSq() * v.lengthSq() );

			if ( denominator === 0 ) return Math.PI / 2;

			const theta = this.dot( v ) / denominator;

			// clamp, to handle numerical problems

			return Math.acos( clamp( theta, -1, 1 ) );

		}

		/**
		 * Computes the distance from the given vector to this instance.
		 *
		 * @param {Vector3} v - The vector to compute the distance to.
		 * @return {number} The distance.
		 */
		distanceTo( v ) {

			return Math.sqrt( this.distanceToSquared( v ) );

		}

		/**
		 * Computes the squared distance from the given vector to this instance.
		 * If you are just comparing the distance with another distance, you should compare
		 * the distance squared instead as it is slightly more efficient to calculate.
		 *
		 * @param {Vector3} v - The vector to compute the squared distance to.
		 * @return {number} The squared distance.
		 */
		distanceToSquared( v ) {

			const dx = this.x - v.x, dy = this.y - v.y, dz = this.z - v.z;

			return dx * dx + dy * dy + dz * dz;

		}

		/**
		 * Computes the Manhattan distance from the given vector to this instance.
		 *
		 * @param {Vector3} v - The vector to compute the Manhattan distance to.
		 * @return {number} The Manhattan distance.
		 */
		manhattanDistanceTo( v ) {

			return Math.abs( this.x - v.x ) + Math.abs( this.y - v.y ) + Math.abs( this.z - v.z );

		}

		/**
		 * Sets the vector components from the given spherical coordinates.
		 *
		 * @param {Spherical} s - The spherical coordinates.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromSpherical( s ) {

			return this.setFromSphericalCoords( s.radius, s.phi, s.theta );

		}

		/**
		 * Sets the vector components from the given spherical coordinates.
		 *
		 * @param {number} radius - The radius.
		 * @param {number} phi - The phi angle in radians.
		 * @param {number} theta - The theta angle in radians.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromSphericalCoords( radius, phi, theta ) {

			const sinPhiRadius = Math.sin( phi ) * radius;

			this.x = sinPhiRadius * Math.sin( theta );
			this.y = Math.cos( phi ) * radius;
			this.z = sinPhiRadius * Math.cos( theta );

			return this;

		}

		/**
		 * Sets the vector components from the given cylindrical coordinates.
		 *
		 * @param {Cylindrical} c - The cylindrical coordinates.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromCylindrical( c ) {

			return this.setFromCylindricalCoords( c.radius, c.theta, c.y );

		}

		/**
		 * Sets the vector components from the given cylindrical coordinates.
		 *
		 * @param {number} radius - The radius.
		 * @param {number} theta - The theta angle in radians.
		 * @param {number} y - The y value.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromCylindricalCoords( radius, theta, y ) {

			this.x = radius * Math.sin( theta );
			this.y = y;
			this.z = radius * Math.cos( theta );

			return this;

		}

		/**
		 * Sets the vector components to the position elements of the
		 * given transformation matrix.
		 *
		 * @param {Matrix4} m - The 4x4 matrix.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromMatrixPosition( m ) {

			const e = m.elements;

			this.x = e[ 12 ];
			this.y = e[ 13 ];
			this.z = e[ 14 ];

			return this;

		}

		/**
		 * Sets the vector components to the scale elements of the
		 * given transformation matrix.
		 *
		 * @param {Matrix4} m - The 4x4 matrix.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromMatrixScale( m ) {

			const sx = this.setFromMatrixColumn( m, 0 ).length();
			const sy = this.setFromMatrixColumn( m, 1 ).length();
			const sz = this.setFromMatrixColumn( m, 2 ).length();

			this.x = sx;
			this.y = sy;
			this.z = sz;

			return this;

		}

		/**
		 * Sets the vector components from the specified matrix column.
		 *
		 * @param {Matrix4} m - The 4x4 matrix.
		 * @param {number} index - The column index.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromMatrixColumn( m, index ) {

			return this.fromArray( m.elements, index * 4 );

		}

		/**
		 * Sets the vector components from the specified matrix column.
		 *
		 * @param {Matrix3} m - The 3x3 matrix.
		 * @param {number} index - The column index.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromMatrix3Column( m, index ) {

			return this.fromArray( m.elements, index * 3 );

		}

		/**
		 * Sets the vector components from the given Euler angles.
		 *
		 * @param {Euler} e - The Euler angles to set.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromEuler( e ) {

			this.x = e._x;
			this.y = e._y;
			this.z = e._z;

			return this;

		}

		/**
		 * Sets the vector components from the RGB components of the
		 * given color.
		 *
		 * @param {Color} c - The color to set.
		 * @return {Vector3} A reference to this vector.
		 */
		setFromColor( c ) {

			this.x = c.r;
			this.y = c.g;
			this.z = c.b;

			return this;

		}

		/**
		 * Returns `true` if this vector is equal with the given one.
		 *
		 * @param {Vector3} v - The vector to test for equality.
		 * @return {boolean} Whether this vector is equal with the given one.
		 */
		equals( v ) {

			return ( ( v.x === this.x ) && ( v.y === this.y ) && ( v.z === this.z ) );

		}

		/**
		 * Sets this vector's x value to be `array[ offset ]`, y value to be `array[ offset + 1 ]`
		 * and z value to be `array[ offset + 2 ]`.
		 *
		 * @param {Array<number>} array - An array holding the vector component values.
		 * @param {number} [offset=0] - The offset into the array.
		 * @return {Vector3} A reference to this vector.
		 */
		fromArray( array, offset = 0 ) {

			this.x = array[ offset ];
			this.y = array[ offset + 1 ];
			this.z = array[ offset + 2 ];

			return this;

		}

		/**
		 * Writes the components of this vector to the given array. If no array is provided,
		 * the method returns a new instance.
		 *
		 * @param {Array<number>} [array=[]] - The target array holding the vector components.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Array<number>} The vector components.
		 */
		toArray( array = [], offset = 0 ) {

			array[ offset ] = this.x;
			array[ offset + 1 ] = this.y;
			array[ offset + 2 ] = this.z;

			return array;

		}

		/**
		 * Sets the components of this vector from the given buffer attribute.
		 *
		 * @param {BufferAttribute} attribute - The buffer attribute holding vector data.
		 * @param {number} index - The index into the attribute.
		 * @return {Vector3} A reference to this vector.
		 */
		fromBufferAttribute( attribute, index ) {

			this.x = attribute.getX( index );
			this.y = attribute.getY( index );
			this.z = attribute.getZ( index );

			return this;

		}

		/**
		 * Sets each component of this vector to a pseudo-random value between `0` and
		 * `1`, excluding `1`.
		 *
		 * @return {Vector3} A reference to this vector.
		 */
		random() {

			this.x = Math.random();
			this.y = Math.random();
			this.z = Math.random();

			return this;

		}

		/**
		 * Sets this vector to a uniformly random point on a unit sphere.
		 *
		 * @return {Vector3} A reference to this vector.
		 */
		randomDirection() {

			// https://mathworld.wolfram.com/SpherePointPicking.html

			const theta = Math.random() * Math.PI * 2;
			const u = Math.random() * 2 - 1;
			const c = Math.sqrt( 1 - u * u );

			this.x = c * Math.cos( theta );
			this.y = u;
			this.z = c * Math.sin( theta );

			return this;

		}

		*[ Symbol.iterator ]() {

			yield this.x;
			yield this.y;
			yield this.z;

		}

	}

	const _vector$c = /*@__PURE__*/ new Vector3();
	const _quaternion$4 = /*@__PURE__*/ new Quaternion();

	/**
	 * Represents a 3x3 matrix.
	 *
	 * A Note on Row-Major and Column-Major Ordering:
	 *
	 * The constructor and {@link Matrix3#set} method take arguments in
	 * [row-major]{@link https://en.wikipedia.org/wiki/Row-_and_column-major_order#Column-major_order}
	 * order, while internally they are stored in the {@link Matrix3#elements} array in column-major order.
	 * This means that calling:
	 * ```js
	 * const m = new THREE.Matrix();
	 * m.set( 11, 12, 13,
	 *        21, 22, 23,
	 *        31, 32, 33 );
	 * ```
	 * will result in the elements array containing:
	 * ```js
	 * m.elements = [ 11, 21, 31,
	 *                12, 22, 32,
	 *                13, 23, 33 ];
	 * ```
	 * and internally all calculations are performed using column-major ordering.
	 * However, as the actual ordering makes no difference mathematically and
	 * most people are used to thinking about matrices in row-major order, the
	 * three.js documentation shows matrices in row-major order. Just bear in
	 * mind that if you are reading the source code, you'll have to take the
	 * transpose of any matrices outlined here to make sense of the calculations.
	 */
	class Matrix3 {

		/**
		 * Constructs a new 3x3 matrix. The arguments are supposed to be
		 * in row-major order. If no arguments are provided, the constructor
		 * initializes the matrix as an identity matrix.
		 *
		 * @param {number} [n11] - 1-1 matrix element.
		 * @param {number} [n12] - 1-2 matrix element.
		 * @param {number} [n13] - 1-3 matrix element.
		 * @param {number} [n21] - 2-1 matrix element.
		 * @param {number} [n22] - 2-2 matrix element.
		 * @param {number} [n23] - 2-3 matrix element.
		 * @param {number} [n31] - 3-1 matrix element.
		 * @param {number} [n32] - 3-2 matrix element.
		 * @param {number} [n33] - 3-3 matrix element.
		 */
		constructor( n11, n12, n13, n21, n22, n23, n31, n32, n33 ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			Matrix3.prototype.isMatrix3 = true;

			/**
			 * A column-major list of matrix values.
			 *
			 * @type {Array<number>}
			 */
			this.elements = [

				1, 0, 0,
				0, 1, 0,
				0, 0, 1

			];

			if ( n11 !== undefined ) {

				this.set( n11, n12, n13, n21, n22, n23, n31, n32, n33 );

			}

		}

		/**
		 * Sets the elements of the matrix.The arguments are supposed to be
		 * in row-major order.
		 *
		 * @param {number} [n11] - 1-1 matrix element.
		 * @param {number} [n12] - 1-2 matrix element.
		 * @param {number} [n13] - 1-3 matrix element.
		 * @param {number} [n21] - 2-1 matrix element.
		 * @param {number} [n22] - 2-2 matrix element.
		 * @param {number} [n23] - 2-3 matrix element.
		 * @param {number} [n31] - 3-1 matrix element.
		 * @param {number} [n32] - 3-2 matrix element.
		 * @param {number} [n33] - 3-3 matrix element.
		 * @return {Matrix3} A reference to this matrix.
		 */
		set( n11, n12, n13, n21, n22, n23, n31, n32, n33 ) {

			const te = this.elements;

			te[ 0 ] = n11; te[ 1 ] = n21; te[ 2 ] = n31;
			te[ 3 ] = n12; te[ 4 ] = n22; te[ 5 ] = n32;
			te[ 6 ] = n13; te[ 7 ] = n23; te[ 8 ] = n33;

			return this;

		}

		/**
		 * Sets this matrix to the 3x3 identity matrix.
		 *
		 * @return {Matrix3} A reference to this matrix.
		 */
		identity() {

			this.set(

				1, 0, 0,
				0, 1, 0,
				0, 0, 1

			);

			return this;

		}

		/**
		 * Copies the values of the given matrix to this instance.
		 *
		 * @param {Matrix3} m - The matrix to copy.
		 * @return {Matrix3} A reference to this matrix.
		 */
		copy( m ) {

			const te = this.elements;
			const me = m.elements;

			te[ 0 ] = me[ 0 ]; te[ 1 ] = me[ 1 ]; te[ 2 ] = me[ 2 ];
			te[ 3 ] = me[ 3 ]; te[ 4 ] = me[ 4 ]; te[ 5 ] = me[ 5 ];
			te[ 6 ] = me[ 6 ]; te[ 7 ] = me[ 7 ]; te[ 8 ] = me[ 8 ];

			return this;

		}

		/**
		 * Extracts the basis of this matrix into the three axis vectors provided.
		 *
		 * @param {Vector3} xAxis - The basis's x axis.
		 * @param {Vector3} yAxis - The basis's y axis.
		 * @param {Vector3} zAxis - The basis's z axis.
		 * @return {Matrix3} A reference to this matrix.
		 */
		extractBasis( xAxis, yAxis, zAxis ) {

			xAxis.setFromMatrix3Column( this, 0 );
			yAxis.setFromMatrix3Column( this, 1 );
			zAxis.setFromMatrix3Column( this, 2 );

			return this;

		}

		/**
		 * Set this matrix to the upper 3x3 matrix of the given 4x4 matrix.
		 *
		 * @param {Matrix4} m - The 4x4 matrix.
		 * @return {Matrix3} A reference to this matrix.
		 */
		setFromMatrix4( m ) {

			const me = m.elements;

			this.set(

				me[ 0 ], me[ 4 ], me[ 8 ],
				me[ 1 ], me[ 5 ], me[ 9 ],
				me[ 2 ], me[ 6 ], me[ 10 ]

			);

			return this;

		}

		/**
		 * Post-multiplies this matrix by the given 3x3 matrix.
		 *
		 * @param {Matrix3} m - The matrix to multiply with.
		 * @return {Matrix3} A reference to this matrix.
		 */
		multiply( m ) {

			return this.multiplyMatrices( this, m );

		}

		/**
		 * Pre-multiplies this matrix by the given 3x3 matrix.
		 *
		 * @param {Matrix3} m - The matrix to multiply with.
		 * @return {Matrix3} A reference to this matrix.
		 */
		premultiply( m ) {

			return this.multiplyMatrices( m, this );

		}

		/**
		 * Multiples the given 3x3 matrices and stores the result
		 * in this matrix.
		 *
		 * @param {Matrix3} a - The first matrix.
		 * @param {Matrix3} b - The second matrix.
		 * @return {Matrix3} A reference to this matrix.
		 */
		multiplyMatrices( a, b ) {

			const ae = a.elements;
			const be = b.elements;
			const te = this.elements;

			const a11 = ae[ 0 ], a12 = ae[ 3 ], a13 = ae[ 6 ];
			const a21 = ae[ 1 ], a22 = ae[ 4 ], a23 = ae[ 7 ];
			const a31 = ae[ 2 ], a32 = ae[ 5 ], a33 = ae[ 8 ];

			const b11 = be[ 0 ], b12 = be[ 3 ], b13 = be[ 6 ];
			const b21 = be[ 1 ], b22 = be[ 4 ], b23 = be[ 7 ];
			const b31 = be[ 2 ], b32 = be[ 5 ], b33 = be[ 8 ];

			te[ 0 ] = a11 * b11 + a12 * b21 + a13 * b31;
			te[ 3 ] = a11 * b12 + a12 * b22 + a13 * b32;
			te[ 6 ] = a11 * b13 + a12 * b23 + a13 * b33;

			te[ 1 ] = a21 * b11 + a22 * b21 + a23 * b31;
			te[ 4 ] = a21 * b12 + a22 * b22 + a23 * b32;
			te[ 7 ] = a21 * b13 + a22 * b23 + a23 * b33;

			te[ 2 ] = a31 * b11 + a32 * b21 + a33 * b31;
			te[ 5 ] = a31 * b12 + a32 * b22 + a33 * b32;
			te[ 8 ] = a31 * b13 + a32 * b23 + a33 * b33;

			return this;

		}

		/**
		 * Multiplies every component of the matrix by the given scalar.
		 *
		 * @param {number} s - The scalar.
		 * @return {Matrix3} A reference to this matrix.
		 */
		multiplyScalar( s ) {

			const te = this.elements;

			te[ 0 ] *= s; te[ 3 ] *= s; te[ 6 ] *= s;
			te[ 1 ] *= s; te[ 4 ] *= s; te[ 7 ] *= s;
			te[ 2 ] *= s; te[ 5 ] *= s; te[ 8 ] *= s;

			return this;

		}

		/**
		 * Computes and returns the determinant of this matrix.
		 *
		 * @return {number} The determinant.
		 */
		determinant() {

			const te = this.elements;

			const a = te[ 0 ], b = te[ 1 ], c = te[ 2 ],
				d = te[ 3 ], e = te[ 4 ], f = te[ 5 ],
				g = te[ 6 ], h = te[ 7 ], i = te[ 8 ];

			return a * e * i - a * f * h - b * d * i + b * f * g + c * d * h - c * e * g;

		}

		/**
		 * Inverts this matrix, using the [analytic method]{@link https://en.wikipedia.org/wiki/Invertible_matrix#Analytic_solution}.
		 * You can not invert with a determinant of zero. If you attempt this, the method produces
		 * a zero matrix instead.
		 *
		 * @return {Matrix3} A reference to this matrix.
		 */
		invert() {

			const te = this.elements,

				n11 = te[ 0 ], n21 = te[ 1 ], n31 = te[ 2 ],
				n12 = te[ 3 ], n22 = te[ 4 ], n32 = te[ 5 ],
				n13 = te[ 6 ], n23 = te[ 7 ], n33 = te[ 8 ],

				t11 = n33 * n22 - n32 * n23,
				t12 = n32 * n13 - n33 * n12,
				t13 = n23 * n12 - n22 * n13,

				det = n11 * t11 + n21 * t12 + n31 * t13;

			if ( det === 0 ) return this.set( 0, 0, 0, 0, 0, 0, 0, 0, 0 );

			const detInv = 1 / det;

			te[ 0 ] = t11 * detInv;
			te[ 1 ] = ( n31 * n23 - n33 * n21 ) * detInv;
			te[ 2 ] = ( n32 * n21 - n31 * n22 ) * detInv;

			te[ 3 ] = t12 * detInv;
			te[ 4 ] = ( n33 * n11 - n31 * n13 ) * detInv;
			te[ 5 ] = ( n31 * n12 - n32 * n11 ) * detInv;

			te[ 6 ] = t13 * detInv;
			te[ 7 ] = ( n21 * n13 - n23 * n11 ) * detInv;
			te[ 8 ] = ( n22 * n11 - n21 * n12 ) * detInv;

			return this;

		}

		/**
		 * Transposes this matrix in place.
		 *
		 * @return {Matrix3} A reference to this matrix.
		 */
		transpose() {

			let tmp;
			const m = this.elements;

			tmp = m[ 1 ]; m[ 1 ] = m[ 3 ]; m[ 3 ] = tmp;
			tmp = m[ 2 ]; m[ 2 ] = m[ 6 ]; m[ 6 ] = tmp;
			tmp = m[ 5 ]; m[ 5 ] = m[ 7 ]; m[ 7 ] = tmp;

			return this;

		}

		/**
		 * Computes the normal matrix which is the inverse transpose of the upper
		 * left 3x3 portion of the given 4x4 matrix.
		 *
		 * @param {Matrix4} matrix4 - The 4x4 matrix.
		 * @return {Matrix3} A reference to this matrix.
		 */
		getNormalMatrix( matrix4 ) {

			return this.setFromMatrix4( matrix4 ).invert().transpose();

		}

		/**
		 * Transposes this matrix into the supplied array, and returns itself unchanged.
		 *
		 * @param {Array<number>} r - An array to store the transposed matrix elements.
		 * @return {Matrix3} A reference to this matrix.
		 */
		transposeIntoArray( r ) {

			const m = this.elements;

			r[ 0 ] = m[ 0 ];
			r[ 1 ] = m[ 3 ];
			r[ 2 ] = m[ 6 ];
			r[ 3 ] = m[ 1 ];
			r[ 4 ] = m[ 4 ];
			r[ 5 ] = m[ 7 ];
			r[ 6 ] = m[ 2 ];
			r[ 7 ] = m[ 5 ];
			r[ 8 ] = m[ 8 ];

			return this;

		}

		/**
		 * Sets the UV transform matrix from offset, repeat, rotation, and center.
		 *
		 * @param {number} tx - Offset x.
		 * @param {number} ty - Offset y.
		 * @param {number} sx - Repeat x.
		 * @param {number} sy - Repeat y.
		 * @param {number} rotation - Rotation, in radians. Positive values rotate counterclockwise.
		 * @param {number} cx - Center x of rotation.
		 * @param {number} cy - Center y of rotation
		 * @return {Matrix3} A reference to this matrix.
		 */
		setUvTransform( tx, ty, sx, sy, rotation, cx, cy ) {

			const c = Math.cos( rotation );
			const s = Math.sin( rotation );

			this.set(
				sx * c, sx * s, - sx * ( c * cx + s * cy ) + cx + tx,
				- sy * s, sy * c, - sy * ( - s * cx + c * cy ) + cy + ty,
				0, 0, 1
			);

			return this;

		}

		/**
		 * Scales this matrix with the given scalar values.
		 *
		 * @param {number} sx - The amount to scale in the X axis.
		 * @param {number} sy - The amount to scale in the Y axis.
		 * @return {Matrix3} A reference to this matrix.
		 */
		scale( sx, sy ) {

			this.premultiply( _m3.makeScale( sx, sy ) );

			return this;

		}

		/**
		 * Rotates this matrix by the given angle.
		 *
		 * @param {number} theta - The rotation in radians.
		 * @return {Matrix3} A reference to this matrix.
		 */
		rotate( theta ) {

			this.premultiply( _m3.makeRotation( - theta ) );

			return this;

		}

		/**
		 * Translates this matrix by the given scalar values.
		 *
		 * @param {number} tx - The amount to translate in the X axis.
		 * @param {number} ty - The amount to translate in the Y axis.
		 * @return {Matrix3} A reference to this matrix.
		 */
		translate( tx, ty ) {

			this.premultiply( _m3.makeTranslation( tx, ty ) );

			return this;

		}

		// for 2D Transforms

		/**
		 * Sets this matrix as a 2D translation transform.
		 *
		 * @param {number|Vector2} x - The amount to translate in the X axis or alternatively a translation vector.
		 * @param {number} y - The amount to translate in the Y axis.
		 * @return {Matrix3} A reference to this matrix.
		 */
		makeTranslation( x, y ) {

			if ( x.isVector2 ) {

				this.set(

					1, 0, x.x,
					0, 1, x.y,
					0, 0, 1

				);

			} else {

				this.set(

					1, 0, x,
					0, 1, y,
					0, 0, 1

				);

			}

			return this;

		}

		/**
		 * Sets this matrix as a 2D rotational transformation.
		 *
		 * @param {number} theta - The rotation in radians.
		 * @return {Matrix3} A reference to this matrix.
		 */
		makeRotation( theta ) {

			// counterclockwise

			const c = Math.cos( theta );
			const s = Math.sin( theta );

			this.set(

				c, - s, 0,
				s, c, 0,
				0, 0, 1

			);

			return this;

		}

		/**
		 * Sets this matrix as a 2D scale transform.
		 *
		 * @param {number} x - The amount to scale in the X axis.
		 * @param {number} y - The amount to scale in the Y axis.
		 * @return {Matrix3} A reference to this matrix.
		 */
		makeScale( x, y ) {

			this.set(

				x, 0, 0,
				0, y, 0,
				0, 0, 1

			);

			return this;

		}

		/**
		 * Returns `true` if this matrix is equal with the given one.
		 *
		 * @param {Matrix3} matrix - The matrix to test for equality.
		 * @return {boolean} Whether this matrix is equal with the given one.
		 */
		equals( matrix ) {

			const te = this.elements;
			const me = matrix.elements;

			for ( let i = 0; i < 9; i ++ ) {

				if ( te[ i ] !== me[ i ] ) return false;

			}

			return true;

		}

		/**
		 * Sets the elements of the matrix from the given array.
		 *
		 * @param {Array<number>} array - The matrix elements in column-major order.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Matrix3} A reference to this matrix.
		 */
		fromArray( array, offset = 0 ) {

			for ( let i = 0; i < 9; i ++ ) {

				this.elements[ i ] = array[ i + offset ];

			}

			return this;

		}

		/**
		 * Writes the elements of this matrix to the given array. If no array is provided,
		 * the method returns a new instance.
		 *
		 * @param {Array<number>} [array=[]] - The target array holding the matrix elements in column-major order.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Array<number>} The matrix elements in column-major order.
		 */
		toArray( array = [], offset = 0 ) {

			const te = this.elements;

			array[ offset ] = te[ 0 ];
			array[ offset + 1 ] = te[ 1 ];
			array[ offset + 2 ] = te[ 2 ];

			array[ offset + 3 ] = te[ 3 ];
			array[ offset + 4 ] = te[ 4 ];
			array[ offset + 5 ] = te[ 5 ];

			array[ offset + 6 ] = te[ 6 ];
			array[ offset + 7 ] = te[ 7 ];
			array[ offset + 8 ] = te[ 8 ];

			return array;

		}

		/**
		 * Returns a matrix with copied values from this instance.
		 *
		 * @return {Matrix3} A clone of this instance.
		 */
		clone() {

			return new this.constructor().fromArray( this.elements );

		}

	}

	const _m3 = /*@__PURE__*/ new Matrix3();

	function arrayNeedsUint32( array ) {

		// assumes larger values usually on last

		for ( let i = array.length - 1; i >= 0; -- i ) {

			if ( array[ i ] >= 65535 ) return true; // account for PRIMITIVE_RESTART_FIXED_INDEX, #24565

		}

		return false;

	}

	function createElementNS( name ) {

		return document.createElementNS( 'http://www.w3.org/1999/xhtml', name );

	}

	function createCanvasElement() {

		const canvas = createElementNS( 'canvas' );
		canvas.style.display = 'block';
		return canvas;

	}

	const _cache = {};

	function warnOnce( message ) {

		if ( message in _cache ) return;

		_cache[ message ] = true;

		console.warn( message );

	}

	function probeAsync( gl, sync, interval ) {

		return new Promise( function ( resolve, reject ) {

			function probe() {

				switch ( gl.clientWaitSync( sync, gl.SYNC_FLUSH_COMMANDS_BIT, 0 ) ) {

					case gl.WAIT_FAILED:
						reject();
						break;

					case gl.TIMEOUT_EXPIRED:
						setTimeout( probe, interval );
						break;

					default:
						resolve();

				}

			}

			setTimeout( probe, interval );

		} );

	}

	function toNormalizedProjectionMatrix( projectionMatrix ) {

		const m = projectionMatrix.elements;

		// Convert [-1, 1] to [0, 1] projection matrix
		m[ 2 ] = 0.5 * m[ 2 ] + 0.5 * m[ 3 ];
		m[ 6 ] = 0.5 * m[ 6 ] + 0.5 * m[ 7 ];
		m[ 10 ] = 0.5 * m[ 10 ] + 0.5 * m[ 11 ];
		m[ 14 ] = 0.5 * m[ 14 ] + 0.5 * m[ 15 ];

	}

	function toReversedProjectionMatrix( projectionMatrix ) {

		const m = projectionMatrix.elements;
		const isPerspectiveMatrix = m[ 11 ] === -1;

		// Reverse [0, 1] projection matrix
		if ( isPerspectiveMatrix ) {

			m[ 10 ] = - m[ 10 ] - 1;
			m[ 14 ] = - m[ 14 ];

		} else {

			m[ 10 ] = - m[ 10 ];
			m[ 14 ] = - m[ 14 ] + 1;

		}

	}

	const LINEAR_REC709_TO_XYZ = /*@__PURE__*/ new Matrix3().set(
		0.4123908, 0.3575843, 0.1804808,
		0.2126390, 0.7151687, 0.0721923,
		0.0193308, 0.1191948, 0.9505322
	);

	const XYZ_TO_LINEAR_REC709 = /*@__PURE__*/ new Matrix3().set(
		3.2409699, -1.5373832, -0.4986108,
		-0.9692436, 1.8759675, 0.0415551,
		0.0556301, -0.203977, 1.0569715
	);

	function createColorManagement() {

		const ColorManagement = {

			enabled: true,

			workingColorSpace: LinearSRGBColorSpace,

			/**
			 * Implementations of supported color spaces.
			 *
			 * Required:
			 *	- primaries: chromaticity coordinates [ rx ry gx gy bx by ]
			 *	- whitePoint: reference white [ x y ]
			 *	- transfer: transfer function (pre-defined)
			 *	- toXYZ: Matrix3 RGB to XYZ transform
			 *	- fromXYZ: Matrix3 XYZ to RGB transform
			 *	- luminanceCoefficients: RGB luminance coefficients
			 *
			 * Optional:
			 *  - outputColorSpaceConfig: { drawingBufferColorSpace: ColorSpace }
			 *  - workingColorSpaceConfig: { unpackColorSpace: ColorSpace }
			 *
			 * Reference:
			 * - https://www.russellcottrell.com/photo/matrixCalculator.htm
			 */
			spaces: {},

			convert: function ( color, sourceColorSpace, targetColorSpace ) {

				if ( this.enabled === false || sourceColorSpace === targetColorSpace || ! sourceColorSpace || ! targetColorSpace ) {

					return color;

				}

				if ( this.spaces[ sourceColorSpace ].transfer === SRGBTransfer ) {

					color.r = SRGBToLinear( color.r );
					color.g = SRGBToLinear( color.g );
					color.b = SRGBToLinear( color.b );

				}

				if ( this.spaces[ sourceColorSpace ].primaries !== this.spaces[ targetColorSpace ].primaries ) {

					color.applyMatrix3( this.spaces[ sourceColorSpace ].toXYZ );
					color.applyMatrix3( this.spaces[ targetColorSpace ].fromXYZ );

				}

				if ( this.spaces[ targetColorSpace ].transfer === SRGBTransfer ) {

					color.r = LinearToSRGB( color.r );
					color.g = LinearToSRGB( color.g );
					color.b = LinearToSRGB( color.b );

				}

				return color;

			},

			workingToColorSpace: function ( color, targetColorSpace ) {

				return this.convert( color, this.workingColorSpace, targetColorSpace );

			},

			colorSpaceToWorking: function ( color, sourceColorSpace ) {

				return this.convert( color, sourceColorSpace, this.workingColorSpace );

			},

			getPrimaries: function ( colorSpace ) {

				return this.spaces[ colorSpace ].primaries;

			},

			getTransfer: function ( colorSpace ) {

				if ( colorSpace === NoColorSpace ) return LinearTransfer;

				return this.spaces[ colorSpace ].transfer;

			},

			getLuminanceCoefficients: function ( target, colorSpace = this.workingColorSpace ) {

				return target.fromArray( this.spaces[ colorSpace ].luminanceCoefficients );

			},

			define: function ( colorSpaces ) {

				Object.assign( this.spaces, colorSpaces );

			},

			// Internal APIs

			_getMatrix: function ( targetMatrix, sourceColorSpace, targetColorSpace ) {

				return targetMatrix
					.copy( this.spaces[ sourceColorSpace ].toXYZ )
					.multiply( this.spaces[ targetColorSpace ].fromXYZ );

			},

			_getDrawingBufferColorSpace: function ( colorSpace ) {

				return this.spaces[ colorSpace ].outputColorSpaceConfig.drawingBufferColorSpace;

			},

			_getUnpackColorSpace: function ( colorSpace = this.workingColorSpace ) {

				return this.spaces[ colorSpace ].workingColorSpaceConfig.unpackColorSpace;

			},

			// Deprecated

			fromWorkingColorSpace: function ( color, targetColorSpace ) {

				warnOnce( 'THREE.ColorManagement: .fromWorkingColorSpace() has been renamed to .workingToColorSpace().' ); // @deprecated, r177

				return ColorManagement.workingToColorSpace( color, targetColorSpace );

			},

			toWorkingColorSpace: function ( color, sourceColorSpace ) {

				warnOnce( 'THREE.ColorManagement: .toWorkingColorSpace() has been renamed to .colorSpaceToWorking().' ); // @deprecated, r177

				return ColorManagement.colorSpaceToWorking( color, sourceColorSpace );

			},

		};

		/******************************************************************************
		 * sRGB definitions
		 */

		const REC709_PRIMARIES = [ 0.640, 0.330, 0.300, 0.600, 0.150, 0.060 ];
		const REC709_LUMINANCE_COEFFICIENTS = [ 0.2126, 0.7152, 0.0722 ];
		const D65 = [ 0.3127, 0.3290 ];

		ColorManagement.define( {

			[ LinearSRGBColorSpace ]: {
				primaries: REC709_PRIMARIES,
				whitePoint: D65,
				transfer: LinearTransfer,
				toXYZ: LINEAR_REC709_TO_XYZ,
				fromXYZ: XYZ_TO_LINEAR_REC709,
				luminanceCoefficients: REC709_LUMINANCE_COEFFICIENTS,
				workingColorSpaceConfig: { unpackColorSpace: SRGBColorSpace },
				outputColorSpaceConfig: { drawingBufferColorSpace: SRGBColorSpace }
			},

			[ SRGBColorSpace ]: {
				primaries: REC709_PRIMARIES,
				whitePoint: D65,
				transfer: SRGBTransfer,
				toXYZ: LINEAR_REC709_TO_XYZ,
				fromXYZ: XYZ_TO_LINEAR_REC709,
				luminanceCoefficients: REC709_LUMINANCE_COEFFICIENTS,
				outputColorSpaceConfig: { drawingBufferColorSpace: SRGBColorSpace }
			},

		} );

		return ColorManagement;

	}

	const ColorManagement = /*@__PURE__*/ createColorManagement();

	function SRGBToLinear( c ) {

		return ( c < 0.04045 ) ? c * 0.0773993808 : Math.pow( c * 0.9478672986 + 0.0521327014, 2.4 );

	}

	function LinearToSRGB( c ) {

		return ( c < 0.0031308 ) ? c * 12.92 : 1.055 * ( Math.pow( c, 0.41666 ) ) - 0.055;

	}

	let _canvas;

	/**
	 * A class containing utility functions for images.
	 *
	 * @hideconstructor
	 */
	class ImageUtils {

		/**
		 * Returns a data URI containing a representation of the given image.
		 *
		 * @param {(HTMLImageElement|HTMLCanvasElement)} image - The image object.
		 * @param {string} [type='image/png'] - Indicates the image format.
		 * @return {string} The data URI.
		 */
		static getDataURL( image, type = 'image/png' ) {

			if ( /^data:/i.test( image.src ) ) {

				return image.src;

			}

			if ( typeof HTMLCanvasElement === 'undefined' ) {

				return image.src;

			}

			let canvas;

			if ( image instanceof HTMLCanvasElement ) {

				canvas = image;

			} else {

				if ( _canvas === undefined ) _canvas = createElementNS( 'canvas' );

				_canvas.width = image.width;
				_canvas.height = image.height;

				const context = _canvas.getContext( '2d' );

				if ( image instanceof ImageData ) {

					context.putImageData( image, 0, 0 );

				} else {

					context.drawImage( image, 0, 0, image.width, image.height );

				}

				canvas = _canvas;

			}

			return canvas.toDataURL( type );

		}

		/**
		 * Converts the given sRGB image data to linear color space.
		 *
		 * @param {(HTMLImageElement|HTMLCanvasElement|ImageBitmap|Object)} image - The image object.
		 * @return {HTMLCanvasElement|Object} The converted image.
		 */
		static sRGBToLinear( image ) {

			if ( ( typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement ) ||
				( typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement ) ||
				( typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap ) ) {

				const canvas = createElementNS( 'canvas' );

				canvas.width = image.width;
				canvas.height = image.height;

				const context = canvas.getContext( '2d' );
				context.drawImage( image, 0, 0, image.width, image.height );

				const imageData = context.getImageData( 0, 0, image.width, image.height );
				const data = imageData.data;

				for ( let i = 0; i < data.length; i ++ ) {

					data[ i ] = SRGBToLinear( data[ i ] / 255 ) * 255;

				}

				context.putImageData( imageData, 0, 0 );

				return canvas;

			} else if ( image.data ) {

				const data = image.data.slice( 0 );

				for ( let i = 0; i < data.length; i ++ ) {

					if ( data instanceof Uint8Array || data instanceof Uint8ClampedArray ) {

						data[ i ] = Math.floor( SRGBToLinear( data[ i ] / 255 ) * 255 );

					} else {

						// assuming float

						data[ i ] = SRGBToLinear( data[ i ] );

					}

				}

				return {
					data: data,
					width: image.width,
					height: image.height
				};

			} else {

				console.warn( 'THREE.ImageUtils.sRGBToLinear(): Unsupported image type. No color space conversion applied.' );
				return image;

			}

		}

	}

	let _sourceId = 0;

	/**
	 * Represents the data source of a texture.
	 *
	 * The main purpose of this class is to decouple the data definition from the texture
	 * definition so the same data can be used with multiple texture instances.
	 */
	class Source {

		/**
		 * Constructs a new video texture.
		 *
		 * @param {any} [data=null] - The data definition of a texture.
		 */
		constructor( data = null ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isSource = true;

			/**
			 * The ID of the source.
			 *
			 * @name Source#id
			 * @type {number}
			 * @readonly
			 */
			Object.defineProperty( this, 'id', { value: _sourceId ++ } );

			/**
			 * The UUID of the source.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.uuid = generateUUID();

			/**
			 * The data definition of a texture.
			 *
			 * @type {any}
			 */
			this.data = data;

			/**
			 * This property is only relevant when {@link Source#needsUpdate} is set to `true` and
			 * provides more control on how texture data should be processed. When `dataReady` is set
			 * to `false`, the engine performs the memory allocation (if necessary) but does not transfer
			 * the data into the GPU memory.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.dataReady = true;

			/**
			 * This starts at `0` and counts how many times {@link Source#needsUpdate} is set to `true`.
			 *
			 * @type {number}
			 * @readonly
			 * @default 0
			 */
			this.version = 0;

		}

		getSize( target ) {

			const data = this.data;

			if ( data instanceof HTMLVideoElement ) {

				target.set( data.videoWidth, data.videoHeight );

			} else if ( data !== null ) {

				target.set( data.width, data.height, data.depth || 0 );

			} else {

				target.set( 0, 0, 0 );

			}

			return target;

		}

		/**
		 * When the property is set to `true`, the engine allocates the memory
		 * for the texture (if necessary) and triggers the actual texture upload
		 * to the GPU next time the source is used.
		 *
		 * @type {boolean}
		 * @default false
		 * @param {boolean} value
		 */
		set needsUpdate( value ) {

			if ( value === true ) this.version ++;

		}

		/**
		 * Serializes the source into JSON.
		 *
		 * @param {?(Object|string)} meta - An optional value holding meta information about the serialization.
		 * @return {Object} A JSON object representing the serialized source.
		 * @see {@link ObjectLoader#parse}
		 */
		toJSON( meta ) {

			const isRootObject = ( meta === undefined || typeof meta === 'string' );

			if ( ! isRootObject && meta.images[ this.uuid ] !== undefined ) {

				return meta.images[ this.uuid ];

			}

			const output = {
				uuid: this.uuid,
				url: ''
			};

			const data = this.data;

			if ( data !== null ) {

				let url;

				if ( Array.isArray( data ) ) {

					// cube texture

					url = [];

					for ( let i = 0, l = data.length; i < l; i ++ ) {

						if ( data[ i ].isDataTexture ) {

							url.push( serializeImage( data[ i ].image ) );

						} else {

							url.push( serializeImage( data[ i ] ) );

						}

					}

				} else {

					// texture

					url = serializeImage( data );

				}

				output.url = url;

			}

			if ( ! isRootObject ) {

				meta.images[ this.uuid ] = output;

			}

			return output;

		}

	}

	function serializeImage( image ) {

		if ( ( typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement ) ||
			( typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement ) ||
			( typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap ) ) {

			// default images

			return ImageUtils.getDataURL( image );

		} else {

			if ( image.data ) {

				// images of DataTexture

				return {
					data: Array.from( image.data ),
					width: image.width,
					height: image.height,
					type: image.data.constructor.name
				};

			} else {

				console.warn( 'THREE.Texture: Unable to serialize Texture.' );
				return {};

			}

		}

	}

	let _textureId = 0;

	const _tempVec3 = /*@__PURE__*/ new Vector3();

	/**
	 * Base class for all textures.
	 *
	 * Note: After the initial use of a texture, its dimensions, format, and type
	 * cannot be changed. Instead, call {@link Texture#dispose} on the texture and instantiate a new one.
	 *
	 * @augments EventDispatcher
	 */
	class Texture extends EventDispatcher {

		/**
		 * Constructs a new texture.
		 *
		 * @param {?Object} [image=Texture.DEFAULT_IMAGE] - The image holding the texture data.
		 * @param {number} [mapping=Texture.DEFAULT_MAPPING] - The texture mapping.
		 * @param {number} [wrapS=ClampToEdgeWrapping] - The wrapS value.
		 * @param {number} [wrapT=ClampToEdgeWrapping] - The wrapT value.
		 * @param {number} [magFilter=LinearFilter] - The mag filter value.
		 * @param {number} [minFilter=LinearMipmapLinearFilter] - The min filter value.
		 * @param {number} [format=RGBAFormat] - The texture format.
		 * @param {number} [type=UnsignedByteType] - The texture type.
		 * @param {number} [anisotropy=Texture.DEFAULT_ANISOTROPY] - The anisotropy value.
		 * @param {string} [colorSpace=NoColorSpace] - The color space.
		 */
		constructor( image = Texture.DEFAULT_IMAGE, mapping = Texture.DEFAULT_MAPPING, wrapS = ClampToEdgeWrapping, wrapT = ClampToEdgeWrapping, magFilter = LinearFilter, minFilter = LinearMipmapLinearFilter, format = RGBAFormat, type = UnsignedByteType, anisotropy = Texture.DEFAULT_ANISOTROPY, colorSpace = NoColorSpace ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isTexture = true;

			/**
			 * The ID of the texture.
			 *
			 * @name Texture#id
			 * @type {number}
			 * @readonly
			 */
			Object.defineProperty( this, 'id', { value: _textureId ++ } );

			/**
			 * The UUID of the material.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.uuid = generateUUID();

			/**
			 * The name of the material.
			 *
			 * @type {string}
			 */
			this.name = '';

			/**
			 * The data definition of a texture. A reference to the data source can be
			 * shared across textures. This is often useful in context of spritesheets
			 * where multiple textures render the same data but with different texture
			 * transformations.
			 *
			 * @type {Source}
			 */
			this.source = new Source( image );

			/**
			 * An array holding user-defined mipmaps.
			 *
			 * @type {Array<Object>}
			 */
			this.mipmaps = [];

			/**
			 * How the texture is applied to the object. The value `UVMapping`
			 * is the default, where texture or uv coordinates are used to apply the map.
			 *
			 * @type {(UVMapping|CubeReflectionMapping|CubeRefractionMapping|EquirectangularReflectionMapping|EquirectangularRefractionMapping|CubeUVReflectionMapping)}
			 * @default UVMapping
			*/
			this.mapping = mapping;

			/**
			 * Lets you select the uv attribute to map the texture to. `0` for `uv`,
			 * `1` for `uv1`, `2` for `uv2` and `3` for `uv3`.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.channel = 0;

			/**
			 * This defines how the texture is wrapped horizontally and corresponds to
			 * *U* in UV mapping.
			 *
			 * @type {(RepeatWrapping|ClampToEdgeWrapping|MirroredRepeatWrapping)}
			 * @default ClampToEdgeWrapping
			 */
			this.wrapS = wrapS;

			/**
			 * This defines how the texture is wrapped horizontally and corresponds to
			 * *V* in UV mapping.
			 *
			 * @type {(RepeatWrapping|ClampToEdgeWrapping|MirroredRepeatWrapping)}
			 * @default ClampToEdgeWrapping
			 */
			this.wrapT = wrapT;

			/**
			 * How the texture is sampled when a texel covers more than one pixel.
			 *
			 * @type {(NearestFilter|NearestMipmapNearestFilter|NearestMipmapLinearFilter|LinearFilter|LinearMipmapNearestFilter|LinearMipmapLinearFilter)}
			 * @default LinearFilter
			 */
			this.magFilter = magFilter;

			/**
			 * How the texture is sampled when a texel covers less than one pixel.
			 *
			 * @type {(NearestFilter|NearestMipmapNearestFilter|NearestMipmapLinearFilter|LinearFilter|LinearMipmapNearestFilter|LinearMipmapLinearFilter)}
			 * @default LinearMipmapLinearFilter
			 */
			this.minFilter = minFilter;

			/**
			 * The number of samples taken along the axis through the pixel that has the
			 * highest density of texels. By default, this value is `1`. A higher value
			 * gives a less blurry result than a basic mipmap, at the cost of more
			 * texture samples being used.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.anisotropy = anisotropy;

			/**
			 * The format of the texture.
			 *
			 * @type {number}
			 * @default RGBAFormat
			 */
			this.format = format;

			/**
			 * The default internal format is derived from {@link Texture#format} and {@link Texture#type} and
			 * defines how the texture data is going to be stored on the GPU.
			 *
			 * This property allows to overwrite the default format.
			 *
			 * @type {?string}
			 * @default null
			 */
			this.internalFormat = null;

			/**
			 * The data type of the texture.
			 *
			 * @type {number}
			 * @default UnsignedByteType
			 */
			this.type = type;

			/**
			 * How much a single repetition of the texture is offset from the beginning,
			 * in each direction U and V. Typical range is `0.0` to `1.0`.
			 *
			 * @type {Vector2}
			 * @default (0,0)
			 */
			this.offset = new Vector2( 0, 0 );

			/**
			 * How many times the texture is repeated across the surface, in each
			 * direction U and V. If repeat is set greater than `1` in either direction,
			 * the corresponding wrap parameter should also be set to `RepeatWrapping`
			 * or `MirroredRepeatWrapping` to achieve the desired tiling effect.
			 *
			 * @type {Vector2}
			 * @default (1,1)
			 */
			this.repeat = new Vector2( 1, 1 );

			/**
			 * The point around which rotation occurs. A value of `(0.5, 0.5)` corresponds
			 * to the center of the texture. Default is `(0, 0)`, the lower left.
			 *
			 * @type {Vector2}
			 * @default (0,0)
			 */
			this.center = new Vector2( 0, 0 );

			/**
			 * How much the texture is rotated around the center point, in radians.
			 * Positive values are counter-clockwise.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.rotation = 0;

			/**
			 * Whether to update the texture's uv-transformation {@link Texture#matrix}
			 * from the properties {@link Texture#offset}, {@link Texture#repeat},
			 * {@link Texture#rotation}, and {@link Texture#center}.
			 *
			 * Set this to `false` if you are specifying the uv-transform matrix directly.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.matrixAutoUpdate = true;

			/**
			 * The uv-transformation matrix of the texture.
			 *
			 * @type {Matrix3}
			 */
			this.matrix = new Matrix3();

			/**
			 * Whether to generate mipmaps (if possible) for a texture.
			 *
			 * Set this to `false` if you are creating mipmaps manually.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.generateMipmaps = true;

			/**
			 * If set to `true`, the alpha channel, if present, is multiplied into the
			 * color channels when the texture is uploaded to the GPU.
			 *
			 * Note that this property has no effect when using `ImageBitmap`. You need to
			 * configure premultiply alpha on bitmap creation instead.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.premultiplyAlpha = false;

			/**
			 * If set to `true`, the texture is flipped along the vertical axis when
			 * uploaded to the GPU.
			 *
			 * Note that this property has no effect when using `ImageBitmap`. You need to
			 * configure the flip on bitmap creation instead.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.flipY = true;

			/**
			 * Specifies the alignment requirements for the start of each pixel row in memory.
			 * The allowable values are `1` (byte-alignment), `2` (rows aligned to even-numbered bytes),
			 * `4` (word-alignment), and `8` (rows start on double-word boundaries).
			 *
			 * @type {number}
			 * @default 4
			 */
			this.unpackAlignment = 4;	// valid values: 1, 2, 4, 8 (see http://www.khronos.org/opengles/sdk/docs/man/xhtml/glPixelStorei.xml)

			/**
			 * Textures containing color data should be annotated with `SRGBColorSpace` or `LinearSRGBColorSpace`.
			 *
			 * @type {string}
			 * @default NoColorSpace
			 */
			this.colorSpace = colorSpace;

			/**
			 * An object that can be used to store custom data about the texture. It
			 * should not hold references to functions as these will not be cloned.
			 *
			 * @type {Object}
			 */
			this.userData = {};

			/**
			 * This can be used to only update a subregion or specific rows of the texture (for example, just the
			 * first 3 rows). Use the `addUpdateRange()` function to add ranges to this array.
			 *
			 * @type {Array<Object>}
			 */
			this.updateRanges = [];

			/**
			 * This starts at `0` and counts how many times {@link Texture#needsUpdate} is set to `true`.
			 *
			 * @type {number}
			 * @readonly
			 * @default 0
			 */
			this.version = 0;

			/**
			 * A callback function, called when the texture is updated (e.g., when
			 * {@link Texture#needsUpdate} has been set to true and then the texture is used).
			 *
			 * @type {?Function}
			 * @default null
			 */
			this.onUpdate = null;

			/**
			 * An optional back reference to the textures render target.
			 *
			 * @type {?(RenderTarget|WebGLRenderTarget)}
			 * @default null
			 */
			this.renderTarget = null;

			/**
			 * Indicates whether a texture belongs to a render target or not.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default false
			 */
			this.isRenderTargetTexture = false;

			/**
			 * Indicates if a texture should be handled like a texture array.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default false
			 */
			this.isArrayTexture = image && image.depth && image.depth > 1 ? true : false;

			/**
			 * Indicates whether this texture should be processed by `PMREMGenerator` or not
			 * (only relevant for render target textures).
			 *
			 * @type {number}
			 * @readonly
			 * @default 0
			 */
			this.pmremVersion = 0;

		}

		/**
		 * The width of the texture in pixels.
		 */
		get width() {

			return this.source.getSize( _tempVec3 ).x;

		}

		/**
		 * The height of the texture in pixels.
		 */
		get height() {

			return this.source.getSize( _tempVec3 ).y;

		}

		/**
		 * The depth of the texture in pixels.
		 */
		get depth() {

			return this.source.getSize( _tempVec3 ).z;

		}

		/**
		 * The image object holding the texture data.
		 *
		 * @type {?Object}
		 */
		get image() {

			return this.source.data;

		}

		set image( value = null ) {

			this.source.data = value;

		}

		/**
		 * Updates the texture transformation matrix from the from the properties {@link Texture#offset},
		 * {@link Texture#repeat}, {@link Texture#rotation}, and {@link Texture#center}.
		 */
		updateMatrix() {

			this.matrix.setUvTransform( this.offset.x, this.offset.y, this.repeat.x, this.repeat.y, this.rotation, this.center.x, this.center.y );

		}

		/**
		 * Adds a range of data in the data texture to be updated on the GPU.
		 *
		 * @param {number} start - Position at which to start update.
		 * @param {number} count - The number of components to update.
		 */
		addUpdateRange( start, count ) {

			this.updateRanges.push( { start, count } );

		}

		/**
		 * Clears the update ranges.
		 */
		clearUpdateRanges() {

			this.updateRanges.length = 0;

		}

		/**
		 * Returns a new texture with copied values from this instance.
		 *
		 * @return {Texture} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Copies the values of the given texture to this instance.
		 *
		 * @param {Texture} source - The texture to copy.
		 * @return {Texture} A reference to this instance.
		 */
		copy( source ) {

			this.name = source.name;

			this.source = source.source;
			this.mipmaps = source.mipmaps.slice( 0 );

			this.mapping = source.mapping;
			this.channel = source.channel;

			this.wrapS = source.wrapS;
			this.wrapT = source.wrapT;

			this.magFilter = source.magFilter;
			this.minFilter = source.minFilter;

			this.anisotropy = source.anisotropy;

			this.format = source.format;
			this.internalFormat = source.internalFormat;
			this.type = source.type;

			this.offset.copy( source.offset );
			this.repeat.copy( source.repeat );
			this.center.copy( source.center );
			this.rotation = source.rotation;

			this.matrixAutoUpdate = source.matrixAutoUpdate;
			this.matrix.copy( source.matrix );

			this.generateMipmaps = source.generateMipmaps;
			this.premultiplyAlpha = source.premultiplyAlpha;
			this.flipY = source.flipY;
			this.unpackAlignment = source.unpackAlignment;
			this.colorSpace = source.colorSpace;

			this.renderTarget = source.renderTarget;
			this.isRenderTargetTexture = source.isRenderTargetTexture;
			this.isArrayTexture = source.isArrayTexture;

			this.userData = JSON.parse( JSON.stringify( source.userData ) );

			this.needsUpdate = true;

			return this;

		}

		/**
		 * Sets this texture's properties based on `values`.
		 * @param {Object} values - A container with texture parameters.
		 */
		setValues( values ) {

			for ( const key in values ) {

				const newValue = values[ key ];

				if ( newValue === undefined ) {

					console.warn( `THREE.Texture.setValues(): parameter '${ key }' has value of undefined.` );
					continue;

				}

				const currentValue = this[ key ];

				if ( currentValue === undefined ) {

					console.warn( `THREE.Texture.setValues(): property '${ key }' does not exist.` );
					continue;

				}

				if ( ( currentValue && newValue ) && ( currentValue.isVector2 && newValue.isVector2 ) ) {

					currentValue.copy( newValue );

				} else if ( ( currentValue && newValue ) && ( currentValue.isVector3 && newValue.isVector3 ) ) {

					currentValue.copy( newValue );

				} else if ( ( currentValue && newValue ) && ( currentValue.isMatrix3 && newValue.isMatrix3 ) ) {

					currentValue.copy( newValue );

				} else {

					this[ key ] = newValue;

				}

			}

		}

		/**
		 * Serializes the texture into JSON.
		 *
		 * @param {?(Object|string)} meta - An optional value holding meta information about the serialization.
		 * @return {Object} A JSON object representing the serialized texture.
		 * @see {@link ObjectLoader#parse}
		 */
		toJSON( meta ) {

			const isRootObject = ( meta === undefined || typeof meta === 'string' );

			if ( ! isRootObject && meta.textures[ this.uuid ] !== undefined ) {

				return meta.textures[ this.uuid ];

			}

			const output = {

				metadata: {
					version: 4.7,
					type: 'Texture',
					generator: 'Texture.toJSON'
				},

				uuid: this.uuid,
				name: this.name,

				image: this.source.toJSON( meta ).uuid,

				mapping: this.mapping,
				channel: this.channel,

				repeat: [ this.repeat.x, this.repeat.y ],
				offset: [ this.offset.x, this.offset.y ],
				center: [ this.center.x, this.center.y ],
				rotation: this.rotation,

				wrap: [ this.wrapS, this.wrapT ],

				format: this.format,
				internalFormat: this.internalFormat,
				type: this.type,
				colorSpace: this.colorSpace,

				minFilter: this.minFilter,
				magFilter: this.magFilter,
				anisotropy: this.anisotropy,

				flipY: this.flipY,

				generateMipmaps: this.generateMipmaps,
				premultiplyAlpha: this.premultiplyAlpha,
				unpackAlignment: this.unpackAlignment

			};

			if ( Object.keys( this.userData ).length > 0 ) output.userData = this.userData;

			if ( ! isRootObject ) {

				meta.textures[ this.uuid ] = output;

			}

			return output;

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 *
		 * @fires Texture#dispose
		 */
		dispose() {

			/**
			 * Fires when the texture has been disposed of.
			 *
			 * @event Texture#dispose
			 * @type {Object}
			 */
			this.dispatchEvent( { type: 'dispose' } );

		}

		/**
		 * Transforms the given uv vector with the textures uv transformation matrix.
		 *
		 * @param {Vector2} uv - The uv vector.
		 * @return {Vector2} The transformed uv vector.
		 */
		transformUv( uv ) {

			if ( this.mapping !== UVMapping ) return uv;

			uv.applyMatrix3( this.matrix );

			if ( uv.x < 0 || uv.x > 1 ) {

				switch ( this.wrapS ) {

					case RepeatWrapping:

						uv.x = uv.x - Math.floor( uv.x );
						break;

					case ClampToEdgeWrapping:

						uv.x = uv.x < 0 ? 0 : 1;
						break;

					case MirroredRepeatWrapping:

						if ( Math.abs( Math.floor( uv.x ) % 2 ) === 1 ) {

							uv.x = Math.ceil( uv.x ) - uv.x;

						} else {

							uv.x = uv.x - Math.floor( uv.x );

						}

						break;

				}

			}

			if ( uv.y < 0 || uv.y > 1 ) {

				switch ( this.wrapT ) {

					case RepeatWrapping:

						uv.y = uv.y - Math.floor( uv.y );
						break;

					case ClampToEdgeWrapping:

						uv.y = uv.y < 0 ? 0 : 1;
						break;

					case MirroredRepeatWrapping:

						if ( Math.abs( Math.floor( uv.y ) % 2 ) === 1 ) {

							uv.y = Math.ceil( uv.y ) - uv.y;

						} else {

							uv.y = uv.y - Math.floor( uv.y );

						}

						break;

				}

			}

			if ( this.flipY ) {

				uv.y = 1 - uv.y;

			}

			return uv;

		}

		/**
		 * Setting this property to `true` indicates the engine the texture
		 * must be updated in the next render. This triggers a texture upload
		 * to the GPU and ensures correct texture parameter configuration.
		 *
		 * @type {boolean}
		 * @default false
		 * @param {boolean} value
		 */
		set needsUpdate( value ) {

			if ( value === true ) {

				this.version ++;
				this.source.needsUpdate = true;

			}

		}

		/**
		 * Setting this property to `true` indicates the engine the PMREM
		 * must be regenerated.
		 *
		 * @type {boolean}
		 * @default false
		 * @param {boolean} value
		 */
		set needsPMREMUpdate( value ) {

			if ( value === true ) {

				this.pmremVersion ++;

			}

		}

	}

	/**
	 * The default image for all textures.
	 *
	 * @static
	 * @type {?Image}
	 * @default null
	 */
	Texture.DEFAULT_IMAGE = null;

	/**
	 * The default mapping for all textures.
	 *
	 * @static
	 * @type {number}
	 * @default UVMapping
	 */
	Texture.DEFAULT_MAPPING = UVMapping;

	/**
	 * The default anisotropy value for all textures.
	 *
	 * @static
	 * @type {number}
	 * @default 1
	 */
	Texture.DEFAULT_ANISOTROPY = 1;

	/**
	 * Class representing a 4D vector. A 4D vector is an ordered quadruplet of numbers
	 * (labeled x, y, z and w), which can be used to represent a number of things, such as:
	 *
	 * - A point in 4D space.
	 * - A direction and length in 4D space. In three.js the length will
	 * always be the Euclidean distance(straight-line distance) from `(0, 0, 0, 0)` to `(x, y, z, w)`
	 * and the direction is also measured from `(0, 0, 0, 0)` towards `(x, y, z, w)`.
	 * - Any arbitrary ordered quadruplet of numbers.
	 *
	 * There are other things a 4D vector can be used to represent, however these
	 * are the most common uses in *three.js*.
	 *
	 * Iterating through a vector instance will yield its components `(x, y, z, w)` in
	 * the corresponding order.
	 * ```js
	 * const a = new THREE.Vector4( 0, 1, 0, 0 );
	 *
	 * //no arguments; will be initialised to (0, 0, 0, 1)
	 * const b = new THREE.Vector4( );
	 *
	 * const d = a.dot( b );
	 * ```
	 */
	class Vector4 {

		/**
		 * Constructs a new 4D vector.
		 *
		 * @param {number} [x=0] - The x value of this vector.
		 * @param {number} [y=0] - The y value of this vector.
		 * @param {number} [z=0] - The z value of this vector.
		 * @param {number} [w=1] - The w value of this vector.
		 */
		constructor( x = 0, y = 0, z = 0, w = 1 ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			Vector4.prototype.isVector4 = true;

			/**
			 * The x value of this vector.
			 *
			 * @type {number}
			 */
			this.x = x;

			/**
			 * The y value of this vector.
			 *
			 * @type {number}
			 */
			this.y = y;

			/**
			 * The z value of this vector.
			 *
			 * @type {number}
			 */
			this.z = z;

			/**
			 * The w value of this vector.
			 *
			 * @type {number}
			 */
			this.w = w;

		}

		/**
		 * Alias for {@link Vector4#z}.
		 *
		 * @type {number}
		 */
		get width() {

			return this.z;

		}

		set width( value ) {

			this.z = value;

		}

		/**
		 * Alias for {@link Vector4#w}.
		 *
		 * @type {number}
		 */
		get height() {

			return this.w;

		}

		set height( value ) {

			this.w = value;

		}

		/**
		 * Sets the vector components.
		 *
		 * @param {number} x - The value of the x component.
		 * @param {number} y - The value of the y component.
		 * @param {number} z - The value of the z component.
		 * @param {number} w - The value of the w component.
		 * @return {Vector4} A reference to this vector.
		 */
		set( x, y, z, w ) {

			this.x = x;
			this.y = y;
			this.z = z;
			this.w = w;

			return this;

		}

		/**
		 * Sets the vector components to the same value.
		 *
		 * @param {number} scalar - The value to set for all vector components.
		 * @return {Vector4} A reference to this vector.
		 */
		setScalar( scalar ) {

			this.x = scalar;
			this.y = scalar;
			this.z = scalar;
			this.w = scalar;

			return this;

		}

		/**
		 * Sets the vector's x component to the given value
		 *
		 * @param {number} x - The value to set.
		 * @return {Vector4} A reference to this vector.
		 */
		setX( x ) {

			this.x = x;

			return this;

		}

		/**
		 * Sets the vector's y component to the given value
		 *
		 * @param {number} y - The value to set.
		 * @return {Vector4} A reference to this vector.
		 */
		setY( y ) {

			this.y = y;

			return this;

		}

		/**
		 * Sets the vector's z component to the given value
		 *
		 * @param {number} z - The value to set.
		 * @return {Vector4} A reference to this vector.
		 */
		setZ( z ) {

			this.z = z;

			return this;

		}

		/**
		 * Sets the vector's w component to the given value
		 *
		 * @param {number} w - The value to set.
		 * @return {Vector4} A reference to this vector.
		 */
		setW( w ) {

			this.w = w;

			return this;

		}

		/**
		 * Allows to set a vector component with an index.
		 *
		 * @param {number} index - The component index. `0` equals to x, `1` equals to y,
		 * `2` equals to z, `3` equals to w.
		 * @param {number} value - The value to set.
		 * @return {Vector4} A reference to this vector.
		 */
		setComponent( index, value ) {

			switch ( index ) {

				case 0: this.x = value; break;
				case 1: this.y = value; break;
				case 2: this.z = value; break;
				case 3: this.w = value; break;
				default: throw new Error( 'index is out of range: ' + index );

			}

			return this;

		}

		/**
		 * Returns the value of the vector component which matches the given index.
		 *
		 * @param {number} index - The component index. `0` equals to x, `1` equals to y,
		 * `2` equals to z, `3` equals to w.
		 * @return {number} A vector component value.
		 */
		getComponent( index ) {

			switch ( index ) {

				case 0: return this.x;
				case 1: return this.y;
				case 2: return this.z;
				case 3: return this.w;
				default: throw new Error( 'index is out of range: ' + index );

			}

		}

		/**
		 * Returns a new vector with copied values from this instance.
		 *
		 * @return {Vector4} A clone of this instance.
		 */
		clone() {

			return new this.constructor( this.x, this.y, this.z, this.w );

		}

		/**
		 * Copies the values of the given vector to this instance.
		 *
		 * @param {Vector3|Vector4} v - The vector to copy.
		 * @return {Vector4} A reference to this vector.
		 */
		copy( v ) {

			this.x = v.x;
			this.y = v.y;
			this.z = v.z;
			this.w = ( v.w !== undefined ) ? v.w : 1;

			return this;

		}

		/**
		 * Adds the given vector to this instance.
		 *
		 * @param {Vector4} v - The vector to add.
		 * @return {Vector4} A reference to this vector.
		 */
		add( v ) {

			this.x += v.x;
			this.y += v.y;
			this.z += v.z;
			this.w += v.w;

			return this;

		}

		/**
		 * Adds the given scalar value to all components of this instance.
		 *
		 * @param {number} s - The scalar to add.
		 * @return {Vector4} A reference to this vector.
		 */
		addScalar( s ) {

			this.x += s;
			this.y += s;
			this.z += s;
			this.w += s;

			return this;

		}

		/**
		 * Adds the given vectors and stores the result in this instance.
		 *
		 * @param {Vector4} a - The first vector.
		 * @param {Vector4} b - The second vector.
		 * @return {Vector4} A reference to this vector.
		 */
		addVectors( a, b ) {

			this.x = a.x + b.x;
			this.y = a.y + b.y;
			this.z = a.z + b.z;
			this.w = a.w + b.w;

			return this;

		}

		/**
		 * Adds the given vector scaled by the given factor to this instance.
		 *
		 * @param {Vector4} v - The vector.
		 * @param {number} s - The factor that scales `v`.
		 * @return {Vector4} A reference to this vector.
		 */
		addScaledVector( v, s ) {

			this.x += v.x * s;
			this.y += v.y * s;
			this.z += v.z * s;
			this.w += v.w * s;

			return this;

		}

		/**
		 * Subtracts the given vector from this instance.
		 *
		 * @param {Vector4} v - The vector to subtract.
		 * @return {Vector4} A reference to this vector.
		 */
		sub( v ) {

			this.x -= v.x;
			this.y -= v.y;
			this.z -= v.z;
			this.w -= v.w;

			return this;

		}

		/**
		 * Subtracts the given scalar value from all components of this instance.
		 *
		 * @param {number} s - The scalar to subtract.
		 * @return {Vector4} A reference to this vector.
		 */
		subScalar( s ) {

			this.x -= s;
			this.y -= s;
			this.z -= s;
			this.w -= s;

			return this;

		}

		/**
		 * Subtracts the given vectors and stores the result in this instance.
		 *
		 * @param {Vector4} a - The first vector.
		 * @param {Vector4} b - The second vector.
		 * @return {Vector4} A reference to this vector.
		 */
		subVectors( a, b ) {

			this.x = a.x - b.x;
			this.y = a.y - b.y;
			this.z = a.z - b.z;
			this.w = a.w - b.w;

			return this;

		}

		/**
		 * Multiplies the given vector with this instance.
		 *
		 * @param {Vector4} v - The vector to multiply.
		 * @return {Vector4} A reference to this vector.
		 */
		multiply( v ) {

			this.x *= v.x;
			this.y *= v.y;
			this.z *= v.z;
			this.w *= v.w;

			return this;

		}

		/**
		 * Multiplies the given scalar value with all components of this instance.
		 *
		 * @param {number} scalar - The scalar to multiply.
		 * @return {Vector4} A reference to this vector.
		 */
		multiplyScalar( scalar ) {

			this.x *= scalar;
			this.y *= scalar;
			this.z *= scalar;
			this.w *= scalar;

			return this;

		}

		/**
		 * Multiplies this vector with the given 4x4 matrix.
		 *
		 * @param {Matrix4} m - The 4x4 matrix.
		 * @return {Vector4} A reference to this vector.
		 */
		applyMatrix4( m ) {

			const x = this.x, y = this.y, z = this.z, w = this.w;
			const e = m.elements;

			this.x = e[ 0 ] * x + e[ 4 ] * y + e[ 8 ] * z + e[ 12 ] * w;
			this.y = e[ 1 ] * x + e[ 5 ] * y + e[ 9 ] * z + e[ 13 ] * w;
			this.z = e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] * w;
			this.w = e[ 3 ] * x + e[ 7 ] * y + e[ 11 ] * z + e[ 15 ] * w;

			return this;

		}

		/**
		 * Divides this instance by the given vector.
		 *
		 * @param {Vector4} v - The vector to divide.
		 * @return {Vector4} A reference to this vector.
		 */
		divide( v ) {

			this.x /= v.x;
			this.y /= v.y;
			this.z /= v.z;
			this.w /= v.w;

			return this;

		}

		/**
		 * Divides this vector by the given scalar.
		 *
		 * @param {number} scalar - The scalar to divide.
		 * @return {Vector4} A reference to this vector.
		 */
		divideScalar( scalar ) {

			return this.multiplyScalar( 1 / scalar );

		}

		/**
		 * Sets the x, y and z components of this
		 * vector to the quaternion's axis and w to the angle.
		 *
		 * @param {Quaternion} q - The Quaternion to set.
		 * @return {Vector4} A reference to this vector.
		 */
		setAxisAngleFromQuaternion( q ) {

			// http://www.euclideanspace.com/maths/geometry/rotations/conversions/quaternionToAngle/index.htm

			// q is assumed to be normalized

			this.w = 2 * Math.acos( q.w );

			const s = Math.sqrt( 1 - q.w * q.w );

			if ( s < 0.0001 ) {

				this.x = 1;
				this.y = 0;
				this.z = 0;

			} else {

				this.x = q.x / s;
				this.y = q.y / s;
				this.z = q.z / s;

			}

			return this;

		}

		/**
		 * Sets the x, y and z components of this
		 * vector to the axis of rotation and w to the angle.
		 *
		 * @param {Matrix4} m - A 4x4 matrix of which the upper left 3x3 matrix is a pure rotation matrix.
		 * @return {Vector4} A reference to this vector.
		 */
		setAxisAngleFromRotationMatrix( m ) {

			// http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToAngle/index.htm

			// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)

			let angle, x, y, z; // variables for result
			const epsilon = 0.01,		// margin to allow for rounding errors
				epsilon2 = 0.1,		// margin to distinguish between 0 and 180 degrees

				te = m.elements,

				m11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ],
				m21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ],
				m31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ];

			if ( ( Math.abs( m12 - m21 ) < epsilon ) &&
			     ( Math.abs( m13 - m31 ) < epsilon ) &&
			     ( Math.abs( m23 - m32 ) < epsilon ) ) {

				// singularity found
				// first check for identity matrix which must have +1 for all terms
				// in leading diagonal and zero in other terms

				if ( ( Math.abs( m12 + m21 ) < epsilon2 ) &&
				     ( Math.abs( m13 + m31 ) < epsilon2 ) &&
				     ( Math.abs( m23 + m32 ) < epsilon2 ) &&
				     ( Math.abs( m11 + m22 + m33 - 3 ) < epsilon2 ) ) {

					// this singularity is identity matrix so angle = 0

					this.set( 1, 0, 0, 0 );

					return this; // zero angle, arbitrary axis

				}

				// otherwise this singularity is angle = 180

				angle = Math.PI;

				const xx = ( m11 + 1 ) / 2;
				const yy = ( m22 + 1 ) / 2;
				const zz = ( m33 + 1 ) / 2;
				const xy = ( m12 + m21 ) / 4;
				const xz = ( m13 + m31 ) / 4;
				const yz = ( m23 + m32 ) / 4;

				if ( ( xx > yy ) && ( xx > zz ) ) {

					// m11 is the largest diagonal term

					if ( xx < epsilon ) {

						x = 0;
						y = 0.707106781;
						z = 0.707106781;

					} else {

						x = Math.sqrt( xx );
						y = xy / x;
						z = xz / x;

					}

				} else if ( yy > zz ) {

					// m22 is the largest diagonal term

					if ( yy < epsilon ) {

						x = 0.707106781;
						y = 0;
						z = 0.707106781;

					} else {

						y = Math.sqrt( yy );
						x = xy / y;
						z = yz / y;

					}

				} else {

					// m33 is the largest diagonal term so base result on this

					if ( zz < epsilon ) {

						x = 0.707106781;
						y = 0.707106781;
						z = 0;

					} else {

						z = Math.sqrt( zz );
						x = xz / z;
						y = yz / z;

					}

				}

				this.set( x, y, z, angle );

				return this; // return 180 deg rotation

			}

			// as we have reached here there are no singularities so we can handle normally

			let s = Math.sqrt( ( m32 - m23 ) * ( m32 - m23 ) +
				( m13 - m31 ) * ( m13 - m31 ) +
				( m21 - m12 ) * ( m21 - m12 ) ); // used to normalize

			if ( Math.abs( s ) < 0.001 ) s = 1;

			// prevent divide by zero, should not happen if matrix is orthogonal and should be
			// caught by singularity test above, but I've left it in just in case

			this.x = ( m32 - m23 ) / s;
			this.y = ( m13 - m31 ) / s;
			this.z = ( m21 - m12 ) / s;
			this.w = Math.acos( ( m11 + m22 + m33 - 1 ) / 2 );

			return this;

		}

		/**
		 * Sets the vector components to the position elements of the
		 * given transformation matrix.
		 *
		 * @param {Matrix4} m - The 4x4 matrix.
		 * @return {Vector4} A reference to this vector.
		 */
		setFromMatrixPosition( m ) {

			const e = m.elements;

			this.x = e[ 12 ];
			this.y = e[ 13 ];
			this.z = e[ 14 ];
			this.w = e[ 15 ];

			return this;

		}

		/**
		 * If this vector's x, y, z or w value is greater than the given vector's x, y, z or w
		 * value, replace that value with the corresponding min value.
		 *
		 * @param {Vector4} v - The vector.
		 * @return {Vector4} A reference to this vector.
		 */
		min( v ) {

			this.x = Math.min( this.x, v.x );
			this.y = Math.min( this.y, v.y );
			this.z = Math.min( this.z, v.z );
			this.w = Math.min( this.w, v.w );

			return this;

		}

		/**
		 * If this vector's x, y, z or w value is less than the given vector's x, y, z or w
		 * value, replace that value with the corresponding max value.
		 *
		 * @param {Vector4} v - The vector.
		 * @return {Vector4} A reference to this vector.
		 */
		max( v ) {

			this.x = Math.max( this.x, v.x );
			this.y = Math.max( this.y, v.y );
			this.z = Math.max( this.z, v.z );
			this.w = Math.max( this.w, v.w );

			return this;

		}

		/**
		 * If this vector's x, y, z or w value is greater than the max vector's x, y, z or w
		 * value, it is replaced by the corresponding value.
		 * If this vector's x, y, z or w value is less than the min vector's x, y, z or w value,
		 * it is replaced by the corresponding value.
		 *
		 * @param {Vector4} min - The minimum x, y and z values.
		 * @param {Vector4} max - The maximum x, y and z values in the desired range.
		 * @return {Vector4} A reference to this vector.
		 */
		clamp( min, max ) {

			// assumes min < max, componentwise

			this.x = clamp( this.x, min.x, max.x );
			this.y = clamp( this.y, min.y, max.y );
			this.z = clamp( this.z, min.z, max.z );
			this.w = clamp( this.w, min.w, max.w );

			return this;

		}

		/**
		 * If this vector's x, y, z or w values are greater than the max value, they are
		 * replaced by the max value.
		 * If this vector's x, y, z or w values are less than the min value, they are
		 * replaced by the min value.
		 *
		 * @param {number} minVal - The minimum value the components will be clamped to.
		 * @param {number} maxVal - The maximum value the components will be clamped to.
		 * @return {Vector4} A reference to this vector.
		 */
		clampScalar( minVal, maxVal ) {

			this.x = clamp( this.x, minVal, maxVal );
			this.y = clamp( this.y, minVal, maxVal );
			this.z = clamp( this.z, minVal, maxVal );
			this.w = clamp( this.w, minVal, maxVal );

			return this;

		}

		/**
		 * If this vector's length is greater than the max value, it is replaced by
		 * the max value.
		 * If this vector's length is less than the min value, it is replaced by the
		 * min value.
		 *
		 * @param {number} min - The minimum value the vector length will be clamped to.
		 * @param {number} max - The maximum value the vector length will be clamped to.
		 * @return {Vector4} A reference to this vector.
		 */
		clampLength( min, max ) {

			const length = this.length();

			return this.divideScalar( length || 1 ).multiplyScalar( clamp( length, min, max ) );

		}

		/**
		 * The components of this vector are rounded down to the nearest integer value.
		 *
		 * @return {Vector4} A reference to this vector.
		 */
		floor() {

			this.x = Math.floor( this.x );
			this.y = Math.floor( this.y );
			this.z = Math.floor( this.z );
			this.w = Math.floor( this.w );

			return this;

		}

		/**
		 * The components of this vector are rounded up to the nearest integer value.
		 *
		 * @return {Vector4} A reference to this vector.
		 */
		ceil() {

			this.x = Math.ceil( this.x );
			this.y = Math.ceil( this.y );
			this.z = Math.ceil( this.z );
			this.w = Math.ceil( this.w );

			return this;

		}

		/**
		 * The components of this vector are rounded to the nearest integer value
		 *
		 * @return {Vector4} A reference to this vector.
		 */
		round() {

			this.x = Math.round( this.x );
			this.y = Math.round( this.y );
			this.z = Math.round( this.z );
			this.w = Math.round( this.w );

			return this;

		}

		/**
		 * The components of this vector are rounded towards zero (up if negative,
		 * down if positive) to an integer value.
		 *
		 * @return {Vector4} A reference to this vector.
		 */
		roundToZero() {

			this.x = Math.trunc( this.x );
			this.y = Math.trunc( this.y );
			this.z = Math.trunc( this.z );
			this.w = Math.trunc( this.w );

			return this;

		}

		/**
		 * Inverts this vector - i.e. sets x = -x, y = -y, z = -z, w = -w.
		 *
		 * @return {Vector4} A reference to this vector.
		 */
		negate() {

			this.x = - this.x;
			this.y = - this.y;
			this.z = - this.z;
			this.w = - this.w;

			return this;

		}

		/**
		 * Calculates the dot product of the given vector with this instance.
		 *
		 * @param {Vector4} v - The vector to compute the dot product with.
		 * @return {number} The result of the dot product.
		 */
		dot( v ) {

			return this.x * v.x + this.y * v.y + this.z * v.z + this.w * v.w;

		}

		/**
		 * Computes the square of the Euclidean length (straight-line length) from
		 * (0, 0, 0, 0) to (x, y, z, w). If you are comparing the lengths of vectors, you should
		 * compare the length squared instead as it is slightly more efficient to calculate.
		 *
		 * @return {number} The square length of this vector.
		 */
		lengthSq() {

			return this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w;

		}

		/**
		 * Computes the  Euclidean length (straight-line length) from (0, 0, 0, 0) to (x, y, z, w).
		 *
		 * @return {number} The length of this vector.
		 */
		length() {

			return Math.sqrt( this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w );

		}

		/**
		 * Computes the Manhattan length of this vector.
		 *
		 * @return {number} The length of this vector.
		 */
		manhattanLength() {

			return Math.abs( this.x ) + Math.abs( this.y ) + Math.abs( this.z ) + Math.abs( this.w );

		}

		/**
		 * Converts this vector to a unit vector - that is, sets it equal to a vector
		 * with the same direction as this one, but with a vector length of `1`.
		 *
		 * @return {Vector4} A reference to this vector.
		 */
		normalize() {

			return this.divideScalar( this.length() || 1 );

		}

		/**
		 * Sets this vector to a vector with the same direction as this one, but
		 * with the specified length.
		 *
		 * @param {number} length - The new length of this vector.
		 * @return {Vector4} A reference to this vector.
		 */
		setLength( length ) {

			return this.normalize().multiplyScalar( length );

		}

		/**
		 * Linearly interpolates between the given vector and this instance, where
		 * alpha is the percent distance along the line - alpha = 0 will be this
		 * vector, and alpha = 1 will be the given one.
		 *
		 * @param {Vector4} v - The vector to interpolate towards.
		 * @param {number} alpha - The interpolation factor, typically in the closed interval `[0, 1]`.
		 * @return {Vector4} A reference to this vector.
		 */
		lerp( v, alpha ) {

			this.x += ( v.x - this.x ) * alpha;
			this.y += ( v.y - this.y ) * alpha;
			this.z += ( v.z - this.z ) * alpha;
			this.w += ( v.w - this.w ) * alpha;

			return this;

		}

		/**
		 * Linearly interpolates between the given vectors, where alpha is the percent
		 * distance along the line - alpha = 0 will be first vector, and alpha = 1 will
		 * be the second one. The result is stored in this instance.
		 *
		 * @param {Vector4} v1 - The first vector.
		 * @param {Vector4} v2 - The second vector.
		 * @param {number} alpha - The interpolation factor, typically in the closed interval `[0, 1]`.
		 * @return {Vector4} A reference to this vector.
		 */
		lerpVectors( v1, v2, alpha ) {

			this.x = v1.x + ( v2.x - v1.x ) * alpha;
			this.y = v1.y + ( v2.y - v1.y ) * alpha;
			this.z = v1.z + ( v2.z - v1.z ) * alpha;
			this.w = v1.w + ( v2.w - v1.w ) * alpha;

			return this;

		}

		/**
		 * Returns `true` if this vector is equal with the given one.
		 *
		 * @param {Vector4} v - The vector to test for equality.
		 * @return {boolean} Whether this vector is equal with the given one.
		 */
		equals( v ) {

			return ( ( v.x === this.x ) && ( v.y === this.y ) && ( v.z === this.z ) && ( v.w === this.w ) );

		}

		/**
		 * Sets this vector's x value to be `array[ offset ]`, y value to be `array[ offset + 1 ]`,
		 * z value to be `array[ offset + 2 ]`, w value to be `array[ offset + 3 ]`.
		 *
		 * @param {Array<number>} array - An array holding the vector component values.
		 * @param {number} [offset=0] - The offset into the array.
		 * @return {Vector4} A reference to this vector.
		 */
		fromArray( array, offset = 0 ) {

			this.x = array[ offset ];
			this.y = array[ offset + 1 ];
			this.z = array[ offset + 2 ];
			this.w = array[ offset + 3 ];

			return this;

		}

		/**
		 * Writes the components of this vector to the given array. If no array is provided,
		 * the method returns a new instance.
		 *
		 * @param {Array<number>} [array=[]] - The target array holding the vector components.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Array<number>} The vector components.
		 */
		toArray( array = [], offset = 0 ) {

			array[ offset ] = this.x;
			array[ offset + 1 ] = this.y;
			array[ offset + 2 ] = this.z;
			array[ offset + 3 ] = this.w;

			return array;

		}

		/**
		 * Sets the components of this vector from the given buffer attribute.
		 *
		 * @param {BufferAttribute} attribute - The buffer attribute holding vector data.
		 * @param {number} index - The index into the attribute.
		 * @return {Vector4} A reference to this vector.
		 */
		fromBufferAttribute( attribute, index ) {

			this.x = attribute.getX( index );
			this.y = attribute.getY( index );
			this.z = attribute.getZ( index );
			this.w = attribute.getW( index );

			return this;

		}

		/**
		 * Sets each component of this vector to a pseudo-random value between `0` and
		 * `1`, excluding `1`.
		 *
		 * @return {Vector4} A reference to this vector.
		 */
		random() {

			this.x = Math.random();
			this.y = Math.random();
			this.z = Math.random();
			this.w = Math.random();

			return this;

		}

		*[ Symbol.iterator ]() {

			yield this.x;
			yield this.y;
			yield this.z;
			yield this.w;

		}

	}

	/**
	 * A render target is a buffer where the video card draws pixels for a scene
	 * that is being rendered in the background. It is used in different effects,
	 * such as applying postprocessing to a rendered image before displaying it
	 * on the screen.
	 *
	 * @augments EventDispatcher
	 */
	class RenderTarget extends EventDispatcher {

		/**
		 * Render target options.
		 *
		 * @typedef {Object} RenderTarget~Options
		 * @property {boolean} [generateMipmaps=false] - Whether to generate mipmaps or not.
		 * @property {number} [magFilter=LinearFilter] - The mag filter.
		 * @property {number} [minFilter=LinearFilter] - The min filter.
		 * @property {number} [format=RGBAFormat] - The texture format.
		 * @property {number} [type=UnsignedByteType] - The texture type.
		 * @property {?string} [internalFormat=null] - The texture's internal format.
		 * @property {number} [wrapS=ClampToEdgeWrapping] - The texture's uv wrapping mode.
		 * @property {number} [wrapT=ClampToEdgeWrapping] - The texture's uv wrapping mode.
		 * @property {number} [anisotropy=1] - The texture's anisotropy value.
		 * @property {string} [colorSpace=NoColorSpace] - The texture's color space.
		 * @property {boolean} [depthBuffer=true] - Whether to allocate a depth buffer or not.
		 * @property {boolean} [stencilBuffer=false] - Whether to allocate a stencil buffer or not.
		 * @property {boolean} [resolveDepthBuffer=true] - Whether to resolve the depth buffer or not.
		 * @property {boolean} [resolveStencilBuffer=true] - Whether  to resolve the stencil buffer or not.
		 * @property {?Texture} [depthTexture=null] - Reference to a depth texture.
		 * @property {number} [samples=0] - The MSAA samples count.
		 * @property {number} [count=1] - Defines the number of color attachments . Must be at least `1`.
		 * @property {number} [depth=1] - The texture depth.
		 * @property {boolean} [multiview=false] - Whether this target is used for multiview rendering.
		 */

		/**
		 * Constructs a new render target.
		 *
		 * @param {number} [width=1] - The width of the render target.
		 * @param {number} [height=1] - The height of the render target.
		 * @param {RenderTarget~Options} [options] - The configuration object.
		 */
		constructor( width = 1, height = 1, options = {} ) {

			super();

			options = Object.assign( {
				generateMipmaps: false,
				internalFormat: null,
				minFilter: LinearFilter,
				depthBuffer: true,
				stencilBuffer: false,
				resolveDepthBuffer: true,
				resolveStencilBuffer: true,
				depthTexture: null,
				samples: 0,
				count: 1,
				depth: 1,
				multiview: false
			}, options );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isRenderTarget = true;

			/**
			 * The width of the render target.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.width = width;

			/**
			 * The height of the render target.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.height = height;

			/**
			 * The depth of the render target.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.depth = options.depth;

			/**
			 * A rectangular area inside the render target's viewport. Fragments that are
			 * outside the area will be discarded.
			 *
			 * @type {Vector4}
			 * @default (0,0,width,height)
			 */
			this.scissor = new Vector4( 0, 0, width, height );

			/**
			 * Indicates whether the scissor test should be enabled when rendering into
			 * this render target or not.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.scissorTest = false;

			/**
			 * A rectangular area representing the render target's viewport.
			 *
			 * @type {Vector4}
			 * @default (0,0,width,height)
			 */
			this.viewport = new Vector4( 0, 0, width, height );

			const image = { width: width, height: height, depth: options.depth };

			const texture = new Texture( image );

			/**
			 * An array of textures. Each color attachment is represented as a separate texture.
			 * Has at least a single entry for the default color attachment.
			 *
			 * @type {Array<Texture>}
			 */
			this.textures = [];

			const count = options.count;
			for ( let i = 0; i < count; i ++ ) {

				this.textures[ i ] = texture.clone();
				this.textures[ i ].isRenderTargetTexture = true;
				this.textures[ i ].renderTarget = this;

			}

			this._setTextureOptions( options );

			/**
			 * Whether to allocate a depth buffer or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.depthBuffer = options.depthBuffer;

			/**
			 * Whether to allocate a stencil buffer or not.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.stencilBuffer = options.stencilBuffer;

			/**
			 * Whether to resolve the depth buffer or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.resolveDepthBuffer = options.resolveDepthBuffer;

			/**
			 * Whether to resolve the stencil buffer or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.resolveStencilBuffer = options.resolveStencilBuffer;

			this._depthTexture = null;
			this.depthTexture = options.depthTexture;

			/**
			 * The number of MSAA samples.
			 *
			 * A value of `0` disables MSAA.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.samples = options.samples;

			/**
			 * Whether to this target is used in multiview rendering.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.multiview = options.multiview;

		}

		_setTextureOptions( options = {} ) {

			const values = {
				minFilter: LinearFilter,
				generateMipmaps: false,
				flipY: false,
				internalFormat: null
			};

			if ( options.mapping !== undefined ) values.mapping = options.mapping;
			if ( options.wrapS !== undefined ) values.wrapS = options.wrapS;
			if ( options.wrapT !== undefined ) values.wrapT = options.wrapT;
			if ( options.wrapR !== undefined ) values.wrapR = options.wrapR;
			if ( options.magFilter !== undefined ) values.magFilter = options.magFilter;
			if ( options.minFilter !== undefined ) values.minFilter = options.minFilter;
			if ( options.format !== undefined ) values.format = options.format;
			if ( options.type !== undefined ) values.type = options.type;
			if ( options.anisotropy !== undefined ) values.anisotropy = options.anisotropy;
			if ( options.colorSpace !== undefined ) values.colorSpace = options.colorSpace;
			if ( options.flipY !== undefined ) values.flipY = options.flipY;
			if ( options.generateMipmaps !== undefined ) values.generateMipmaps = options.generateMipmaps;
			if ( options.internalFormat !== undefined ) values.internalFormat = options.internalFormat;

			for ( let i = 0; i < this.textures.length; i ++ ) {

				const texture = this.textures[ i ];
				texture.setValues( values );

			}

		}

		/**
		 * The texture representing the default color attachment.
		 *
		 * @type {Texture}
		 */
		get texture() {

			return this.textures[ 0 ];

		}

		set texture( value ) {

			this.textures[ 0 ] = value;

		}

		set depthTexture( current ) {

			if ( this._depthTexture !== null ) this._depthTexture.renderTarget = null;
			if ( current !== null ) current.renderTarget = this;

			this._depthTexture = current;

		}

		/**
		 * Instead of saving the depth in a renderbuffer, a texture
		 * can be used instead which is useful for further processing
		 * e.g. in context of post-processing.
		 *
		 * @type {?DepthTexture}
		 * @default null
		 */
		get depthTexture() {

			return this._depthTexture;

		}

		/**
		 * Sets the size of this render target.
		 *
		 * @param {number} width - The width.
		 * @param {number} height - The height.
		 * @param {number} [depth=1] - The depth.
		 */
		setSize( width, height, depth = 1 ) {

			if ( this.width !== width || this.height !== height || this.depth !== depth ) {

				this.width = width;
				this.height = height;
				this.depth = depth;

				for ( let i = 0, il = this.textures.length; i < il; i ++ ) {

					this.textures[ i ].image.width = width;
					this.textures[ i ].image.height = height;
					this.textures[ i ].image.depth = depth;
					this.textures[ i ].isArrayTexture = this.textures[ i ].image.depth > 1;

				}

				this.dispose();

			}

			this.viewport.set( 0, 0, width, height );
			this.scissor.set( 0, 0, width, height );

		}

		/**
		 * Returns a new render target with copied values from this instance.
		 *
		 * @return {RenderTarget} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Copies the settings of the given render target. This is a structural copy so
		 * no resources are shared between render targets after the copy. That includes
		 * all MRT textures and the depth texture.
		 *
		 * @param {RenderTarget} source - The render target to copy.
		 * @return {RenderTarget} A reference to this instance.
		 */
		copy( source ) {

			this.width = source.width;
			this.height = source.height;
			this.depth = source.depth;

			this.scissor.copy( source.scissor );
			this.scissorTest = source.scissorTest;

			this.viewport.copy( source.viewport );

			this.textures.length = 0;

			for ( let i = 0, il = source.textures.length; i < il; i ++ ) {

				this.textures[ i ] = source.textures[ i ].clone();
				this.textures[ i ].isRenderTargetTexture = true;
				this.textures[ i ].renderTarget = this;

				// ensure image object is not shared, see #20328

				const image = Object.assign( {}, source.textures[ i ].image );
				this.textures[ i ].source = new Source( image );

			}

			this.depthBuffer = source.depthBuffer;
			this.stencilBuffer = source.stencilBuffer;

			this.resolveDepthBuffer = source.resolveDepthBuffer;
			this.resolveStencilBuffer = source.resolveStencilBuffer;

			if ( source.depthTexture !== null ) this.depthTexture = source.depthTexture.clone();

			this.samples = source.samples;

			return this;

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 *
		 * @fires RenderTarget#dispose
		 */
		dispose() {

			this.dispatchEvent( { type: 'dispose' } );

		}

	}

	/**
	 * A render target used in context of {@link WebGLRenderer}.
	 *
	 * @augments RenderTarget
	 */
	class WebGLRenderTarget extends RenderTarget {

		/**
		 * Constructs a new 3D render target.
		 *
		 * @param {number} [width=1] - The width of the render target.
		 * @param {number} [height=1] - The height of the render target.
		 * @param {RenderTarget~Options} [options] - The configuration object.
		 */
		constructor( width = 1, height = 1, options = {} ) {

			super( width, height, options );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isWebGLRenderTarget = true;

		}

	}

	/**
	 * Creates an array of textures directly from raw buffer data.
	 *
	 * @augments Texture
	 */
	class DataArrayTexture extends Texture {

		/**
		 * Constructs a new data array texture.
		 *
		 * @param {?TypedArray} [data=null] - The buffer data.
		 * @param {number} [width=1] - The width of the texture.
		 * @param {number} [height=1] - The height of the texture.
		 * @param {number} [depth=1] - The depth of the texture.
		 */
		constructor( data = null, width = 1, height = 1, depth = 1 ) {

			super( null );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isDataArrayTexture = true;

			/**
			 * The image definition of a data texture.
			 *
			 * @type {{data:TypedArray,width:number,height:number,depth:number}}
			 */
			this.image = { data, width, height, depth };

			/**
			 * How the texture is sampled when a texel covers more than one pixel.
			 *
			 * Overwritten and set to `NearestFilter` by default.
			 *
			 * @type {(NearestFilter|NearestMipmapNearestFilter|NearestMipmapLinearFilter|LinearFilter|LinearMipmapNearestFilter|LinearMipmapLinearFilter)}
			 * @default NearestFilter
			 */
			this.magFilter = NearestFilter;

			/**
			 * How the texture is sampled when a texel covers less than one pixel.
			 *
			 * Overwritten and set to `NearestFilter` by default.
			 *
			 * @type {(NearestFilter|NearestMipmapNearestFilter|NearestMipmapLinearFilter|LinearFilter|LinearMipmapNearestFilter|LinearMipmapLinearFilter)}
			 * @default NearestFilter
			 */
			this.minFilter = NearestFilter;

			/**
			 * This defines how the texture is wrapped in the depth and corresponds to
			 * *W* in UVW mapping.
			 *
			 * @type {(RepeatWrapping|ClampToEdgeWrapping|MirroredRepeatWrapping)}
			 * @default ClampToEdgeWrapping
			 */
			this.wrapR = ClampToEdgeWrapping;

			/**
			 * Whether to generate mipmaps (if possible) for a texture.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.generateMipmaps = false;

			/**
			 * If set to `true`, the texture is flipped along the vertical axis when
			 * uploaded to the GPU.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.flipY = false;

			/**
			 * Specifies the alignment requirements for the start of each pixel row in memory.
			 *
			 * Overwritten and set to `1` by default.
			 *
			 * @type {boolean}
			 * @default 1
			 */
			this.unpackAlignment = 1;

			/**
			 * A set of all layers which need to be updated in the texture.
			 *
			 * @type {Set<number>}
			 */
			this.layerUpdates = new Set();

		}

		/**
		 * Describes that a specific layer of the texture needs to be updated.
		 * Normally when {@link Texture#needsUpdate} is set to `true`, the
		 * entire data texture array is sent to the GPU. Marking specific
		 * layers will only transmit subsets of all mipmaps associated with a
		 * specific depth in the array which is often much more performant.
		 *
		 * @param {number} layerIndex - The layer index that should be updated.
		 */
		addLayerUpdate( layerIndex ) {

			this.layerUpdates.add( layerIndex );

		}

		/**
		 * Resets the layer updates registry.
		 */
		clearLayerUpdates() {

			this.layerUpdates.clear();

		}

	}

	/**
	 * Creates a three-dimensional texture from raw data, with parameters to
	 * divide it into width, height, and depth.
	 *
	 * @augments Texture
	 */
	class Data3DTexture extends Texture {

		/**
		 * Constructs a new data array texture.
		 *
		 * @param {?TypedArray} [data=null] - The buffer data.
		 * @param {number} [width=1] - The width of the texture.
		 * @param {number} [height=1] - The height of the texture.
		 * @param {number} [depth=1] - The depth of the texture.
		 */
		constructor( data = null, width = 1, height = 1, depth = 1 ) {

			// We're going to add .setXXX() methods for setting properties later.
			// Users can still set in Data3DTexture directly.
			//
			//	const texture = new THREE.Data3DTexture( data, width, height, depth );
			// 	texture.anisotropy = 16;
			//
			// See #14839

			super( null );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isData3DTexture = true;

			/**
			 * The image definition of a data texture.
			 *
			 * @type {{data:TypedArray,width:number,height:number,depth:number}}
			 */
			this.image = { data, width, height, depth };

			/**
			 * How the texture is sampled when a texel covers more than one pixel.
			 *
			 * Overwritten and set to `NearestFilter` by default.
			 *
			 * @type {(NearestFilter|NearestMipmapNearestFilter|NearestMipmapLinearFilter|LinearFilter|LinearMipmapNearestFilter|LinearMipmapLinearFilter)}
			 * @default NearestFilter
			 */
			this.magFilter = NearestFilter;

			/**
			 * How the texture is sampled when a texel covers less than one pixel.
			 *
			 * Overwritten and set to `NearestFilter` by default.
			 *
			 * @type {(NearestFilter|NearestMipmapNearestFilter|NearestMipmapLinearFilter|LinearFilter|LinearMipmapNearestFilter|LinearMipmapLinearFilter)}
			 * @default NearestFilter
			 */
			this.minFilter = NearestFilter;

			/**
			 * This defines how the texture is wrapped in the depth and corresponds to
			 * *W* in UVW mapping.
			 *
			 * @type {(RepeatWrapping|ClampToEdgeWrapping|MirroredRepeatWrapping)}
			 * @default ClampToEdgeWrapping
			 */
			this.wrapR = ClampToEdgeWrapping;

			/**
			 * Whether to generate mipmaps (if possible) for a texture.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.generateMipmaps = false;

			/**
			 * If set to `true`, the texture is flipped along the vertical axis when
			 * uploaded to the GPU.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.flipY = false;

			/**
			 * Specifies the alignment requirements for the start of each pixel row in memory.
			 *
			 * Overwritten and set to `1` by default.
			 *
			 * @type {boolean}
			 * @default 1
			 */
			this.unpackAlignment = 1;

		}

	}

	/**
	 * Represents an axis-aligned bounding box (AABB) in 3D space.
	 */
	class Box3 {

		/**
		 * Constructs a new bounding box.
		 *
		 * @param {Vector3} [min=(Infinity,Infinity,Infinity)] - A vector representing the lower boundary of the box.
		 * @param {Vector3} [max=(-Infinity,-Infinity,-Infinity)] - A vector representing the upper boundary of the box.
		 */
		constructor( min = new Vector3( + Infinity, + Infinity, + Infinity ), max = new Vector3( - Infinity, - Infinity, - Infinity ) ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isBox3 = true;

			/**
			 * The lower boundary of the box.
			 *
			 * @type {Vector3}
			 */
			this.min = min;

			/**
			 * The upper boundary of the box.
			 *
			 * @type {Vector3}
			 */
			this.max = max;

		}

		/**
		 * Sets the lower and upper boundaries of this box.
		 * Please note that this method only copies the values from the given objects.
		 *
		 * @param {Vector3} min - The lower boundary of the box.
		 * @param {Vector3} max - The upper boundary of the box.
		 * @return {Box3} A reference to this bounding box.
		 */
		set( min, max ) {

			this.min.copy( min );
			this.max.copy( max );

			return this;

		}

		/**
		 * Sets the upper and lower bounds of this box so it encloses the position data
		 * in the given array.
		 *
		 * @param {Array<number>} array - An array holding 3D position data.
		 * @return {Box3} A reference to this bounding box.
		 */
		setFromArray( array ) {

			this.makeEmpty();

			for ( let i = 0, il = array.length; i < il; i += 3 ) {

				this.expandByPoint( _vector$b.fromArray( array, i ) );

			}

			return this;

		}

		/**
		 * Sets the upper and lower bounds of this box so it encloses the position data
		 * in the given buffer attribute.
		 *
		 * @param {BufferAttribute} attribute - A buffer attribute holding 3D position data.
		 * @return {Box3} A reference to this bounding box.
		 */
		setFromBufferAttribute( attribute ) {

			this.makeEmpty();

			for ( let i = 0, il = attribute.count; i < il; i ++ ) {

				this.expandByPoint( _vector$b.fromBufferAttribute( attribute, i ) );

			}

			return this;

		}

		/**
		 * Sets the upper and lower bounds of this box so it encloses the position data
		 * in the given array.
		 *
		 * @param {Array<Vector3>} points - An array holding 3D position data as instances of {@link Vector3}.
		 * @return {Box3} A reference to this bounding box.
		 */
		setFromPoints( points ) {

			this.makeEmpty();

			for ( let i = 0, il = points.length; i < il; i ++ ) {

				this.expandByPoint( points[ i ] );

			}

			return this;

		}

		/**
		 * Centers this box on the given center vector and sets this box's width, height and
		 * depth to the given size values.
		 *
		 * @param {Vector3} center - The center of the box.
		 * @param {Vector3} size - The x, y and z dimensions of the box.
		 * @return {Box3} A reference to this bounding box.
		 */
		setFromCenterAndSize( center, size ) {

			const halfSize = _vector$b.copy( size ).multiplyScalar( 0.5 );

			this.min.copy( center ).sub( halfSize );
			this.max.copy( center ).add( halfSize );

			return this;

		}

		/**
		 * Computes the world-axis-aligned bounding box for the given 3D object
		 * (including its children), accounting for the object's, and children's,
		 * world transforms. The function may result in a larger box than strictly necessary.
		 *
		 * @param {Object3D} object - The 3D object to compute the bounding box for.
		 * @param {boolean} [precise=false] - If set to `true`, the method computes the smallest
		 * world-axis-aligned bounding box at the expense of more computation.
		 * @return {Box3} A reference to this bounding box.
		 */
		setFromObject( object, precise = false ) {

			this.makeEmpty();

			return this.expandByObject( object, precise );

		}

		/**
		 * Returns a new box with copied values from this instance.
		 *
		 * @return {Box3} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Copies the values of the given box to this instance.
		 *
		 * @param {Box3} box - The box to copy.
		 * @return {Box3} A reference to this bounding box.
		 */
		copy( box ) {

			this.min.copy( box.min );
			this.max.copy( box.max );

			return this;

		}

		/**
		 * Makes this box empty which means in encloses a zero space in 3D.
		 *
		 * @return {Box3} A reference to this bounding box.
		 */
		makeEmpty() {

			this.min.x = this.min.y = this.min.z = + Infinity;
			this.max.x = this.max.y = this.max.z = - Infinity;

			return this;

		}

		/**
		 * Returns true if this box includes zero points within its bounds.
		 * Note that a box with equal lower and upper bounds still includes one
		 * point, the one both bounds share.
		 *
		 * @return {boolean} Whether this box is empty or not.
		 */
		isEmpty() {

			// this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes

			return ( this.max.x < this.min.x ) || ( this.max.y < this.min.y ) || ( this.max.z < this.min.z );

		}

		/**
		 * Returns the center point of this box.
		 *
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The center point.
		 */
		getCenter( target ) {

			return this.isEmpty() ? target.set( 0, 0, 0 ) : target.addVectors( this.min, this.max ).multiplyScalar( 0.5 );

		}

		/**
		 * Returns the dimensions of this box.
		 *
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The size.
		 */
		getSize( target ) {

			return this.isEmpty() ? target.set( 0, 0, 0 ) : target.subVectors( this.max, this.min );

		}

		/**
		 * Expands the boundaries of this box to include the given point.
		 *
		 * @param {Vector3} point - The point that should be included by the bounding box.
		 * @return {Box3} A reference to this bounding box.
		 */
		expandByPoint( point ) {

			this.min.min( point );
			this.max.max( point );

			return this;

		}

		/**
		 * Expands this box equilaterally by the given vector. The width of this
		 * box will be expanded by the x component of the vector in both
		 * directions. The height of this box will be expanded by the y component of
		 * the vector in both directions. The depth of this box will be
		 * expanded by the z component of the vector in both directions.
		 *
		 * @param {Vector3} vector - The vector that should expand the bounding box.
		 * @return {Box3} A reference to this bounding box.
		 */
		expandByVector( vector ) {

			this.min.sub( vector );
			this.max.add( vector );

			return this;

		}

		/**
		 * Expands each dimension of the box by the given scalar. If negative, the
		 * dimensions of the box will be contracted.
		 *
		 * @param {number} scalar - The scalar value that should expand the bounding box.
		 * @return {Box3} A reference to this bounding box.
		 */
		expandByScalar( scalar ) {

			this.min.addScalar( - scalar );
			this.max.addScalar( scalar );

			return this;

		}

		/**
		 * Expands the boundaries of this box to include the given 3D object and
		 * its children, accounting for the object's, and children's, world
		 * transforms. The function may result in a larger box than strictly
		 * necessary (unless the precise parameter is set to true).
		 *
		 * @param {Object3D} object - The 3D object that should expand the bounding box.
		 * @param {boolean} precise - If set to `true`, the method expands the bounding box
		 * as little as necessary at the expense of more computation.
		 * @return {Box3} A reference to this bounding box.
		 */
		expandByObject( object, precise = false ) {

			// Computes the world-axis-aligned bounding box of an object (including its children),
			// accounting for both the object's, and children's, world transforms

			object.updateWorldMatrix( false, false );

			const geometry = object.geometry;

			if ( geometry !== undefined ) {

				const positionAttribute = geometry.getAttribute( 'position' );

				// precise AABB computation based on vertex data requires at least a position attribute.
				// instancing isn't supported so far and uses the normal (conservative) code path.

				if ( precise === true && positionAttribute !== undefined && object.isInstancedMesh !== true ) {

					for ( let i = 0, l = positionAttribute.count; i < l; i ++ ) {

						if ( object.isMesh === true ) {

							object.getVertexPosition( i, _vector$b );

						} else {

							_vector$b.fromBufferAttribute( positionAttribute, i );

						}

						_vector$b.applyMatrix4( object.matrixWorld );
						this.expandByPoint( _vector$b );

					}

				} else {

					if ( object.boundingBox !== undefined ) {

						// object-level bounding box

						if ( object.boundingBox === null ) {

							object.computeBoundingBox();

						}

						_box$4.copy( object.boundingBox );


					} else {

						// geometry-level bounding box

						if ( geometry.boundingBox === null ) {

							geometry.computeBoundingBox();

						}

						_box$4.copy( geometry.boundingBox );

					}

					_box$4.applyMatrix4( object.matrixWorld );

					this.union( _box$4 );

				}

			}

			const children = object.children;

			for ( let i = 0, l = children.length; i < l; i ++ ) {

				this.expandByObject( children[ i ], precise );

			}

			return this;

		}

		/**
		 * Returns `true` if the given point lies within or on the boundaries of this box.
		 *
		 * @param {Vector3} point - The point to test.
		 * @return {boolean} Whether the bounding box contains the given point or not.
		 */
		containsPoint( point ) {

			return point.x >= this.min.x && point.x <= this.max.x &&
				point.y >= this.min.y && point.y <= this.max.y &&
				point.z >= this.min.z && point.z <= this.max.z;

		}

		/**
		 * Returns `true` if this bounding box includes the entirety of the given bounding box.
		 * If this box and the given one are identical, this function also returns `true`.
		 *
		 * @param {Box3} box - The bounding box to test.
		 * @return {boolean} Whether the bounding box contains the given bounding box or not.
		 */
		containsBox( box ) {

			return this.min.x <= box.min.x && box.max.x <= this.max.x &&
				this.min.y <= box.min.y && box.max.y <= this.max.y &&
				this.min.z <= box.min.z && box.max.z <= this.max.z;

		}

		/**
		 * Returns a point as a proportion of this box's width, height and depth.
		 *
		 * @param {Vector3} point - A point in 3D space.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} A point as a proportion of this box's width, height and depth.
		 */
		getParameter( point, target ) {

			// This can potentially have a divide by zero if the box
			// has a size dimension of 0.

			return target.set(
				( point.x - this.min.x ) / ( this.max.x - this.min.x ),
				( point.y - this.min.y ) / ( this.max.y - this.min.y ),
				( point.z - this.min.z ) / ( this.max.z - this.min.z )
			);

		}

		/**
		 * Returns `true` if the given bounding box intersects with this bounding box.
		 *
		 * @param {Box3} box - The bounding box to test.
		 * @return {boolean} Whether the given bounding box intersects with this bounding box.
		 */
		intersectsBox( box ) {

			// using 6 splitting planes to rule out intersections.
			return box.max.x >= this.min.x && box.min.x <= this.max.x &&
				box.max.y >= this.min.y && box.min.y <= this.max.y &&
				box.max.z >= this.min.z && box.min.z <= this.max.z;

		}

		/**
		 * Returns `true` if the given bounding sphere intersects with this bounding box.
		 *
		 * @param {Sphere} sphere - The bounding sphere to test.
		 * @return {boolean} Whether the given bounding sphere intersects with this bounding box.
		 */
		intersectsSphere( sphere ) {

			// Find the point on the AABB closest to the sphere center.
			this.clampPoint( sphere.center, _vector$b );

			// If that point is inside the sphere, the AABB and sphere intersect.
			return _vector$b.distanceToSquared( sphere.center ) <= ( sphere.radius * sphere.radius );

		}

		/**
		 * Returns `true` if the given plane intersects with this bounding box.
		 *
		 * @param {Plane} plane - The plane to test.
		 * @return {boolean} Whether the given plane intersects with this bounding box.
		 */
		intersectsPlane( plane ) {

			// We compute the minimum and maximum dot product values. If those values
			// are on the same side (back or front) of the plane, then there is no intersection.

			let min, max;

			if ( plane.normal.x > 0 ) {

				min = plane.normal.x * this.min.x;
				max = plane.normal.x * this.max.x;

			} else {

				min = plane.normal.x * this.max.x;
				max = plane.normal.x * this.min.x;

			}

			if ( plane.normal.y > 0 ) {

				min += plane.normal.y * this.min.y;
				max += plane.normal.y * this.max.y;

			} else {

				min += plane.normal.y * this.max.y;
				max += plane.normal.y * this.min.y;

			}

			if ( plane.normal.z > 0 ) {

				min += plane.normal.z * this.min.z;
				max += plane.normal.z * this.max.z;

			} else {

				min += plane.normal.z * this.max.z;
				max += plane.normal.z * this.min.z;

			}

			return ( min <= - plane.constant && max >= - plane.constant );

		}

		/**
		 * Returns `true` if the given triangle intersects with this bounding box.
		 *
		 * @param {Triangle} triangle - The triangle to test.
		 * @return {boolean} Whether the given triangle intersects with this bounding box.
		 */
		intersectsTriangle( triangle ) {

			if ( this.isEmpty() ) {

				return false;

			}

			// compute box center and extents
			this.getCenter( _center );
			_extents.subVectors( this.max, _center );

			// translate triangle to aabb origin
			_v0$2.subVectors( triangle.a, _center );
			_v1$7.subVectors( triangle.b, _center );
			_v2$4.subVectors( triangle.c, _center );

			// compute edge vectors for triangle
			_f0.subVectors( _v1$7, _v0$2 );
			_f1.subVectors( _v2$4, _v1$7 );
			_f2.subVectors( _v0$2, _v2$4 );

			// test against axes that are given by cross product combinations of the edges of the triangle and the edges of the aabb
			// make an axis testing of each of the 3 sides of the aabb against each of the 3 sides of the triangle = 9 axis of separation
			// axis_ij = u_i x f_j (u0, u1, u2 = face normals of aabb = x,y,z axes vectors since aabb is axis aligned)
			let axes = [
				0, - _f0.z, _f0.y, 0, - _f1.z, _f1.y, 0, - _f2.z, _f2.y,
				_f0.z, 0, - _f0.x, _f1.z, 0, - _f1.x, _f2.z, 0, - _f2.x,
				- _f0.y, _f0.x, 0, - _f1.y, _f1.x, 0, - _f2.y, _f2.x, 0
			];
			if ( ! satForAxes( axes, _v0$2, _v1$7, _v2$4, _extents ) ) {

				return false;

			}

			// test 3 face normals from the aabb
			axes = [ 1, 0, 0, 0, 1, 0, 0, 0, 1 ];
			if ( ! satForAxes( axes, _v0$2, _v1$7, _v2$4, _extents ) ) {

				return false;

			}

			// finally testing the face normal of the triangle
			// use already existing triangle edge vectors here
			_triangleNormal.crossVectors( _f0, _f1 );
			axes = [ _triangleNormal.x, _triangleNormal.y, _triangleNormal.z ];

			return satForAxes( axes, _v0$2, _v1$7, _v2$4, _extents );

		}

		/**
		 * Clamps the given point within the bounds of this box.
		 *
		 * @param {Vector3} point - The point to clamp.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The clamped point.
		 */
		clampPoint( point, target ) {

			return target.copy( point ).clamp( this.min, this.max );

		}

		/**
		 * Returns the euclidean distance from any edge of this box to the specified point. If
		 * the given point lies inside of this box, the distance will be `0`.
		 *
		 * @param {Vector3} point - The point to compute the distance to.
		 * @return {number} The euclidean distance.
		 */
		distanceToPoint( point ) {

			return this.clampPoint( point, _vector$b ).distanceTo( point );

		}

		/**
		 * Returns a bounding sphere that encloses this bounding box.
		 *
		 * @param {Sphere} target - The target sphere that is used to store the method's result.
		 * @return {Sphere} The bounding sphere that encloses this bounding box.
		 */
		getBoundingSphere( target ) {

			if ( this.isEmpty() ) {

				target.makeEmpty();

			} else {

				this.getCenter( target.center );

				target.radius = this.getSize( _vector$b ).length() * 0.5;

			}

			return target;

		}

		/**
		 * Computes the intersection of this bounding box and the given one, setting the upper
		 * bound of this box to the lesser of the two boxes' upper bounds and the
		 * lower bound of this box to the greater of the two boxes' lower bounds. If
		 * there's no overlap, makes this box empty.
		 *
		 * @param {Box3} box - The bounding box to intersect with.
		 * @return {Box3} A reference to this bounding box.
		 */
		intersect( box ) {

			this.min.max( box.min );
			this.max.min( box.max );

			// ensure that if there is no overlap, the result is fully empty, not slightly empty with non-inf/+inf values that will cause subsequence intersects to erroneously return valid values.
			if ( this.isEmpty() ) this.makeEmpty();

			return this;

		}

		/**
		 * Computes the union of this box and another and the given one, setting the upper
		 * bound of this box to the greater of the two boxes' upper bounds and the
		 * lower bound of this box to the lesser of the two boxes' lower bounds.
		 *
		 * @param {Box3} box - The bounding box that will be unioned with this instance.
		 * @return {Box3} A reference to this bounding box.
		 */
		union( box ) {

			this.min.min( box.min );
			this.max.max( box.max );

			return this;

		}

		/**
		 * Transforms this bounding box by the given 4x4 transformation matrix.
		 *
		 * @param {Matrix4} matrix - The transformation matrix.
		 * @return {Box3} A reference to this bounding box.
		 */
		applyMatrix4( matrix ) {

			// transform of empty box is an empty box.
			if ( this.isEmpty() ) return this;

			// NOTE: I am using a binary pattern to specify all 2^3 combinations below
			_points[ 0 ].set( this.min.x, this.min.y, this.min.z ).applyMatrix4( matrix ); // 000
			_points[ 1 ].set( this.min.x, this.min.y, this.max.z ).applyMatrix4( matrix ); // 001
			_points[ 2 ].set( this.min.x, this.max.y, this.min.z ).applyMatrix4( matrix ); // 010
			_points[ 3 ].set( this.min.x, this.max.y, this.max.z ).applyMatrix4( matrix ); // 011
			_points[ 4 ].set( this.max.x, this.min.y, this.min.z ).applyMatrix4( matrix ); // 100
			_points[ 5 ].set( this.max.x, this.min.y, this.max.z ).applyMatrix4( matrix ); // 101
			_points[ 6 ].set( this.max.x, this.max.y, this.min.z ).applyMatrix4( matrix ); // 110
			_points[ 7 ].set( this.max.x, this.max.y, this.max.z ).applyMatrix4( matrix ); // 111

			this.setFromPoints( _points );

			return this;

		}

		/**
		 * Adds the given offset to both the upper and lower bounds of this bounding box,
		 * effectively moving it in 3D space.
		 *
		 * @param {Vector3} offset - The offset that should be used to translate the bounding box.
		 * @return {Box3} A reference to this bounding box.
		 */
		translate( offset ) {

			this.min.add( offset );
			this.max.add( offset );

			return this;

		}

		/**
		 * Returns `true` if this bounding box is equal with the given one.
		 *
		 * @param {Box3} box - The box to test for equality.
		 * @return {boolean} Whether this bounding box is equal with the given one.
		 */
		equals( box ) {

			return box.min.equals( this.min ) && box.max.equals( this.max );

		}

		/**
		 * Returns a serialized structure of the bounding box.
		 *
		 * @return {Object} Serialized structure with fields representing the object state.
		 */
		toJSON() {

			return {
				min: this.min.toArray(),
				max: this.max.toArray()
			};

		}

		/**
		 * Returns a serialized structure of the bounding box.
		 *
		 * @param {Object} json - The serialized json to set the box from.
		 * @return {Box3} A reference to this bounding box.
		 */
		fromJSON( json ) {

			this.min.fromArray( json.min );
			this.max.fromArray( json.max );
			return this;

		}

	}

	const _points = [
		/*@__PURE__*/ new Vector3(),
		/*@__PURE__*/ new Vector3(),
		/*@__PURE__*/ new Vector3(),
		/*@__PURE__*/ new Vector3(),
		/*@__PURE__*/ new Vector3(),
		/*@__PURE__*/ new Vector3(),
		/*@__PURE__*/ new Vector3(),
		/*@__PURE__*/ new Vector3()
	];

	const _vector$b = /*@__PURE__*/ new Vector3();

	const _box$4 = /*@__PURE__*/ new Box3();

	// triangle centered vertices

	const _v0$2 = /*@__PURE__*/ new Vector3();
	const _v1$7 = /*@__PURE__*/ new Vector3();
	const _v2$4 = /*@__PURE__*/ new Vector3();

	// triangle edge vectors

	const _f0 = /*@__PURE__*/ new Vector3();
	const _f1 = /*@__PURE__*/ new Vector3();
	const _f2 = /*@__PURE__*/ new Vector3();

	const _center = /*@__PURE__*/ new Vector3();
	const _extents = /*@__PURE__*/ new Vector3();
	const _triangleNormal = /*@__PURE__*/ new Vector3();
	const _testAxis = /*@__PURE__*/ new Vector3();

	function satForAxes( axes, v0, v1, v2, extents ) {

		for ( let i = 0, j = axes.length - 3; i <= j; i += 3 ) {

			_testAxis.fromArray( axes, i );
			// project the aabb onto the separating axis
			const r = extents.x * Math.abs( _testAxis.x ) + extents.y * Math.abs( _testAxis.y ) + extents.z * Math.abs( _testAxis.z );
			// project all 3 vertices of the triangle onto the separating axis
			const p0 = v0.dot( _testAxis );
			const p1 = v1.dot( _testAxis );
			const p2 = v2.dot( _testAxis );
			// actual test, basically see if either of the most extreme of the triangle points intersects r
			if ( Math.max( - Math.max( p0, p1, p2 ), Math.min( p0, p1, p2 ) ) > r ) {

				// points of the projected triangle are outside the projected half-length of the aabb
				// the axis is separating and we can exit
				return false;

			}

		}

		return true;

	}

	const _box$3 = /*@__PURE__*/ new Box3();
	const _v1$6 = /*@__PURE__*/ new Vector3();
	const _v2$3 = /*@__PURE__*/ new Vector3();

	/**
	 * An analytical 3D sphere defined by a center and radius. This class is mainly
	 * used as a Bounding Sphere for 3D objects.
	 */
	class Sphere {

		/**
		 * Constructs a new sphere.
		 *
		 * @param {Vector3} [center=(0,0,0)] - The center of the sphere
		 * @param {number} [radius=-1] - The radius of the sphere.
		 */
		constructor( center = new Vector3(), radius = -1 ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isSphere = true;

			/**
			 * The center of the sphere
			 *
			 * @type {Vector3}
			 */
			this.center = center;

			/**
			 * The radius of the sphere.
			 *
			 * @type {number}
			 */
			this.radius = radius;

		}

		/**
		 * Sets the sphere's components by copying the given values.
		 *
		 * @param {Vector3} center - The center.
		 * @param {number} radius - The radius.
		 * @return {Sphere} A reference to this sphere.
		 */
		set( center, radius ) {

			this.center.copy( center );
			this.radius = radius;

			return this;

		}

		/**
		 * Computes the minimum bounding sphere for list of points.
		 * If the optional center point is given, it is used as the sphere's
		 * center. Otherwise, the center of the axis-aligned bounding box
		 * encompassing the points is calculated.
		 *
		 * @param {Array<Vector3>} points - A list of points in 3D space.
		 * @param {Vector3} [optionalCenter] - The center of the sphere.
		 * @return {Sphere} A reference to this sphere.
		 */
		setFromPoints( points, optionalCenter ) {

			const center = this.center;

			if ( optionalCenter !== undefined ) {

				center.copy( optionalCenter );

			} else {

				_box$3.setFromPoints( points ).getCenter( center );

			}

			let maxRadiusSq = 0;

			for ( let i = 0, il = points.length; i < il; i ++ ) {

				maxRadiusSq = Math.max( maxRadiusSq, center.distanceToSquared( points[ i ] ) );

			}

			this.radius = Math.sqrt( maxRadiusSq );

			return this;

		}

		/**
		 * Copies the values of the given sphere to this instance.
		 *
		 * @param {Sphere} sphere - The sphere to copy.
		 * @return {Sphere} A reference to this sphere.
		 */
		copy( sphere ) {

			this.center.copy( sphere.center );
			this.radius = sphere.radius;

			return this;

		}

		/**
		 * Returns `true` if the sphere is empty (the radius set to a negative number).
		 *
		 * Spheres with a radius of `0` contain only their center point and are not
		 * considered to be empty.
		 *
		 * @return {boolean} Whether this sphere is empty or not.
		 */
		isEmpty() {

			return ( this.radius < 0 );

		}

		/**
		 * Makes this sphere empty which means in encloses a zero space in 3D.
		 *
		 * @return {Sphere} A reference to this sphere.
		 */
		makeEmpty() {

			this.center.set( 0, 0, 0 );
			this.radius = -1;

			return this;

		}

		/**
		 * Returns `true` if this sphere contains the given point inclusive of
		 * the surface of the sphere.
		 *
		 * @param {Vector3} point - The point to check.
		 * @return {boolean} Whether this sphere contains the given point or not.
		 */
		containsPoint( point ) {

			return ( point.distanceToSquared( this.center ) <= ( this.radius * this.radius ) );

		}

		/**
		 * Returns the closest distance from the boundary of the sphere to the
		 * given point. If the sphere contains the point, the distance will
		 * be negative.
		 *
		 * @param {Vector3} point - The point to compute the distance to.
		 * @return {number} The distance to the point.
		 */
		distanceToPoint( point ) {

			return ( point.distanceTo( this.center ) - this.radius );

		}

		/**
		 * Returns `true` if this sphere intersects with the given one.
		 *
		 * @param {Sphere} sphere - The sphere to test.
		 * @return {boolean} Whether this sphere intersects with the given one or not.
		 */
		intersectsSphere( sphere ) {

			const radiusSum = this.radius + sphere.radius;

			return sphere.center.distanceToSquared( this.center ) <= ( radiusSum * radiusSum );

		}

		/**
		 * Returns `true` if this sphere intersects with the given box.
		 *
		 * @param {Box3} box - The box to test.
		 * @return {boolean} Whether this sphere intersects with the given box or not.
		 */
		intersectsBox( box ) {

			return box.intersectsSphere( this );

		}

		/**
		 * Returns `true` if this sphere intersects with the given plane.
		 *
		 * @param {Plane} plane - The plane to test.
		 * @return {boolean} Whether this sphere intersects with the given plane or not.
		 */
		intersectsPlane( plane ) {

			return Math.abs( plane.distanceToPoint( this.center ) ) <= this.radius;

		}

		/**
		 * Clamps a point within the sphere. If the point is outside the sphere, it
		 * will clamp it to the closest point on the edge of the sphere. Points
		 * already inside the sphere will not be affected.
		 *
		 * @param {Vector3} point - The plane to clamp.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The clamped point.
		 */
		clampPoint( point, target ) {

			const deltaLengthSq = this.center.distanceToSquared( point );

			target.copy( point );

			if ( deltaLengthSq > ( this.radius * this.radius ) ) {

				target.sub( this.center ).normalize();
				target.multiplyScalar( this.radius ).add( this.center );

			}

			return target;

		}

		/**
		 * Returns a bounding box that encloses this sphere.
		 *
		 * @param {Box3} target - The target box that is used to store the method's result.
		 * @return {Box3} The bounding box that encloses this sphere.
		 */
		getBoundingBox( target ) {

			if ( this.isEmpty() ) {

				// Empty sphere produces empty bounding box
				target.makeEmpty();
				return target;

			}

			target.set( this.center, this.center );
			target.expandByScalar( this.radius );

			return target;

		}

		/**
		 * Transforms this sphere with the given 4x4 transformation matrix.
		 *
		 * @param {Matrix4} matrix - The transformation matrix.
		 * @return {Sphere} A reference to this sphere.
		 */
		applyMatrix4( matrix ) {

			this.center.applyMatrix4( matrix );
			this.radius = this.radius * matrix.getMaxScaleOnAxis();

			return this;

		}

		/**
		 * Translates the sphere's center by the given offset.
		 *
		 * @param {Vector3} offset - The offset.
		 * @return {Sphere} A reference to this sphere.
		 */
		translate( offset ) {

			this.center.add( offset );

			return this;

		}

		/**
		 * Expands the boundaries of this sphere to include the given point.
		 *
		 * @param {Vector3} point - The point to include.
		 * @return {Sphere} A reference to this sphere.
		 */
		expandByPoint( point ) {

			if ( this.isEmpty() ) {

				this.center.copy( point );

				this.radius = 0;

				return this;

			}

			_v1$6.subVectors( point, this.center );

			const lengthSq = _v1$6.lengthSq();

			if ( lengthSq > ( this.radius * this.radius ) ) {

				// calculate the minimal sphere

				const length = Math.sqrt( lengthSq );

				const delta = ( length - this.radius ) * 0.5;

				this.center.addScaledVector( _v1$6, delta / length );

				this.radius += delta;

			}

			return this;

		}

		/**
		 * Expands this sphere to enclose both the original sphere and the given sphere.
		 *
		 * @param {Sphere} sphere - The sphere to include.
		 * @return {Sphere} A reference to this sphere.
		 */
		union( sphere ) {

			if ( sphere.isEmpty() ) {

				return this;

			}

			if ( this.isEmpty() ) {

				this.copy( sphere );

				return this;

			}

			if ( this.center.equals( sphere.center ) === true ) {

				 this.radius = Math.max( this.radius, sphere.radius );

			} else {

				_v2$3.subVectors( sphere.center, this.center ).setLength( sphere.radius );

				this.expandByPoint( _v1$6.copy( sphere.center ).add( _v2$3 ) );

				this.expandByPoint( _v1$6.copy( sphere.center ).sub( _v2$3 ) );

			}

			return this;

		}

		/**
		 * Returns `true` if this sphere is equal with the given one.
		 *
		 * @param {Sphere} sphere - The sphere to test for equality.
		 * @return {boolean} Whether this bounding sphere is equal with the given one.
		 */
		equals( sphere ) {

			return sphere.center.equals( this.center ) && ( sphere.radius === this.radius );

		}

		/**
		 * Returns a new sphere with copied values from this instance.
		 *
		 * @return {Sphere} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Returns a serialized structure of the bounding sphere.
		 *
		 * @return {Object} Serialized structure with fields representing the object state.
		 */
		toJSON() {

			return {
				radius: this.radius,
				center: this.center.toArray()
			};

		}

		/**
		 * Returns a serialized structure of the bounding sphere.
		 *
		 * @param {Object} json - The serialized json to set the sphere from.
		 * @return {Box3} A reference to this bounding sphere.
		 */
		fromJSON( json ) {

			this.radius = json.radius;
			this.center.fromArray( json.center );
			return this;

		}

	}

	const _vector$a = /*@__PURE__*/ new Vector3();
	const _segCenter = /*@__PURE__*/ new Vector3();
	const _segDir = /*@__PURE__*/ new Vector3();
	const _diff = /*@__PURE__*/ new Vector3();

	const _edge1 = /*@__PURE__*/ new Vector3();
	const _edge2 = /*@__PURE__*/ new Vector3();
	const _normal$1 = /*@__PURE__*/ new Vector3();

	/**
	 * A ray that emits from an origin in a certain direction. The class is used by
	 * {@link Raycaster} to assist with raycasting. Raycasting is used for
	 * mouse picking (working out what objects in the 3D space the mouse is over)
	 * amongst other things.
	 */
	class Ray {

		/**
		 * Constructs a new ray.
		 *
		 * @param {Vector3} [origin=(0,0,0)] - The origin of the ray.
		 * @param {Vector3} [direction=(0,0,-1)] - The (normalized) direction of the ray.
		 */
		constructor( origin = new Vector3(), direction = new Vector3( 0, 0, -1 ) ) {

			/**
			 * The origin of the ray.
			 *
			 * @type {Vector3}
			 */
			this.origin = origin;

			/**
			 * The (normalized) direction of the ray.
			 *
			 * @type {Vector3}
			 */
			this.direction = direction;

		}

		/**
		 * Sets the ray's components by copying the given values.
		 *
		 * @param {Vector3} origin - The origin.
		 * @param {Vector3} direction - The direction.
		 * @return {Ray} A reference to this ray.
		 */
		set( origin, direction ) {

			this.origin.copy( origin );
			this.direction.copy( direction );

			return this;

		}

		/**
		 * Copies the values of the given ray to this instance.
		 *
		 * @param {Ray} ray - The ray to copy.
		 * @return {Ray} A reference to this ray.
		 */
		copy( ray ) {

			this.origin.copy( ray.origin );
			this.direction.copy( ray.direction );

			return this;

		}

		/**
		 * Returns a vector that is located at a given distance along this ray.
		 *
		 * @param {number} t - The distance along the ray to retrieve a position for.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} A position on the ray.
		 */
		at( t, target ) {

			return target.copy( this.origin ).addScaledVector( this.direction, t );

		}

		/**
		 * Adjusts the direction of the ray to point at the given vector in world space.
		 *
		 * @param {Vector3} v - The target position.
		 * @return {Ray} A reference to this ray.
		 */
		lookAt( v ) {

			this.direction.copy( v ).sub( this.origin ).normalize();

			return this;

		}

		/**
		 * Shift the origin of this ray along its direction by the given distance.
		 *
		 * @param {number} t - The distance along the ray to interpolate.
		 * @return {Ray} A reference to this ray.
		 */
		recast( t ) {

			this.origin.copy( this.at( t, _vector$a ) );

			return this;

		}

		/**
		 * Returns the point along this ray that is closest to the given point.
		 *
		 * @param {Vector3} point - A point in 3D space to get the closet location on the ray for.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The closest point on this ray.
		 */
		closestPointToPoint( point, target ) {

			target.subVectors( point, this.origin );

			const directionDistance = target.dot( this.direction );

			if ( directionDistance < 0 ) {

				return target.copy( this.origin );

			}

			return target.copy( this.origin ).addScaledVector( this.direction, directionDistance );

		}

		/**
		 * Returns the distance of the closest approach between this ray and the given point.
		 *
		 * @param {Vector3} point - A point in 3D space to compute the distance to.
		 * @return {number} The distance.
		 */
		distanceToPoint( point ) {

			return Math.sqrt( this.distanceSqToPoint( point ) );

		}

		/**
		 * Returns the squared distance of the closest approach between this ray and the given point.
		 *
		 * @param {Vector3} point - A point in 3D space to compute the distance to.
		 * @return {number} The squared distance.
		 */
		distanceSqToPoint( point ) {

			const directionDistance = _vector$a.subVectors( point, this.origin ).dot( this.direction );

			// point behind the ray

			if ( directionDistance < 0 ) {

				return this.origin.distanceToSquared( point );

			}

			_vector$a.copy( this.origin ).addScaledVector( this.direction, directionDistance );

			return _vector$a.distanceToSquared( point );

		}

		/**
		 * Returns the squared distance between this ray and the given line segment.
		 *
		 * @param {Vector3} v0 - The start point of the line segment.
		 * @param {Vector3} v1 - The end point of the line segment.
		 * @param {Vector3} [optionalPointOnRay] - When provided, it receives the point on this ray that is closest to the segment.
		 * @param {Vector3} [optionalPointOnSegment] - When provided, it receives the point on the line segment that is closest to this ray.
		 * @return {number} The squared distance.
		 */
		distanceSqToSegment( v0, v1, optionalPointOnRay, optionalPointOnSegment ) {

			// from https://github.com/pmjoniak/GeometricTools/blob/master/GTEngine/Include/Mathematics/GteDistRaySegment.h
			// It returns the min distance between the ray and the segment
			// defined by v0 and v1
			// It can also set two optional targets :
			// - The closest point on the ray
			// - The closest point on the segment

			_segCenter.copy( v0 ).add( v1 ).multiplyScalar( 0.5 );
			_segDir.copy( v1 ).sub( v0 ).normalize();
			_diff.copy( this.origin ).sub( _segCenter );

			const segExtent = v0.distanceTo( v1 ) * 0.5;
			const a01 = - this.direction.dot( _segDir );
			const b0 = _diff.dot( this.direction );
			const b1 = - _diff.dot( _segDir );
			const c = _diff.lengthSq();
			const det = Math.abs( 1 - a01 * a01 );
			let s0, s1, sqrDist, extDet;

			if ( det > 0 ) {

				// The ray and segment are not parallel.

				s0 = a01 * b1 - b0;
				s1 = a01 * b0 - b1;
				extDet = segExtent * det;

				if ( s0 >= 0 ) {

					if ( s1 >= - extDet ) {

						if ( s1 <= extDet ) {

							// region 0
							// Minimum at interior points of ray and segment.

							const invDet = 1 / det;
							s0 *= invDet;
							s1 *= invDet;
							sqrDist = s0 * ( s0 + a01 * s1 + 2 * b0 ) + s1 * ( a01 * s0 + s1 + 2 * b1 ) + c;

						} else {

							// region 1

							s1 = segExtent;
							s0 = Math.max( 0, - ( a01 * s1 + b0 ) );
							sqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;

						}

					} else {

						// region 5

						s1 = - segExtent;
						s0 = Math.max( 0, - ( a01 * s1 + b0 ) );
						sqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;

					}

				} else {

					if ( s1 <= - extDet ) {

						// region 4

						s0 = Math.max( 0, - ( - a01 * segExtent + b0 ) );
						s1 = ( s0 > 0 ) ? - segExtent : Math.min( Math.max( - segExtent, - b1 ), segExtent );
						sqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;

					} else if ( s1 <= extDet ) {

						// region 3

						s0 = 0;
						s1 = Math.min( Math.max( - segExtent, - b1 ), segExtent );
						sqrDist = s1 * ( s1 + 2 * b1 ) + c;

					} else {

						// region 2

						s0 = Math.max( 0, - ( a01 * segExtent + b0 ) );
						s1 = ( s0 > 0 ) ? segExtent : Math.min( Math.max( - segExtent, - b1 ), segExtent );
						sqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;

					}

				}

			} else {

				// Ray and segment are parallel.

				s1 = ( a01 > 0 ) ? - segExtent : segExtent;
				s0 = Math.max( 0, - ( a01 * s1 + b0 ) );
				sqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;

			}

			if ( optionalPointOnRay ) {

				optionalPointOnRay.copy( this.origin ).addScaledVector( this.direction, s0 );

			}

			if ( optionalPointOnSegment ) {

				optionalPointOnSegment.copy( _segCenter ).addScaledVector( _segDir, s1 );

			}

			return sqrDist;

		}

		/**
		 * Intersects this ray with the given sphere, returning the intersection
		 * point or `null` if there is no intersection.
		 *
		 * @param {Sphere} sphere - The sphere to intersect.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The intersection point.
		 */
		intersectSphere( sphere, target ) {

			_vector$a.subVectors( sphere.center, this.origin );
			const tca = _vector$a.dot( this.direction );
			const d2 = _vector$a.dot( _vector$a ) - tca * tca;
			const radius2 = sphere.radius * sphere.radius;

			if ( d2 > radius2 ) return null;

			const thc = Math.sqrt( radius2 - d2 );

			// t0 = first intersect point - entrance on front of sphere
			const t0 = tca - thc;

			// t1 = second intersect point - exit point on back of sphere
			const t1 = tca + thc;

			// test to see if t1 is behind the ray - if so, return null
			if ( t1 < 0 ) return null;

			// test to see if t0 is behind the ray:
			// if it is, the ray is inside the sphere, so return the second exit point scaled by t1,
			// in order to always return an intersect point that is in front of the ray.
			if ( t0 < 0 ) return this.at( t1, target );

			// else t0 is in front of the ray, so return the first collision point scaled by t0
			return this.at( t0, target );

		}

		/**
		 * Returns `true` if this ray intersects with the given sphere.
		 *
		 * @param {Sphere} sphere - The sphere to intersect.
		 * @return {boolean} Whether this ray intersects with the given sphere or not.
		 */
		intersectsSphere( sphere ) {

			if ( sphere.radius < 0 ) return false; // handle empty spheres, see #31187

			return this.distanceSqToPoint( sphere.center ) <= ( sphere.radius * sphere.radius );

		}

		/**
		 * Computes the distance from the ray's origin to the given plane. Returns `null` if the ray
		 * does not intersect with the plane.
		 *
		 * @param {Plane} plane - The plane to compute the distance to.
		 * @return {?number} Whether this ray intersects with the given sphere or not.
		 */
		distanceToPlane( plane ) {

			const denominator = plane.normal.dot( this.direction );

			if ( denominator === 0 ) {

				// line is coplanar, return origin
				if ( plane.distanceToPoint( this.origin ) === 0 ) {

					return 0;

				}

				// Null is preferable to undefined since undefined means.... it is undefined

				return null;

			}

			const t = - ( this.origin.dot( plane.normal ) + plane.constant ) / denominator;

			// Return if the ray never intersects the plane

			return t >= 0 ? t : null;

		}

		/**
		 * Intersects this ray with the given plane, returning the intersection
		 * point or `null` if there is no intersection.
		 *
		 * @param {Plane} plane - The plane to intersect.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The intersection point.
		 */
		intersectPlane( plane, target ) {

			const t = this.distanceToPlane( plane );

			if ( t === null ) {

				return null;

			}

			return this.at( t, target );

		}

		/**
		 * Returns `true` if this ray intersects with the given plane.
		 *
		 * @param {Plane} plane - The plane to intersect.
		 * @return {boolean} Whether this ray intersects with the given plane or not.
		 */
		intersectsPlane( plane ) {

			// check if the ray lies on the plane first

			const distToPoint = plane.distanceToPoint( this.origin );

			if ( distToPoint === 0 ) {

				return true;

			}

			const denominator = plane.normal.dot( this.direction );

			if ( denominator * distToPoint < 0 ) {

				return true;

			}

			// ray origin is behind the plane (and is pointing behind it)

			return false;

		}

		/**
		 * Intersects this ray with the given bounding box, returning the intersection
		 * point or `null` if there is no intersection.
		 *
		 * @param {Box3} box - The box to intersect.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The intersection point.
		 */
		intersectBox( box, target ) {

			let tmin, tmax, tymin, tymax, tzmin, tzmax;

			const invdirx = 1 / this.direction.x,
				invdiry = 1 / this.direction.y,
				invdirz = 1 / this.direction.z;

			const origin = this.origin;

			if ( invdirx >= 0 ) {

				tmin = ( box.min.x - origin.x ) * invdirx;
				tmax = ( box.max.x - origin.x ) * invdirx;

			} else {

				tmin = ( box.max.x - origin.x ) * invdirx;
				tmax = ( box.min.x - origin.x ) * invdirx;

			}

			if ( invdiry >= 0 ) {

				tymin = ( box.min.y - origin.y ) * invdiry;
				tymax = ( box.max.y - origin.y ) * invdiry;

			} else {

				tymin = ( box.max.y - origin.y ) * invdiry;
				tymax = ( box.min.y - origin.y ) * invdiry;

			}

			if ( ( tmin > tymax ) || ( tymin > tmax ) ) return null;

			if ( tymin > tmin || isNaN( tmin ) ) tmin = tymin;

			if ( tymax < tmax || isNaN( tmax ) ) tmax = tymax;

			if ( invdirz >= 0 ) {

				tzmin = ( box.min.z - origin.z ) * invdirz;
				tzmax = ( box.max.z - origin.z ) * invdirz;

			} else {

				tzmin = ( box.max.z - origin.z ) * invdirz;
				tzmax = ( box.min.z - origin.z ) * invdirz;

			}

			if ( ( tmin > tzmax ) || ( tzmin > tmax ) ) return null;

			if ( tzmin > tmin || tmin !== tmin ) tmin = tzmin;

			if ( tzmax < tmax || tmax !== tmax ) tmax = tzmax;

			//return point closest to the ray (positive side)

			if ( tmax < 0 ) return null;

			return this.at( tmin >= 0 ? tmin : tmax, target );

		}

		/**
		 * Returns `true` if this ray intersects with the given box.
		 *
		 * @param {Box3} box - The box to intersect.
		 * @return {boolean} Whether this ray intersects with the given box or not.
		 */
		intersectsBox( box ) {

			return this.intersectBox( box, _vector$a ) !== null;

		}

		/**
		 * Intersects this ray with the given triangle, returning the intersection
		 * point or `null` if there is no intersection.
		 *
		 * @param {Vector3} a - The first vertex of the triangle.
		 * @param {Vector3} b - The second vertex of the triangle.
		 * @param {Vector3} c - The third vertex of the triangle.
		 * @param {boolean} backfaceCulling - Whether to use backface culling or not.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The intersection point.
		 */
		intersectTriangle( a, b, c, backfaceCulling, target ) {

			// Compute the offset origin, edges, and normal.

			// from https://github.com/pmjoniak/GeometricTools/blob/master/GTEngine/Include/Mathematics/GteIntrRay3Triangle3.h

			_edge1.subVectors( b, a );
			_edge2.subVectors( c, a );
			_normal$1.crossVectors( _edge1, _edge2 );

			// Solve Q + t*D = b1*E1 + b2*E2 (Q = kDiff, D = ray direction,
			// E1 = kEdge1, E2 = kEdge2, N = Cross(E1,E2)) by
			//   |Dot(D,N)|*b1 = sign(Dot(D,N))*Dot(D,Cross(Q,E2))
			//   |Dot(D,N)|*b2 = sign(Dot(D,N))*Dot(D,Cross(E1,Q))
			//   |Dot(D,N)|*t = -sign(Dot(D,N))*Dot(Q,N)
			let DdN = this.direction.dot( _normal$1 );
			let sign;

			if ( DdN > 0 ) {

				if ( backfaceCulling ) return null;
				sign = 1;

			} else if ( DdN < 0 ) {

				sign = -1;
				DdN = - DdN;

			} else {

				return null;

			}

			_diff.subVectors( this.origin, a );
			const DdQxE2 = sign * this.direction.dot( _edge2.crossVectors( _diff, _edge2 ) );

			// b1 < 0, no intersection
			if ( DdQxE2 < 0 ) {

				return null;

			}

			const DdE1xQ = sign * this.direction.dot( _edge1.cross( _diff ) );

			// b2 < 0, no intersection
			if ( DdE1xQ < 0 ) {

				return null;

			}

			// b1+b2 > 1, no intersection
			if ( DdQxE2 + DdE1xQ > DdN ) {

				return null;

			}

			// Line intersects triangle, check if ray does.
			const QdN = - sign * _diff.dot( _normal$1 );

			// t < 0, no intersection
			if ( QdN < 0 ) {

				return null;

			}

			// Ray intersects triangle.
			return this.at( QdN / DdN, target );

		}

		/**
		 * Transforms this ray with the given 4x4 transformation matrix.
		 *
		 * @param {Matrix4} matrix4 - The transformation matrix.
		 * @return {Ray} A reference to this ray.
		 */
		applyMatrix4( matrix4 ) {

			this.origin.applyMatrix4( matrix4 );
			this.direction.transformDirection( matrix4 );

			return this;

		}

		/**
		 * Returns `true` if this ray is equal with the given one.
		 *
		 * @param {Ray} ray - The ray to test for equality.
		 * @return {boolean} Whether this ray is equal with the given one.
		 */
		equals( ray ) {

			return ray.origin.equals( this.origin ) && ray.direction.equals( this.direction );

		}

		/**
		 * Returns a new ray with copied values from this instance.
		 *
		 * @return {Ray} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

	}

	/**
	 * Represents a 4x4 matrix.
	 *
	 * The most common use of a 4x4 matrix in 3D computer graphics is as a transformation matrix.
	 * For an introduction to transformation matrices as used in WebGL, check out [this tutorial]{@link https://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices}
	 *
	 * This allows a 3D vector representing a point in 3D space to undergo
	 * transformations such as translation, rotation, shear, scale, reflection,
	 * orthogonal or perspective projection and so on, by being multiplied by the
	 * matrix. This is known as `applying` the matrix to the vector.
	 *
	 * A Note on Row-Major and Column-Major Ordering:
	 *
	 * The constructor and {@link Matrix3#set} method take arguments in
	 * [row-major]{@link https://en.wikipedia.org/wiki/Row-_and_column-major_order#Column-major_order}
	 * order, while internally they are stored in the {@link Matrix3#elements} array in column-major order.
	 * This means that calling:
	 * ```js
	 * const m = new THREE.Matrix4();
	 * m.set( 11, 12, 13, 14,
	 *        21, 22, 23, 24,
	 *        31, 32, 33, 34,
	 *        41, 42, 43, 44 );
	 * ```
	 * will result in the elements array containing:
	 * ```js
	 * m.elements = [ 11, 21, 31, 41,
	 *                12, 22, 32, 42,
	 *                13, 23, 33, 43,
	 *                14, 24, 34, 44 ];
	 * ```
	 * and internally all calculations are performed using column-major ordering.
	 * However, as the actual ordering makes no difference mathematically and
	 * most people are used to thinking about matrices in row-major order, the
	 * three.js documentation shows matrices in row-major order. Just bear in
	 * mind that if you are reading the source code, you'll have to take the
	 * transpose of any matrices outlined here to make sense of the calculations.
	 */
	class Matrix4 {

		/**
		 * Constructs a new 4x4 matrix. The arguments are supposed to be
		 * in row-major order. If no arguments are provided, the constructor
		 * initializes the matrix as an identity matrix.
		 *
		 * @param {number} [n11] - 1-1 matrix element.
		 * @param {number} [n12] - 1-2 matrix element.
		 * @param {number} [n13] - 1-3 matrix element.
		 * @param {number} [n14] - 1-4 matrix element.
		 * @param {number} [n21] - 2-1 matrix element.
		 * @param {number} [n22] - 2-2 matrix element.
		 * @param {number} [n23] - 2-3 matrix element.
		 * @param {number} [n24] - 2-4 matrix element.
		 * @param {number} [n31] - 3-1 matrix element.
		 * @param {number} [n32] - 3-2 matrix element.
		 * @param {number} [n33] - 3-3 matrix element.
		 * @param {number} [n34] - 3-4 matrix element.
		 * @param {number} [n41] - 4-1 matrix element.
		 * @param {number} [n42] - 4-2 matrix element.
		 * @param {number} [n43] - 4-3 matrix element.
		 * @param {number} [n44] - 4-4 matrix element.
		 */
		constructor( n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44 ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			Matrix4.prototype.isMatrix4 = true;

			/**
			 * A column-major list of matrix values.
			 *
			 * @type {Array<number>}
			 */
			this.elements = [

				1, 0, 0, 0,
				0, 1, 0, 0,
				0, 0, 1, 0,
				0, 0, 0, 1

			];

			if ( n11 !== undefined ) {

				this.set( n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44 );

			}

		}

		/**
		 * Sets the elements of the matrix.The arguments are supposed to be
		 * in row-major order.
		 *
		 * @param {number} [n11] - 1-1 matrix element.
		 * @param {number} [n12] - 1-2 matrix element.
		 * @param {number} [n13] - 1-3 matrix element.
		 * @param {number} [n14] - 1-4 matrix element.
		 * @param {number} [n21] - 2-1 matrix element.
		 * @param {number} [n22] - 2-2 matrix element.
		 * @param {number} [n23] - 2-3 matrix element.
		 * @param {number} [n24] - 2-4 matrix element.
		 * @param {number} [n31] - 3-1 matrix element.
		 * @param {number} [n32] - 3-2 matrix element.
		 * @param {number} [n33] - 3-3 matrix element.
		 * @param {number} [n34] - 3-4 matrix element.
		 * @param {number} [n41] - 4-1 matrix element.
		 * @param {number} [n42] - 4-2 matrix element.
		 * @param {number} [n43] - 4-3 matrix element.
		 * @param {number} [n44] - 4-4 matrix element.
		 * @return {Matrix4} A reference to this matrix.
		 */
		set( n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44 ) {

			const te = this.elements;

			te[ 0 ] = n11; te[ 4 ] = n12; te[ 8 ] = n13; te[ 12 ] = n14;
			te[ 1 ] = n21; te[ 5 ] = n22; te[ 9 ] = n23; te[ 13 ] = n24;
			te[ 2 ] = n31; te[ 6 ] = n32; te[ 10 ] = n33; te[ 14 ] = n34;
			te[ 3 ] = n41; te[ 7 ] = n42; te[ 11 ] = n43; te[ 15 ] = n44;

			return this;

		}

		/**
		 * Sets this matrix to the 4x4 identity matrix.
		 *
		 * @return {Matrix4} A reference to this matrix.
		 */
		identity() {

			this.set(

				1, 0, 0, 0,
				0, 1, 0, 0,
				0, 0, 1, 0,
				0, 0, 0, 1

			);

			return this;

		}

		/**
		 * Returns a matrix with copied values from this instance.
		 *
		 * @return {Matrix4} A clone of this instance.
		 */
		clone() {

			return new Matrix4().fromArray( this.elements );

		}

		/**
		 * Copies the values of the given matrix to this instance.
		 *
		 * @param {Matrix4} m - The matrix to copy.
		 * @return {Matrix4} A reference to this matrix.
		 */
		copy( m ) {

			const te = this.elements;
			const me = m.elements;

			te[ 0 ] = me[ 0 ]; te[ 1 ] = me[ 1 ]; te[ 2 ] = me[ 2 ]; te[ 3 ] = me[ 3 ];
			te[ 4 ] = me[ 4 ]; te[ 5 ] = me[ 5 ]; te[ 6 ] = me[ 6 ]; te[ 7 ] = me[ 7 ];
			te[ 8 ] = me[ 8 ]; te[ 9 ] = me[ 9 ]; te[ 10 ] = me[ 10 ]; te[ 11 ] = me[ 11 ];
			te[ 12 ] = me[ 12 ]; te[ 13 ] = me[ 13 ]; te[ 14 ] = me[ 14 ]; te[ 15 ] = me[ 15 ];

			return this;

		}

		/**
		 * Copies the translation component of the given matrix
		 * into this matrix's translation component.
		 *
		 * @param {Matrix4} m - The matrix to copy the translation component.
		 * @return {Matrix4} A reference to this matrix.
		 */
		copyPosition( m ) {

			const te = this.elements, me = m.elements;

			te[ 12 ] = me[ 12 ];
			te[ 13 ] = me[ 13 ];
			te[ 14 ] = me[ 14 ];

			return this;

		}

		/**
		 * Set the upper 3x3 elements of this matrix to the values of given 3x3 matrix.
		 *
		 * @param {Matrix3} m - The 3x3 matrix.
		 * @return {Matrix4} A reference to this matrix.
		 */
		setFromMatrix3( m ) {

			const me = m.elements;

			this.set(

				me[ 0 ], me[ 3 ], me[ 6 ], 0,
				me[ 1 ], me[ 4 ], me[ 7 ], 0,
				me[ 2 ], me[ 5 ], me[ 8 ], 0,
				0, 0, 0, 1

			);

			return this;

		}

		/**
		 * Extracts the basis of this matrix into the three axis vectors provided.
		 *
		 * @param {Vector3} xAxis - The basis's x axis.
		 * @param {Vector3} yAxis - The basis's y axis.
		 * @param {Vector3} zAxis - The basis's z axis.
		 * @return {Matrix4} A reference to this matrix.
		 */
		extractBasis( xAxis, yAxis, zAxis ) {

			xAxis.setFromMatrixColumn( this, 0 );
			yAxis.setFromMatrixColumn( this, 1 );
			zAxis.setFromMatrixColumn( this, 2 );

			return this;

		}

		/**
		 * Sets the given basis vectors to this matrix.
		 *
		 * @param {Vector3} xAxis - The basis's x axis.
		 * @param {Vector3} yAxis - The basis's y axis.
		 * @param {Vector3} zAxis - The basis's z axis.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeBasis( xAxis, yAxis, zAxis ) {

			this.set(
				xAxis.x, yAxis.x, zAxis.x, 0,
				xAxis.y, yAxis.y, zAxis.y, 0,
				xAxis.z, yAxis.z, zAxis.z, 0,
				0, 0, 0, 1
			);

			return this;

		}

		/**
		 * Extracts the rotation component of the given matrix
		 * into this matrix's rotation component.
		 *
		 * Note: This method does not support reflection matrices.
		 *
		 * @param {Matrix4} m - The matrix.
		 * @return {Matrix4} A reference to this matrix.
		 */
		extractRotation( m ) {

			const te = this.elements;
			const me = m.elements;

			const scaleX = 1 / _v1$5.setFromMatrixColumn( m, 0 ).length();
			const scaleY = 1 / _v1$5.setFromMatrixColumn( m, 1 ).length();
			const scaleZ = 1 / _v1$5.setFromMatrixColumn( m, 2 ).length();

			te[ 0 ] = me[ 0 ] * scaleX;
			te[ 1 ] = me[ 1 ] * scaleX;
			te[ 2 ] = me[ 2 ] * scaleX;
			te[ 3 ] = 0;

			te[ 4 ] = me[ 4 ] * scaleY;
			te[ 5 ] = me[ 5 ] * scaleY;
			te[ 6 ] = me[ 6 ] * scaleY;
			te[ 7 ] = 0;

			te[ 8 ] = me[ 8 ] * scaleZ;
			te[ 9 ] = me[ 9 ] * scaleZ;
			te[ 10 ] = me[ 10 ] * scaleZ;
			te[ 11 ] = 0;

			te[ 12 ] = 0;
			te[ 13 ] = 0;
			te[ 14 ] = 0;
			te[ 15 ] = 1;

			return this;

		}

		/**
		 * Sets the rotation component (the upper left 3x3 matrix) of this matrix to
		 * the rotation specified by the given Euler angles. The rest of
		 * the matrix is set to the identity. Depending on the {@link Euler#order},
		 * there are six possible outcomes. See [this page]{@link https://en.wikipedia.org/wiki/Euler_angles#Rotation_matrix}
		 * for a complete list.
		 *
		 * @param {Euler} euler - The Euler angles.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeRotationFromEuler( euler ) {

			const te = this.elements;

			const x = euler.x, y = euler.y, z = euler.z;
			const a = Math.cos( x ), b = Math.sin( x );
			const c = Math.cos( y ), d = Math.sin( y );
			const e = Math.cos( z ), f = Math.sin( z );

			if ( euler.order === 'XYZ' ) {

				const ae = a * e, af = a * f, be = b * e, bf = b * f;

				te[ 0 ] = c * e;
				te[ 4 ] = - c * f;
				te[ 8 ] = d;

				te[ 1 ] = af + be * d;
				te[ 5 ] = ae - bf * d;
				te[ 9 ] = - b * c;

				te[ 2 ] = bf - ae * d;
				te[ 6 ] = be + af * d;
				te[ 10 ] = a * c;

			} else if ( euler.order === 'YXZ' ) {

				const ce = c * e, cf = c * f, de = d * e, df = d * f;

				te[ 0 ] = ce + df * b;
				te[ 4 ] = de * b - cf;
				te[ 8 ] = a * d;

				te[ 1 ] = a * f;
				te[ 5 ] = a * e;
				te[ 9 ] = - b;

				te[ 2 ] = cf * b - de;
				te[ 6 ] = df + ce * b;
				te[ 10 ] = a * c;

			} else if ( euler.order === 'ZXY' ) {

				const ce = c * e, cf = c * f, de = d * e, df = d * f;

				te[ 0 ] = ce - df * b;
				te[ 4 ] = - a * f;
				te[ 8 ] = de + cf * b;

				te[ 1 ] = cf + de * b;
				te[ 5 ] = a * e;
				te[ 9 ] = df - ce * b;

				te[ 2 ] = - a * d;
				te[ 6 ] = b;
				te[ 10 ] = a * c;

			} else if ( euler.order === 'ZYX' ) {

				const ae = a * e, af = a * f, be = b * e, bf = b * f;

				te[ 0 ] = c * e;
				te[ 4 ] = be * d - af;
				te[ 8 ] = ae * d + bf;

				te[ 1 ] = c * f;
				te[ 5 ] = bf * d + ae;
				te[ 9 ] = af * d - be;

				te[ 2 ] = - d;
				te[ 6 ] = b * c;
				te[ 10 ] = a * c;

			} else if ( euler.order === 'YZX' ) {

				const ac = a * c, ad = a * d, bc = b * c, bd = b * d;

				te[ 0 ] = c * e;
				te[ 4 ] = bd - ac * f;
				te[ 8 ] = bc * f + ad;

				te[ 1 ] = f;
				te[ 5 ] = a * e;
				te[ 9 ] = - b * e;

				te[ 2 ] = - d * e;
				te[ 6 ] = ad * f + bc;
				te[ 10 ] = ac - bd * f;

			} else if ( euler.order === 'XZY' ) {

				const ac = a * c, ad = a * d, bc = b * c, bd = b * d;

				te[ 0 ] = c * e;
				te[ 4 ] = - f;
				te[ 8 ] = d * e;

				te[ 1 ] = ac * f + bd;
				te[ 5 ] = a * e;
				te[ 9 ] = ad * f - bc;

				te[ 2 ] = bc * f - ad;
				te[ 6 ] = b * e;
				te[ 10 ] = bd * f + ac;

			}

			// bottom row
			te[ 3 ] = 0;
			te[ 7 ] = 0;
			te[ 11 ] = 0;

			// last column
			te[ 12 ] = 0;
			te[ 13 ] = 0;
			te[ 14 ] = 0;
			te[ 15 ] = 1;

			return this;

		}

		/**
		 * Sets the rotation component of this matrix to the rotation specified by
		 * the given Quaternion as outlined [here]{@link https://en.wikipedia.org/wiki/Rotation_matrix#Quaternion}
		 * The rest of the matrix is set to the identity.
		 *
		 * @param {Quaternion} q - The Quaternion.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeRotationFromQuaternion( q ) {

			return this.compose( _zero, q, _one );

		}

		/**
		 * Sets the rotation component of the transformation matrix, looking from `eye` towards
		 * `target`, and oriented by the up-direction.
		 *
		 * @param {Vector3} eye - The eye vector.
		 * @param {Vector3} target - The target vector.
		 * @param {Vector3} up - The up vector.
		 * @return {Matrix4} A reference to this matrix.
		 */
		lookAt( eye, target, up ) {

			const te = this.elements;

			_z.subVectors( eye, target );

			if ( _z.lengthSq() === 0 ) {

				// eye and target are in the same position

				_z.z = 1;

			}

			_z.normalize();
			_x.crossVectors( up, _z );

			if ( _x.lengthSq() === 0 ) {

				// up and z are parallel

				if ( Math.abs( up.z ) === 1 ) {

					_z.x += 0.0001;

				} else {

					_z.z += 0.0001;

				}

				_z.normalize();
				_x.crossVectors( up, _z );

			}

			_x.normalize();
			_y.crossVectors( _z, _x );

			te[ 0 ] = _x.x; te[ 4 ] = _y.x; te[ 8 ] = _z.x;
			te[ 1 ] = _x.y; te[ 5 ] = _y.y; te[ 9 ] = _z.y;
			te[ 2 ] = _x.z; te[ 6 ] = _y.z; te[ 10 ] = _z.z;

			return this;

		}

		/**
		 * Post-multiplies this matrix by the given 4x4 matrix.
		 *
		 * @param {Matrix4} m - The matrix to multiply with.
		 * @return {Matrix4} A reference to this matrix.
		 */
		multiply( m ) {

			return this.multiplyMatrices( this, m );

		}

		/**
		 * Pre-multiplies this matrix by the given 4x4 matrix.
		 *
		 * @param {Matrix4} m - The matrix to multiply with.
		 * @return {Matrix4} A reference to this matrix.
		 */
		premultiply( m ) {

			return this.multiplyMatrices( m, this );

		}

		/**
		 * Multiples the given 4x4 matrices and stores the result
		 * in this matrix.
		 *
		 * @param {Matrix4} a - The first matrix.
		 * @param {Matrix4} b - The second matrix.
		 * @return {Matrix4} A reference to this matrix.
		 */
		multiplyMatrices( a, b ) {

			const ae = a.elements;
			const be = b.elements;
			const te = this.elements;

			const a11 = ae[ 0 ], a12 = ae[ 4 ], a13 = ae[ 8 ], a14 = ae[ 12 ];
			const a21 = ae[ 1 ], a22 = ae[ 5 ], a23 = ae[ 9 ], a24 = ae[ 13 ];
			const a31 = ae[ 2 ], a32 = ae[ 6 ], a33 = ae[ 10 ], a34 = ae[ 14 ];
			const a41 = ae[ 3 ], a42 = ae[ 7 ], a43 = ae[ 11 ], a44 = ae[ 15 ];

			const b11 = be[ 0 ], b12 = be[ 4 ], b13 = be[ 8 ], b14 = be[ 12 ];
			const b21 = be[ 1 ], b22 = be[ 5 ], b23 = be[ 9 ], b24 = be[ 13 ];
			const b31 = be[ 2 ], b32 = be[ 6 ], b33 = be[ 10 ], b34 = be[ 14 ];
			const b41 = be[ 3 ], b42 = be[ 7 ], b43 = be[ 11 ], b44 = be[ 15 ];

			te[ 0 ] = a11 * b11 + a12 * b21 + a13 * b31 + a14 * b41;
			te[ 4 ] = a11 * b12 + a12 * b22 + a13 * b32 + a14 * b42;
			te[ 8 ] = a11 * b13 + a12 * b23 + a13 * b33 + a14 * b43;
			te[ 12 ] = a11 * b14 + a12 * b24 + a13 * b34 + a14 * b44;

			te[ 1 ] = a21 * b11 + a22 * b21 + a23 * b31 + a24 * b41;
			te[ 5 ] = a21 * b12 + a22 * b22 + a23 * b32 + a24 * b42;
			te[ 9 ] = a21 * b13 + a22 * b23 + a23 * b33 + a24 * b43;
			te[ 13 ] = a21 * b14 + a22 * b24 + a23 * b34 + a24 * b44;

			te[ 2 ] = a31 * b11 + a32 * b21 + a33 * b31 + a34 * b41;
			te[ 6 ] = a31 * b12 + a32 * b22 + a33 * b32 + a34 * b42;
			te[ 10 ] = a31 * b13 + a32 * b23 + a33 * b33 + a34 * b43;
			te[ 14 ] = a31 * b14 + a32 * b24 + a33 * b34 + a34 * b44;

			te[ 3 ] = a41 * b11 + a42 * b21 + a43 * b31 + a44 * b41;
			te[ 7 ] = a41 * b12 + a42 * b22 + a43 * b32 + a44 * b42;
			te[ 11 ] = a41 * b13 + a42 * b23 + a43 * b33 + a44 * b43;
			te[ 15 ] = a41 * b14 + a42 * b24 + a43 * b34 + a44 * b44;

			return this;

		}

		/**
		 * Multiplies every component of the matrix by the given scalar.
		 *
		 * @param {number} s - The scalar.
		 * @return {Matrix4} A reference to this matrix.
		 */
		multiplyScalar( s ) {

			const te = this.elements;

			te[ 0 ] *= s; te[ 4 ] *= s; te[ 8 ] *= s; te[ 12 ] *= s;
			te[ 1 ] *= s; te[ 5 ] *= s; te[ 9 ] *= s; te[ 13 ] *= s;
			te[ 2 ] *= s; te[ 6 ] *= s; te[ 10 ] *= s; te[ 14 ] *= s;
			te[ 3 ] *= s; te[ 7 ] *= s; te[ 11 ] *= s; te[ 15 ] *= s;

			return this;

		}

		/**
		 * Computes and returns the determinant of this matrix.
		 *
		 * Based on the method outlined [here]{@link http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.html}.
		 *
		 * @return {number} The determinant.
		 */
		determinant() {

			const te = this.elements;

			const n11 = te[ 0 ], n12 = te[ 4 ], n13 = te[ 8 ], n14 = te[ 12 ];
			const n21 = te[ 1 ], n22 = te[ 5 ], n23 = te[ 9 ], n24 = te[ 13 ];
			const n31 = te[ 2 ], n32 = te[ 6 ], n33 = te[ 10 ], n34 = te[ 14 ];
			const n41 = te[ 3 ], n42 = te[ 7 ], n43 = te[ 11 ], n44 = te[ 15 ];

			//TODO: make this more efficient

			return (
				n41 * (
					+ n14 * n23 * n32
					 - n13 * n24 * n32
					 - n14 * n22 * n33
					 + n12 * n24 * n33
					 + n13 * n22 * n34
					 - n12 * n23 * n34
				) +
				n42 * (
					+ n11 * n23 * n34
					 - n11 * n24 * n33
					 + n14 * n21 * n33
					 - n13 * n21 * n34
					 + n13 * n24 * n31
					 - n14 * n23 * n31
				) +
				n43 * (
					+ n11 * n24 * n32
					 - n11 * n22 * n34
					 - n14 * n21 * n32
					 + n12 * n21 * n34
					 + n14 * n22 * n31
					 - n12 * n24 * n31
				) +
				n44 * (
					- n13 * n22 * n31
					 - n11 * n23 * n32
					 + n11 * n22 * n33
					 + n13 * n21 * n32
					 - n12 * n21 * n33
					 + n12 * n23 * n31
				)

			);

		}

		/**
		 * Transposes this matrix in place.
		 *
		 * @return {Matrix4} A reference to this matrix.
		 */
		transpose() {

			const te = this.elements;
			let tmp;

			tmp = te[ 1 ]; te[ 1 ] = te[ 4 ]; te[ 4 ] = tmp;
			tmp = te[ 2 ]; te[ 2 ] = te[ 8 ]; te[ 8 ] = tmp;
			tmp = te[ 6 ]; te[ 6 ] = te[ 9 ]; te[ 9 ] = tmp;

			tmp = te[ 3 ]; te[ 3 ] = te[ 12 ]; te[ 12 ] = tmp;
			tmp = te[ 7 ]; te[ 7 ] = te[ 13 ]; te[ 13 ] = tmp;
			tmp = te[ 11 ]; te[ 11 ] = te[ 14 ]; te[ 14 ] = tmp;

			return this;

		}

		/**
		 * Sets the position component for this matrix from the given vector,
		 * without affecting the rest of the matrix.
		 *
		 * @param {number|Vector3} x - The x component of the vector or alternatively the vector object.
		 * @param {number} y - The y component of the vector.
		 * @param {number} z - The z component of the vector.
		 * @return {Matrix4} A reference to this matrix.
		 */
		setPosition( x, y, z ) {

			const te = this.elements;

			if ( x.isVector3 ) {

				te[ 12 ] = x.x;
				te[ 13 ] = x.y;
				te[ 14 ] = x.z;

			} else {

				te[ 12 ] = x;
				te[ 13 ] = y;
				te[ 14 ] = z;

			}

			return this;

		}

		/**
		 * Inverts this matrix, using the [analytic method]{@link https://en.wikipedia.org/wiki/Invertible_matrix#Analytic_solution}.
		 * You can not invert with a determinant of zero. If you attempt this, the method produces
		 * a zero matrix instead.
		 *
		 * @return {Matrix4} A reference to this matrix.
		 */
		invert() {

			// based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm
			const te = this.elements,

				n11 = te[ 0 ], n21 = te[ 1 ], n31 = te[ 2 ], n41 = te[ 3 ],
				n12 = te[ 4 ], n22 = te[ 5 ], n32 = te[ 6 ], n42 = te[ 7 ],
				n13 = te[ 8 ], n23 = te[ 9 ], n33 = te[ 10 ], n43 = te[ 11 ],
				n14 = te[ 12 ], n24 = te[ 13 ], n34 = te[ 14 ], n44 = te[ 15 ],

				t11 = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44,
				t12 = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44,
				t13 = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44,
				t14 = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;

			const det = n11 * t11 + n21 * t12 + n31 * t13 + n41 * t14;

			if ( det === 0 ) return this.set( 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 );

			const detInv = 1 / det;

			te[ 0 ] = t11 * detInv;
			te[ 1 ] = ( n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44 ) * detInv;
			te[ 2 ] = ( n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44 ) * detInv;
			te[ 3 ] = ( n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43 ) * detInv;

			te[ 4 ] = t12 * detInv;
			te[ 5 ] = ( n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44 ) * detInv;
			te[ 6 ] = ( n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44 ) * detInv;
			te[ 7 ] = ( n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43 ) * detInv;

			te[ 8 ] = t13 * detInv;
			te[ 9 ] = ( n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44 ) * detInv;
			te[ 10 ] = ( n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44 ) * detInv;
			te[ 11 ] = ( n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43 ) * detInv;

			te[ 12 ] = t14 * detInv;
			te[ 13 ] = ( n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34 ) * detInv;
			te[ 14 ] = ( n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34 ) * detInv;
			te[ 15 ] = ( n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33 ) * detInv;

			return this;

		}

		/**
		 * Multiplies the columns of this matrix by the given vector.
		 *
		 * @param {Vector3} v - The scale vector.
		 * @return {Matrix4} A reference to this matrix.
		 */
		scale( v ) {

			const te = this.elements;
			const x = v.x, y = v.y, z = v.z;

			te[ 0 ] *= x; te[ 4 ] *= y; te[ 8 ] *= z;
			te[ 1 ] *= x; te[ 5 ] *= y; te[ 9 ] *= z;
			te[ 2 ] *= x; te[ 6 ] *= y; te[ 10 ] *= z;
			te[ 3 ] *= x; te[ 7 ] *= y; te[ 11 ] *= z;

			return this;

		}

		/**
		 * Gets the maximum scale value of the three axes.
		 *
		 * @return {number} The maximum scale.
		 */
		getMaxScaleOnAxis() {

			const te = this.elements;

			const scaleXSq = te[ 0 ] * te[ 0 ] + te[ 1 ] * te[ 1 ] + te[ 2 ] * te[ 2 ];
			const scaleYSq = te[ 4 ] * te[ 4 ] + te[ 5 ] * te[ 5 ] + te[ 6 ] * te[ 6 ];
			const scaleZSq = te[ 8 ] * te[ 8 ] + te[ 9 ] * te[ 9 ] + te[ 10 ] * te[ 10 ];

			return Math.sqrt( Math.max( scaleXSq, scaleYSq, scaleZSq ) );

		}

		/**
		 * Sets this matrix as a translation transform from the given vector.
		 *
		 * @param {number|Vector3} x - The amount to translate in the X axis or alternatively a translation vector.
		 * @param {number} y - The amount to translate in the Y axis.
		 * @param {number} z - The amount to translate in the z axis.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeTranslation( x, y, z ) {

			if ( x.isVector3 ) {

				this.set(

					1, 0, 0, x.x,
					0, 1, 0, x.y,
					0, 0, 1, x.z,
					0, 0, 0, 1

				);

			} else {

				this.set(

					1, 0, 0, x,
					0, 1, 0, y,
					0, 0, 1, z,
					0, 0, 0, 1

				);

			}

			return this;

		}

		/**
		 * Sets this matrix as a rotational transformation around the X axis by
		 * the given angle.
		 *
		 * @param {number} theta - The rotation in radians.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeRotationX( theta ) {

			const c = Math.cos( theta ), s = Math.sin( theta );

			this.set(

				1, 0, 0, 0,
				0, c, - s, 0,
				0, s, c, 0,
				0, 0, 0, 1

			);

			return this;

		}

		/**
		 * Sets this matrix as a rotational transformation around the Y axis by
		 * the given angle.
		 *
		 * @param {number} theta - The rotation in radians.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeRotationY( theta ) {

			const c = Math.cos( theta ), s = Math.sin( theta );

			this.set(

				 c, 0, s, 0,
				 0, 1, 0, 0,
				- s, 0, c, 0,
				 0, 0, 0, 1

			);

			return this;

		}

		/**
		 * Sets this matrix as a rotational transformation around the Z axis by
		 * the given angle.
		 *
		 * @param {number} theta - The rotation in radians.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeRotationZ( theta ) {

			const c = Math.cos( theta ), s = Math.sin( theta );

			this.set(

				c, - s, 0, 0,
				s, c, 0, 0,
				0, 0, 1, 0,
				0, 0, 0, 1

			);

			return this;

		}

		/**
		 * Sets this matrix as a rotational transformation around the given axis by
		 * the given angle.
		 *
		 * This is a somewhat controversial but mathematically sound alternative to
		 * rotating via Quaternions. See the discussion [here]{@link https://www.gamedev.net/articles/programming/math-and-physics/do-we-really-need-quaternions-r1199}.
		 *
		 * @param {Vector3} axis - The normalized rotation axis.
		 * @param {number} angle - The rotation in radians.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeRotationAxis( axis, angle ) {

			// Based on http://www.gamedev.net/reference/articles/article1199.asp

			const c = Math.cos( angle );
			const s = Math.sin( angle );
			const t = 1 - c;
			const x = axis.x, y = axis.y, z = axis.z;
			const tx = t * x, ty = t * y;

			this.set(

				tx * x + c, tx * y - s * z, tx * z + s * y, 0,
				tx * y + s * z, ty * y + c, ty * z - s * x, 0,
				tx * z - s * y, ty * z + s * x, t * z * z + c, 0,
				0, 0, 0, 1

			);

			return this;

		}

		/**
		 * Sets this matrix as a scale transformation.
		 *
		 * @param {number} x - The amount to scale in the X axis.
		 * @param {number} y - The amount to scale in the Y axis.
		 * @param {number} z - The amount to scale in the Z axis.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeScale( x, y, z ) {

			this.set(

				x, 0, 0, 0,
				0, y, 0, 0,
				0, 0, z, 0,
				0, 0, 0, 1

			);

			return this;

		}

		/**
		 * Sets this matrix as a shear transformation.
		 *
		 * @param {number} xy - The amount to shear X by Y.
		 * @param {number} xz - The amount to shear X by Z.
		 * @param {number} yx - The amount to shear Y by X.
		 * @param {number} yz - The amount to shear Y by Z.
		 * @param {number} zx - The amount to shear Z by X.
		 * @param {number} zy - The amount to shear Z by Y.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeShear( xy, xz, yx, yz, zx, zy ) {

			this.set(

				1, yx, zx, 0,
				xy, 1, zy, 0,
				xz, yz, 1, 0,
				0, 0, 0, 1

			);

			return this;

		}

		/**
		 * Sets this matrix to the transformation composed of the given position,
		 * rotation (Quaternion) and scale.
		 *
		 * @param {Vector3} position - The position vector.
		 * @param {Quaternion} quaternion - The rotation as a Quaternion.
		 * @param {Vector3} scale - The scale vector.
		 * @return {Matrix4} A reference to this matrix.
		 */
		compose( position, quaternion, scale ) {

			const te = this.elements;

			const x = quaternion._x, y = quaternion._y, z = quaternion._z, w = quaternion._w;
			const x2 = x + x,	y2 = y + y, z2 = z + z;
			const xx = x * x2, xy = x * y2, xz = x * z2;
			const yy = y * y2, yz = y * z2, zz = z * z2;
			const wx = w * x2, wy = w * y2, wz = w * z2;

			const sx = scale.x, sy = scale.y, sz = scale.z;

			te[ 0 ] = ( 1 - ( yy + zz ) ) * sx;
			te[ 1 ] = ( xy + wz ) * sx;
			te[ 2 ] = ( xz - wy ) * sx;
			te[ 3 ] = 0;

			te[ 4 ] = ( xy - wz ) * sy;
			te[ 5 ] = ( 1 - ( xx + zz ) ) * sy;
			te[ 6 ] = ( yz + wx ) * sy;
			te[ 7 ] = 0;

			te[ 8 ] = ( xz + wy ) * sz;
			te[ 9 ] = ( yz - wx ) * sz;
			te[ 10 ] = ( 1 - ( xx + yy ) ) * sz;
			te[ 11 ] = 0;

			te[ 12 ] = position.x;
			te[ 13 ] = position.y;
			te[ 14 ] = position.z;
			te[ 15 ] = 1;

			return this;

		}

		/**
		 * Decomposes this matrix into its position, rotation and scale components
		 * and provides the result in the given objects.
		 *
		 * Note: Not all matrices are decomposable in this way. For example, if an
		 * object has a non-uniformly scaled parent, then the object's world matrix
		 * may not be decomposable, and this method may not be appropriate.
		 *
		 * @param {Vector3} position - The position vector.
		 * @param {Quaternion} quaternion - The rotation as a Quaternion.
		 * @param {Vector3} scale - The scale vector.
		 * @return {Matrix4} A reference to this matrix.
		 */
		decompose( position, quaternion, scale ) {

			const te = this.elements;

			let sx = _v1$5.set( te[ 0 ], te[ 1 ], te[ 2 ] ).length();
			const sy = _v1$5.set( te[ 4 ], te[ 5 ], te[ 6 ] ).length();
			const sz = _v1$5.set( te[ 8 ], te[ 9 ], te[ 10 ] ).length();

			// if determine is negative, we need to invert one scale
			const det = this.determinant();
			if ( det < 0 ) sx = - sx;

			position.x = te[ 12 ];
			position.y = te[ 13 ];
			position.z = te[ 14 ];

			// scale the rotation part
			_m1$2.copy( this );

			const invSX = 1 / sx;
			const invSY = 1 / sy;
			const invSZ = 1 / sz;

			_m1$2.elements[ 0 ] *= invSX;
			_m1$2.elements[ 1 ] *= invSX;
			_m1$2.elements[ 2 ] *= invSX;

			_m1$2.elements[ 4 ] *= invSY;
			_m1$2.elements[ 5 ] *= invSY;
			_m1$2.elements[ 6 ] *= invSY;

			_m1$2.elements[ 8 ] *= invSZ;
			_m1$2.elements[ 9 ] *= invSZ;
			_m1$2.elements[ 10 ] *= invSZ;

			quaternion.setFromRotationMatrix( _m1$2 );

			scale.x = sx;
			scale.y = sy;
			scale.z = sz;

			return this;

		}

		/**
		 * Creates a perspective projection matrix. This is used internally by
		 * {@link PerspectiveCamera#updateProjectionMatrix}.

		 * @param {number} left - Left boundary of the viewing frustum at the near plane.
		 * @param {number} right - Right boundary of the viewing frustum at the near plane.
		 * @param {number} top - Top boundary of the viewing frustum at the near plane.
		 * @param {number} bottom - Bottom boundary of the viewing frustum at the near plane.
		 * @param {number} near - The distance from the camera to the near plane.
		 * @param {number} far - The distance from the camera to the far plane.
		 * @param {(WebGLCoordinateSystem|WebGPUCoordinateSystem)} [coordinateSystem=WebGLCoordinateSystem] - The coordinate system.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makePerspective( left, right, top, bottom, near, far, coordinateSystem = WebGLCoordinateSystem ) {

			const te = this.elements;
			const x = 2 * near / ( right - left );
			const y = 2 * near / ( top - bottom );

			const a = ( right + left ) / ( right - left );
			const b = ( top + bottom ) / ( top - bottom );

			let c, d;

			if ( coordinateSystem === WebGLCoordinateSystem ) {

				c = - ( far + near ) / ( far - near );
				d = ( -2 * far * near ) / ( far - near );

			} else if ( coordinateSystem === WebGPUCoordinateSystem ) {

				c = - far / ( far - near );
				d = ( - far * near ) / ( far - near );

			} else {

				throw new Error( 'THREE.Matrix4.makePerspective(): Invalid coordinate system: ' + coordinateSystem );

			}

			te[ 0 ] = x;	te[ 4 ] = 0;	te[ 8 ] = a; 	te[ 12 ] = 0;
			te[ 1 ] = 0;	te[ 5 ] = y;	te[ 9 ] = b; 	te[ 13 ] = 0;
			te[ 2 ] = 0;	te[ 6 ] = 0;	te[ 10 ] = c; 	te[ 14 ] = d;
			te[ 3 ] = 0;	te[ 7 ] = 0;	te[ 11 ] = -1;	te[ 15 ] = 0;

			return this;

		}

		/**
		 * Creates a orthographic projection matrix. This is used internally by
		 * {@link OrthographicCamera#updateProjectionMatrix}.

		 * @param {number} left - Left boundary of the viewing frustum at the near plane.
		 * @param {number} right - Right boundary of the viewing frustum at the near plane.
		 * @param {number} top - Top boundary of the viewing frustum at the near plane.
		 * @param {number} bottom - Bottom boundary of the viewing frustum at the near plane.
		 * @param {number} near - The distance from the camera to the near plane.
		 * @param {number} far - The distance from the camera to the far plane.
		 * @param {(WebGLCoordinateSystem|WebGPUCoordinateSystem)} [coordinateSystem=WebGLCoordinateSystem] - The coordinate system.
		 * @return {Matrix4} A reference to this matrix.
		 */
		makeOrthographic( left, right, top, bottom, near, far, coordinateSystem = WebGLCoordinateSystem ) {

			const te = this.elements;
			const w = 1.0 / ( right - left );
			const h = 1.0 / ( top - bottom );
			const p = 1.0 / ( far - near );

			const x = ( right + left ) * w;
			const y = ( top + bottom ) * h;

			let z, zInv;

			if ( coordinateSystem === WebGLCoordinateSystem ) {

				z = ( far + near ) * p;
				zInv = -2 * p;

			} else if ( coordinateSystem === WebGPUCoordinateSystem ) {

				z = near * p;
				zInv = -1 * p;

			} else {

				throw new Error( 'THREE.Matrix4.makeOrthographic(): Invalid coordinate system: ' + coordinateSystem );

			}

			te[ 0 ] = 2 * w;	te[ 4 ] = 0;		te[ 8 ] = 0; 		te[ 12 ] = - x;
			te[ 1 ] = 0; 		te[ 5 ] = 2 * h;	te[ 9 ] = 0; 		te[ 13 ] = - y;
			te[ 2 ] = 0; 		te[ 6 ] = 0;		te[ 10 ] = zInv;	te[ 14 ] = - z;
			te[ 3 ] = 0; 		te[ 7 ] = 0;		te[ 11 ] = 0;		te[ 15 ] = 1;

			return this;

		}

		/**
		 * Returns `true` if this matrix is equal with the given one.
		 *
		 * @param {Matrix4} matrix - The matrix to test for equality.
		 * @return {boolean} Whether this matrix is equal with the given one.
		 */
		equals( matrix ) {

			const te = this.elements;
			const me = matrix.elements;

			for ( let i = 0; i < 16; i ++ ) {

				if ( te[ i ] !== me[ i ] ) return false;

			}

			return true;

		}

		/**
		 * Sets the elements of the matrix from the given array.
		 *
		 * @param {Array<number>} array - The matrix elements in column-major order.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Matrix4} A reference to this matrix.
		 */
		fromArray( array, offset = 0 ) {

			for ( let i = 0; i < 16; i ++ ) {

				this.elements[ i ] = array[ i + offset ];

			}

			return this;

		}

		/**
		 * Writes the elements of this matrix to the given array. If no array is provided,
		 * the method returns a new instance.
		 *
		 * @param {Array<number>} [array=[]] - The target array holding the matrix elements in column-major order.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Array<number>} The matrix elements in column-major order.
		 */
		toArray( array = [], offset = 0 ) {

			const te = this.elements;

			array[ offset ] = te[ 0 ];
			array[ offset + 1 ] = te[ 1 ];
			array[ offset + 2 ] = te[ 2 ];
			array[ offset + 3 ] = te[ 3 ];

			array[ offset + 4 ] = te[ 4 ];
			array[ offset + 5 ] = te[ 5 ];
			array[ offset + 6 ] = te[ 6 ];
			array[ offset + 7 ] = te[ 7 ];

			array[ offset + 8 ] = te[ 8 ];
			array[ offset + 9 ] = te[ 9 ];
			array[ offset + 10 ] = te[ 10 ];
			array[ offset + 11 ] = te[ 11 ];

			array[ offset + 12 ] = te[ 12 ];
			array[ offset + 13 ] = te[ 13 ];
			array[ offset + 14 ] = te[ 14 ];
			array[ offset + 15 ] = te[ 15 ];

			return array;

		}

	}

	const _v1$5 = /*@__PURE__*/ new Vector3();
	const _m1$2 = /*@__PURE__*/ new Matrix4();
	const _zero = /*@__PURE__*/ new Vector3( 0, 0, 0 );
	const _one = /*@__PURE__*/ new Vector3( 1, 1, 1 );
	const _x = /*@__PURE__*/ new Vector3();
	const _y = /*@__PURE__*/ new Vector3();
	const _z = /*@__PURE__*/ new Vector3();

	const _matrix$2 = /*@__PURE__*/ new Matrix4();
	const _quaternion$3 = /*@__PURE__*/ new Quaternion();

	/**
	 * A class representing Euler angles.
	 *
	 * Euler angles describe a rotational transformation by rotating an object on
	 * its various axes in specified amounts per axis, and a specified axis
	 * order.
	 *
	 * Iterating through an instance will yield its components (x, y, z,
	 * order) in the corresponding order.
	 *
	 * ```js
	 * const a = new THREE.Euler( 0, 1, 1.57, 'XYZ' );
	 * const b = new THREE.Vector3( 1, 0, 1 );
	 * b.applyEuler(a);
	 * ```
	 */
	class Euler {

		/**
		 * Constructs a new euler instance.
		 *
		 * @param {number} [x=0] - The angle of the x axis in radians.
		 * @param {number} [y=0] - The angle of the y axis in radians.
		 * @param {number} [z=0] - The angle of the z axis in radians.
		 * @param {string} [order=Euler.DEFAULT_ORDER] - A string representing the order that the rotations are applied.
		 */
		constructor( x = 0, y = 0, z = 0, order = Euler.DEFAULT_ORDER ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isEuler = true;

			this._x = x;
			this._y = y;
			this._z = z;
			this._order = order;

		}

		/**
		 * The angle of the x axis in radians.
		 *
		 * @type {number}
		 * @default 0
		 */
		get x() {

			return this._x;

		}

		set x( value ) {

			this._x = value;
			this._onChangeCallback();

		}

		/**
		 * The angle of the y axis in radians.
		 *
		 * @type {number}
		 * @default 0
		 */
		get y() {

			return this._y;

		}

		set y( value ) {

			this._y = value;
			this._onChangeCallback();

		}

		/**
		 * The angle of the z axis in radians.
		 *
		 * @type {number}
		 * @default 0
		 */
		get z() {

			return this._z;

		}

		set z( value ) {

			this._z = value;
			this._onChangeCallback();

		}

		/**
		 * A string representing the order that the rotations are applied.
		 *
		 * @type {string}
		 * @default 'XYZ'
		 */
		get order() {

			return this._order;

		}

		set order( value ) {

			this._order = value;
			this._onChangeCallback();

		}

		/**
		 * Sets the Euler components.
		 *
		 * @param {number} x - The angle of the x axis in radians.
		 * @param {number} y - The angle of the y axis in radians.
		 * @param {number} z - The angle of the z axis in radians.
		 * @param {string} [order] - A string representing the order that the rotations are applied.
		 * @return {Euler} A reference to this Euler instance.
		 */
		set( x, y, z, order = this._order ) {

			this._x = x;
			this._y = y;
			this._z = z;
			this._order = order;

			this._onChangeCallback();

			return this;

		}

		/**
		 * Returns a new Euler instance with copied values from this instance.
		 *
		 * @return {Euler} A clone of this instance.
		 */
		clone() {

			return new this.constructor( this._x, this._y, this._z, this._order );

		}

		/**
		 * Copies the values of the given Euler instance to this instance.
		 *
		 * @param {Euler} euler - The Euler instance to copy.
		 * @return {Euler} A reference to this Euler instance.
		 */
		copy( euler ) {

			this._x = euler._x;
			this._y = euler._y;
			this._z = euler._z;
			this._order = euler._order;

			this._onChangeCallback();

			return this;

		}

		/**
		 * Sets the angles of this Euler instance from a pure rotation matrix.
		 *
		 * @param {Matrix4} m - A 4x4 matrix of which the upper 3x3 of matrix is a pure rotation matrix (i.e. unscaled).
		 * @param {string} [order] - A string representing the order that the rotations are applied.
		 * @param {boolean} [update=true] - Whether the internal `onChange` callback should be executed or not.
		 * @return {Euler} A reference to this Euler instance.
		 */
		setFromRotationMatrix( m, order = this._order, update = true ) {

			const te = m.elements;
			const m11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ];
			const m21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ];
			const m31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ];

			switch ( order ) {

				case 'XYZ':

					this._y = Math.asin( clamp( m13, -1, 1 ) );

					if ( Math.abs( m13 ) < 0.9999999 ) {

						this._x = Math.atan2( - m23, m33 );
						this._z = Math.atan2( - m12, m11 );

					} else {

						this._x = Math.atan2( m32, m22 );
						this._z = 0;

					}

					break;

				case 'YXZ':

					this._x = Math.asin( - clamp( m23, -1, 1 ) );

					if ( Math.abs( m23 ) < 0.9999999 ) {

						this._y = Math.atan2( m13, m33 );
						this._z = Math.atan2( m21, m22 );

					} else {

						this._y = Math.atan2( - m31, m11 );
						this._z = 0;

					}

					break;

				case 'ZXY':

					this._x = Math.asin( clamp( m32, -1, 1 ) );

					if ( Math.abs( m32 ) < 0.9999999 ) {

						this._y = Math.atan2( - m31, m33 );
						this._z = Math.atan2( - m12, m22 );

					} else {

						this._y = 0;
						this._z = Math.atan2( m21, m11 );

					}

					break;

				case 'ZYX':

					this._y = Math.asin( - clamp( m31, -1, 1 ) );

					if ( Math.abs( m31 ) < 0.9999999 ) {

						this._x = Math.atan2( m32, m33 );
						this._z = Math.atan2( m21, m11 );

					} else {

						this._x = 0;
						this._z = Math.atan2( - m12, m22 );

					}

					break;

				case 'YZX':

					this._z = Math.asin( clamp( m21, -1, 1 ) );

					if ( Math.abs( m21 ) < 0.9999999 ) {

						this._x = Math.atan2( - m23, m22 );
						this._y = Math.atan2( - m31, m11 );

					} else {

						this._x = 0;
						this._y = Math.atan2( m13, m33 );

					}

					break;

				case 'XZY':

					this._z = Math.asin( - clamp( m12, -1, 1 ) );

					if ( Math.abs( m12 ) < 0.9999999 ) {

						this._x = Math.atan2( m32, m22 );
						this._y = Math.atan2( m13, m11 );

					} else {

						this._x = Math.atan2( - m23, m33 );
						this._y = 0;

					}

					break;

				default:

					console.warn( 'THREE.Euler: .setFromRotationMatrix() encountered an unknown order: ' + order );

			}

			this._order = order;

			if ( update === true ) this._onChangeCallback();

			return this;

		}

		/**
		 * Sets the angles of this Euler instance from a normalized quaternion.
		 *
		 * @param {Quaternion} q - A normalized Quaternion.
		 * @param {string} [order] - A string representing the order that the rotations are applied.
		 * @param {boolean} [update=true] - Whether the internal `onChange` callback should be executed or not.
		 * @return {Euler} A reference to this Euler instance.
		 */
		setFromQuaternion( q, order, update ) {

			_matrix$2.makeRotationFromQuaternion( q );

			return this.setFromRotationMatrix( _matrix$2, order, update );

		}

		/**
		 * Sets the angles of this Euler instance from the given vector.
		 *
		 * @param {Vector3} v - The vector.
		 * @param {string} [order] - A string representing the order that the rotations are applied.
		 * @return {Euler} A reference to this Euler instance.
		 */
		setFromVector3( v, order = this._order ) {

			return this.set( v.x, v.y, v.z, order );

		}

		/**
		 * Resets the euler angle with a new order by creating a quaternion from this
		 * euler angle and then setting this euler angle with the quaternion and the
		 * new order.
		 *
		 * Warning: This discards revolution information.
		 *
		 * @param {string} [newOrder] - A string representing the new order that the rotations are applied.
		 * @return {Euler} A reference to this Euler instance.
		 */
		reorder( newOrder ) {

			_quaternion$3.setFromEuler( this );

			return this.setFromQuaternion( _quaternion$3, newOrder );

		}

		/**
		 * Returns `true` if this Euler instance is equal with the given one.
		 *
		 * @param {Euler} euler - The Euler instance to test for equality.
		 * @return {boolean} Whether this Euler instance is equal with the given one.
		 */
		equals( euler ) {

			return ( euler._x === this._x ) && ( euler._y === this._y ) && ( euler._z === this._z ) && ( euler._order === this._order );

		}

		/**
		 * Sets this Euler instance's components to values from the given array. The first three
		 * entries of the array are assign to the x,y and z components. An optional fourth entry
		 * defines the Euler order.
		 *
		 * @param {Array<number,number,number,?string>} array - An array holding the Euler component values.
		 * @return {Euler} A reference to this Euler instance.
		 */
		fromArray( array ) {

			this._x = array[ 0 ];
			this._y = array[ 1 ];
			this._z = array[ 2 ];
			if ( array[ 3 ] !== undefined ) this._order = array[ 3 ];

			this._onChangeCallback();

			return this;

		}

		/**
		 * Writes the components of this Euler instance to the given array. If no array is provided,
		 * the method returns a new instance.
		 *
		 * @param {Array<number,number,number,string>} [array=[]] - The target array holding the Euler components.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Array<number,number,number,string>} The Euler components.
		 */
		toArray( array = [], offset = 0 ) {

			array[ offset ] = this._x;
			array[ offset + 1 ] = this._y;
			array[ offset + 2 ] = this._z;
			array[ offset + 3 ] = this._order;

			return array;

		}

		_onChange( callback ) {

			this._onChangeCallback = callback;

			return this;

		}

		_onChangeCallback() {}

		*[ Symbol.iterator ]() {

			yield this._x;
			yield this._y;
			yield this._z;
			yield this._order;

		}

	}

	/**
	 * The default Euler angle order.
	 *
	 * @static
	 * @type {string}
	 * @default 'XYZ'
	 */
	Euler.DEFAULT_ORDER = 'XYZ';

	/**
	 * A layers object assigns an 3D object to 1 or more of 32
	 * layers numbered `0` to `31` - internally the layers are stored as a
	 * bit mask], and by default all 3D objects are a member of layer `0`.
	 *
	 * This can be used to control visibility - an object must share a layer with
	 * a camera to be visible when that camera's view is
	 * rendered.
	 *
	 * All classes that inherit from {@link Object3D} have an `layers` property which
	 * is an instance of this class.
	 */
	class Layers {

		/**
		 * Constructs a new layers instance, with membership
		 * initially set to layer `0`.
		 */
		constructor() {

			/**
			 * A bit mask storing which of the 32 layers this layers object is currently
			 * a member of.
			 *
			 * @type {number}
			 */
			this.mask = 1 | 0;

		}

		/**
		 * Sets membership to the given layer, and remove membership all other layers.
		 *
		 * @param {number} layer - The layer to set.
		 */
		set( layer ) {

			this.mask = ( 1 << layer | 0 ) >>> 0;

		}

		/**
		 * Adds membership of the given layer.
		 *
		 * @param {number} layer - The layer to enable.
		 */
		enable( layer ) {

			this.mask |= 1 << layer | 0;

		}

		/**
		 * Adds membership to all layers.
		 */
		enableAll() {

			this.mask = 0xffffffff | 0;

		}

		/**
		 * Toggles the membership of the given layer.
		 *
		 * @param {number} layer - The layer to toggle.
		 */
		toggle( layer ) {

			this.mask ^= 1 << layer | 0;

		}

		/**
		 * Removes membership of the given layer.
		 *
		 * @param {number} layer - The layer to enable.
		 */
		disable( layer ) {

			this.mask &= ~ ( 1 << layer | 0 );

		}

		/**
		 * Removes the membership from all layers.
		 */
		disableAll() {

			this.mask = 0;

		}

		/**
		 * Returns `true` if this and the given layers object have at least one
		 * layer in common.
		 *
		 * @param {Layers} layers - The layers to test.
		 * @return {boolean } Whether this and the given layers object have at least one layer in common or not.
		 */
		test( layers ) {

			return ( this.mask & layers.mask ) !== 0;

		}

		/**
		 * Returns `true` if the given layer is enabled.
		 *
		 * @param {number} layer - The layer to test.
		 * @return {boolean } Whether the given layer is enabled or not.
		 */
		isEnabled( layer ) {

			return ( this.mask & ( 1 << layer | 0 ) ) !== 0;

		}

	}

	let _object3DId = 0;

	const _v1$4 = /*@__PURE__*/ new Vector3();
	const _q1 = /*@__PURE__*/ new Quaternion();
	const _m1$1 = /*@__PURE__*/ new Matrix4();
	const _target = /*@__PURE__*/ new Vector3();

	const _position$3 = /*@__PURE__*/ new Vector3();
	const _scale$2 = /*@__PURE__*/ new Vector3();
	const _quaternion$2 = /*@__PURE__*/ new Quaternion();

	const _xAxis = /*@__PURE__*/ new Vector3( 1, 0, 0 );
	const _yAxis = /*@__PURE__*/ new Vector3( 0, 1, 0 );
	const _zAxis = /*@__PURE__*/ new Vector3( 0, 0, 1 );

	/**
	 * Fires when the object has been added to its parent object.
	 *
	 * @event Object3D#added
	 * @type {Object}
	 */
	const _addedEvent = { type: 'added' };

	/**
	 * Fires when the object has been removed from its parent object.
	 *
	 * @event Object3D#removed
	 * @type {Object}
	 */
	const _removedEvent = { type: 'removed' };

	/**
	 * Fires when a new child object has been added.
	 *
	 * @event Object3D#childadded
	 * @type {Object}
	 */
	const _childaddedEvent = { type: 'childadded', child: null };

	/**
	 * Fires when a new child object has been added.
	 *
	 * @event Object3D#childremoved
	 * @type {Object}
	 */
	const _childremovedEvent = { type: 'childremoved', child: null };

	/**
	 * This is the base class for most objects in three.js and provides a set of
	 * properties and methods for manipulating objects in 3D space.
	 *
	 * @augments EventDispatcher
	 */
	class Object3D extends EventDispatcher {

		/**
		 * Constructs a new 3D object.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isObject3D = true;

			/**
			 * The ID of the 3D object.
			 *
			 * @name Object3D#id
			 * @type {number}
			 * @readonly
			 */
			Object.defineProperty( this, 'id', { value: _object3DId ++ } );

			/**
			 * The UUID of the 3D object.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.uuid = generateUUID();

			/**
			 * The name of the 3D object.
			 *
			 * @type {string}
			 */
			this.name = '';

			/**
			 * The type property is used for detecting the object type
			 * in context of serialization/deserialization.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.type = 'Object3D';

			/**
			 * A reference to the parent object.
			 *
			 * @type {?Object3D}
			 * @default null
			 */
			this.parent = null;

			/**
			 * An array holding the child 3D objects of this instance.
			 *
			 * @type {Array<Object3D>}
			 */
			this.children = [];

			/**
			 * Defines the `up` direction of the 3D object which influences
			 * the orientation via methods like {@link Object3D#lookAt}.
			 *
			 * The default values for all 3D objects is defined by `Object3D.DEFAULT_UP`.
			 *
			 * @type {Vector3}
			 */
			this.up = Object3D.DEFAULT_UP.clone();

			const position = new Vector3();
			const rotation = new Euler();
			const quaternion = new Quaternion();
			const scale = new Vector3( 1, 1, 1 );

			function onRotationChange() {

				quaternion.setFromEuler( rotation, false );

			}

			function onQuaternionChange() {

				rotation.setFromQuaternion( quaternion, undefined, false );

			}

			rotation._onChange( onRotationChange );
			quaternion._onChange( onQuaternionChange );

			Object.defineProperties( this, {
				/**
				 * Represents the object's local position.
				 *
				 * @name Object3D#position
				 * @type {Vector3}
				 * @default (0,0,0)
				 */
				position: {
					configurable: true,
					enumerable: true,
					value: position
				},
				/**
				 * Represents the object's local rotation as Euler angles, in radians.
				 *
				 * @name Object3D#rotation
				 * @type {Euler}
				 * @default (0,0,0)
				 */
				rotation: {
					configurable: true,
					enumerable: true,
					value: rotation
				},
				/**
				 * Represents the object's local rotation as Quaternions.
				 *
				 * @name Object3D#quaternion
				 * @type {Quaternion}
				 */
				quaternion: {
					configurable: true,
					enumerable: true,
					value: quaternion
				},
				/**
				 * Represents the object's local scale.
				 *
				 * @name Object3D#scale
				 * @type {Vector3}
				 * @default (1,1,1)
				 */
				scale: {
					configurable: true,
					enumerable: true,
					value: scale
				},
				/**
				 * Represents the object's model-view matrix.
				 *
				 * @name Object3D#modelViewMatrix
				 * @type {Matrix4}
				 */
				modelViewMatrix: {
					value: new Matrix4()
				},
				/**
				 * Represents the object's normal matrix.
				 *
				 * @name Object3D#normalMatrix
				 * @type {Matrix3}
				 */
				normalMatrix: {
					value: new Matrix3()
				}
			} );

			/**
			 * Represents the object's transformation matrix in local space.
			 *
			 * @type {Matrix4}
			 */
			this.matrix = new Matrix4();

			/**
			 * Represents the object's transformation matrix in world space.
			 * If the 3D object has no parent, then it's identical to the local transformation matrix
			 *
			 * @type {Matrix4}
			 */
			this.matrixWorld = new Matrix4();

			/**
			 * When set to `true`, the engine automatically computes the local matrix from position,
			 * rotation and scale every frame.
			 *
			 * The default values for all 3D objects is defined by `Object3D.DEFAULT_MATRIX_AUTO_UPDATE`.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.matrixAutoUpdate = Object3D.DEFAULT_MATRIX_AUTO_UPDATE;

			/**
			 * When set to `true`, the engine automatically computes the world matrix from the current local
			 * matrix and the object's transformation hierarchy.
			 *
			 * The default values for all 3D objects is defined by `Object3D.DEFAULT_MATRIX_WORLD_AUTO_UPDATE`.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.matrixWorldAutoUpdate = Object3D.DEFAULT_MATRIX_WORLD_AUTO_UPDATE; // checked by the renderer

			/**
			 * When set to `true`, it calculates the world matrix in that frame and resets this property
			 * to `false`.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.matrixWorldNeedsUpdate = false;

			/**
			 * The layer membership of the 3D object. The 3D object is only visible if it has
			 * at least one layer in common with the camera in use. This property can also be
			 * used to filter out unwanted objects in ray-intersection tests when using {@link Raycaster}.
			 *
			 * @type {Layers}
			 */
			this.layers = new Layers();

			/**
			 * When set to `true`, the 3D object gets rendered.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.visible = true;

			/**
			 * When set to `true`, the 3D object gets rendered into shadow maps.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.castShadow = false;

			/**
			 * When set to `true`, the 3D object is affected by shadows in the scene.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.receiveShadow = false;

			/**
			 * When set to `true`, the 3D object is honored by view frustum culling.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.frustumCulled = true;

			/**
			 * This value allows the default rendering order of scene graph objects to be
			 * overridden although opaque and transparent objects remain sorted independently.
			 * When this property is set for an instance of {@link Group},all descendants
			 * objects will be sorted and rendered together. Sorting is from lowest to highest
			 * render order.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.renderOrder = 0;

			/**
			 * An array holding the animation clips of the 3D object.
			 *
			 * @type {Array<AnimationClip>}
			 */
			this.animations = [];

			/**
			 * Custom depth material to be used when rendering to the depth map. Can only be used
			 * in context of meshes. When shadow-casting with a {@link DirectionalLight} or {@link SpotLight},
			 * if you are modifying vertex positions in the vertex shader you must specify a custom depth
			 * material for proper shadows.
			 *
			 * Only relevant in context of {@link WebGLRenderer}.
			 *
			 * @type {(Material|undefined)}
			 * @default undefined
			 */
			this.customDepthMaterial = undefined;

			/**
			 * Same as {@link Object3D#customDepthMaterial}, but used with {@link PointLight}.
			 *
			 * Only relevant in context of {@link WebGLRenderer}.
			 *
			 * @type {(Material|undefined)}
			 * @default undefined
			 */
			this.customDistanceMaterial = undefined;

			/**
			 * An object that can be used to store custom data about the 3D object. It
			 * should not hold references to functions as these will not be cloned.
			 *
			 * @type {Object}
			 */
			this.userData = {};

		}

		/**
		 * A callback that is executed immediately before a 3D object is rendered to a shadow map.
		 *
		 * @param {Renderer|WebGLRenderer} renderer - The renderer.
		 * @param {Object3D} object - The 3D object.
		 * @param {Camera} camera - The camera that is used to render the scene.
		 * @param {Camera} shadowCamera - The shadow camera.
		 * @param {BufferGeometry} geometry - The 3D object's geometry.
		 * @param {Material} depthMaterial - The depth material.
		 * @param {Object} group - The geometry group data.
		 */
		onBeforeShadow( /* renderer, object, camera, shadowCamera, geometry, depthMaterial, group */ ) {}

		/**
		 * A callback that is executed immediately after a 3D object is rendered to a shadow map.
		 *
		 * @param {Renderer|WebGLRenderer} renderer - The renderer.
		 * @param {Object3D} object - The 3D object.
		 * @param {Camera} camera - The camera that is used to render the scene.
		 * @param {Camera} shadowCamera - The shadow camera.
		 * @param {BufferGeometry} geometry - The 3D object's geometry.
		 * @param {Material} depthMaterial - The depth material.
		 * @param {Object} group - The geometry group data.
		 */
		onAfterShadow( /* renderer, object, camera, shadowCamera, geometry, depthMaterial, group */ ) {}

		/**
		 * A callback that is executed immediately before a 3D object is rendered.
		 *
		 * @param {Renderer|WebGLRenderer} renderer - The renderer.
		 * @param {Object3D} object - The 3D object.
		 * @param {Camera} camera - The camera that is used to render the scene.
		 * @param {BufferGeometry} geometry - The 3D object's geometry.
		 * @param {Material} material - The 3D object's material.
		 * @param {Object} group - The geometry group data.
		 */
		onBeforeRender( /* renderer, scene, camera, geometry, material, group */ ) {}

		/**
		 * A callback that is executed immediately after a 3D object is rendered.
		 *
		 * @param {Renderer|WebGLRenderer} renderer - The renderer.
		 * @param {Object3D} object - The 3D object.
		 * @param {Camera} camera - The camera that is used to render the scene.
		 * @param {BufferGeometry} geometry - The 3D object's geometry.
		 * @param {Material} material - The 3D object's material.
		 * @param {Object} group - The geometry group data.
		 */
		onAfterRender( /* renderer, scene, camera, geometry, material, group */ ) {}

		/**
		 * Applies the given transformation matrix to the object and updates the object's position,
		 * rotation and scale.
		 *
		 * @param {Matrix4} matrix - The transformation matrix.
		 */
		applyMatrix4( matrix ) {

			if ( this.matrixAutoUpdate ) this.updateMatrix();

			this.matrix.premultiply( matrix );

			this.matrix.decompose( this.position, this.quaternion, this.scale );

		}

		/**
		 * Applies a rotation represented by given the quaternion to the 3D object.
		 *
		 * @param {Quaternion} q - The quaternion.
		 * @return {Object3D} A reference to this instance.
		 */
		applyQuaternion( q ) {

			this.quaternion.premultiply( q );

			return this;

		}

		/**
		 * Sets the given rotation represented as an axis/angle couple to the 3D object.
		 *
		 * @param {Vector3} axis - The (normalized) axis vector.
		 * @param {number} angle - The angle in radians.
		 */
		setRotationFromAxisAngle( axis, angle ) {

			// assumes axis is normalized

			this.quaternion.setFromAxisAngle( axis, angle );

		}

		/**
		 * Sets the given rotation represented as Euler angles to the 3D object.
		 *
		 * @param {Euler} euler - The Euler angles.
		 */
		setRotationFromEuler( euler ) {

			this.quaternion.setFromEuler( euler, true );

		}

		/**
		 * Sets the given rotation represented as rotation matrix to the 3D object.
		 *
		 * @param {Matrix4} m - Although a 4x4 matrix is expected, the upper 3x3 portion must be
		 * a pure rotation matrix (i.e, unscaled).
		 */
		setRotationFromMatrix( m ) {

			// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)

			this.quaternion.setFromRotationMatrix( m );

		}

		/**
		 * Sets the given rotation represented as a Quaternion to the 3D object.
		 *
		 * @param {Quaternion} q - The Quaternion
		 */
		setRotationFromQuaternion( q ) {

			// assumes q is normalized

			this.quaternion.copy( q );

		}

		/**
		 * Rotates the 3D object along an axis in local space.
		 *
		 * @param {Vector3} axis - The (normalized) axis vector.
		 * @param {number} angle - The angle in radians.
		 * @return {Object3D} A reference to this instance.
		 */
		rotateOnAxis( axis, angle ) {

			// rotate object on axis in object space
			// axis is assumed to be normalized

			_q1.setFromAxisAngle( axis, angle );

			this.quaternion.multiply( _q1 );

			return this;

		}

		/**
		 * Rotates the 3D object along an axis in world space.
		 *
		 * @param {Vector3} axis - The (normalized) axis vector.
		 * @param {number} angle - The angle in radians.
		 * @return {Object3D} A reference to this instance.
		 */
		rotateOnWorldAxis( axis, angle ) {

			// rotate object on axis in world space
			// axis is assumed to be normalized
			// method assumes no rotated parent

			_q1.setFromAxisAngle( axis, angle );

			this.quaternion.premultiply( _q1 );

			return this;

		}

		/**
		 * Rotates the 3D object around its X axis in local space.
		 *
		 * @param {number} angle - The angle in radians.
		 * @return {Object3D} A reference to this instance.
		 */
		rotateX( angle ) {

			return this.rotateOnAxis( _xAxis, angle );

		}

		/**
		 * Rotates the 3D object around its Y axis in local space.
		 *
		 * @param {number} angle - The angle in radians.
		 * @return {Object3D} A reference to this instance.
		 */
		rotateY( angle ) {

			return this.rotateOnAxis( _yAxis, angle );

		}

		/**
		 * Rotates the 3D object around its Z axis in local space.
		 *
		 * @param {number} angle - The angle in radians.
		 * @return {Object3D} A reference to this instance.
		 */
		rotateZ( angle ) {

			return this.rotateOnAxis( _zAxis, angle );

		}

		/**
		 * Translate the 3D object by a distance along the given axis in local space.
		 *
		 * @param {Vector3} axis - The (normalized) axis vector.
		 * @param {number} distance - The distance in world units.
		 * @return {Object3D} A reference to this instance.
		 */
		translateOnAxis( axis, distance ) {

			// translate object by distance along axis in object space
			// axis is assumed to be normalized

			_v1$4.copy( axis ).applyQuaternion( this.quaternion );

			this.position.add( _v1$4.multiplyScalar( distance ) );

			return this;

		}

		/**
		 * Translate the 3D object by a distance along its X-axis in local space.
		 *
		 * @param {number} distance - The distance in world units.
		 * @return {Object3D} A reference to this instance.
		 */
		translateX( distance ) {

			return this.translateOnAxis( _xAxis, distance );

		}

		/**
		 * Translate the 3D object by a distance along its Y-axis in local space.
		 *
		 * @param {number} distance - The distance in world units.
		 * @return {Object3D} A reference to this instance.
		 */
		translateY( distance ) {

			return this.translateOnAxis( _yAxis, distance );

		}

		/**
		 * Translate the 3D object by a distance along its Z-axis in local space.
		 *
		 * @param {number} distance - The distance in world units.
		 * @return {Object3D} A reference to this instance.
		 */
		translateZ( distance ) {

			return this.translateOnAxis( _zAxis, distance );

		}

		/**
		 * Converts the given vector from this 3D object's local space to world space.
		 *
		 * @param {Vector3} vector - The vector to convert.
		 * @return {Vector3} The converted vector.
		 */
		localToWorld( vector ) {

			this.updateWorldMatrix( true, false );

			return vector.applyMatrix4( this.matrixWorld );

		}

		/**
		 * Converts the given vector from this 3D object's word space to local space.
		 *
		 * @param {Vector3} vector - The vector to convert.
		 * @return {Vector3} The converted vector.
		 */
		worldToLocal( vector ) {

			this.updateWorldMatrix( true, false );

			return vector.applyMatrix4( _m1$1.copy( this.matrixWorld ).invert() );

		}

		/**
		 * Rotates the object to face a point in world space.
		 *
		 * This method does not support objects having non-uniformly-scaled parent(s).
		 *
		 * @param {number|Vector3} x - The x coordinate in world space. Alternatively, a vector representing a position in world space
		 * @param {number} [y] - The y coordinate in world space.
		 * @param {number} [z] - The z coordinate in world space.
		 */
		lookAt( x, y, z ) {

			// This method does not support objects having non-uniformly-scaled parent(s)

			if ( x.isVector3 ) {

				_target.copy( x );

			} else {

				_target.set( x, y, z );

			}

			const parent = this.parent;

			this.updateWorldMatrix( true, false );

			_position$3.setFromMatrixPosition( this.matrixWorld );

			if ( this.isCamera || this.isLight ) {

				_m1$1.lookAt( _position$3, _target, this.up );

			} else {

				_m1$1.lookAt( _target, _position$3, this.up );

			}

			this.quaternion.setFromRotationMatrix( _m1$1 );

			if ( parent ) {

				_m1$1.extractRotation( parent.matrixWorld );
				_q1.setFromRotationMatrix( _m1$1 );
				this.quaternion.premultiply( _q1.invert() );

			}

		}

		/**
		 * Adds the given 3D object as a child to this 3D object. An arbitrary number of
		 * objects may be added. Any current parent on an object passed in here will be
		 * removed, since an object can have at most one parent.
		 *
		 * @fires Object3D#added
		 * @fires Object3D#childadded
		 * @param {Object3D} object - The 3D object to add.
		 * @return {Object3D} A reference to this instance.
		 */
		add( object ) {

			if ( arguments.length > 1 ) {

				for ( let i = 0; i < arguments.length; i ++ ) {

					this.add( arguments[ i ] );

				}

				return this;

			}

			if ( object === this ) {

				console.error( 'THREE.Object3D.add: object can\'t be added as a child of itself.', object );
				return this;

			}

			if ( object && object.isObject3D ) {

				object.removeFromParent();
				object.parent = this;
				this.children.push( object );

				object.dispatchEvent( _addedEvent );

				_childaddedEvent.child = object;
				this.dispatchEvent( _childaddedEvent );
				_childaddedEvent.child = null;

			} else {

				console.error( 'THREE.Object3D.add: object not an instance of THREE.Object3D.', object );

			}

			return this;

		}

		/**
		 * Removes the given 3D object as child from this 3D object.
		 * An arbitrary number of objects may be removed.
		 *
		 * @fires Object3D#removed
		 * @fires Object3D#childremoved
		 * @param {Object3D} object - The 3D object to remove.
		 * @return {Object3D} A reference to this instance.
		 */
		remove( object ) {

			if ( arguments.length > 1 ) {

				for ( let i = 0; i < arguments.length; i ++ ) {

					this.remove( arguments[ i ] );

				}

				return this;

			}

			const index = this.children.indexOf( object );

			if ( index !== -1 ) {

				object.parent = null;
				this.children.splice( index, 1 );

				object.dispatchEvent( _removedEvent );

				_childremovedEvent.child = object;
				this.dispatchEvent( _childremovedEvent );
				_childremovedEvent.child = null;

			}

			return this;

		}

		/**
		 * Removes this 3D object from its current parent.
		 *
		 * @fires Object3D#removed
		 * @fires Object3D#childremoved
		 * @return {Object3D} A reference to this instance.
		 */
		removeFromParent() {

			const parent = this.parent;

			if ( parent !== null ) {

				parent.remove( this );

			}

			return this;

		}

		/**
		 * Removes all child objects.
		 *
		 * @fires Object3D#removed
		 * @fires Object3D#childremoved
		 * @return {Object3D} A reference to this instance.
		 */
		clear() {

			return this.remove( ... this.children );

		}

		/**
		 * Adds the given 3D object as a child of this 3D object, while maintaining the object's world
		 * transform. This method does not support scene graphs having non-uniformly-scaled nodes(s).
		 *
		 * @fires Object3D#added
		 * @fires Object3D#childadded
		 * @param {Object3D} object - The 3D object to attach.
		 * @return {Object3D} A reference to this instance.
		 */
		attach( object ) {

			// adds object as a child of this, while maintaining the object's world transform

			// Note: This method does not support scene graphs having non-uniformly-scaled nodes(s)

			this.updateWorldMatrix( true, false );

			_m1$1.copy( this.matrixWorld ).invert();

			if ( object.parent !== null ) {

				object.parent.updateWorldMatrix( true, false );

				_m1$1.multiply( object.parent.matrixWorld );

			}

			object.applyMatrix4( _m1$1 );

			object.removeFromParent();
			object.parent = this;
			this.children.push( object );

			object.updateWorldMatrix( false, true );

			object.dispatchEvent( _addedEvent );

			_childaddedEvent.child = object;
			this.dispatchEvent( _childaddedEvent );
			_childaddedEvent.child = null;

			return this;

		}

		/**
		 * Searches through the 3D object and its children, starting with the 3D object
		 * itself, and returns the first with a matching ID.
		 *
		 * @param {number} id - The id.
		 * @return {Object3D|undefined} The found 3D object. Returns `undefined` if no 3D object has been found.
		 */
		getObjectById( id ) {

			return this.getObjectByProperty( 'id', id );

		}

		/**
		 * Searches through the 3D object and its children, starting with the 3D object
		 * itself, and returns the first with a matching name.
		 *
		 * @param {string} name - The name.
		 * @return {Object3D|undefined} The found 3D object. Returns `undefined` if no 3D object has been found.
		 */
		getObjectByName( name ) {

			return this.getObjectByProperty( 'name', name );

		}

		/**
		 * Searches through the 3D object and its children, starting with the 3D object
		 * itself, and returns the first with a matching property value.
		 *
		 * @param {string} name - The name of the property.
		 * @param {any} value - The value.
		 * @return {Object3D|undefined} The found 3D object. Returns `undefined` if no 3D object has been found.
		 */
		getObjectByProperty( name, value ) {

			if ( this[ name ] === value ) return this;

			for ( let i = 0, l = this.children.length; i < l; i ++ ) {

				const child = this.children[ i ];
				const object = child.getObjectByProperty( name, value );

				if ( object !== undefined ) {

					return object;

				}

			}

			return undefined;

		}

		/**
		 * Searches through the 3D object and its children, starting with the 3D object
		 * itself, and returns all 3D objects with a matching property value.
		 *
		 * @param {string} name - The name of the property.
		 * @param {any} value - The value.
		 * @param {Array<Object3D>} result - The method stores the result in this array.
		 * @return {Array<Object3D>} The found 3D objects.
		 */
		getObjectsByProperty( name, value, result = [] ) {

			if ( this[ name ] === value ) result.push( this );

			const children = this.children;

			for ( let i = 0, l = children.length; i < l; i ++ ) {

				children[ i ].getObjectsByProperty( name, value, result );

			}

			return result;

		}

		/**
		 * Returns a vector representing the position of the 3D object in world space.
		 *
		 * @param {Vector3} target - The target vector the result is stored to.
		 * @return {Vector3} The 3D object's position in world space.
		 */
		getWorldPosition( target ) {

			this.updateWorldMatrix( true, false );

			return target.setFromMatrixPosition( this.matrixWorld );

		}

		/**
		 * Returns a Quaternion representing the position of the 3D object in world space.
		 *
		 * @param {Quaternion} target - The target Quaternion the result is stored to.
		 * @return {Quaternion} The 3D object's rotation in world space.
		 */
		getWorldQuaternion( target ) {

			this.updateWorldMatrix( true, false );

			this.matrixWorld.decompose( _position$3, target, _scale$2 );

			return target;

		}

		/**
		 * Returns a vector representing the scale of the 3D object in world space.
		 *
		 * @param {Vector3} target - The target vector the result is stored to.
		 * @return {Vector3} The 3D object's scale in world space.
		 */
		getWorldScale( target ) {

			this.updateWorldMatrix( true, false );

			this.matrixWorld.decompose( _position$3, _quaternion$2, target );

			return target;

		}

		/**
		 * Returns a vector representing the ("look") direction of the 3D object in world space.
		 *
		 * @param {Vector3} target - The target vector the result is stored to.
		 * @return {Vector3} The 3D object's direction in world space.
		 */
		getWorldDirection( target ) {

			this.updateWorldMatrix( true, false );

			const e = this.matrixWorld.elements;

			return target.set( e[ 8 ], e[ 9 ], e[ 10 ] ).normalize();

		}

		/**
		 * Abstract method to get intersections between a casted ray and this
		 * 3D object. Renderable 3D objects such as {@link Mesh}, {@link Line} or {@link Points}
		 * implement this method in order to use raycasting.
		 *
		 * @abstract
		 * @param {Raycaster} raycaster - The raycaster.
		 * @param {Array<Object>} intersects - An array holding the result of the method.
		 */
		raycast( /* raycaster, intersects */ ) {}

		/**
		 * Executes the callback on this 3D object and all descendants.
		 *
		 * Note: Modifying the scene graph inside the callback is discouraged.
		 *
		 * @param {Function} callback - A callback function that allows to process the current 3D object.
		 */
		traverse( callback ) {

			callback( this );

			const children = this.children;

			for ( let i = 0, l = children.length; i < l; i ++ ) {

				children[ i ].traverse( callback );

			}

		}

		/**
		 * Like {@link Object3D#traverse}, but the callback will only be executed for visible 3D objects.
		 * Descendants of invisible 3D objects are not traversed.
		 *
		 * Note: Modifying the scene graph inside the callback is discouraged.
		 *
		 * @param {Function} callback - A callback function that allows to process the current 3D object.
		 */
		traverseVisible( callback ) {

			if ( this.visible === false ) return;

			callback( this );

			const children = this.children;

			for ( let i = 0, l = children.length; i < l; i ++ ) {

				children[ i ].traverseVisible( callback );

			}

		}

		/**
		 * Like {@link Object3D#traverse}, but the callback will only be executed for all ancestors.
		 *
		 * Note: Modifying the scene graph inside the callback is discouraged.
		 *
		 * @param {Function} callback - A callback function that allows to process the current 3D object.
		 */
		traverseAncestors( callback ) {

			const parent = this.parent;

			if ( parent !== null ) {

				callback( parent );

				parent.traverseAncestors( callback );

			}

		}

		/**
		 * Updates the transformation matrix in local space by computing it from the current
		 * position, rotation and scale values.
		 */
		updateMatrix() {

			this.matrix.compose( this.position, this.quaternion, this.scale );

			this.matrixWorldNeedsUpdate = true;

		}

		/**
		 * Updates the transformation matrix in world space of this 3D objects and its descendants.
		 *
		 * To ensure correct results, this method also recomputes the 3D object's transformation matrix in
		 * local space. The computation of the local and world matrix can be controlled with the
		 * {@link Object3D#matrixAutoUpdate} and {@link Object3D#matrixWorldAutoUpdate} flags which are both
		 * `true` by default.  Set these flags to `false` if you need more control over the update matrix process.
		 *
		 * @param {boolean} [force=false] - When set to `true`, a recomputation of world matrices is forced even
		 * when {@link Object3D#matrixWorldAutoUpdate} is set to `false`.
		 */
		updateMatrixWorld( force ) {

			if ( this.matrixAutoUpdate ) this.updateMatrix();

			if ( this.matrixWorldNeedsUpdate || force ) {

				if ( this.matrixWorldAutoUpdate === true ) {

					if ( this.parent === null ) {

						this.matrixWorld.copy( this.matrix );

					} else {

						this.matrixWorld.multiplyMatrices( this.parent.matrixWorld, this.matrix );

					}

				}

				this.matrixWorldNeedsUpdate = false;

				force = true;

			}

			// make sure descendants are updated if required

			const children = this.children;

			for ( let i = 0, l = children.length; i < l; i ++ ) {

				const child = children[ i ];

				child.updateMatrixWorld( force );

			}

		}

		/**
		 * An alternative version of {@link Object3D#updateMatrixWorld} with more control over the
		 * update of ancestor and descendant nodes.
		 *
		 * @param {boolean} [updateParents=false] Whether ancestor nodes should be updated or not.
		 * @param {boolean} [updateChildren=false] Whether descendant nodes should be updated or not.
		 */
		updateWorldMatrix( updateParents, updateChildren ) {

			const parent = this.parent;

			if ( updateParents === true && parent !== null ) {

				parent.updateWorldMatrix( true, false );

			}

			if ( this.matrixAutoUpdate ) this.updateMatrix();

			if ( this.matrixWorldAutoUpdate === true ) {

				if ( this.parent === null ) {

					this.matrixWorld.copy( this.matrix );

				} else {

					this.matrixWorld.multiplyMatrices( this.parent.matrixWorld, this.matrix );

				}

			}

			// make sure descendants are updated

			if ( updateChildren === true ) {

				const children = this.children;

				for ( let i = 0, l = children.length; i < l; i ++ ) {

					const child = children[ i ];

					child.updateWorldMatrix( false, true );

				}

			}

		}

		/**
		 * Serializes the 3D object into JSON.
		 *
		 * @param {?(Object|string)} meta - An optional value holding meta information about the serialization.
		 * @return {Object} A JSON object representing the serialized 3D object.
		 * @see {@link ObjectLoader#parse}
		 */
		toJSON( meta ) {

			// meta is a string when called from JSON.stringify
			const isRootObject = ( meta === undefined || typeof meta === 'string' );

			const output = {};

			// meta is a hash used to collect geometries, materials.
			// not providing it implies that this is the root object
			// being serialized.
			if ( isRootObject ) {

				// initialize meta obj
				meta = {
					geometries: {},
					materials: {},
					textures: {},
					images: {},
					shapes: {},
					skeletons: {},
					animations: {},
					nodes: {}
				};

				output.metadata = {
					version: 4.7,
					type: 'Object',
					generator: 'Object3D.toJSON'
				};

			}

			// standard Object3D serialization

			const object = {};

			object.uuid = this.uuid;
			object.type = this.type;

			if ( this.name !== '' ) object.name = this.name;
			if ( this.castShadow === true ) object.castShadow = true;
			if ( this.receiveShadow === true ) object.receiveShadow = true;
			if ( this.visible === false ) object.visible = false;
			if ( this.frustumCulled === false ) object.frustumCulled = false;
			if ( this.renderOrder !== 0 ) object.renderOrder = this.renderOrder;
			if ( Object.keys( this.userData ).length > 0 ) object.userData = this.userData;

			object.layers = this.layers.mask;
			object.matrix = this.matrix.toArray();
			object.up = this.up.toArray();

			if ( this.matrixAutoUpdate === false ) object.matrixAutoUpdate = false;

			// object specific properties

			if ( this.isInstancedMesh ) {

				object.type = 'InstancedMesh';
				object.count = this.count;
				object.instanceMatrix = this.instanceMatrix.toJSON();
				if ( this.instanceColor !== null ) object.instanceColor = this.instanceColor.toJSON();

			}

			if ( this.isBatchedMesh ) {

				object.type = 'BatchedMesh';
				object.perObjectFrustumCulled = this.perObjectFrustumCulled;
				object.sortObjects = this.sortObjects;

				object.drawRanges = this._drawRanges;
				object.reservedRanges = this._reservedRanges;

				object.geometryInfo = this._geometryInfo.map( info => ( {
					...info,
					boundingBox: info.boundingBox ? info.boundingBox.toJSON() : undefined,
					boundingSphere: info.boundingSphere ? info.boundingSphere.toJSON() : undefined
				} ) );
				object.instanceInfo = this._instanceInfo.map( info => ( { ...info } ) );

				object.availableInstanceIds = this._availableInstanceIds.slice();
				object.availableGeometryIds = this._availableGeometryIds.slice();

				object.nextIndexStart = this._nextIndexStart;
				object.nextVertexStart = this._nextVertexStart;
				object.geometryCount = this._geometryCount;

				object.maxInstanceCount = this._maxInstanceCount;
				object.maxVertexCount = this._maxVertexCount;
				object.maxIndexCount = this._maxIndexCount;

				object.geometryInitialized = this._geometryInitialized;

				object.matricesTexture = this._matricesTexture.toJSON( meta );

				object.indirectTexture = this._indirectTexture.toJSON( meta );

				if ( this._colorsTexture !== null ) {

					object.colorsTexture = this._colorsTexture.toJSON( meta );

				}

				if ( this.boundingSphere !== null ) {

					object.boundingSphere = this.boundingSphere.toJSON();

				}

				if ( this.boundingBox !== null ) {

					object.boundingBox = this.boundingBox.toJSON();

				}

			}

			//

			function serialize( library, element ) {

				if ( library[ element.uuid ] === undefined ) {

					library[ element.uuid ] = element.toJSON( meta );

				}

				return element.uuid;

			}

			if ( this.isScene ) {

				if ( this.background ) {

					if ( this.background.isColor ) {

						object.background = this.background.toJSON();

					} else if ( this.background.isTexture ) {

						object.background = this.background.toJSON( meta ).uuid;

					}

				}

				if ( this.environment && this.environment.isTexture && this.environment.isRenderTargetTexture !== true ) {

					object.environment = this.environment.toJSON( meta ).uuid;

				}

			} else if ( this.isMesh || this.isLine || this.isPoints ) {

				object.geometry = serialize( meta.geometries, this.geometry );

				const parameters = this.geometry.parameters;

				if ( parameters !== undefined && parameters.shapes !== undefined ) {

					const shapes = parameters.shapes;

					if ( Array.isArray( shapes ) ) {

						for ( let i = 0, l = shapes.length; i < l; i ++ ) {

							const shape = shapes[ i ];

							serialize( meta.shapes, shape );

						}

					} else {

						serialize( meta.shapes, shapes );

					}

				}

			}

			if ( this.isSkinnedMesh ) {

				object.bindMode = this.bindMode;
				object.bindMatrix = this.bindMatrix.toArray();

				if ( this.skeleton !== undefined ) {

					serialize( meta.skeletons, this.skeleton );

					object.skeleton = this.skeleton.uuid;

				}

			}

			if ( this.material !== undefined ) {

				if ( Array.isArray( this.material ) ) {

					const uuids = [];

					for ( let i = 0, l = this.material.length; i < l; i ++ ) {

						uuids.push( serialize( meta.materials, this.material[ i ] ) );

					}

					object.material = uuids;

				} else {

					object.material = serialize( meta.materials, this.material );

				}

			}

			//

			if ( this.children.length > 0 ) {

				object.children = [];

				for ( let i = 0; i < this.children.length; i ++ ) {

					object.children.push( this.children[ i ].toJSON( meta ).object );

				}

			}

			//

			if ( this.animations.length > 0 ) {

				object.animations = [];

				for ( let i = 0; i < this.animations.length; i ++ ) {

					const animation = this.animations[ i ];

					object.animations.push( serialize( meta.animations, animation ) );

				}

			}

			if ( isRootObject ) {

				const geometries = extractFromCache( meta.geometries );
				const materials = extractFromCache( meta.materials );
				const textures = extractFromCache( meta.textures );
				const images = extractFromCache( meta.images );
				const shapes = extractFromCache( meta.shapes );
				const skeletons = extractFromCache( meta.skeletons );
				const animations = extractFromCache( meta.animations );
				const nodes = extractFromCache( meta.nodes );

				if ( geometries.length > 0 ) output.geometries = geometries;
				if ( materials.length > 0 ) output.materials = materials;
				if ( textures.length > 0 ) output.textures = textures;
				if ( images.length > 0 ) output.images = images;
				if ( shapes.length > 0 ) output.shapes = shapes;
				if ( skeletons.length > 0 ) output.skeletons = skeletons;
				if ( animations.length > 0 ) output.animations = animations;
				if ( nodes.length > 0 ) output.nodes = nodes;

			}

			output.object = object;

			return output;

			// extract data from the cache hash
			// remove metadata on each item
			// and return as array
			function extractFromCache( cache ) {

				const values = [];
				for ( const key in cache ) {

					const data = cache[ key ];
					delete data.metadata;
					values.push( data );

				}

				return values;

			}

		}

		/**
		 * Returns a new 3D object with copied values from this instance.
		 *
		 * @param {boolean} [recursive=true] - When set to `true`, descendants of the 3D object are also cloned.
		 * @return {Object3D} A clone of this instance.
		 */
		clone( recursive ) {

			return new this.constructor().copy( this, recursive );

		}

		/**
		 * Copies the values of the given 3D object to this instance.
		 *
		 * @param {Object3D} source - The 3D object to copy.
		 * @param {boolean} [recursive=true] - When set to `true`, descendants of the 3D object are cloned.
		 * @return {Object3D} A reference to this instance.
		 */
		copy( source, recursive = true ) {

			this.name = source.name;

			this.up.copy( source.up );

			this.position.copy( source.position );
			this.rotation.order = source.rotation.order;
			this.quaternion.copy( source.quaternion );
			this.scale.copy( source.scale );

			this.matrix.copy( source.matrix );
			this.matrixWorld.copy( source.matrixWorld );

			this.matrixAutoUpdate = source.matrixAutoUpdate;

			this.matrixWorldAutoUpdate = source.matrixWorldAutoUpdate;
			this.matrixWorldNeedsUpdate = source.matrixWorldNeedsUpdate;

			this.layers.mask = source.layers.mask;
			this.visible = source.visible;

			this.castShadow = source.castShadow;
			this.receiveShadow = source.receiveShadow;

			this.frustumCulled = source.frustumCulled;
			this.renderOrder = source.renderOrder;

			this.animations = source.animations.slice();

			this.userData = JSON.parse( JSON.stringify( source.userData ) );

			if ( recursive === true ) {

				for ( let i = 0; i < source.children.length; i ++ ) {

					const child = source.children[ i ];
					this.add( child.clone() );

				}

			}

			return this;

		}

	}

	/**
	 * The default up direction for objects, also used as the default
	 * position for {@link DirectionalLight} and {@link HemisphereLight}.
	 *
	 * @static
	 * @type {Vector3}
	 * @default (0,1,0)
	 */
	Object3D.DEFAULT_UP = /*@__PURE__*/ new Vector3( 0, 1, 0 );

	/**
	 * The default setting for {@link Object3D#matrixAutoUpdate} for
	 * newly created 3D objects.
	 *
	 * @static
	 * @type {boolean}
	 * @default true
	 */
	Object3D.DEFAULT_MATRIX_AUTO_UPDATE = true;

	/**
	 * The default setting for {@link Object3D#matrixWorldAutoUpdate} for
	 * newly created 3D objects.
	 *
	 * @static
	 * @type {boolean}
	 * @default true
	 */
	Object3D.DEFAULT_MATRIX_WORLD_AUTO_UPDATE = true;

	const _v0$1 = /*@__PURE__*/ new Vector3();
	const _v1$3 = /*@__PURE__*/ new Vector3();
	const _v2$2 = /*@__PURE__*/ new Vector3();
	const _v3$2 = /*@__PURE__*/ new Vector3();

	const _vab = /*@__PURE__*/ new Vector3();
	const _vac = /*@__PURE__*/ new Vector3();
	const _vbc = /*@__PURE__*/ new Vector3();
	const _vap = /*@__PURE__*/ new Vector3();
	const _vbp = /*@__PURE__*/ new Vector3();
	const _vcp = /*@__PURE__*/ new Vector3();

	const _v40 = /*@__PURE__*/ new Vector4();
	const _v41 = /*@__PURE__*/ new Vector4();
	const _v42 = /*@__PURE__*/ new Vector4();

	/**
	 * A geometric triangle as defined by three vectors representing its three corners.
	 */
	class Triangle {

		/**
		 * Constructs a new triangle.
		 *
		 * @param {Vector3} [a=(0,0,0)] - The first corner of the triangle.
		 * @param {Vector3} [b=(0,0,0)] - The second corner of the triangle.
		 * @param {Vector3} [c=(0,0,0)] - The third corner of the triangle.
		 */
		constructor( a = new Vector3(), b = new Vector3(), c = new Vector3() ) {

			/**
			 * The first corner of the triangle.
			 *
			 * @type {Vector3}
			 */
			this.a = a;

			/**
			 * The second corner of the triangle.
			 *
			 * @type {Vector3}
			 */
			this.b = b;

			/**
			 * The third corner of the triangle.
			 *
			 * @type {Vector3}
			 */
			this.c = c;

		}

		/**
		 * Computes the normal vector of a triangle.
		 *
		 * @param {Vector3} a - The first corner of the triangle.
		 * @param {Vector3} b - The second corner of the triangle.
		 * @param {Vector3} c - The third corner of the triangle.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The triangle's normal.
		 */
		static getNormal( a, b, c, target ) {

			target.subVectors( c, b );
			_v0$1.subVectors( a, b );
			target.cross( _v0$1 );

			const targetLengthSq = target.lengthSq();
			if ( targetLengthSq > 0 ) {

				return target.multiplyScalar( 1 / Math.sqrt( targetLengthSq ) );

			}

			return target.set( 0, 0, 0 );

		}

		/**
		 * Computes a barycentric coordinates from the given vector.
		 * Returns `null` if the triangle is degenerate.
		 *
		 * @param {Vector3} point - A point in 3D space.
		 * @param {Vector3} a - The first corner of the triangle.
		 * @param {Vector3} b - The second corner of the triangle.
		 * @param {Vector3} c - The third corner of the triangle.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The barycentric coordinates for the given point
		 */
		static getBarycoord( point, a, b, c, target ) {

			// based on: http://www.blackpawn.com/texts/pointinpoly/default.html

			_v0$1.subVectors( c, a );
			_v1$3.subVectors( b, a );
			_v2$2.subVectors( point, a );

			const dot00 = _v0$1.dot( _v0$1 );
			const dot01 = _v0$1.dot( _v1$3 );
			const dot02 = _v0$1.dot( _v2$2 );
			const dot11 = _v1$3.dot( _v1$3 );
			const dot12 = _v1$3.dot( _v2$2 );

			const denom = ( dot00 * dot11 - dot01 * dot01 );

			// collinear or singular triangle
			if ( denom === 0 ) {

				target.set( 0, 0, 0 );
				return null;

			}

			const invDenom = 1 / denom;
			const u = ( dot11 * dot02 - dot01 * dot12 ) * invDenom;
			const v = ( dot00 * dot12 - dot01 * dot02 ) * invDenom;

			// barycentric coordinates must always sum to 1
			return target.set( 1 - u - v, v, u );

		}

		/**
		 * Returns `true` if the given point, when projected onto the plane of the
		 * triangle, lies within the triangle.
		 *
		 * @param {Vector3} point - The point in 3D space to test.
		 * @param {Vector3} a - The first corner of the triangle.
		 * @param {Vector3} b - The second corner of the triangle.
		 * @param {Vector3} c - The third corner of the triangle.
		 * @return {boolean} Whether the given point, when projected onto the plane of the
		 * triangle, lies within the triangle or not.
		 */
		static containsPoint( point, a, b, c ) {

			// if the triangle is degenerate then we can't contain a point
			if ( this.getBarycoord( point, a, b, c, _v3$2 ) === null ) {

				return false;

			}

			return ( _v3$2.x >= 0 ) && ( _v3$2.y >= 0 ) && ( ( _v3$2.x + _v3$2.y ) <= 1 );

		}

		/**
		 * Computes the value barycentrically interpolated for the given point on the
		 * triangle. Returns `null` if the triangle is degenerate.
		 *
		 * @param {Vector3} point - Position of interpolated point.
		 * @param {Vector3} p1 - The first corner of the triangle.
		 * @param {Vector3} p2 - The second corner of the triangle.
		 * @param {Vector3} p3 - The third corner of the triangle.
		 * @param {Vector3} v1 - Value to interpolate of first vertex.
		 * @param {Vector3} v2 - Value to interpolate of second vertex.
		 * @param {Vector3} v3 - Value to interpolate of third vertex.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The interpolated value.
		 */
		static getInterpolation( point, p1, p2, p3, v1, v2, v3, target ) {

			if ( this.getBarycoord( point, p1, p2, p3, _v3$2 ) === null ) {

				target.x = 0;
				target.y = 0;
				if ( 'z' in target ) target.z = 0;
				if ( 'w' in target ) target.w = 0;
				return null;

			}

			target.setScalar( 0 );
			target.addScaledVector( v1, _v3$2.x );
			target.addScaledVector( v2, _v3$2.y );
			target.addScaledVector( v3, _v3$2.z );

			return target;

		}

		/**
		 * Computes the value barycentrically interpolated for the given attribute and indices.
		 *
		 * @param {BufferAttribute} attr - The attribute to interpolate.
		 * @param {number} i1 - Index of first vertex.
		 * @param {number} i2 - Index of second vertex.
		 * @param {number} i3 - Index of third vertex.
		 * @param {Vector3} barycoord - The barycoordinate value to use to interpolate.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The interpolated attribute value.
		 */
		static getInterpolatedAttribute( attr, i1, i2, i3, barycoord, target ) {

			_v40.setScalar( 0 );
			_v41.setScalar( 0 );
			_v42.setScalar( 0 );

			_v40.fromBufferAttribute( attr, i1 );
			_v41.fromBufferAttribute( attr, i2 );
			_v42.fromBufferAttribute( attr, i3 );

			target.setScalar( 0 );
			target.addScaledVector( _v40, barycoord.x );
			target.addScaledVector( _v41, barycoord.y );
			target.addScaledVector( _v42, barycoord.z );

			return target;

		}

		/**
		 * Returns `true` if the triangle is oriented towards the given direction.
		 *
		 * @param {Vector3} a - The first corner of the triangle.
		 * @param {Vector3} b - The second corner of the triangle.
		 * @param {Vector3} c - The third corner of the triangle.
		 * @param {Vector3} direction - The (normalized) direction vector.
		 * @return {boolean} Whether the triangle is oriented towards the given direction or not.
		 */
		static isFrontFacing( a, b, c, direction ) {

			_v0$1.subVectors( c, b );
			_v1$3.subVectors( a, b );

			// strictly front facing
			return ( _v0$1.cross( _v1$3 ).dot( direction ) < 0 ) ? true : false;

		}

		/**
		 * Sets the triangle's vertices by copying the given values.
		 *
		 * @param {Vector3} a - The first corner of the triangle.
		 * @param {Vector3} b - The second corner of the triangle.
		 * @param {Vector3} c - The third corner of the triangle.
		 * @return {Triangle} A reference to this triangle.
		 */
		set( a, b, c ) {

			this.a.copy( a );
			this.b.copy( b );
			this.c.copy( c );

			return this;

		}

		/**
		 * Sets the triangle's vertices by copying the given array values.
		 *
		 * @param {Array<Vector3>} points - An array with 3D points.
		 * @param {number} i0 - The array index representing the first corner of the triangle.
		 * @param {number} i1 - The array index representing the second corner of the triangle.
		 * @param {number} i2 - The array index representing the third corner of the triangle.
		 * @return {Triangle} A reference to this triangle.
		 */
		setFromPointsAndIndices( points, i0, i1, i2 ) {

			this.a.copy( points[ i0 ] );
			this.b.copy( points[ i1 ] );
			this.c.copy( points[ i2 ] );

			return this;

		}

		/**
		 * Sets the triangle's vertices by copying the given attribute values.
		 *
		 * @param {BufferAttribute} attribute - A buffer attribute with 3D points data.
		 * @param {number} i0 - The attribute index representing the first corner of the triangle.
		 * @param {number} i1 - The attribute index representing the second corner of the triangle.
		 * @param {number} i2 - The attribute index representing the third corner of the triangle.
		 * @return {Triangle} A reference to this triangle.
		 */
		setFromAttributeAndIndices( attribute, i0, i1, i2 ) {

			this.a.fromBufferAttribute( attribute, i0 );
			this.b.fromBufferAttribute( attribute, i1 );
			this.c.fromBufferAttribute( attribute, i2 );

			return this;

		}

		/**
		 * Returns a new triangle with copied values from this instance.
		 *
		 * @return {Triangle} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Copies the values of the given triangle to this instance.
		 *
		 * @param {Triangle} triangle - The triangle to copy.
		 * @return {Triangle} A reference to this triangle.
		 */
		copy( triangle ) {

			this.a.copy( triangle.a );
			this.b.copy( triangle.b );
			this.c.copy( triangle.c );

			return this;

		}

		/**
		 * Computes the area of the triangle.
		 *
		 * @return {number} The triangle's area.
		 */
		getArea() {

			_v0$1.subVectors( this.c, this.b );
			_v1$3.subVectors( this.a, this.b );

			return _v0$1.cross( _v1$3 ).length() * 0.5;

		}

		/**
		 * Computes the midpoint of the triangle.
		 *
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The triangle's midpoint.
		 */
		getMidpoint( target ) {

			return target.addVectors( this.a, this.b ).add( this.c ).multiplyScalar( 1 / 3 );

		}

		/**
		 * Computes the normal of the triangle.
		 *
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The triangle's normal.
		 */
		getNormal( target ) {

			return Triangle.getNormal( this.a, this.b, this.c, target );

		}

		/**
		 * Computes a plane the triangle lies within.
		 *
		 * @param {Plane} target - The target vector that is used to store the method's result.
		 * @return {Plane} The plane the triangle lies within.
		 */
		getPlane( target ) {

			return target.setFromCoplanarPoints( this.a, this.b, this.c );

		}

		/**
		 * Computes a barycentric coordinates from the given vector.
		 * Returns `null` if the triangle is degenerate.
		 *
		 * @param {Vector3} point - A point in 3D space.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The barycentric coordinates for the given point
		 */
		getBarycoord( point, target ) {

			return Triangle.getBarycoord( point, this.a, this.b, this.c, target );

		}

		/**
		 * Computes the value barycentrically interpolated for the given point on the
		 * triangle. Returns `null` if the triangle is degenerate.
		 *
		 * @param {Vector3} point - Position of interpolated point.
		 * @param {Vector3} v1 - Value to interpolate of first vertex.
		 * @param {Vector3} v2 - Value to interpolate of second vertex.
		 * @param {Vector3} v3 - Value to interpolate of third vertex.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The interpolated value.
		 */
		getInterpolation( point, v1, v2, v3, target ) {

			return Triangle.getInterpolation( point, this.a, this.b, this.c, v1, v2, v3, target );

		}

		/**
		 * Returns `true` if the given point, when projected onto the plane of the
		 * triangle, lies within the triangle.
		 *
		 * @param {Vector3} point - The point in 3D space to test.
		 * @return {boolean} Whether the given point, when projected onto the plane of the
		 * triangle, lies within the triangle or not.
		 */
		containsPoint( point ) {

			return Triangle.containsPoint( point, this.a, this.b, this.c );

		}

		/**
		 * Returns `true` if the triangle is oriented towards the given direction.
		 *
		 * @param {Vector3} direction - The (normalized) direction vector.
		 * @return {boolean} Whether the triangle is oriented towards the given direction or not.
		 */
		isFrontFacing( direction ) {

			return Triangle.isFrontFacing( this.a, this.b, this.c, direction );

		}

		/**
		 * Returns `true` if this triangle intersects with the given box.
		 *
		 * @param {Box3} box - The box to intersect.
		 * @return {boolean} Whether this triangle intersects with the given box or not.
		 */
		intersectsBox( box ) {

			return box.intersectsTriangle( this );

		}

		/**
		 * Returns the closest point on the triangle to the given point.
		 *
		 * @param {Vector3} p - The point to compute the closest point for.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The closest point on the triangle.
		 */
		closestPointToPoint( p, target ) {

			const a = this.a, b = this.b, c = this.c;
			let v, w;

			// algorithm thanks to Real-Time Collision Detection by Christer Ericson,
			// published by Morgan Kaufmann Publishers, (c) 2005 Elsevier Inc.,
			// under the accompanying license; see chapter 5.1.5 for detailed explanation.
			// basically, we're distinguishing which of the voronoi regions of the triangle
			// the point lies in with the minimum amount of redundant computation.

			_vab.subVectors( b, a );
			_vac.subVectors( c, a );
			_vap.subVectors( p, a );
			const d1 = _vab.dot( _vap );
			const d2 = _vac.dot( _vap );
			if ( d1 <= 0 && d2 <= 0 ) {

				// vertex region of A; barycentric coords (1, 0, 0)
				return target.copy( a );

			}

			_vbp.subVectors( p, b );
			const d3 = _vab.dot( _vbp );
			const d4 = _vac.dot( _vbp );
			if ( d3 >= 0 && d4 <= d3 ) {

				// vertex region of B; barycentric coords (0, 1, 0)
				return target.copy( b );

			}

			const vc = d1 * d4 - d3 * d2;
			if ( vc <= 0 && d1 >= 0 && d3 <= 0 ) {

				v = d1 / ( d1 - d3 );
				// edge region of AB; barycentric coords (1-v, v, 0)
				return target.copy( a ).addScaledVector( _vab, v );

			}

			_vcp.subVectors( p, c );
			const d5 = _vab.dot( _vcp );
			const d6 = _vac.dot( _vcp );
			if ( d6 >= 0 && d5 <= d6 ) {

				// vertex region of C; barycentric coords (0, 0, 1)
				return target.copy( c );

			}

			const vb = d5 * d2 - d1 * d6;
			if ( vb <= 0 && d2 >= 0 && d6 <= 0 ) {

				w = d2 / ( d2 - d6 );
				// edge region of AC; barycentric coords (1-w, 0, w)
				return target.copy( a ).addScaledVector( _vac, w );

			}

			const va = d3 * d6 - d5 * d4;
			if ( va <= 0 && ( d4 - d3 ) >= 0 && ( d5 - d6 ) >= 0 ) {

				_vbc.subVectors( c, b );
				w = ( d4 - d3 ) / ( ( d4 - d3 ) + ( d5 - d6 ) );
				// edge region of BC; barycentric coords (0, 1-w, w)
				return target.copy( b ).addScaledVector( _vbc, w ); // edge region of BC

			}

			// face region
			const denom = 1 / ( va + vb + vc );
			// u = va * denom
			v = vb * denom;
			w = vc * denom;

			return target.copy( a ).addScaledVector( _vab, v ).addScaledVector( _vac, w );

		}

		/**
		 * Returns `true` if this triangle is equal with the given one.
		 *
		 * @param {Triangle} triangle - The triangle to test for equality.
		 * @return {boolean} Whether this triangle is equal with the given one.
		 */
		equals( triangle ) {

			return triangle.a.equals( this.a ) && triangle.b.equals( this.b ) && triangle.c.equals( this.c );

		}

	}

	const _colorKeywords = { 'aliceblue': 0xF0F8FF, 'antiquewhite': 0xFAEBD7, 'aqua': 0x00FFFF, 'aquamarine': 0x7FFFD4, 'azure': 0xF0FFFF,
		'beige': 0xF5F5DC, 'bisque': 0xFFE4C4, 'black': 0x000000, 'blanchedalmond': 0xFFEBCD, 'blue': 0x0000FF, 'blueviolet': 0x8A2BE2,
		'brown': 0xA52A2A, 'burlywood': 0xDEB887, 'cadetblue': 0x5F9EA0, 'chartreuse': 0x7FFF00, 'chocolate': 0xD2691E, 'coral': 0xFF7F50,
		'cornflowerblue': 0x6495ED, 'cornsilk': 0xFFF8DC, 'crimson': 0xDC143C, 'cyan': 0x00FFFF, 'darkblue': 0x00008B, 'darkcyan': 0x008B8B,
		'darkgoldenrod': 0xB8860B, 'darkgray': 0xA9A9A9, 'darkgreen': 0x006400, 'darkgrey': 0xA9A9A9, 'darkkhaki': 0xBDB76B, 'darkmagenta': 0x8B008B,
		'darkolivegreen': 0x556B2F, 'darkorange': 0xFF8C00, 'darkorchid': 0x9932CC, 'darkred': 0x8B0000, 'darksalmon': 0xE9967A, 'darkseagreen': 0x8FBC8F,
		'darkslateblue': 0x483D8B, 'darkslategray': 0x2F4F4F, 'darkslategrey': 0x2F4F4F, 'darkturquoise': 0x00CED1, 'darkviolet': 0x9400D3,
		'deeppink': 0xFF1493, 'deepskyblue': 0x00BFFF, 'dimgray': 0x696969, 'dimgrey': 0x696969, 'dodgerblue': 0x1E90FF, 'firebrick': 0xB22222,
		'floralwhite': 0xFFFAF0, 'forestgreen': 0x228B22, 'fuchsia': 0xFF00FF, 'gainsboro': 0xDCDCDC, 'ghostwhite': 0xF8F8FF, 'gold': 0xFFD700,
		'goldenrod': 0xDAA520, 'gray': 0x808080, 'green': 0x008000, 'greenyellow': 0xADFF2F, 'grey': 0x808080, 'honeydew': 0xF0FFF0, 'hotpink': 0xFF69B4,
		'indianred': 0xCD5C5C, 'indigo': 0x4B0082, 'ivory': 0xFFFFF0, 'khaki': 0xF0E68C, 'lavender': 0xE6E6FA, 'lavenderblush': 0xFFF0F5, 'lawngreen': 0x7CFC00,
		'lemonchiffon': 0xFFFACD, 'lightblue': 0xADD8E6, 'lightcoral': 0xF08080, 'lightcyan': 0xE0FFFF, 'lightgoldenrodyellow': 0xFAFAD2, 'lightgray': 0xD3D3D3,
		'lightgreen': 0x90EE90, 'lightgrey': 0xD3D3D3, 'lightpink': 0xFFB6C1, 'lightsalmon': 0xFFA07A, 'lightseagreen': 0x20B2AA, 'lightskyblue': 0x87CEFA,
		'lightslategray': 0x778899, 'lightslategrey': 0x778899, 'lightsteelblue': 0xB0C4DE, 'lightyellow': 0xFFFFE0, 'lime': 0x00FF00, 'limegreen': 0x32CD32,
		'linen': 0xFAF0E6, 'magenta': 0xFF00FF, 'maroon': 0x800000, 'mediumaquamarine': 0x66CDAA, 'mediumblue': 0x0000CD, 'mediumorchid': 0xBA55D3,
		'mediumpurple': 0x9370DB, 'mediumseagreen': 0x3CB371, 'mediumslateblue': 0x7B68EE, 'mediumspringgreen': 0x00FA9A, 'mediumturquoise': 0x48D1CC,
		'mediumvioletred': 0xC71585, 'midnightblue': 0x191970, 'mintcream': 0xF5FFFA, 'mistyrose': 0xFFE4E1, 'moccasin': 0xFFE4B5, 'navajowhite': 0xFFDEAD,
		'navy': 0x000080, 'oldlace': 0xFDF5E6, 'olive': 0x808000, 'olivedrab': 0x6B8E23, 'orange': 0xFFA500, 'orangered': 0xFF4500, 'orchid': 0xDA70D6,
		'palegoldenrod': 0xEEE8AA, 'palegreen': 0x98FB98, 'paleturquoise': 0xAFEEEE, 'palevioletred': 0xDB7093, 'papayawhip': 0xFFEFD5, 'peachpuff': 0xFFDAB9,
		'peru': 0xCD853F, 'pink': 0xFFC0CB, 'plum': 0xDDA0DD, 'powderblue': 0xB0E0E6, 'purple': 0x800080, 'rebeccapurple': 0x663399, 'red': 0xFF0000, 'rosybrown': 0xBC8F8F,
		'royalblue': 0x4169E1, 'saddlebrown': 0x8B4513, 'salmon': 0xFA8072, 'sandybrown': 0xF4A460, 'seagreen': 0x2E8B57, 'seashell': 0xFFF5EE,
		'sienna': 0xA0522D, 'silver': 0xC0C0C0, 'skyblue': 0x87CEEB, 'slateblue': 0x6A5ACD, 'slategray': 0x708090, 'slategrey': 0x708090, 'snow': 0xFFFAFA,
		'springgreen': 0x00FF7F, 'steelblue': 0x4682B4, 'tan': 0xD2B48C, 'teal': 0x008080, 'thistle': 0xD8BFD8, 'tomato': 0xFF6347, 'turquoise': 0x40E0D0,
		'violet': 0xEE82EE, 'wheat': 0xF5DEB3, 'white': 0xFFFFFF, 'whitesmoke': 0xF5F5F5, 'yellow': 0xFFFF00, 'yellowgreen': 0x9ACD32 };

	const _hslA = { h: 0, s: 0, l: 0 };
	const _hslB = { h: 0, s: 0, l: 0 };

	function hue2rgb( p, q, t ) {

		if ( t < 0 ) t += 1;
		if ( t > 1 ) t -= 1;
		if ( t < 1 / 6 ) return p + ( q - p ) * 6 * t;
		if ( t < 1 / 2 ) return q;
		if ( t < 2 / 3 ) return p + ( q - p ) * 6 * ( 2 / 3 - t );
		return p;

	}

	/**
	 * A Color instance is represented by RGB components in the linear <i>working
	 * color space</i>, which defaults to `LinearSRGBColorSpace`. Inputs
	 * conventionally using `SRGBColorSpace` (such as hexadecimals and CSS
	 * strings) are converted to the working color space automatically.
	 *
	 * ```js
	 * // converted automatically from SRGBColorSpace to LinearSRGBColorSpace
	 * const color = new THREE.Color().setHex( 0x112233 );
	 * ```
	 * Source color spaces may be specified explicitly, to ensure correct conversions.
	 * ```js
	 * // assumed already LinearSRGBColorSpace; no conversion
	 * const color = new THREE.Color().setRGB( 0.5, 0.5, 0.5 );
	 *
	 * // converted explicitly from SRGBColorSpace to LinearSRGBColorSpace
	 * const color = new THREE.Color().setRGB( 0.5, 0.5, 0.5, SRGBColorSpace );
	 * ```
	 * If THREE.ColorManagement is disabled, no conversions occur. For details,
	 * see <i>Color management</i>. Iterating through a Color instance will yield
	 * its components (r, g, b) in the corresponding order. A Color can be initialised
	 * in any of the following ways:
	 * ```js
	 * //empty constructor - will default white
	 * const color1 = new THREE.Color();
	 *
	 * //Hexadecimal color (recommended)
	 * const color2 = new THREE.Color( 0xff0000 );
	 *
	 * //RGB string
	 * const color3 = new THREE.Color("rgb(255, 0, 0)");
	 * const color4 = new THREE.Color("rgb(100%, 0%, 0%)");
	 *
	 * //X11 color name - all 140 color names are supported.
	 * //Note the lack of CamelCase in the name
	 * const color5 = new THREE.Color( 'skyblue' );
	 * //HSL string
	 * const color6 = new THREE.Color("hsl(0, 100%, 50%)");
	 *
	 * //Separate RGB values between 0 and 1
	 * const color7 = new THREE.Color( 1, 0, 0 );
	 * ```
	 */
	class Color {

		/**
		 * Constructs a new color.
		 *
		 * Note that standard method of specifying color in three.js is with a hexadecimal triplet,
		 * and that method is used throughout the rest of the documentation.
		 *
		 * @param {(number|string|Color)} [r] - The red component of the color. If `g` and `b` are
		 * not provided, it can be hexadecimal triplet, a CSS-style string or another `Color` instance.
		 * @param {number} [g] - The green component.
		 * @param {number} [b] - The blue component.
		 */
		constructor( r, g, b ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isColor = true;

			/**
			 * The red component.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.r = 1;

			/**
			 * The green component.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.g = 1;

			/**
			 * The blue component.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.b = 1;

			return this.set( r, g, b );

		}

		/**
		 * Sets the colors's components from the given values.
		 *
		 * @param {(number|string|Color)} [r] - The red component of the color. If `g` and `b` are
		 * not provided, it can be hexadecimal triplet, a CSS-style string or another `Color` instance.
		 * @param {number} [g] - The green component.
		 * @param {number} [b] - The blue component.
		 * @return {Color} A reference to this color.
		 */
		set( r, g, b ) {

			if ( g === undefined && b === undefined ) {

				// r is THREE.Color, hex or string

				const value = r;

				if ( value && value.isColor ) {

					this.copy( value );

				} else if ( typeof value === 'number' ) {

					this.setHex( value );

				} else if ( typeof value === 'string' ) {

					this.setStyle( value );

				}

			} else {

				this.setRGB( r, g, b );

			}

			return this;

		}

		/**
		 * Sets the colors's components to the given scalar value.
		 *
		 * @param {number} scalar - The scalar value.
		 * @return {Color} A reference to this color.
		 */
		setScalar( scalar ) {

			this.r = scalar;
			this.g = scalar;
			this.b = scalar;

			return this;

		}

		/**
		 * Sets this color from a hexadecimal value.
		 *
		 * @param {number} hex - The hexadecimal value.
		 * @param {string} [colorSpace=SRGBColorSpace] - The color space.
		 * @return {Color} A reference to this color.
		 */
		setHex( hex, colorSpace = SRGBColorSpace ) {

			hex = Math.floor( hex );

			this.r = ( hex >> 16 & 255 ) / 255;
			this.g = ( hex >> 8 & 255 ) / 255;
			this.b = ( hex & 255 ) / 255;

			ColorManagement.colorSpaceToWorking( this, colorSpace );

			return this;

		}

		/**
		 * Sets this color from RGB values.
		 *
		 * @param {number} r - Red channel value between `0.0` and `1.0`.
		 * @param {number} g - Green channel value between `0.0` and `1.0`.
		 * @param {number} b - Blue channel value between `0.0` and `1.0`.
		 * @param {string} [colorSpace=ColorManagement.workingColorSpace] - The color space.
		 * @return {Color} A reference to this color.
		 */
		setRGB( r, g, b, colorSpace = ColorManagement.workingColorSpace ) {

			this.r = r;
			this.g = g;
			this.b = b;

			ColorManagement.colorSpaceToWorking( this, colorSpace );

			return this;

		}

		/**
		 * Sets this color from RGB values.
		 *
		 * @param {number} h - Hue value between `0.0` and `1.0`.
		 * @param {number} s - Saturation value between `0.0` and `1.0`.
		 * @param {number} l - Lightness value between `0.0` and `1.0`.
		 * @param {string} [colorSpace=ColorManagement.workingColorSpace] - The color space.
		 * @return {Color} A reference to this color.
		 */
		setHSL( h, s, l, colorSpace = ColorManagement.workingColorSpace ) {

			// h,s,l ranges are in 0.0 - 1.0
			h = euclideanModulo( h, 1 );
			s = clamp( s, 0, 1 );
			l = clamp( l, 0, 1 );

			if ( s === 0 ) {

				this.r = this.g = this.b = l;

			} else {

				const p = l <= 0.5 ? l * ( 1 + s ) : l + s - ( l * s );
				const q = ( 2 * l ) - p;

				this.r = hue2rgb( q, p, h + 1 / 3 );
				this.g = hue2rgb( q, p, h );
				this.b = hue2rgb( q, p, h - 1 / 3 );

			}

			ColorManagement.colorSpaceToWorking( this, colorSpace );

			return this;

		}

		/**
		 * Sets this color from a CSS-style string. For example, `rgb(250, 0,0)`,
		 * `rgb(100%, 0%, 0%)`, `hsl(0, 100%, 50%)`, `#ff0000`, `#f00`, or `red` ( or
		 * any [X11 color name]{@link https://en.wikipedia.org/wiki/X11_color_names#Color_name_chart} -
		 * all 140 color names are supported).
		 *
		 * @param {string} style - Color as a CSS-style string.
		 * @param {string} [colorSpace=SRGBColorSpace] - The color space.
		 * @return {Color} A reference to this color.
		 */
		setStyle( style, colorSpace = SRGBColorSpace ) {

			function handleAlpha( string ) {

				if ( string === undefined ) return;

				if ( parseFloat( string ) < 1 ) {

					console.warn( 'THREE.Color: Alpha component of ' + style + ' will be ignored.' );

				}

			}


			let m;

			if ( m = /^(\w+)\(([^\)]*)\)/.exec( style ) ) {

				// rgb / hsl

				let color;
				const name = m[ 1 ];
				const components = m[ 2 ];

				switch ( name ) {

					case 'rgb':
					case 'rgba':

						if ( color = /^\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*(?:,\s*(\d*\.?\d+)\s*)?$/.exec( components ) ) {

							// rgb(255,0,0) rgba(255,0,0,0.5)

							handleAlpha( color[ 4 ] );

							return this.setRGB(
								Math.min( 255, parseInt( color[ 1 ], 10 ) ) / 255,
								Math.min( 255, parseInt( color[ 2 ], 10 ) ) / 255,
								Math.min( 255, parseInt( color[ 3 ], 10 ) ) / 255,
								colorSpace
							);

						}

						if ( color = /^\s*(\d+)\%\s*,\s*(\d+)\%\s*,\s*(\d+)\%\s*(?:,\s*(\d*\.?\d+)\s*)?$/.exec( components ) ) {

							// rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)

							handleAlpha( color[ 4 ] );

							return this.setRGB(
								Math.min( 100, parseInt( color[ 1 ], 10 ) ) / 100,
								Math.min( 100, parseInt( color[ 2 ], 10 ) ) / 100,
								Math.min( 100, parseInt( color[ 3 ], 10 ) ) / 100,
								colorSpace
							);

						}

						break;

					case 'hsl':
					case 'hsla':

						if ( color = /^\s*(\d*\.?\d+)\s*,\s*(\d*\.?\d+)\%\s*,\s*(\d*\.?\d+)\%\s*(?:,\s*(\d*\.?\d+)\s*)?$/.exec( components ) ) {

							// hsl(120,50%,50%) hsla(120,50%,50%,0.5)

							handleAlpha( color[ 4 ] );

							return this.setHSL(
								parseFloat( color[ 1 ] ) / 360,
								parseFloat( color[ 2 ] ) / 100,
								parseFloat( color[ 3 ] ) / 100,
								colorSpace
							);

						}

						break;

					default:

						console.warn( 'THREE.Color: Unknown color model ' + style );

				}

			} else if ( m = /^\#([A-Fa-f\d]+)$/.exec( style ) ) {

				// hex color

				const hex = m[ 1 ];
				const size = hex.length;

				if ( size === 3 ) {

					// #ff0
					return this.setRGB(
						parseInt( hex.charAt( 0 ), 16 ) / 15,
						parseInt( hex.charAt( 1 ), 16 ) / 15,
						parseInt( hex.charAt( 2 ), 16 ) / 15,
						colorSpace
					);

				} else if ( size === 6 ) {

					// #ff0000
					return this.setHex( parseInt( hex, 16 ), colorSpace );

				} else {

					console.warn( 'THREE.Color: Invalid hex color ' + style );

				}

			} else if ( style && style.length > 0 ) {

				return this.setColorName( style, colorSpace );

			}

			return this;

		}

		/**
		 * Sets this color from a color name. Faster than {@link Color#setStyle} if
		 * you don't need the other CSS-style formats.
		 *
		 * For convenience, the list of names is exposed in `Color.NAMES` as a hash.
		 * ```js
		 * Color.NAMES.aliceblue // returns 0xF0F8FF
		 * ```
		 *
		 * @param {string} style - The color name.
		 * @param {string} [colorSpace=SRGBColorSpace] - The color space.
		 * @return {Color} A reference to this color.
		 */
		setColorName( style, colorSpace = SRGBColorSpace ) {

			// color keywords
			const hex = _colorKeywords[ style.toLowerCase() ];

			if ( hex !== undefined ) {

				// red
				this.setHex( hex, colorSpace );

			} else {

				// unknown color
				console.warn( 'THREE.Color: Unknown color ' + style );

			}

			return this;

		}

		/**
		 * Returns a new color with copied values from this instance.
		 *
		 * @return {Color} A clone of this instance.
		 */
		clone() {

			return new this.constructor( this.r, this.g, this.b );

		}

		/**
		 * Copies the values of the given color to this instance.
		 *
		 * @param {Color} color - The color to copy.
		 * @return {Color} A reference to this color.
		 */
		copy( color ) {

			this.r = color.r;
			this.g = color.g;
			this.b = color.b;

			return this;

		}

		/**
		 * Copies the given color into this color, and then converts this color from
		 * `SRGBColorSpace` to `LinearSRGBColorSpace`.
		 *
		 * @param {Color} color - The color to copy/convert.
		 * @return {Color} A reference to this color.
		 */
		copySRGBToLinear( color ) {

			this.r = SRGBToLinear( color.r );
			this.g = SRGBToLinear( color.g );
			this.b = SRGBToLinear( color.b );

			return this;

		}

		/**
		 * Copies the given color into this color, and then converts this color from
		 * `LinearSRGBColorSpace` to `SRGBColorSpace`.
		 *
		 * @param {Color} color - The color to copy/convert.
		 * @return {Color} A reference to this color.
		 */
		copyLinearToSRGB( color ) {

			this.r = LinearToSRGB( color.r );
			this.g = LinearToSRGB( color.g );
			this.b = LinearToSRGB( color.b );

			return this;

		}

		/**
		 * Converts this color from `SRGBColorSpace` to `LinearSRGBColorSpace`.
		 *
		 * @return {Color} A reference to this color.
		 */
		convertSRGBToLinear() {

			this.copySRGBToLinear( this );

			return this;

		}

		/**
		 * Converts this color from `LinearSRGBColorSpace` to `SRGBColorSpace`.
		 *
		 * @return {Color} A reference to this color.
		 */
		convertLinearToSRGB() {

			this.copyLinearToSRGB( this );

			return this;

		}

		/**
		 * Returns the hexadecimal value of this color.
		 *
		 * @param {string} [colorSpace=SRGBColorSpace] - The color space.
		 * @return {number} The hexadecimal value.
		 */
		getHex( colorSpace = SRGBColorSpace ) {

			ColorManagement.workingToColorSpace( _color.copy( this ), colorSpace );

			return Math.round( clamp( _color.r * 255, 0, 255 ) ) * 65536 + Math.round( clamp( _color.g * 255, 0, 255 ) ) * 256 + Math.round( clamp( _color.b * 255, 0, 255 ) );

		}

		/**
		 * Returns the hexadecimal value of this color as a string (for example, 'FFFFFF').
		 *
		 * @param {string} [colorSpace=SRGBColorSpace] - The color space.
		 * @return {string} The hexadecimal value as a string.
		 */
		getHexString( colorSpace = SRGBColorSpace ) {

			return ( '000000' + this.getHex( colorSpace ).toString( 16 ) ).slice( -6 );

		}

		/**
		 * Converts the colors RGB values into the HSL format and stores them into the
		 * given target object.
		 *
		 * @param {{h:number,s:number,l:number}} target - The target object that is used to store the method's result.
		 * @param {string} [colorSpace=ColorManagement.workingColorSpace] - The color space.
		 * @return {{h:number,s:number,l:number}} The HSL representation of this color.
		 */
		getHSL( target, colorSpace = ColorManagement.workingColorSpace ) {

			// h,s,l ranges are in 0.0 - 1.0

			ColorManagement.workingToColorSpace( _color.copy( this ), colorSpace );

			const r = _color.r, g = _color.g, b = _color.b;

			const max = Math.max( r, g, b );
			const min = Math.min( r, g, b );

			let hue, saturation;
			const lightness = ( min + max ) / 2.0;

			if ( min === max ) {

				hue = 0;
				saturation = 0;

			} else {

				const delta = max - min;

				saturation = lightness <= 0.5 ? delta / ( max + min ) : delta / ( 2 - max - min );

				switch ( max ) {

					case r: hue = ( g - b ) / delta + ( g < b ? 6 : 0 ); break;
					case g: hue = ( b - r ) / delta + 2; break;
					case b: hue = ( r - g ) / delta + 4; break;

				}

				hue /= 6;

			}

			target.h = hue;
			target.s = saturation;
			target.l = lightness;

			return target;

		}

		/**
		 * Returns the RGB values of this color and stores them into the given target object.
		 *
		 * @param {Color} target - The target color that is used to store the method's result.
		 * @param {string} [colorSpace=ColorManagement.workingColorSpace] - The color space.
		 * @return {Color} The RGB representation of this color.
		 */
		getRGB( target, colorSpace = ColorManagement.workingColorSpace ) {

			ColorManagement.workingToColorSpace( _color.copy( this ), colorSpace );

			target.r = _color.r;
			target.g = _color.g;
			target.b = _color.b;

			return target;

		}

		/**
		 * Returns the value of this color as a CSS style string. Example: `rgb(255,0,0)`.
		 *
		 * @param {string} [colorSpace=SRGBColorSpace] - The color space.
		 * @return {string} The CSS representation of this color.
		 */
		getStyle( colorSpace = SRGBColorSpace ) {

			ColorManagement.workingToColorSpace( _color.copy( this ), colorSpace );

			const r = _color.r, g = _color.g, b = _color.b;

			if ( colorSpace !== SRGBColorSpace ) {

				// Requires CSS Color Module Level 4 (https://www.w3.org/TR/css-color-4/).
				return `color(${ colorSpace } ${ r.toFixed( 3 ) } ${ g.toFixed( 3 ) } ${ b.toFixed( 3 ) })`;

			}

			return `rgb(${ Math.round( r * 255 ) },${ Math.round( g * 255 ) },${ Math.round( b * 255 ) })`;

		}

		/**
		 * Adds the given HSL values to this color's values.
		 * Internally, this converts the color's RGB values to HSL, adds HSL
		 * and then converts the color back to RGB.
		 *
		 * @param {number} h - Hue value between `0.0` and `1.0`.
		 * @param {number} s - Saturation value between `0.0` and `1.0`.
		 * @param {number} l - Lightness value between `0.0` and `1.0`.
		 * @return {Color} A reference to this color.
		 */
		offsetHSL( h, s, l ) {

			this.getHSL( _hslA );

			return this.setHSL( _hslA.h + h, _hslA.s + s, _hslA.l + l );

		}

		/**
		 * Adds the RGB values of the given color to the RGB values of this color.
		 *
		 * @param {Color} color - The color to add.
		 * @return {Color} A reference to this color.
		 */
		add( color ) {

			this.r += color.r;
			this.g += color.g;
			this.b += color.b;

			return this;

		}

		/**
		 * Adds the RGB values of the given colors and stores the result in this instance.
		 *
		 * @param {Color} color1 - The first color.
		 * @param {Color} color2 - The second color.
		 * @return {Color} A reference to this color.
		 */
		addColors( color1, color2 ) {

			this.r = color1.r + color2.r;
			this.g = color1.g + color2.g;
			this.b = color1.b + color2.b;

			return this;

		}

		/**
		 * Adds the given scalar value to the RGB values of this color.
		 *
		 * @param {number} s - The scalar to add.
		 * @return {Color} A reference to this color.
		 */
		addScalar( s ) {

			this.r += s;
			this.g += s;
			this.b += s;

			return this;

		}

		/**
		 * Subtracts the RGB values of the given color from the RGB values of this color.
		 *
		 * @param {Color} color - The color to subtract.
		 * @return {Color} A reference to this color.
		 */
		sub( color ) {

			this.r = Math.max( 0, this.r - color.r );
			this.g = Math.max( 0, this.g - color.g );
			this.b = Math.max( 0, this.b - color.b );

			return this;

		}

		/**
		 * Multiplies the RGB values of the given color with the RGB values of this color.
		 *
		 * @param {Color} color - The color to multiply.
		 * @return {Color} A reference to this color.
		 */
		multiply( color ) {

			this.r *= color.r;
			this.g *= color.g;
			this.b *= color.b;

			return this;

		}

		/**
		 * Multiplies the given scalar value with the RGB values of this color.
		 *
		 * @param {number} s - The scalar to multiply.
		 * @return {Color} A reference to this color.
		 */
		multiplyScalar( s ) {

			this.r *= s;
			this.g *= s;
			this.b *= s;

			return this;

		}

		/**
		 * Linearly interpolates this color's RGB values toward the RGB values of the
		 * given color. The alpha argument can be thought of as the ratio between
		 * the two colors, where `0.0` is this color and `1.0` is the first argument.
		 *
		 * @param {Color} color - The color to converge on.
		 * @param {number} alpha - The interpolation factor in the closed interval `[0,1]`.
		 * @return {Color} A reference to this color.
		 */
		lerp( color, alpha ) {

			this.r += ( color.r - this.r ) * alpha;
			this.g += ( color.g - this.g ) * alpha;
			this.b += ( color.b - this.b ) * alpha;

			return this;

		}

		/**
		 * Linearly interpolates between the given colors and stores the result in this instance.
		 * The alpha argument can be thought of as the ratio between the two colors, where `0.0`
		 * is the first and `1.0` is the second color.
		 *
		 * @param {Color} color1 - The first color.
		 * @param {Color} color2 - The second color.
		 * @param {number} alpha - The interpolation factor in the closed interval `[0,1]`.
		 * @return {Color} A reference to this color.
		 */
		lerpColors( color1, color2, alpha ) {

			this.r = color1.r + ( color2.r - color1.r ) * alpha;
			this.g = color1.g + ( color2.g - color1.g ) * alpha;
			this.b = color1.b + ( color2.b - color1.b ) * alpha;

			return this;

		}

		/**
		 * Linearly interpolates this color's HSL values toward the HSL values of the
		 * given color. It differs from {@link Color#lerp} by not interpolating straight
		 * from one color to the other, but instead going through all the hues in between
		 * those two colors. The alpha argument can be thought of as the ratio between
		 * the two colors, where 0.0 is this color and 1.0 is the first argument.
		 *
		 * @param {Color} color - The color to converge on.
		 * @param {number} alpha - The interpolation factor in the closed interval `[0,1]`.
		 * @return {Color} A reference to this color.
		 */
		lerpHSL( color, alpha ) {

			this.getHSL( _hslA );
			color.getHSL( _hslB );

			const h = lerp( _hslA.h, _hslB.h, alpha );
			const s = lerp( _hslA.s, _hslB.s, alpha );
			const l = lerp( _hslA.l, _hslB.l, alpha );

			this.setHSL( h, s, l );

			return this;

		}

		/**
		 * Sets the color's RGB components from the given 3D vector.
		 *
		 * @param {Vector3} v - The vector to set.
		 * @return {Color} A reference to this color.
		 */
		setFromVector3( v ) {

			this.r = v.x;
			this.g = v.y;
			this.b = v.z;

			return this;

		}

		/**
		 * Transforms this color with the given 3x3 matrix.
		 *
		 * @param {Matrix3} m - The matrix.
		 * @return {Color} A reference to this color.
		 */
		applyMatrix3( m ) {

			const r = this.r, g = this.g, b = this.b;
			const e = m.elements;

			this.r = e[ 0 ] * r + e[ 3 ] * g + e[ 6 ] * b;
			this.g = e[ 1 ] * r + e[ 4 ] * g + e[ 7 ] * b;
			this.b = e[ 2 ] * r + e[ 5 ] * g + e[ 8 ] * b;

			return this;

		}

		/**
		 * Returns `true` if this color is equal with the given one.
		 *
		 * @param {Color} c - The color to test for equality.
		 * @return {boolean} Whether this bounding color is equal with the given one.
		 */
		equals( c ) {

			return ( c.r === this.r ) && ( c.g === this.g ) && ( c.b === this.b );

		}

		/**
		 * Sets this color's RGB components from the given array.
		 *
		 * @param {Array<number>} array - An array holding the RGB values.
		 * @param {number} [offset=0] - The offset into the array.
		 * @return {Color} A reference to this color.
		 */
		fromArray( array, offset = 0 ) {

			this.r = array[ offset ];
			this.g = array[ offset + 1 ];
			this.b = array[ offset + 2 ];

			return this;

		}

		/**
		 * Writes the RGB components of this color to the given array. If no array is provided,
		 * the method returns a new instance.
		 *
		 * @param {Array<number>} [array=[]] - The target array holding the color components.
		 * @param {number} [offset=0] - Index of the first element in the array.
		 * @return {Array<number>} The color components.
		 */
		toArray( array = [], offset = 0 ) {

			array[ offset ] = this.r;
			array[ offset + 1 ] = this.g;
			array[ offset + 2 ] = this.b;

			return array;

		}

		/**
		 * Sets the components of this color from the given buffer attribute.
		 *
		 * @param {BufferAttribute} attribute - The buffer attribute holding color data.
		 * @param {number} index - The index into the attribute.
		 * @return {Color} A reference to this color.
		 */
		fromBufferAttribute( attribute, index ) {

			this.r = attribute.getX( index );
			this.g = attribute.getY( index );
			this.b = attribute.getZ( index );

			return this;

		}

		/**
		 * This methods defines the serialization result of this class. Returns the color
		 * as a hexadecimal value.
		 *
		 * @return {number} The hexadecimal value.
		 */
		toJSON() {

			return this.getHex();

		}

		*[ Symbol.iterator ]() {

			yield this.r;
			yield this.g;
			yield this.b;

		}

	}

	const _color = /*@__PURE__*/ new Color();

	/**
	 * A dictionary with X11 color names.
	 *
	 * Note that multiple words such as Dark Orange become the string 'darkorange'.
	 *
	 * @static
	 * @type {Object}
	 */
	Color.NAMES = _colorKeywords;

	let _materialId = 0;

	/**
	 * Abstract base class for materials.
	 *
	 * Materials define the appearance of renderable 3D objects.
	 *
	 * @abstract
	 * @augments EventDispatcher
	 */
	class Material extends EventDispatcher {

		/**
		 * Constructs a new material.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isMaterial = true;

			/**
			 * The ID of the material.
			 *
			 * @name Material#id
			 * @type {number}
			 * @readonly
			 */
			Object.defineProperty( this, 'id', { value: _materialId ++ } );

			/**
			 * The UUID of the material.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.uuid = generateUUID();

			/**
			 * The name of the material.
			 *
			 * @type {string}
			 */
			this.name = '';

			/**
			 * The type property is used for detecting the object type
			 * in context of serialization/deserialization.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.type = 'Material';

			/**
			 * Defines the blending type of the material.
			 *
			 * It must be set to `CustomBlending` if custom blending properties like
			 * {@link Material#blendSrc}, {@link Material#blendDst} or {@link Material#blendEquation}
			 * should have any effect.
			 *
			 * @type {(NoBlending|NormalBlending|AdditiveBlending|SubtractiveBlending|MultiplyBlending|CustomBlending)}
			 * @default NormalBlending
			 */
			this.blending = NormalBlending;

			/**
			 * Defines which side of faces will be rendered - front, back or both.
			 *
			 * @type {(FrontSide|BackSide|DoubleSide)}
			 * @default FrontSide
			 */
			this.side = FrontSide;

			/**
			 * If set to `true`, vertex colors should be used.
			 *
			 * The engine supports RGB and RGBA vertex colors depending on whether a three (RGB) or
			 * four (RGBA) component color buffer attribute is used.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.vertexColors = false;

			/**
			 * Defines how transparent the material is.
			 * A value of `0.0` indicates fully transparent, `1.0` is fully opaque.
			 *
			 * If the {@link Material#transparent} is not set to `true`,
			 * the material will remain fully opaque and this value will only affect its color.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.opacity = 1;

			/**
			 * Defines whether this material is transparent. This has an effect on
			 * rendering as transparent objects need special treatment and are rendered
			 * after non-transparent objects.
			 *
			 * When set to true, the extent to which the material is transparent is
			 * controlled by {@link Material#opacity}.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.transparent = false;

			/**
			 * Enables alpha hashed transparency, an alternative to {@link Material#transparent} or
			 * {@link Material#alphaTest}. The material will not be rendered if opacity is lower than
			 * a random threshold. Randomization introduces some grain or noise, but approximates alpha
			 * blending without the associated problems of sorting. Using TAA can reduce the resulting noise.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.alphaHash = false;

			/**
			 * Defines the blending source factor.
			 *
			 * @type {(ZeroFactor|OneFactor|SrcColorFactor|OneMinusSrcColorFactor|SrcAlphaFactor|OneMinusSrcAlphaFactor|DstAlphaFactor|OneMinusDstAlphaFactor|DstColorFactor|OneMinusDstColorFactor|SrcAlphaSaturateFactor|ConstantColorFactor|OneMinusConstantColorFactor|ConstantAlphaFactor|OneMinusConstantAlphaFactor)}
			 * @default SrcAlphaFactor
			 */
			this.blendSrc = SrcAlphaFactor;

			/**
			 * Defines the blending destination factor.
			 *
			 * @type {(ZeroFactor|OneFactor|SrcColorFactor|OneMinusSrcColorFactor|SrcAlphaFactor|OneMinusSrcAlphaFactor|DstAlphaFactor|OneMinusDstAlphaFactor|DstColorFactor|OneMinusDstColorFactor|SrcAlphaSaturateFactor|ConstantColorFactor|OneMinusConstantColorFactor|ConstantAlphaFactor|OneMinusConstantAlphaFactor)}
			 * @default OneMinusSrcAlphaFactor
			 */
			this.blendDst = OneMinusSrcAlphaFactor;

			/**
			 * Defines the blending equation.
			 *
			 * @type {(AddEquation|SubtractEquation|ReverseSubtractEquation|MinEquation|MaxEquation)}
			 * @default AddEquation
			 */
			this.blendEquation = AddEquation;

			/**
			 * Defines the blending source alpha factor.
			 *
			 * @type {?(ZeroFactor|OneFactor|SrcColorFactor|OneMinusSrcColorFactor|SrcAlphaFactor|OneMinusSrcAlphaFactor|DstAlphaFactor|OneMinusDstAlphaFactor|DstColorFactor|OneMinusDstColorFactor|SrcAlphaSaturateFactor|ConstantColorFactor|OneMinusConstantColorFactor|ConstantAlphaFactor|OneMinusConstantAlphaFactor)}
			 * @default null
			 */
			this.blendSrcAlpha = null;

			/**
			 * Defines the blending destination alpha factor.
			 *
			 * @type {?(ZeroFactor|OneFactor|SrcColorFactor|OneMinusSrcColorFactor|SrcAlphaFactor|OneMinusSrcAlphaFactor|DstAlphaFactor|OneMinusDstAlphaFactor|DstColorFactor|OneMinusDstColorFactor|SrcAlphaSaturateFactor|ConstantColorFactor|OneMinusConstantColorFactor|ConstantAlphaFactor|OneMinusConstantAlphaFactor)}
			 * @default null
			 */
			this.blendDstAlpha = null;

			/**
			 * Defines the blending equation of the alpha channel.
			 *
			 * @type {?(AddEquation|SubtractEquation|ReverseSubtractEquation|MinEquation|MaxEquation)}
			 * @default null
			 */
			this.blendEquationAlpha = null;

			/**
			 * Represents the RGB values of the constant blend color.
			 *
			 * This property has only an effect when using custom blending with `ConstantColor` or `OneMinusConstantColor`.
			 *
			 * @type {Color}
			 * @default (0,0,0)
			 */
			this.blendColor = new Color( 0, 0, 0 );

			/**
			 * Represents the alpha value of the constant blend color.
			 *
			 * This property has only an effect when using custom blending with `ConstantAlpha` or `OneMinusConstantAlpha`.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.blendAlpha = 0;

			/**
			 * Defines the depth function.
			 *
			 * @type {(NeverDepth|AlwaysDepth|LessDepth|LessEqualDepth|EqualDepth|GreaterEqualDepth|GreaterDepth|NotEqualDepth)}
			 * @default LessEqualDepth
			 */
			this.depthFunc = LessEqualDepth;

			/**
			 * Whether to have depth test enabled when rendering this material.
			 * When the depth test is disabled, the depth write will also be implicitly disabled.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.depthTest = true;

			/**
			 * Whether rendering this material has any effect on the depth buffer.
			 *
			 * When drawing 2D overlays it can be useful to disable the depth writing in
			 * order to layer several things together without creating z-index artifacts.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.depthWrite = true;

			/**
			 * The bit mask to use when writing to the stencil buffer.
			 *
			 * @type {number}
			 * @default 0xff
			 */
			this.stencilWriteMask = 0xff;

			/**
			 * The stencil comparison function to use.
			 *
			 * @type {NeverStencilFunc|LessStencilFunc|EqualStencilFunc|LessEqualStencilFunc|GreaterStencilFunc|NotEqualStencilFunc|GreaterEqualStencilFunc|AlwaysStencilFunc}
			 * @default AlwaysStencilFunc
			 */
			this.stencilFunc = AlwaysStencilFunc;

			/**
			 * The value to use when performing stencil comparisons or stencil operations.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.stencilRef = 0;

			/**
			 * The bit mask to use when comparing against the stencil buffer.
			 *
			 * @type {number}
			 * @default 0xff
			 */
			this.stencilFuncMask = 0xff;

			/**
			 * Which stencil operation to perform when the comparison function returns `false`.
			 *
			 * @type {ZeroStencilOp|KeepStencilOp|ReplaceStencilOp|IncrementStencilOp|DecrementStencilOp|IncrementWrapStencilOp|DecrementWrapStencilOp|InvertStencilOp}
			 * @default KeepStencilOp
			 */
			this.stencilFail = KeepStencilOp;

			/**
			 * Which stencil operation to perform when the comparison function returns
			 * `true` but the depth test fails.
			 *
			 * @type {ZeroStencilOp|KeepStencilOp|ReplaceStencilOp|IncrementStencilOp|DecrementStencilOp|IncrementWrapStencilOp|DecrementWrapStencilOp|InvertStencilOp}
			 * @default KeepStencilOp
			 */
			this.stencilZFail = KeepStencilOp;

			/**
			 * Which stencil operation to perform when the comparison function returns
			 * `true` and the depth test passes.
			 *
			 * @type {ZeroStencilOp|KeepStencilOp|ReplaceStencilOp|IncrementStencilOp|DecrementStencilOp|IncrementWrapStencilOp|DecrementWrapStencilOp|InvertStencilOp}
			 * @default KeepStencilOp
			 */
			this.stencilZPass = KeepStencilOp;

			/**
			 * Whether stencil operations are performed against the stencil buffer. In
			 * order to perform writes or comparisons against the stencil buffer this
			 * value must be `true`.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.stencilWrite = false;

			/**
			 * User-defined clipping planes specified as THREE.Plane objects in world
			 * space. These planes apply to the objects this material is attached to.
			 * Points in space whose signed distance to the plane is negative are clipped
			 * (not rendered). This requires {@link WebGLRenderer#localClippingEnabled} to
			 * be `true`.
			 *
			 * @type {?Array<Plane>}
			 * @default null
			 */
			this.clippingPlanes = null;

			/**
			 * Changes the behavior of clipping planes so that only their intersection is
			 * clipped, rather than their union.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.clipIntersection = false;

			/**
			 * Defines whether to clip shadows according to the clipping planes specified
			 * on this material.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.clipShadows = false;

			/**
			 * Defines which side of faces cast shadows. If `null`, the side casting shadows
			 * is determined as follows:
			 *
			 * - When {@link Material#side} is set to `FrontSide`, the back side cast shadows.
			 * - When {@link Material#side} is set to `BackSide`, the front side cast shadows.
			 * - When {@link Material#side} is set to `DoubleSide`, both sides cast shadows.
			 *
			 * @type {?(FrontSide|BackSide|DoubleSide)}
			 * @default null
			 */
			this.shadowSide = null;

			/**
			 * Whether to render the material's color.
			 *
			 * This can be used in conjunction with {@link Object3D#renderOder} to create invisible
			 * objects that occlude other objects.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.colorWrite = true;

			/**
			 * Override the renderer's default precision for this material.
			 *
			 * @type {?('highp'|'mediump'|'lowp')}
			 * @default null
			 */
			this.precision = null;

			/**
			 * Whether to use polygon offset or not. When enabled, each fragment's depth value will
			 * be offset after it is interpolated from the depth values of the appropriate vertices.
			 * The offset is added before the depth test is performed and before the value is written
			 * into the depth buffer.
			 *
			 * Can be useful for rendering hidden-line images, for applying decals to surfaces, and for
			 * rendering solids with highlighted edges.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.polygonOffset = false;

			/**
			 * Specifies a scale factor that is used to create a variable depth offset for each polygon.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.polygonOffsetFactor = 0;

			/**
			 * Is multiplied by an implementation-specific value to create a constant depth offset.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.polygonOffsetUnits = 0;

			/**
			 * Whether to apply dithering to the color to remove the appearance of banding.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.dithering = false;

			/**
			 * Whether alpha to coverage should be enabled or not. Can only be used with MSAA-enabled contexts
			 * (meaning when the renderer was created with *antialias* parameter set to `true`). Enabling this
			 * will smooth aliasing on clip plane edges and alphaTest-clipped edges.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.alphaToCoverage = false;

			/**
			 * Whether to premultiply the alpha (transparency) value.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.premultipliedAlpha = false;

			/**
			 * Whether double-sided, transparent objects should be rendered with a single pass or not.
			 *
			 * The engine renders double-sided, transparent objects with two draw calls (back faces first,
			 * then front faces) to mitigate transparency artifacts. There are scenarios however where this
			 * approach produces no quality gains but still doubles draw calls e.g. when rendering flat
			 * vegetation like grass sprites. In these cases, set the `forceSinglePass` flag to `true` to
			 * disable the two pass rendering to avoid performance issues.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.forceSinglePass = false;

			/**
			 * Whether it's possible to override the material with {@link Scene#overrideMaterial} or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.allowOverride = true;

			/**
			 * Defines whether 3D objects using this material are visible.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.visible = true;

			/**
			 * Defines whether this material is tone mapped according to the renderer's tone mapping setting.
			 *
			 * It is ignored when rendering to a render target or using post processing or when using
			 * `WebGPURenderer`. In all these cases, all materials are honored by tone mapping.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.toneMapped = true;

			/**
			 * An object that can be used to store custom data about the Material. It
			 * should not hold references to functions as these will not be cloned.
			 *
			 * @type {Object}
			 */
			this.userData = {};

			/**
			 * This starts at `0` and counts how many times {@link Material#needsUpdate} is set to `true`.
			 *
			 * @type {number}
			 * @readonly
			 * @default 0
			 */
			this.version = 0;

			this._alphaTest = 0;

		}

		/**
		 * Sets the alpha value to be used when running an alpha test. The material
		 * will not be rendered if the opacity is lower than this value.
		 *
		 * @type {number}
		 * @readonly
		 * @default 0
		 */
		get alphaTest() {

			return this._alphaTest;

		}

		set alphaTest( value ) {

			if ( this._alphaTest > 0 !== value > 0 ) {

				this.version ++;

			}

			this._alphaTest = value;

		}

		/**
		 * An optional callback that is executed immediately before the material is used to render a 3D object.
		 *
		 * This method can only be used when rendering with {@link WebGLRenderer}.
		 *
		 * @param {WebGLRenderer} renderer - The renderer.
		 * @param {Scene} scene - The scene.
		 * @param {Camera} camera - The camera that is used to render the scene.
		 * @param {BufferGeometry} geometry - The 3D object's geometry.
		 * @param {Object3D} object - The 3D object.
		 * @param {Object} group - The geometry group data.
		 */
		onBeforeRender( /* renderer, scene, camera, geometry, object, group */ ) {}

		/**
		 * An optional callback that is executed immediately before the shader
		 * program is compiled. This function is called with the shader source code
		 * as a parameter. Useful for the modification of built-in materials.
		 *
		 * This method can only be used when rendering with {@link WebGLRenderer}. The
		 * recommended approach when customizing materials is to use `WebGPURenderer` with the new
		 * Node Material system and [TSL]{@link https://github.com/mrdoob/three.js/wiki/Three.js-Shading-Language}.
		 *
		 * @param {{vertexShader:string,fragmentShader:string,uniforms:Object}} shaderobject - The object holds the uniforms and the vertex and fragment shader source.
		 * @param {WebGLRenderer} renderer - A reference to the renderer.
		 */
		onBeforeCompile( /* shaderobject, renderer */ ) {}

		/**
		 * In case {@link Material#onBeforeCompile} is used, this callback can be used to identify
		 * values of settings used in `onBeforeCompile()`, so three.js can reuse a cached
		 * shader or recompile the shader for this material as needed.
		 *
		 * This method can only be used when rendering with {@link WebGLRenderer}.
		 *
		 * @return {string} The custom program cache key.
		 */
		customProgramCacheKey() {

			return this.onBeforeCompile.toString();

		}

		/**
		 * This method can be used to set default values from parameter objects.
		 * It is a generic implementation so it can be used with different types
		 * of materials.
		 *
		 * @param {Object} [values] - The material values to set.
		 */
		setValues( values ) {

			if ( values === undefined ) return;

			for ( const key in values ) {

				const newValue = values[ key ];

				if ( newValue === undefined ) {

					console.warn( `THREE.Material: parameter '${ key }' has value of undefined.` );
					continue;

				}

				const currentValue = this[ key ];

				if ( currentValue === undefined ) {

					console.warn( `THREE.Material: '${ key }' is not a property of THREE.${ this.type }.` );
					continue;

				}

				if ( currentValue && currentValue.isColor ) {

					currentValue.set( newValue );

				} else if ( ( currentValue && currentValue.isVector3 ) && ( newValue && newValue.isVector3 ) ) {

					currentValue.copy( newValue );

				} else {

					this[ key ] = newValue;

				}

			}

		}

		/**
		 * Serializes the material into JSON.
		 *
		 * @param {?(Object|string)} meta - An optional value holding meta information about the serialization.
		 * @return {Object} A JSON object representing the serialized material.
		 * @see {@link ObjectLoader#parse}
		 */
		toJSON( meta ) {

			const isRootObject = ( meta === undefined || typeof meta === 'string' );

			if ( isRootObject ) {

				meta = {
					textures: {},
					images: {}
				};

			}

			const data = {
				metadata: {
					version: 4.7,
					type: 'Material',
					generator: 'Material.toJSON'
				}
			};

			// standard Material serialization
			data.uuid = this.uuid;
			data.type = this.type;

			if ( this.name !== '' ) data.name = this.name;

			if ( this.color && this.color.isColor ) data.color = this.color.getHex();

			if ( this.roughness !== undefined ) data.roughness = this.roughness;
			if ( this.metalness !== undefined ) data.metalness = this.metalness;

			if ( this.sheen !== undefined ) data.sheen = this.sheen;
			if ( this.sheenColor && this.sheenColor.isColor ) data.sheenColor = this.sheenColor.getHex();
			if ( this.sheenRoughness !== undefined ) data.sheenRoughness = this.sheenRoughness;
			if ( this.emissive && this.emissive.isColor ) data.emissive = this.emissive.getHex();
			if ( this.emissiveIntensity !== undefined && this.emissiveIntensity !== 1 ) data.emissiveIntensity = this.emissiveIntensity;

			if ( this.specular && this.specular.isColor ) data.specular = this.specular.getHex();
			if ( this.specularIntensity !== undefined ) data.specularIntensity = this.specularIntensity;
			if ( this.specularColor && this.specularColor.isColor ) data.specularColor = this.specularColor.getHex();
			if ( this.shininess !== undefined ) data.shininess = this.shininess;
			if ( this.clearcoat !== undefined ) data.clearcoat = this.clearcoat;
			if ( this.clearcoatRoughness !== undefined ) data.clearcoatRoughness = this.clearcoatRoughness;

			if ( this.clearcoatMap && this.clearcoatMap.isTexture ) {

				data.clearcoatMap = this.clearcoatMap.toJSON( meta ).uuid;

			}

			if ( this.clearcoatRoughnessMap && this.clearcoatRoughnessMap.isTexture ) {

				data.clearcoatRoughnessMap = this.clearcoatRoughnessMap.toJSON( meta ).uuid;

			}

			if ( this.clearcoatNormalMap && this.clearcoatNormalMap.isTexture ) {

				data.clearcoatNormalMap = this.clearcoatNormalMap.toJSON( meta ).uuid;
				data.clearcoatNormalScale = this.clearcoatNormalScale.toArray();

			}

			if ( this.dispersion !== undefined ) data.dispersion = this.dispersion;

			if ( this.iridescence !== undefined ) data.iridescence = this.iridescence;
			if ( this.iridescenceIOR !== undefined ) data.iridescenceIOR = this.iridescenceIOR;
			if ( this.iridescenceThicknessRange !== undefined ) data.iridescenceThicknessRange = this.iridescenceThicknessRange;

			if ( this.iridescenceMap && this.iridescenceMap.isTexture ) {

				data.iridescenceMap = this.iridescenceMap.toJSON( meta ).uuid;

			}

			if ( this.iridescenceThicknessMap && this.iridescenceThicknessMap.isTexture ) {

				data.iridescenceThicknessMap = this.iridescenceThicknessMap.toJSON( meta ).uuid;

			}

			if ( this.anisotropy !== undefined ) data.anisotropy = this.anisotropy;
			if ( this.anisotropyRotation !== undefined ) data.anisotropyRotation = this.anisotropyRotation;

			if ( this.anisotropyMap && this.anisotropyMap.isTexture ) {

				data.anisotropyMap = this.anisotropyMap.toJSON( meta ).uuid;

			}

			if ( this.map && this.map.isTexture ) data.map = this.map.toJSON( meta ).uuid;
			if ( this.matcap && this.matcap.isTexture ) data.matcap = this.matcap.toJSON( meta ).uuid;
			if ( this.alphaMap && this.alphaMap.isTexture ) data.alphaMap = this.alphaMap.toJSON( meta ).uuid;

			if ( this.lightMap && this.lightMap.isTexture ) {

				data.lightMap = this.lightMap.toJSON( meta ).uuid;
				data.lightMapIntensity = this.lightMapIntensity;

			}

			if ( this.aoMap && this.aoMap.isTexture ) {

				data.aoMap = this.aoMap.toJSON( meta ).uuid;
				data.aoMapIntensity = this.aoMapIntensity;

			}

			if ( this.bumpMap && this.bumpMap.isTexture ) {

				data.bumpMap = this.bumpMap.toJSON( meta ).uuid;
				data.bumpScale = this.bumpScale;

			}

			if ( this.normalMap && this.normalMap.isTexture ) {

				data.normalMap = this.normalMap.toJSON( meta ).uuid;
				data.normalMapType = this.normalMapType;
				data.normalScale = this.normalScale.toArray();

			}

			if ( this.displacementMap && this.displacementMap.isTexture ) {

				data.displacementMap = this.displacementMap.toJSON( meta ).uuid;
				data.displacementScale = this.displacementScale;
				data.displacementBias = this.displacementBias;

			}

			if ( this.roughnessMap && this.roughnessMap.isTexture ) data.roughnessMap = this.roughnessMap.toJSON( meta ).uuid;
			if ( this.metalnessMap && this.metalnessMap.isTexture ) data.metalnessMap = this.metalnessMap.toJSON( meta ).uuid;

			if ( this.emissiveMap && this.emissiveMap.isTexture ) data.emissiveMap = this.emissiveMap.toJSON( meta ).uuid;
			if ( this.specularMap && this.specularMap.isTexture ) data.specularMap = this.specularMap.toJSON( meta ).uuid;
			if ( this.specularIntensityMap && this.specularIntensityMap.isTexture ) data.specularIntensityMap = this.specularIntensityMap.toJSON( meta ).uuid;
			if ( this.specularColorMap && this.specularColorMap.isTexture ) data.specularColorMap = this.specularColorMap.toJSON( meta ).uuid;

			if ( this.envMap && this.envMap.isTexture ) {

				data.envMap = this.envMap.toJSON( meta ).uuid;

				if ( this.combine !== undefined ) data.combine = this.combine;

			}

			if ( this.envMapRotation !== undefined ) data.envMapRotation = this.envMapRotation.toArray();
			if ( this.envMapIntensity !== undefined ) data.envMapIntensity = this.envMapIntensity;
			if ( this.reflectivity !== undefined ) data.reflectivity = this.reflectivity;
			if ( this.refractionRatio !== undefined ) data.refractionRatio = this.refractionRatio;

			if ( this.gradientMap && this.gradientMap.isTexture ) {

				data.gradientMap = this.gradientMap.toJSON( meta ).uuid;

			}

			if ( this.transmission !== undefined ) data.transmission = this.transmission;
			if ( this.transmissionMap && this.transmissionMap.isTexture ) data.transmissionMap = this.transmissionMap.toJSON( meta ).uuid;
			if ( this.thickness !== undefined ) data.thickness = this.thickness;
			if ( this.thicknessMap && this.thicknessMap.isTexture ) data.thicknessMap = this.thicknessMap.toJSON( meta ).uuid;
			if ( this.attenuationDistance !== undefined && this.attenuationDistance !== Infinity ) data.attenuationDistance = this.attenuationDistance;
			if ( this.attenuationColor !== undefined ) data.attenuationColor = this.attenuationColor.getHex();

			if ( this.size !== undefined ) data.size = this.size;
			if ( this.shadowSide !== null ) data.shadowSide = this.shadowSide;
			if ( this.sizeAttenuation !== undefined ) data.sizeAttenuation = this.sizeAttenuation;

			if ( this.blending !== NormalBlending ) data.blending = this.blending;
			if ( this.side !== FrontSide ) data.side = this.side;
			if ( this.vertexColors === true ) data.vertexColors = true;

			if ( this.opacity < 1 ) data.opacity = this.opacity;
			if ( this.transparent === true ) data.transparent = true;

			if ( this.blendSrc !== SrcAlphaFactor ) data.blendSrc = this.blendSrc;
			if ( this.blendDst !== OneMinusSrcAlphaFactor ) data.blendDst = this.blendDst;
			if ( this.blendEquation !== AddEquation ) data.blendEquation = this.blendEquation;
			if ( this.blendSrcAlpha !== null ) data.blendSrcAlpha = this.blendSrcAlpha;
			if ( this.blendDstAlpha !== null ) data.blendDstAlpha = this.blendDstAlpha;
			if ( this.blendEquationAlpha !== null ) data.blendEquationAlpha = this.blendEquationAlpha;
			if ( this.blendColor && this.blendColor.isColor ) data.blendColor = this.blendColor.getHex();
			if ( this.blendAlpha !== 0 ) data.blendAlpha = this.blendAlpha;

			if ( this.depthFunc !== LessEqualDepth ) data.depthFunc = this.depthFunc;
			if ( this.depthTest === false ) data.depthTest = this.depthTest;
			if ( this.depthWrite === false ) data.depthWrite = this.depthWrite;
			if ( this.colorWrite === false ) data.colorWrite = this.colorWrite;

			if ( this.stencilWriteMask !== 0xff ) data.stencilWriteMask = this.stencilWriteMask;
			if ( this.stencilFunc !== AlwaysStencilFunc ) data.stencilFunc = this.stencilFunc;
			if ( this.stencilRef !== 0 ) data.stencilRef = this.stencilRef;
			if ( this.stencilFuncMask !== 0xff ) data.stencilFuncMask = this.stencilFuncMask;
			if ( this.stencilFail !== KeepStencilOp ) data.stencilFail = this.stencilFail;
			if ( this.stencilZFail !== KeepStencilOp ) data.stencilZFail = this.stencilZFail;
			if ( this.stencilZPass !== KeepStencilOp ) data.stencilZPass = this.stencilZPass;
			if ( this.stencilWrite === true ) data.stencilWrite = this.stencilWrite;

			// rotation (SpriteMaterial)
			if ( this.rotation !== undefined && this.rotation !== 0 ) data.rotation = this.rotation;

			if ( this.polygonOffset === true ) data.polygonOffset = true;
			if ( this.polygonOffsetFactor !== 0 ) data.polygonOffsetFactor = this.polygonOffsetFactor;
			if ( this.polygonOffsetUnits !== 0 ) data.polygonOffsetUnits = this.polygonOffsetUnits;

			if ( this.linewidth !== undefined && this.linewidth !== 1 ) data.linewidth = this.linewidth;
			if ( this.dashSize !== undefined ) data.dashSize = this.dashSize;
			if ( this.gapSize !== undefined ) data.gapSize = this.gapSize;
			if ( this.scale !== undefined ) data.scale = this.scale;

			if ( this.dithering === true ) data.dithering = true;

			if ( this.alphaTest > 0 ) data.alphaTest = this.alphaTest;
			if ( this.alphaHash === true ) data.alphaHash = true;
			if ( this.alphaToCoverage === true ) data.alphaToCoverage = true;
			if ( this.premultipliedAlpha === true ) data.premultipliedAlpha = true;
			if ( this.forceSinglePass === true ) data.forceSinglePass = true;

			if ( this.wireframe === true ) data.wireframe = true;
			if ( this.wireframeLinewidth > 1 ) data.wireframeLinewidth = this.wireframeLinewidth;
			if ( this.wireframeLinecap !== 'round' ) data.wireframeLinecap = this.wireframeLinecap;
			if ( this.wireframeLinejoin !== 'round' ) data.wireframeLinejoin = this.wireframeLinejoin;

			if ( this.flatShading === true ) data.flatShading = true;

			if ( this.visible === false ) data.visible = false;

			if ( this.toneMapped === false ) data.toneMapped = false;

			if ( this.fog === false ) data.fog = false;

			if ( Object.keys( this.userData ).length > 0 ) data.userData = this.userData;

			// TODO: Copied from Object3D.toJSON

			function extractFromCache( cache ) {

				const values = [];

				for ( const key in cache ) {

					const data = cache[ key ];
					delete data.metadata;
					values.push( data );

				}

				return values;

			}

			if ( isRootObject ) {

				const textures = extractFromCache( meta.textures );
				const images = extractFromCache( meta.images );

				if ( textures.length > 0 ) data.textures = textures;
				if ( images.length > 0 ) data.images = images;

			}

			return data;

		}

		/**
		 * Returns a new material with copied values from this instance.
		 *
		 * @return {Material} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Copies the values of the given material to this instance.
		 *
		 * @param {Material} source - The material to copy.
		 * @return {Material} A reference to this instance.
		 */
		copy( source ) {

			this.name = source.name;

			this.blending = source.blending;
			this.side = source.side;
			this.vertexColors = source.vertexColors;

			this.opacity = source.opacity;
			this.transparent = source.transparent;

			this.blendSrc = source.blendSrc;
			this.blendDst = source.blendDst;
			this.blendEquation = source.blendEquation;
			this.blendSrcAlpha = source.blendSrcAlpha;
			this.blendDstAlpha = source.blendDstAlpha;
			this.blendEquationAlpha = source.blendEquationAlpha;
			this.blendColor.copy( source.blendColor );
			this.blendAlpha = source.blendAlpha;

			this.depthFunc = source.depthFunc;
			this.depthTest = source.depthTest;
			this.depthWrite = source.depthWrite;

			this.stencilWriteMask = source.stencilWriteMask;
			this.stencilFunc = source.stencilFunc;
			this.stencilRef = source.stencilRef;
			this.stencilFuncMask = source.stencilFuncMask;
			this.stencilFail = source.stencilFail;
			this.stencilZFail = source.stencilZFail;
			this.stencilZPass = source.stencilZPass;
			this.stencilWrite = source.stencilWrite;

			const srcPlanes = source.clippingPlanes;
			let dstPlanes = null;

			if ( srcPlanes !== null ) {

				const n = srcPlanes.length;
				dstPlanes = new Array( n );

				for ( let i = 0; i !== n; ++ i ) {

					dstPlanes[ i ] = srcPlanes[ i ].clone();

				}

			}

			this.clippingPlanes = dstPlanes;
			this.clipIntersection = source.clipIntersection;
			this.clipShadows = source.clipShadows;

			this.shadowSide = source.shadowSide;

			this.colorWrite = source.colorWrite;

			this.precision = source.precision;

			this.polygonOffset = source.polygonOffset;
			this.polygonOffsetFactor = source.polygonOffsetFactor;
			this.polygonOffsetUnits = source.polygonOffsetUnits;

			this.dithering = source.dithering;

			this.alphaTest = source.alphaTest;
			this.alphaHash = source.alphaHash;
			this.alphaToCoverage = source.alphaToCoverage;
			this.premultipliedAlpha = source.premultipliedAlpha;
			this.forceSinglePass = source.forceSinglePass;

			this.visible = source.visible;

			this.toneMapped = source.toneMapped;

			this.userData = JSON.parse( JSON.stringify( source.userData ) );

			return this;

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 *
		 * @fires Material#dispose
		 */
		dispose() {

			/**
			 * Fires when the material has been disposed of.
			 *
			 * @event Material#dispose
			 * @type {Object}
			 */
			this.dispatchEvent( { type: 'dispose' } );

		}

		/**
		 * Setting this property to `true` indicates the engine the material
		 * needs to be recompiled.
		 *
		 * @type {boolean}
		 * @default false
		 * @param {boolean} value
		 */
		set needsUpdate( value ) {

			if ( value === true ) this.version ++;

		}

	}

	/**
	 * A material for drawing geometries in a simple shaded (flat or wireframe) way.
	 *
	 * This material is not affected by lights.
	 *
	 * @augments Material
	 */
	class MeshBasicMaterial extends Material {

		/**
		 * Constructs a new mesh basic material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isMeshBasicMaterial = true;

			this.type = 'MeshBasicMaterial';

			/**
			 * Color of the material.
			 *
			 * @type {Color}
			 * @default (1,1,1)
			 */
			this.color = new Color( 0xffffff ); // emissive

			/**
			 * The color map. May optionally include an alpha channel, typically combined
			 * with {@link Material#transparent} or {@link Material#alphaTest}. The texture map
			 * color is modulated by the diffuse `color`.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.map = null;

			/**
			 * The light map. Requires a second set of UVs.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.lightMap = null;

			/**
			 * Intensity of the baked light.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.lightMapIntensity = 1.0;

			/**
			 * The red channel of this texture is used as the ambient occlusion map.
			 * Requires a second set of UVs.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.aoMap = null;

			/**
			 * Intensity of the ambient occlusion effect. Range is `[0,1]`, where `0`
			 * disables ambient occlusion. Where intensity is `1` and the AO map's
			 * red channel is also `1`, ambient light is fully occluded on a surface.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.aoMapIntensity = 1.0;

			/**
			 * Specular map used by the material.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.specularMap = null;

			/**
			 * The alpha map is a grayscale texture that controls the opacity across the
			 * surface (black: fully transparent; white: fully opaque).
			 *
			 * Only the color of the texture is used, ignoring the alpha channel if one
			 * exists. For RGB and RGBA textures, the renderer will use the green channel
			 * when sampling this texture due to the extra bit of precision provided for
			 * green in DXT-compressed and uncompressed RGB 565 formats. Luminance-only and
			 * luminance/alpha textures will also still work as expected.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.alphaMap = null;

			/**
			 * The environment map.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.envMap = null;

			/**
			 * The rotation of the environment map in radians.
			 *
			 * @type {Euler}
			 * @default (0,0,0)
			 */
			this.envMapRotation = new Euler();

			/**
			 * How to combine the result of the surface's color with the environment map, if any.
			 *
			 * When set to `MixOperation`, the {@link MeshBasicMaterial#reflectivity} is used to
			 * blend between the two colors.
			 *
			 * @type {(MultiplyOperation|MixOperation|AddOperation)}
			 * @default MultiplyOperation
			 */
			this.combine = MultiplyOperation;

			/**
			 * How much the environment map affects the surface.
			 * The valid range is between `0` (no reflections) and `1` (full reflections).
			 *
			 * @type {number}
			 * @default 1
			 */
			this.reflectivity = 1;

			/**
			 * The index of refraction (IOR) of air (approximately 1) divided by the
			 * index of refraction of the material. It is used with environment mapping
			 * modes {@link CubeRefractionMapping} and {@link EquirectangularRefractionMapping}.
			 * The refraction ratio should not exceed `1`.
			 *
			 * @type {number}
			 * @default 0.98
			 */
			this.refractionRatio = 0.98;

			/**
			 * Renders the geometry as a wireframe.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.wireframe = false;

			/**
			 * Controls the thickness of the wireframe.
			 *
			 * Can only be used with {@link SVGRenderer}.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.wireframeLinewidth = 1;

			/**
			 * Defines appearance of wireframe ends.
			 *
			 * Can only be used with {@link SVGRenderer}.
			 *
			 * @type {('round'|'bevel'|'miter')}
			 * @default 'round'
			 */
			this.wireframeLinecap = 'round';

			/**
			 * Defines appearance of wireframe joints.
			 *
			 * Can only be used with {@link SVGRenderer}.
			 *
			 * @type {('round'|'bevel'|'miter')}
			 * @default 'round'
			 */
			this.wireframeLinejoin = 'round';

			/**
			 * Whether the material is affected by fog or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.fog = true;

			this.setValues( parameters );

		}

		copy( source ) {

			super.copy( source );

			this.color.copy( source.color );

			this.map = source.map;

			this.lightMap = source.lightMap;
			this.lightMapIntensity = source.lightMapIntensity;

			this.aoMap = source.aoMap;
			this.aoMapIntensity = source.aoMapIntensity;

			this.specularMap = source.specularMap;

			this.alphaMap = source.alphaMap;

			this.envMap = source.envMap;
			this.envMapRotation.copy( source.envMapRotation );
			this.combine = source.combine;
			this.reflectivity = source.reflectivity;
			this.refractionRatio = source.refractionRatio;

			this.wireframe = source.wireframe;
			this.wireframeLinewidth = source.wireframeLinewidth;
			this.wireframeLinecap = source.wireframeLinecap;
			this.wireframeLinejoin = source.wireframeLinejoin;

			this.fog = source.fog;

			return this;

		}

	}

	// Fast Half Float Conversions, http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf

	const _tables = /*@__PURE__*/ _generateTables();

	function _generateTables() {

		// float32 to float16 helpers

		const buffer = new ArrayBuffer( 4 );
		const floatView = new Float32Array( buffer );
		const uint32View = new Uint32Array( buffer );

		const baseTable = new Uint32Array( 512 );
		const shiftTable = new Uint32Array( 512 );

		for ( let i = 0; i < 256; ++ i ) {

			const e = i - 127;

			// very small number (0, -0)

			if ( e < -27 ) {

				baseTable[ i ] = 0x0000;
				baseTable[ i | 0x100 ] = 0x8000;
				shiftTable[ i ] = 24;
				shiftTable[ i | 0x100 ] = 24;

				// small number (denorm)

			} else if ( e < -14 ) {

				baseTable[ i ] = 0x0400 >> ( - e - 14 );
				baseTable[ i | 0x100 ] = ( 0x0400 >> ( - e - 14 ) ) | 0x8000;
				shiftTable[ i ] = - e - 1;
				shiftTable[ i | 0x100 ] = - e - 1;

				// normal number

			} else if ( e <= 15 ) {

				baseTable[ i ] = ( e + 15 ) << 10;
				baseTable[ i | 0x100 ] = ( ( e + 15 ) << 10 ) | 0x8000;
				shiftTable[ i ] = 13;
				shiftTable[ i | 0x100 ] = 13;

				// large number (Infinity, -Infinity)

			} else if ( e < 128 ) {

				baseTable[ i ] = 0x7c00;
				baseTable[ i | 0x100 ] = 0xfc00;
				shiftTable[ i ] = 24;
				shiftTable[ i | 0x100 ] = 24;

				// stay (NaN, Infinity, -Infinity)

			} else {

				baseTable[ i ] = 0x7c00;
				baseTable[ i | 0x100 ] = 0xfc00;
				shiftTable[ i ] = 13;
				shiftTable[ i | 0x100 ] = 13;

			}

		}

		// float16 to float32 helpers

		const mantissaTable = new Uint32Array( 2048 );
		const exponentTable = new Uint32Array( 64 );
		const offsetTable = new Uint32Array( 64 );

		for ( let i = 1; i < 1024; ++ i ) {

			let m = i << 13; // zero pad mantissa bits
			let e = 0; // zero exponent

			// normalized
			while ( ( m & 0x00800000 ) === 0 ) {

				m <<= 1;
				e -= 0x00800000; // decrement exponent

			}

			m &= -8388609; // clear leading 1 bit
			e += 0x38800000; // adjust bias

			mantissaTable[ i ] = m | e;

		}

		for ( let i = 1024; i < 2048; ++ i ) {

			mantissaTable[ i ] = 0x38000000 + ( ( i - 1024 ) << 13 );

		}

		for ( let i = 1; i < 31; ++ i ) {

			exponentTable[ i ] = i << 23;

		}

		exponentTable[ 31 ] = 0x47800000;
		exponentTable[ 32 ] = 0x80000000;

		for ( let i = 33; i < 63; ++ i ) {

			exponentTable[ i ] = 0x80000000 + ( ( i - 32 ) << 23 );

		}

		exponentTable[ 63 ] = 0xc7800000;

		for ( let i = 1; i < 64; ++ i ) {

			if ( i !== 32 ) {

				offsetTable[ i ] = 1024;

			}

		}

		return {
			floatView: floatView,
			uint32View: uint32View,
			baseTable: baseTable,
			shiftTable: shiftTable,
			mantissaTable: mantissaTable,
			exponentTable: exponentTable,
			offsetTable: offsetTable
		};

	}

	/**
	 * Returns a half precision floating point value (FP16) from the given single
	 * precision floating point value (FP32).
	 *
	 * @param {number} val - A single precision floating point value.
	 * @return {number} The FP16 value.
	 */
	function toHalfFloat( val ) {

		if ( Math.abs( val ) > 65504 ) console.warn( 'THREE.DataUtils.toHalfFloat(): Value out of range.' );

		val = clamp( val, -65504, 65504 );

		_tables.floatView[ 0 ] = val;
		const f = _tables.uint32View[ 0 ];
		const e = ( f >> 23 ) & 0x1ff;
		return _tables.baseTable[ e ] + ( ( f & 0x007fffff ) >> _tables.shiftTable[ e ] );

	}

	/**
	 * Returns a single precision floating point value (FP32) from the given half
	 * precision floating point value (FP16).
	 *
	 * @param {number} val - A half precision floating point value.
	 * @return {number} The FP32 value.
	 */
	function fromHalfFloat( val ) {

		const m = val >> 10;
		_tables.uint32View[ 0 ] = _tables.mantissaTable[ _tables.offsetTable[ m ] + ( val & 0x3ff ) ] + _tables.exponentTable[ m ];
		return _tables.floatView[ 0 ];

	}

	/**
	 * A class containing utility functions for data.
	 *
	 * @hideconstructor
	 */
	class DataUtils {

		/**
		 * Returns a half precision floating point value (FP16) from the given single
		 * precision floating point value (FP32).
		 *
		 * @param {number} val - A single precision floating point value.
		 * @return {number} The FP16 value.
		 */
		static toHalfFloat( val ) {

			return toHalfFloat( val );

		}

		/**
		 * Returns a single precision floating point value (FP32) from the given half
		 * precision floating point value (FP16).
		 *
		 * @param {number} val - A half precision floating point value.
		 * @return {number} The FP32 value.
		 */
		static fromHalfFloat( val ) {

			return fromHalfFloat( val );

		}

	}

	const _vector$9 = /*@__PURE__*/ new Vector3();
	const _vector2$1 = /*@__PURE__*/ new Vector2();

	let _id$2 = 0;

	/**
	 * This class stores data for an attribute (such as vertex positions, face
	 * indices, normals, colors, UVs, and any custom attributes ) associated with
	 * a geometry, which allows for more efficient passing of data to the GPU.
	 *
	 * When working with vector-like data, the `fromBufferAttribute( attribute, index )`
	 * helper methods on vector and color class might be helpful. E.g. {@link Vector3#fromBufferAttribute}.
	 */
	class BufferAttribute {

		/**
		 * Constructs a new buffer attribute.
		 *
		 * @param {TypedArray} array - The array holding the attribute data.
		 * @param {number} itemSize - The item size.
		 * @param {boolean} [normalized=false] - Whether the data are normalized or not.
		 */
		constructor( array, itemSize, normalized = false ) {

			if ( Array.isArray( array ) ) {

				throw new TypeError( 'THREE.BufferAttribute: array should be a Typed Array.' );

			}

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isBufferAttribute = true;

			/**
			 * The ID of the buffer attribute.
			 *
			 * @name BufferAttribute#id
			 * @type {number}
			 * @readonly
			 */
			Object.defineProperty( this, 'id', { value: _id$2 ++ } );

			/**
			 * The name of the buffer attribute.
			 *
			 * @type {string}
			 */
			this.name = '';

			/**
			 * The array holding the attribute data. It should have `itemSize * numVertices`
			 * elements, where `numVertices` is the number of vertices in the associated geometry.
			 *
			 * @type {TypedArray}
			 */
			this.array = array;

			/**
			 * The number of values of the array that should be associated with a particular vertex.
			 * For instance, if this attribute is storing a 3-component vector (such as a position,
			 * normal, or color), then the value should be `3`.
			 *
			 * @type {number}
			 */
			this.itemSize = itemSize;

			/**
			 * Represents the number of items this buffer attribute stores. It is internally computed
			 * by dividing the `array` length by the `itemSize`.
			 *
			 * @type {number}
			 * @readonly
			 */
			this.count = array !== undefined ? array.length / itemSize : 0;

			/**
			 * Applies to integer data only. Indicates how the underlying data in the buffer maps to
			 * the values in the GLSL code. For instance, if `array` is an instance of `UInt16Array`,
			 * and `normalized` is `true`, the values `0 -+65535` in the array data will be mapped to
			 * `0.0f - +1.0f` in the GLSL attribute. If `normalized` is `false`, the values will be converted
			 * to floats unmodified, i.e. `65535` becomes `65535.0f`.
			 *
			 * @type {boolean}
			 */
			this.normalized = normalized;

			/**
			 * Defines the intended usage pattern of the data store for optimization purposes.
			 *
			 * Note: After the initial use of a buffer, its usage cannot be changed. Instead,
			 * instantiate a new one and set the desired usage before the next render.
			 *
			 * @type {(StaticDrawUsage|DynamicDrawUsage|StreamDrawUsage|StaticReadUsage|DynamicReadUsage|StreamReadUsage|StaticCopyUsage|DynamicCopyUsage|StreamCopyUsage)}
			 * @default StaticDrawUsage
			 */
			this.usage = StaticDrawUsage;

			/**
			 * This can be used to only update some components of stored vectors (for example, just the
			 * component related to color). Use the `addUpdateRange()` function to add ranges to this array.
			 *
			 * @type {Array<Object>}
			 */
			this.updateRanges = [];

			/**
			 * Configures the bound GPU type for use in shaders.
			 *
			 * Note: this only has an effect for integer arrays and is not configurable for float arrays.
			 * For lower precision float types, use `Float16BufferAttribute`.
			 *
			 * @type {(FloatType|IntType)}
			 * @default FloatType
			 */
			this.gpuType = FloatType;

			/**
			 * A version number, incremented every time the `needsUpdate` is set to `true`.
			 *
			 * @type {number}
			 */
			this.version = 0;

		}

		/**
		 * A callback function that is executed after the renderer has transferred the attribute
		 * array data to the GPU.
		 */
		onUploadCallback() {}

		/**
		 * Flag to indicate that this attribute has changed and should be re-sent to
		 * the GPU. Set this to `true` when you modify the value of the array.
		 *
		 * @type {number}
		 * @default false
		 * @param {boolean} value
		 */
		set needsUpdate( value ) {

			if ( value === true ) this.version ++;

		}

		/**
		 * Sets the usage of this buffer attribute.
		 *
		 * @param {(StaticDrawUsage|DynamicDrawUsage|StreamDrawUsage|StaticReadUsage|DynamicReadUsage|StreamReadUsage|StaticCopyUsage|DynamicCopyUsage|StreamCopyUsage)} value - The usage to set.
		 * @return {BufferAttribute} A reference to this buffer attribute.
		 */
		setUsage( value ) {

			this.usage = value;

			return this;

		}

		/**
		 * Adds a range of data in the data array to be updated on the GPU.
		 *
		 * @param {number} start - Position at which to start update.
		 * @param {number} count - The number of components to update.
		 */
		addUpdateRange( start, count ) {

			this.updateRanges.push( { start, count } );

		}

		/**
		 * Clears the update ranges.
		 */
		clearUpdateRanges() {

			this.updateRanges.length = 0;

		}

		/**
		 * Copies the values of the given buffer attribute to this instance.
		 *
		 * @param {BufferAttribute} source - The buffer attribute to copy.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		copy( source ) {

			this.name = source.name;
			this.array = new source.array.constructor( source.array );
			this.itemSize = source.itemSize;
			this.count = source.count;
			this.normalized = source.normalized;

			this.usage = source.usage;
			this.gpuType = source.gpuType;

			return this;

		}

		/**
		 * Copies a vector from the given buffer attribute to this one. The start
		 * and destination position in the attribute buffers are represented by the
		 * given indices.
		 *
		 * @param {number} index1 - The destination index into this buffer attribute.
		 * @param {BufferAttribute} attribute - The buffer attribute to copy from.
		 * @param {number} index2 - The source index into the given buffer attribute.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		copyAt( index1, attribute, index2 ) {

			index1 *= this.itemSize;
			index2 *= attribute.itemSize;

			for ( let i = 0, l = this.itemSize; i < l; i ++ ) {

				this.array[ index1 + i ] = attribute.array[ index2 + i ];

			}

			return this;

		}

		/**
		 * Copies the given array data into this buffer attribute.
		 *
		 * @param {(TypedArray|Array)} array - The array to copy.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		copyArray( array ) {

			this.array.set( array );

			return this;

		}

		/**
		 * Applies the given 3x3 matrix to the given attribute. Works with
		 * item size `2` and `3`.
		 *
		 * @param {Matrix3} m - The matrix to apply.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		applyMatrix3( m ) {

			if ( this.itemSize === 2 ) {

				for ( let i = 0, l = this.count; i < l; i ++ ) {

					_vector2$1.fromBufferAttribute( this, i );
					_vector2$1.applyMatrix3( m );

					this.setXY( i, _vector2$1.x, _vector2$1.y );

				}

			} else if ( this.itemSize === 3 ) {

				for ( let i = 0, l = this.count; i < l; i ++ ) {

					_vector$9.fromBufferAttribute( this, i );
					_vector$9.applyMatrix3( m );

					this.setXYZ( i, _vector$9.x, _vector$9.y, _vector$9.z );

				}

			}

			return this;

		}

		/**
		 * Applies the given 4x4 matrix to the given attribute. Only works with
		 * item size `3`.
		 *
		 * @param {Matrix4} m - The matrix to apply.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		applyMatrix4( m ) {

			for ( let i = 0, l = this.count; i < l; i ++ ) {

				_vector$9.fromBufferAttribute( this, i );

				_vector$9.applyMatrix4( m );

				this.setXYZ( i, _vector$9.x, _vector$9.y, _vector$9.z );

			}

			return this;

		}

		/**
		 * Applies the given 3x3 normal matrix to the given attribute. Only works with
		 * item size `3`.
		 *
		 * @param {Matrix3} m - The normal matrix to apply.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		applyNormalMatrix( m ) {

			for ( let i = 0, l = this.count; i < l; i ++ ) {

				_vector$9.fromBufferAttribute( this, i );

				_vector$9.applyNormalMatrix( m );

				this.setXYZ( i, _vector$9.x, _vector$9.y, _vector$9.z );

			}

			return this;

		}

		/**
		 * Applies the given 4x4 matrix to the given attribute. Only works with
		 * item size `3` and with direction vectors.
		 *
		 * @param {Matrix4} m - The matrix to apply.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		transformDirection( m ) {

			for ( let i = 0, l = this.count; i < l; i ++ ) {

				_vector$9.fromBufferAttribute( this, i );

				_vector$9.transformDirection( m );

				this.setXYZ( i, _vector$9.x, _vector$9.y, _vector$9.z );

			}

			return this;

		}

		/**
		 * Sets the given array data in the buffer attribute.
		 *
		 * @param {(TypedArray|Array)} value - The array data to set.
		 * @param {number} [offset=0] - The offset in this buffer attribute's array.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		set( value, offset = 0 ) {

			// Matching BufferAttribute constructor, do not normalize the array.
			this.array.set( value, offset );

			return this;

		}

		/**
		 * Returns the given component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} component - The component index.
		 * @return {number} The returned value.
		 */
		getComponent( index, component ) {

			let value = this.array[ index * this.itemSize + component ];

			if ( this.normalized ) value = denormalize( value, this.array );

			return value;

		}

		/**
		 * Sets the given value to the given component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} component - The component index.
		 * @param {number} value - The value to set.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		setComponent( index, component, value ) {

			if ( this.normalized ) value = normalize( value, this.array );

			this.array[ index * this.itemSize + component ] = value;

			return this;

		}

		/**
		 * Returns the x component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @return {number} The x component.
		 */
		getX( index ) {

			let x = this.array[ index * this.itemSize ];

			if ( this.normalized ) x = denormalize( x, this.array );

			return x;

		}

		/**
		 * Sets the x component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} x - The value to set.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		setX( index, x ) {

			if ( this.normalized ) x = normalize( x, this.array );

			this.array[ index * this.itemSize ] = x;

			return this;

		}

		/**
		 * Returns the y component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @return {number} The y component.
		 */
		getY( index ) {

			let y = this.array[ index * this.itemSize + 1 ];

			if ( this.normalized ) y = denormalize( y, this.array );

			return y;

		}

		/**
		 * Sets the y component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} y - The value to set.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		setY( index, y ) {

			if ( this.normalized ) y = normalize( y, this.array );

			this.array[ index * this.itemSize + 1 ] = y;

			return this;

		}

		/**
		 * Returns the z component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @return {number} The z component.
		 */
		getZ( index ) {

			let z = this.array[ index * this.itemSize + 2 ];

			if ( this.normalized ) z = denormalize( z, this.array );

			return z;

		}

		/**
		 * Sets the z component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} z - The value to set.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		setZ( index, z ) {

			if ( this.normalized ) z = normalize( z, this.array );

			this.array[ index * this.itemSize + 2 ] = z;

			return this;

		}

		/**
		 * Returns the w component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @return {number} The w component.
		 */
		getW( index ) {

			let w = this.array[ index * this.itemSize + 3 ];

			if ( this.normalized ) w = denormalize( w, this.array );

			return w;

		}

		/**
		 * Sets the w component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} w - The value to set.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		setW( index, w ) {

			if ( this.normalized ) w = normalize( w, this.array );

			this.array[ index * this.itemSize + 3 ] = w;

			return this;

		}

		/**
		 * Sets the x and y component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} x - The value for the x component to set.
		 * @param {number} y - The value for the y component to set.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		setXY( index, x, y ) {

			index *= this.itemSize;

			if ( this.normalized ) {

				x = normalize( x, this.array );
				y = normalize( y, this.array );

			}

			this.array[ index + 0 ] = x;
			this.array[ index + 1 ] = y;

			return this;

		}

		/**
		 * Sets the x, y and z component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} x - The value for the x component to set.
		 * @param {number} y - The value for the y component to set.
		 * @param {number} z - The value for the z component to set.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		setXYZ( index, x, y, z ) {

			index *= this.itemSize;

			if ( this.normalized ) {

				x = normalize( x, this.array );
				y = normalize( y, this.array );
				z = normalize( z, this.array );

			}

			this.array[ index + 0 ] = x;
			this.array[ index + 1 ] = y;
			this.array[ index + 2 ] = z;

			return this;

		}

		/**
		 * Sets the x, y, z and w component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} x - The value for the x component to set.
		 * @param {number} y - The value for the y component to set.
		 * @param {number} z - The value for the z component to set.
		 * @param {number} w - The value for the w component to set.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		setXYZW( index, x, y, z, w ) {

			index *= this.itemSize;

			if ( this.normalized ) {

				x = normalize( x, this.array );
				y = normalize( y, this.array );
				z = normalize( z, this.array );
				w = normalize( w, this.array );

			}

			this.array[ index + 0 ] = x;
			this.array[ index + 1 ] = y;
			this.array[ index + 2 ] = z;
			this.array[ index + 3 ] = w;

			return this;

		}

		/**
		 * Sets the given callback function that is executed after the Renderer has transferred
		 * the attribute array data to the GPU. Can be used to perform clean-up operations after
		 * the upload when attribute data are not needed anymore on the CPU side.
		 *
		 * @param {Function} callback - The `onUpload()` callback.
		 * @return {BufferAttribute} A reference to this instance.
		 */
		onUpload( callback ) {

			this.onUploadCallback = callback;

			return this;

		}

		/**
		 * Returns a new buffer attribute with copied values from this instance.
		 *
		 * @return {BufferAttribute} A clone of this instance.
		 */
		clone() {

			return new this.constructor( this.array, this.itemSize ).copy( this );

		}

		/**
		 * Serializes the buffer attribute into JSON.
		 *
		 * @return {Object} A JSON object representing the serialized buffer attribute.
		 */
		toJSON() {

			const data = {
				itemSize: this.itemSize,
				type: this.array.constructor.name,
				array: Array.from( this.array ),
				normalized: this.normalized
			};

			if ( this.name !== '' ) data.name = this.name;
			if ( this.usage !== StaticDrawUsage ) data.usage = this.usage;

			return data;

		}

	}

	/**
	 * Convenient class that can be used when creating a `UInt16` buffer attribute with
	 * a plain `Array` instance.
	 *
	 * @augments BufferAttribute
	 */
	class Uint16BufferAttribute extends BufferAttribute {

		/**
		 * Constructs a new buffer attribute.
		 *
		 * @param {(Array<number>|Uint16Array)} array - The array holding the attribute data.
		 * @param {number} itemSize - The item size.
		 * @param {boolean} [normalized=false] - Whether the data are normalized or not.
		 */
		constructor( array, itemSize, normalized ) {

			super( new Uint16Array( array ), itemSize, normalized );

		}

	}

	/**
	 * Convenient class that can be used when creating a `UInt32` buffer attribute with
	 * a plain `Array` instance.
	 *
	 * @augments BufferAttribute
	 */
	class Uint32BufferAttribute extends BufferAttribute {

		/**
		 * Constructs a new buffer attribute.
		 *
		 * @param {(Array<number>|Uint32Array)} array - The array holding the attribute data.
		 * @param {number} itemSize - The item size.
		 * @param {boolean} [normalized=false] - Whether the data are normalized or not.
		 */
		constructor( array, itemSize, normalized ) {

			super( new Uint32Array( array ), itemSize, normalized );

		}

	}

	/**
	 * Convenient class that can be used when creating a `Float32` buffer attribute with
	 * a plain `Array` instance.
	 *
	 * @augments BufferAttribute
	 */
	class Float32BufferAttribute extends BufferAttribute {

		/**
		 * Constructs a new buffer attribute.
		 *
		 * @param {(Array<number>|Float32Array)} array - The array holding the attribute data.
		 * @param {number} itemSize - The item size.
		 * @param {boolean} [normalized=false] - Whether the data are normalized or not.
		 */
		constructor( array, itemSize, normalized ) {

			super( new Float32Array( array ), itemSize, normalized );

		}

	}

	let _id$1 = 0;

	const _m1 = /*@__PURE__*/ new Matrix4();
	const _obj = /*@__PURE__*/ new Object3D();
	const _offset = /*@__PURE__*/ new Vector3();
	const _box$2 = /*@__PURE__*/ new Box3();
	const _boxMorphTargets = /*@__PURE__*/ new Box3();
	const _vector$8 = /*@__PURE__*/ new Vector3();

	/**
	 * A representation of mesh, line, or point geometry. Includes vertex
	 * positions, face indices, normals, colors, UVs, and custom attributes
	 * within buffers, reducing the cost of passing all this data to the GPU.
	 *
	 * ```js
	 * const geometry = new THREE.BufferGeometry();
	 * // create a simple square shape. We duplicate the top left and bottom right
	 * // vertices because each vertex needs to appear once per triangle.
	 * const vertices = new Float32Array( [
	 * 	-1.0, -1.0,  1.0, // v0
	 * 	 1.0, -1.0,  1.0, // v1
	 * 	 1.0,  1.0,  1.0, // v2
	 *
	 * 	 1.0,  1.0,  1.0, // v3
	 * 	-1.0,  1.0,  1.0, // v4
	 * 	-1.0, -1.0,  1.0  // v5
	 * ] );
	 * // itemSize = 3 because there are 3 values (components) per vertex
	 * geometry.setAttribute( 'position', new THREE.BufferAttribute( vertices, 3 ) );
	 * const material = new THREE.MeshBasicMaterial( { color: 0xff0000 } );
	 * const mesh = new THREE.Mesh( geometry, material );
	 * ```
	 *
	 * @augments EventDispatcher
	 */
	class BufferGeometry extends EventDispatcher {

		/**
		 * Constructs a new geometry.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isBufferGeometry = true;

			/**
			 * The ID of the geometry.
			 *
			 * @name BufferGeometry#id
			 * @type {number}
			 * @readonly
			 */
			Object.defineProperty( this, 'id', { value: _id$1 ++ } );

			/**
			 * The UUID of the geometry.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.uuid = generateUUID();

			/**
			 * The name of the geometry.
			 *
			 * @type {string}
			 */
			this.name = '';
			this.type = 'BufferGeometry';

			/**
			 * Allows for vertices to be re-used across multiple triangles; this is
			 * called using "indexed triangles". Each triangle is associated with the
			 * indices of three vertices. This attribute therefore stores the index of
			 * each vertex for each triangular face. If this attribute is not set, the
			 * renderer assumes that each three contiguous positions represent a single triangle.
			 *
			 * @type {?BufferAttribute}
			 * @default null
			 */
			this.index = null;

			/**
			 * A (storage) buffer attribute which was generated with a compute shader and
			 * now defines indirect draw calls.
			 *
			 * Can only be used with {@link WebGPURenderer} and a WebGPU backend.
			 *
			 * @type {?BufferAttribute}
			 * @default null
			 */
			this.indirect = null;

			/**
			 * This dictionary has as id the name of the attribute to be set and as value
			 * the buffer attribute to set it to. Rather than accessing this property directly,
			 * use `setAttribute()` and `getAttribute()` to access attributes of this geometry.
			 *
			 * @type {Object<string,(BufferAttribute|InterleavedBufferAttribute)>}
			 */
			this.attributes = {};

			/**
			 * This dictionary holds the morph targets of the geometry.
			 *
			 * Note: Once the geometry has been rendered, the morph attribute data cannot
			 * be changed. You will have to call `dispose()?, and create a new geometry instance.
			 *
			 * @type {Object}
			 */
			this.morphAttributes = {};

			/**
			 * Used to control the morph target behavior; when set to `true`, the morph
			 * target data is treated as relative offsets, rather than as absolute
			 * positions/normals.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.morphTargetsRelative = false;

			/**
			 * Split the geometry into groups, each of which will be rendered in a
			 * separate draw call. This allows an array of materials to be used with the geometry.
			 *
			 * Use `addGroup()` and `clearGroups()` to edit groups, rather than modifying this array directly.
			 *
			 * Every vertex and index must belong to exactly one group — groups must not share vertices or
			 * indices, and must not leave vertices or indices unused.
			 *
			 * @type {Array<Object>}
			 */
			this.groups = [];

			/**
			 * Bounding box for the geometry which can be calculated with `computeBoundingBox()`.
			 *
			 * @type {Box3}
			 * @default null
			 */
			this.boundingBox = null;

			/**
			 * Bounding sphere for the geometry which can be calculated with `computeBoundingSphere()`.
			 *
			 * @type {Sphere}
			 * @default null
			 */
			this.boundingSphere = null;

			/**
			 * Determines the part of the geometry to render. This should not be set directly,
			 * instead use `setDrawRange()`.
			 *
			 * @type {{start:number,count:number}}
			 */
			this.drawRange = { start: 0, count: Infinity };

			/**
			 * An object that can be used to store custom data about the geometry.
			 * It should not hold references to functions as these will not be cloned.
			 *
			 * @type {Object}
			 */
			this.userData = {};

		}

		/**
		 * Returns the index of this geometry.
		 *
		 * @return {?BufferAttribute} The index. Returns `null` if no index is defined.
		 */
		getIndex() {

			return this.index;

		}

		/**
		 * Sets the given index to this geometry.
		 *
		 * @param {Array<number>|BufferAttribute} index - The index to set.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		setIndex( index ) {

			if ( Array.isArray( index ) ) {

				this.index = new ( arrayNeedsUint32( index ) ? Uint32BufferAttribute : Uint16BufferAttribute )( index, 1 );

			} else {

				this.index = index;

			}

			return this;

		}

		/**
		 * Sets the given indirect attribute to this geometry.
		 *
		 * @param {BufferAttribute} indirect - The attribute holding indirect draw calls.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		setIndirect( indirect ) {

			this.indirect = indirect;

			return this;

		}

		/**
		 * Returns the indirect attribute of this geometry.
		 *
		 * @return {?BufferAttribute} The indirect attribute. Returns `null` if no indirect attribute is defined.
		 */
		getIndirect() {

			return this.indirect;

		}

		/**
		 * Returns the buffer attribute for the given name.
		 *
		 * @param {string} name - The attribute name.
		 * @return {BufferAttribute|InterleavedBufferAttribute|undefined} The buffer attribute.
		 * Returns `undefined` if not attribute has been found.
		 */
		getAttribute( name ) {

			return this.attributes[ name ];

		}

		/**
		 * Sets the given attribute for the given name.
		 *
		 * @param {string} name - The attribute name.
		 * @param {BufferAttribute|InterleavedBufferAttribute} attribute - The attribute to set.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		setAttribute( name, attribute ) {

			this.attributes[ name ] = attribute;

			return this;

		}

		/**
		 * Deletes the attribute for the given name.
		 *
		 * @param {string} name - The attribute name to delete.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		deleteAttribute( name ) {

			delete this.attributes[ name ];

			return this;

		}

		/**
		 * Returns `true` if this geometry has an attribute for the given name.
		 *
		 * @param {string} name - The attribute name.
		 * @return {boolean} Whether this geometry has an attribute for the given name or not.
		 */
		hasAttribute( name ) {

			return this.attributes[ name ] !== undefined;

		}

		/**
		 * Adds a group to this geometry.
		 *
		 * @param {number} start - The first element in this draw call. That is the first
		 * vertex for non-indexed geometry, otherwise the first triangle index.
		 * @param {number} count - Specifies how many vertices (or indices) are part of this group.
		 * @param {number} [materialIndex=0] - The material array index to use.
		 */
		addGroup( start, count, materialIndex = 0 ) {

			this.groups.push( {

				start: start,
				count: count,
				materialIndex: materialIndex

			} );

		}

		/**
		 * Clears all groups.
		 */
		clearGroups() {

			this.groups = [];

		}

		/**
		 * Sets the draw range for this geometry.
		 *
		 * @param {number} start - The first vertex for non-indexed geometry, otherwise the first triangle index.
		 * @param {number} count - For non-indexed BufferGeometry, `count` is the number of vertices to render.
		 * For indexed BufferGeometry, `count` is the number of indices to render.
		 */
		setDrawRange( start, count ) {

			this.drawRange.start = start;
			this.drawRange.count = count;

		}

		/**
		 * Applies the given 4x4 transformation matrix to the geometry.
		 *
		 * @param {Matrix4} matrix - The matrix to apply.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		applyMatrix4( matrix ) {

			const position = this.attributes.position;

			if ( position !== undefined ) {

				position.applyMatrix4( matrix );

				position.needsUpdate = true;

			}

			const normal = this.attributes.normal;

			if ( normal !== undefined ) {

				const normalMatrix = new Matrix3().getNormalMatrix( matrix );

				normal.applyNormalMatrix( normalMatrix );

				normal.needsUpdate = true;

			}

			const tangent = this.attributes.tangent;

			if ( tangent !== undefined ) {

				tangent.transformDirection( matrix );

				tangent.needsUpdate = true;

			}

			if ( this.boundingBox !== null ) {

				this.computeBoundingBox();

			}

			if ( this.boundingSphere !== null ) {

				this.computeBoundingSphere();

			}

			return this;

		}

		/**
		 * Applies the rotation represented by the Quaternion to the geometry.
		 *
		 * @param {Quaternion} q - The Quaternion to apply.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		applyQuaternion( q ) {

			_m1.makeRotationFromQuaternion( q );

			this.applyMatrix4( _m1 );

			return this;

		}

		/**
		 * Rotates the geometry about the X axis. This is typically done as a one time
		 * operation, and not during a loop. Use {@link Object3D#rotation} for typical
		 * real-time mesh rotation.
		 *
		 * @param {number} angle - The angle in radians.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		rotateX( angle ) {

			// rotate geometry around world x-axis

			_m1.makeRotationX( angle );

			this.applyMatrix4( _m1 );

			return this;

		}

		/**
		 * Rotates the geometry about the Y axis. This is typically done as a one time
		 * operation, and not during a loop. Use {@link Object3D#rotation} for typical
		 * real-time mesh rotation.
		 *
		 * @param {number} angle - The angle in radians.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		rotateY( angle ) {

			// rotate geometry around world y-axis

			_m1.makeRotationY( angle );

			this.applyMatrix4( _m1 );

			return this;

		}

		/**
		 * Rotates the geometry about the Z axis. This is typically done as a one time
		 * operation, and not during a loop. Use {@link Object3D#rotation} for typical
		 * real-time mesh rotation.
		 *
		 * @param {number} angle - The angle in radians.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		rotateZ( angle ) {

			// rotate geometry around world z-axis

			_m1.makeRotationZ( angle );

			this.applyMatrix4( _m1 );

			return this;

		}

		/**
		 * Translates the geometry. This is typically done as a one time
		 * operation, and not during a loop. Use {@link Object3D#position} for typical
		 * real-time mesh rotation.
		 *
		 * @param {number} x - The x offset.
		 * @param {number} y - The y offset.
		 * @param {number} z - The z offset.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		translate( x, y, z ) {

			// translate geometry

			_m1.makeTranslation( x, y, z );

			this.applyMatrix4( _m1 );

			return this;

		}

		/**
		 * Scales the geometry. This is typically done as a one time
		 * operation, and not during a loop. Use {@link Object3D#scale} for typical
		 * real-time mesh rotation.
		 *
		 * @param {number} x - The x scale.
		 * @param {number} y - The y scale.
		 * @param {number} z - The z scale.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		scale( x, y, z ) {

			// scale geometry

			_m1.makeScale( x, y, z );

			this.applyMatrix4( _m1 );

			return this;

		}

		/**
		 * Rotates the geometry to face a point in 3D space. This is typically done as a one time
		 * operation, and not during a loop. Use {@link Object3D#lookAt} for typical
		 * real-time mesh rotation.
		 *
		 * @param {Vector3} vector - The target point.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		lookAt( vector ) {

			_obj.lookAt( vector );

			_obj.updateMatrix();

			this.applyMatrix4( _obj.matrix );

			return this;

		}

		/**
		 * Center the geometry based on its bounding box.
		 *
		 * @return {BufferGeometry} A reference to this instance.
		 */
		center() {

			this.computeBoundingBox();

			this.boundingBox.getCenter( _offset ).negate();

			this.translate( _offset.x, _offset.y, _offset.z );

			return this;

		}

		/**
		 * Defines a geometry by creating a `position` attribute based on the given array of points. The array
		 * can hold 2D or 3D vectors. When using two-dimensional data, the `z` coordinate for all vertices is
		 * set to `0`.
		 *
		 * If the method is used with an existing `position` attribute, the vertex data are overwritten with the
		 * data from the array. The length of the array must match the vertex count.
		 *
		 * @param {Array<Vector2>|Array<Vector3>} points - The points.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		setFromPoints( points ) {

			const positionAttribute = this.getAttribute( 'position' );

			if ( positionAttribute === undefined ) {

				const position = [];

				for ( let i = 0, l = points.length; i < l; i ++ ) {

					const point = points[ i ];
					position.push( point.x, point.y, point.z || 0 );

				}

				this.setAttribute( 'position', new Float32BufferAttribute( position, 3 ) );

			} else {

				const l = Math.min( points.length, positionAttribute.count ); // make sure data do not exceed buffer size

				for ( let i = 0; i < l; i ++ ) {

					const point = points[ i ];
					positionAttribute.setXYZ( i, point.x, point.y, point.z || 0 );

				}

				if ( points.length > positionAttribute.count ) {

					console.warn( 'THREE.BufferGeometry: Buffer size too small for points data. Use .dispose() and create a new geometry.' );

				}

				positionAttribute.needsUpdate = true;

			}

			return this;

		}

		/**
		 * Computes the bounding box of the geometry, and updates the `boundingBox` member.
		 * The bounding box is not computed by the engine; it must be computed by your app.
		 * You may need to recompute the bounding box if the geometry vertices are modified.
		 */
		computeBoundingBox() {

			if ( this.boundingBox === null ) {

				this.boundingBox = new Box3();

			}

			const position = this.attributes.position;
			const morphAttributesPosition = this.morphAttributes.position;

			if ( position && position.isGLBufferAttribute ) {

				console.error( 'THREE.BufferGeometry.computeBoundingBox(): GLBufferAttribute requires a manual bounding box.', this );

				this.boundingBox.set(
					new Vector3( - Infinity, - Infinity, - Infinity ),
					new Vector3( + Infinity, + Infinity, + Infinity )
				);

				return;

			}

			if ( position !== undefined ) {

				this.boundingBox.setFromBufferAttribute( position );

				// process morph attributes if present

				if ( morphAttributesPosition ) {

					for ( let i = 0, il = morphAttributesPosition.length; i < il; i ++ ) {

						const morphAttribute = morphAttributesPosition[ i ];
						_box$2.setFromBufferAttribute( morphAttribute );

						if ( this.morphTargetsRelative ) {

							_vector$8.addVectors( this.boundingBox.min, _box$2.min );
							this.boundingBox.expandByPoint( _vector$8 );

							_vector$8.addVectors( this.boundingBox.max, _box$2.max );
							this.boundingBox.expandByPoint( _vector$8 );

						} else {

							this.boundingBox.expandByPoint( _box$2.min );
							this.boundingBox.expandByPoint( _box$2.max );

						}

					}

				}

			} else {

				this.boundingBox.makeEmpty();

			}

			if ( isNaN( this.boundingBox.min.x ) || isNaN( this.boundingBox.min.y ) || isNaN( this.boundingBox.min.z ) ) {

				console.error( 'THREE.BufferGeometry.computeBoundingBox(): Computed min/max have NaN values. The "position" attribute is likely to have NaN values.', this );

			}

		}

		/**
		 * Computes the bounding sphere of the geometry, and updates the `boundingSphere` member.
		 * The engine automatically computes the bounding sphere when it is needed, e.g., for ray casting or view frustum culling.
		 * You may need to recompute the bounding sphere if the geometry vertices are modified.
		 */
		computeBoundingSphere() {

			if ( this.boundingSphere === null ) {

				this.boundingSphere = new Sphere();

			}

			const position = this.attributes.position;
			const morphAttributesPosition = this.morphAttributes.position;

			if ( position && position.isGLBufferAttribute ) {

				console.error( 'THREE.BufferGeometry.computeBoundingSphere(): GLBufferAttribute requires a manual bounding sphere.', this );

				this.boundingSphere.set( new Vector3(), Infinity );

				return;

			}

			if ( position ) {

				// first, find the center of the bounding sphere

				const center = this.boundingSphere.center;

				_box$2.setFromBufferAttribute( position );

				// process morph attributes if present

				if ( morphAttributesPosition ) {

					for ( let i = 0, il = morphAttributesPosition.length; i < il; i ++ ) {

						const morphAttribute = morphAttributesPosition[ i ];
						_boxMorphTargets.setFromBufferAttribute( morphAttribute );

						if ( this.morphTargetsRelative ) {

							_vector$8.addVectors( _box$2.min, _boxMorphTargets.min );
							_box$2.expandByPoint( _vector$8 );

							_vector$8.addVectors( _box$2.max, _boxMorphTargets.max );
							_box$2.expandByPoint( _vector$8 );

						} else {

							_box$2.expandByPoint( _boxMorphTargets.min );
							_box$2.expandByPoint( _boxMorphTargets.max );

						}

					}

				}

				_box$2.getCenter( center );

				// second, try to find a boundingSphere with a radius smaller than the
				// boundingSphere of the boundingBox: sqrt(3) smaller in the best case

				let maxRadiusSq = 0;

				for ( let i = 0, il = position.count; i < il; i ++ ) {

					_vector$8.fromBufferAttribute( position, i );

					maxRadiusSq = Math.max( maxRadiusSq, center.distanceToSquared( _vector$8 ) );

				}

				// process morph attributes if present

				if ( morphAttributesPosition ) {

					for ( let i = 0, il = morphAttributesPosition.length; i < il; i ++ ) {

						const morphAttribute = morphAttributesPosition[ i ];
						const morphTargetsRelative = this.morphTargetsRelative;

						for ( let j = 0, jl = morphAttribute.count; j < jl; j ++ ) {

							_vector$8.fromBufferAttribute( morphAttribute, j );

							if ( morphTargetsRelative ) {

								_offset.fromBufferAttribute( position, j );
								_vector$8.add( _offset );

							}

							maxRadiusSq = Math.max( maxRadiusSq, center.distanceToSquared( _vector$8 ) );

						}

					}

				}

				this.boundingSphere.radius = Math.sqrt( maxRadiusSq );

				if ( isNaN( this.boundingSphere.radius ) ) {

					console.error( 'THREE.BufferGeometry.computeBoundingSphere(): Computed radius is NaN. The "position" attribute is likely to have NaN values.', this );

				}

			}

		}

		/**
		 * Calculates and adds a tangent attribute to this geometry.
		 *
		 * The computation is only supported for indexed geometries and if position, normal, and uv attributes
		 * are defined. When using a tangent space normal map, prefer the MikkTSpace algorithm provided by
		 * {@link BufferGeometryUtils#computeMikkTSpaceTangents} instead.
		 */
		computeTangents() {

			const index = this.index;
			const attributes = this.attributes;

			// based on http://www.terathon.com/code/tangent.html
			// (per vertex tangents)

			if ( index === null ||
				 attributes.position === undefined ||
				 attributes.normal === undefined ||
				 attributes.uv === undefined ) {

				console.error( 'THREE.BufferGeometry: .computeTangents() failed. Missing required attributes (index, position, normal or uv)' );
				return;

			}

			const positionAttribute = attributes.position;
			const normalAttribute = attributes.normal;
			const uvAttribute = attributes.uv;

			if ( this.hasAttribute( 'tangent' ) === false ) {

				this.setAttribute( 'tangent', new BufferAttribute( new Float32Array( 4 * positionAttribute.count ), 4 ) );

			}

			const tangentAttribute = this.getAttribute( 'tangent' );

			const tan1 = [], tan2 = [];

			for ( let i = 0; i < positionAttribute.count; i ++ ) {

				tan1[ i ] = new Vector3();
				tan2[ i ] = new Vector3();

			}

			const vA = new Vector3(),
				vB = new Vector3(),
				vC = new Vector3(),

				uvA = new Vector2(),
				uvB = new Vector2(),
				uvC = new Vector2(),

				sdir = new Vector3(),
				tdir = new Vector3();

			function handleTriangle( a, b, c ) {

				vA.fromBufferAttribute( positionAttribute, a );
				vB.fromBufferAttribute( positionAttribute, b );
				vC.fromBufferAttribute( positionAttribute, c );

				uvA.fromBufferAttribute( uvAttribute, a );
				uvB.fromBufferAttribute( uvAttribute, b );
				uvC.fromBufferAttribute( uvAttribute, c );

				vB.sub( vA );
				vC.sub( vA );

				uvB.sub( uvA );
				uvC.sub( uvA );

				const r = 1.0 / ( uvB.x * uvC.y - uvC.x * uvB.y );

				// silently ignore degenerate uv triangles having coincident or colinear vertices

				if ( ! isFinite( r ) ) return;

				sdir.copy( vB ).multiplyScalar( uvC.y ).addScaledVector( vC, - uvB.y ).multiplyScalar( r );
				tdir.copy( vC ).multiplyScalar( uvB.x ).addScaledVector( vB, - uvC.x ).multiplyScalar( r );

				tan1[ a ].add( sdir );
				tan1[ b ].add( sdir );
				tan1[ c ].add( sdir );

				tan2[ a ].add( tdir );
				tan2[ b ].add( tdir );
				tan2[ c ].add( tdir );

			}

			let groups = this.groups;

			if ( groups.length === 0 ) {

				groups = [ {
					start: 0,
					count: index.count
				} ];

			}

			for ( let i = 0, il = groups.length; i < il; ++ i ) {

				const group = groups[ i ];

				const start = group.start;
				const count = group.count;

				for ( let j = start, jl = start + count; j < jl; j += 3 ) {

					handleTriangle(
						index.getX( j + 0 ),
						index.getX( j + 1 ),
						index.getX( j + 2 )
					);

				}

			}

			const tmp = new Vector3(), tmp2 = new Vector3();
			const n = new Vector3(), n2 = new Vector3();

			function handleVertex( v ) {

				n.fromBufferAttribute( normalAttribute, v );
				n2.copy( n );

				const t = tan1[ v ];

				// Gram-Schmidt orthogonalize

				tmp.copy( t );
				tmp.sub( n.multiplyScalar( n.dot( t ) ) ).normalize();

				// Calculate handedness

				tmp2.crossVectors( n2, t );
				const test = tmp2.dot( tan2[ v ] );
				const w = ( test < 0.0 ) ? -1 : 1.0;

				tangentAttribute.setXYZW( v, tmp.x, tmp.y, tmp.z, w );

			}

			for ( let i = 0, il = groups.length; i < il; ++ i ) {

				const group = groups[ i ];

				const start = group.start;
				const count = group.count;

				for ( let j = start, jl = start + count; j < jl; j += 3 ) {

					handleVertex( index.getX( j + 0 ) );
					handleVertex( index.getX( j + 1 ) );
					handleVertex( index.getX( j + 2 ) );

				}

			}

		}

		/**
		 * Computes vertex normals for the given vertex data. For indexed geometries, the method sets
		 * each vertex normal to be the average of the face normals of the faces that share that vertex.
		 * For non-indexed geometries, vertices are not shared, and the method sets each vertex normal
		 * to be the same as the face normal.
		 */
		computeVertexNormals() {

			const index = this.index;
			const positionAttribute = this.getAttribute( 'position' );

			if ( positionAttribute !== undefined ) {

				let normalAttribute = this.getAttribute( 'normal' );

				if ( normalAttribute === undefined ) {

					normalAttribute = new BufferAttribute( new Float32Array( positionAttribute.count * 3 ), 3 );
					this.setAttribute( 'normal', normalAttribute );

				} else {

					// reset existing normals to zero

					for ( let i = 0, il = normalAttribute.count; i < il; i ++ ) {

						normalAttribute.setXYZ( i, 0, 0, 0 );

					}

				}

				const pA = new Vector3(), pB = new Vector3(), pC = new Vector3();
				const nA = new Vector3(), nB = new Vector3(), nC = new Vector3();
				const cb = new Vector3(), ab = new Vector3();

				// indexed elements

				if ( index ) {

					for ( let i = 0, il = index.count; i < il; i += 3 ) {

						const vA = index.getX( i + 0 );
						const vB = index.getX( i + 1 );
						const vC = index.getX( i + 2 );

						pA.fromBufferAttribute( positionAttribute, vA );
						pB.fromBufferAttribute( positionAttribute, vB );
						pC.fromBufferAttribute( positionAttribute, vC );

						cb.subVectors( pC, pB );
						ab.subVectors( pA, pB );
						cb.cross( ab );

						nA.fromBufferAttribute( normalAttribute, vA );
						nB.fromBufferAttribute( normalAttribute, vB );
						nC.fromBufferAttribute( normalAttribute, vC );

						nA.add( cb );
						nB.add( cb );
						nC.add( cb );

						normalAttribute.setXYZ( vA, nA.x, nA.y, nA.z );
						normalAttribute.setXYZ( vB, nB.x, nB.y, nB.z );
						normalAttribute.setXYZ( vC, nC.x, nC.y, nC.z );

					}

				} else {

					// non-indexed elements (unconnected triangle soup)

					for ( let i = 0, il = positionAttribute.count; i < il; i += 3 ) {

						pA.fromBufferAttribute( positionAttribute, i + 0 );
						pB.fromBufferAttribute( positionAttribute, i + 1 );
						pC.fromBufferAttribute( positionAttribute, i + 2 );

						cb.subVectors( pC, pB );
						ab.subVectors( pA, pB );
						cb.cross( ab );

						normalAttribute.setXYZ( i + 0, cb.x, cb.y, cb.z );
						normalAttribute.setXYZ( i + 1, cb.x, cb.y, cb.z );
						normalAttribute.setXYZ( i + 2, cb.x, cb.y, cb.z );

					}

				}

				this.normalizeNormals();

				normalAttribute.needsUpdate = true;

			}

		}

		/**
		 * Ensures every normal vector in a geometry will have a magnitude of `1`. This will
		 * correct lighting on the geometry surfaces.
		 */
		normalizeNormals() {

			const normals = this.attributes.normal;

			for ( let i = 0, il = normals.count; i < il; i ++ ) {

				_vector$8.fromBufferAttribute( normals, i );

				_vector$8.normalize();

				normals.setXYZ( i, _vector$8.x, _vector$8.y, _vector$8.z );

			}

		}

		/**
		 * Return a new non-index version of this indexed geometry. If the geometry
		 * is already non-indexed, the method is a NOOP.
		 *
		 * @return {BufferGeometry} The non-indexed version of this indexed geometry.
		 */
		toNonIndexed() {

			function convertBufferAttribute( attribute, indices ) {

				const array = attribute.array;
				const itemSize = attribute.itemSize;
				const normalized = attribute.normalized;

				const array2 = new array.constructor( indices.length * itemSize );

				let index = 0, index2 = 0;

				for ( let i = 0, l = indices.length; i < l; i ++ ) {

					if ( attribute.isInterleavedBufferAttribute ) {

						index = indices[ i ] * attribute.data.stride + attribute.offset;

					} else {

						index = indices[ i ] * itemSize;

					}

					for ( let j = 0; j < itemSize; j ++ ) {

						array2[ index2 ++ ] = array[ index ++ ];

					}

				}

				return new BufferAttribute( array2, itemSize, normalized );

			}

			//

			if ( this.index === null ) {

				console.warn( 'THREE.BufferGeometry.toNonIndexed(): BufferGeometry is already non-indexed.' );
				return this;

			}

			const geometry2 = new BufferGeometry();

			const indices = this.index.array;
			const attributes = this.attributes;

			// attributes

			for ( const name in attributes ) {

				const attribute = attributes[ name ];

				const newAttribute = convertBufferAttribute( attribute, indices );

				geometry2.setAttribute( name, newAttribute );

			}

			// morph attributes

			const morphAttributes = this.morphAttributes;

			for ( const name in morphAttributes ) {

				const morphArray = [];
				const morphAttribute = morphAttributes[ name ]; // morphAttribute: array of Float32BufferAttributes

				for ( let i = 0, il = morphAttribute.length; i < il; i ++ ) {

					const attribute = morphAttribute[ i ];

					const newAttribute = convertBufferAttribute( attribute, indices );

					morphArray.push( newAttribute );

				}

				geometry2.morphAttributes[ name ] = morphArray;

			}

			geometry2.morphTargetsRelative = this.morphTargetsRelative;

			// groups

			const groups = this.groups;

			for ( let i = 0, l = groups.length; i < l; i ++ ) {

				const group = groups[ i ];
				geometry2.addGroup( group.start, group.count, group.materialIndex );

			}

			return geometry2;

		}

		/**
		 * Serializes the geometry into JSON.
		 *
		 * @return {Object} A JSON object representing the serialized geometry.
		 */
		toJSON() {

			const data = {
				metadata: {
					version: 4.7,
					type: 'BufferGeometry',
					generator: 'BufferGeometry.toJSON'
				}
			};

			// standard BufferGeometry serialization

			data.uuid = this.uuid;
			data.type = this.type;
			if ( this.name !== '' ) data.name = this.name;
			if ( Object.keys( this.userData ).length > 0 ) data.userData = this.userData;

			if ( this.parameters !== undefined ) {

				const parameters = this.parameters;

				for ( const key in parameters ) {

					if ( parameters[ key ] !== undefined ) data[ key ] = parameters[ key ];

				}

				return data;

			}

			// for simplicity the code assumes attributes are not shared across geometries, see #15811

			data.data = { attributes: {} };

			const index = this.index;

			if ( index !== null ) {

				data.data.index = {
					type: index.array.constructor.name,
					array: Array.prototype.slice.call( index.array )
				};

			}

			const attributes = this.attributes;

			for ( const key in attributes ) {

				const attribute = attributes[ key ];

				data.data.attributes[ key ] = attribute.toJSON( data.data );

			}

			const morphAttributes = {};
			let hasMorphAttributes = false;

			for ( const key in this.morphAttributes ) {

				const attributeArray = this.morphAttributes[ key ];

				const array = [];

				for ( let i = 0, il = attributeArray.length; i < il; i ++ ) {

					const attribute = attributeArray[ i ];

					array.push( attribute.toJSON( data.data ) );

				}

				if ( array.length > 0 ) {

					morphAttributes[ key ] = array;

					hasMorphAttributes = true;

				}

			}

			if ( hasMorphAttributes ) {

				data.data.morphAttributes = morphAttributes;
				data.data.morphTargetsRelative = this.morphTargetsRelative;

			}

			const groups = this.groups;

			if ( groups.length > 0 ) {

				data.data.groups = JSON.parse( JSON.stringify( groups ) );

			}

			const boundingSphere = this.boundingSphere;

			if ( boundingSphere !== null ) {

				data.data.boundingSphere = boundingSphere.toJSON();

			}

			return data;

		}

		/**
		 * Returns a new geometry with copied values from this instance.
		 *
		 * @return {BufferGeometry} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Copies the values of the given geometry to this instance.
		 *
		 * @param {BufferGeometry} source - The geometry to copy.
		 * @return {BufferGeometry} A reference to this instance.
		 */
		copy( source ) {

			// reset

			this.index = null;
			this.attributes = {};
			this.morphAttributes = {};
			this.groups = [];
			this.boundingBox = null;
			this.boundingSphere = null;

			// used for storing cloned, shared data

			const data = {};

			// name

			this.name = source.name;

			// index

			const index = source.index;

			if ( index !== null ) {

				this.setIndex( index.clone() );

			}

			// attributes

			const attributes = source.attributes;

			for ( const name in attributes ) {

				const attribute = attributes[ name ];
				this.setAttribute( name, attribute.clone( data ) );

			}

			// morph attributes

			const morphAttributes = source.morphAttributes;

			for ( const name in morphAttributes ) {

				const array = [];
				const morphAttribute = morphAttributes[ name ]; // morphAttribute: array of Float32BufferAttributes

				for ( let i = 0, l = morphAttribute.length; i < l; i ++ ) {

					array.push( morphAttribute[ i ].clone( data ) );

				}

				this.morphAttributes[ name ] = array;

			}

			this.morphTargetsRelative = source.morphTargetsRelative;

			// groups

			const groups = source.groups;

			for ( let i = 0, l = groups.length; i < l; i ++ ) {

				const group = groups[ i ];
				this.addGroup( group.start, group.count, group.materialIndex );

			}

			// bounding box

			const boundingBox = source.boundingBox;

			if ( boundingBox !== null ) {

				this.boundingBox = boundingBox.clone();

			}

			// bounding sphere

			const boundingSphere = source.boundingSphere;

			if ( boundingSphere !== null ) {

				this.boundingSphere = boundingSphere.clone();

			}

			// draw range

			this.drawRange.start = source.drawRange.start;
			this.drawRange.count = source.drawRange.count;

			// user data

			this.userData = source.userData;

			return this;

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 *
		 * @fires BufferGeometry#dispose
		 */
		dispose() {

			this.dispatchEvent( { type: 'dispose' } );

		}

	}

	const _inverseMatrix$3 = /*@__PURE__*/ new Matrix4();
	const _ray$3 = /*@__PURE__*/ new Ray();
	const _sphere$6 = /*@__PURE__*/ new Sphere();
	const _sphereHitAt = /*@__PURE__*/ new Vector3();

	const _vA$1 = /*@__PURE__*/ new Vector3();
	const _vB$1 = /*@__PURE__*/ new Vector3();
	const _vC$1 = /*@__PURE__*/ new Vector3();

	const _tempA = /*@__PURE__*/ new Vector3();
	const _morphA = /*@__PURE__*/ new Vector3();

	const _intersectionPoint = /*@__PURE__*/ new Vector3();
	const _intersectionPointWorld = /*@__PURE__*/ new Vector3();

	/**
	 * Class representing triangular polygon mesh based objects.
	 *
	 * ```js
	 * const geometry = new THREE.BoxGeometry( 1, 1, 1 );
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffff00 } );
	 * const mesh = new THREE.Mesh( geometry, material );
	 * scene.add( mesh );
	 * ```
	 *
	 * @augments Object3D
	 */
	class Mesh extends Object3D {

		/**
		 * Constructs a new mesh.
		 *
		 * @param {BufferGeometry} [geometry] - The mesh geometry.
		 * @param {Material|Array<Material>} [material] - The mesh material.
		 */
		constructor( geometry = new BufferGeometry(), material = new MeshBasicMaterial() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isMesh = true;

			this.type = 'Mesh';

			/**
			 * The mesh geometry.
			 *
			 * @type {BufferGeometry}
			 */
			this.geometry = geometry;

			/**
			 * The mesh material.
			 *
			 * @type {Material|Array<Material>}
			 * @default MeshBasicMaterial
			 */
			this.material = material;

			/**
			 * A dictionary representing the morph targets in the geometry. The key is the
			 * morph targets name, the value its attribute index. This member is `undefined`
			 * by default and only set when morph targets are detected in the geometry.
			 *
			 * @type {Object<String,number>|undefined}
			 * @default undefined
			 */
			this.morphTargetDictionary = undefined;

			/**
			 * An array of weights typically in the range `[0,1]` that specify how much of the morph
			 * is applied. This member is `undefined` by default and only set when morph targets are
			 * detected in the geometry.
			 *
			 * @type {Array<number>|undefined}
			 * @default undefined
			 */
			this.morphTargetInfluences = undefined;

			/**
			 * The number of instances of this mesh.
			 * Can only be used with {@link WebGPURenderer}.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.count = 1;

			this.updateMorphTargets();

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			if ( source.morphTargetInfluences !== undefined ) {

				this.morphTargetInfluences = source.morphTargetInfluences.slice();

			}

			if ( source.morphTargetDictionary !== undefined ) {

				this.morphTargetDictionary = Object.assign( {}, source.morphTargetDictionary );

			}

			this.material = Array.isArray( source.material ) ? source.material.slice() : source.material;
			this.geometry = source.geometry;

			return this;

		}

		/**
		 * Sets the values of {@link Mesh#morphTargetDictionary} and {@link Mesh#morphTargetInfluences}
		 * to make sure existing morph targets can influence this 3D object.
		 */
		updateMorphTargets() {

			const geometry = this.geometry;

			const morphAttributes = geometry.morphAttributes;
			const keys = Object.keys( morphAttributes );

			if ( keys.length > 0 ) {

				const morphAttribute = morphAttributes[ keys[ 0 ] ];

				if ( morphAttribute !== undefined ) {

					this.morphTargetInfluences = [];
					this.morphTargetDictionary = {};

					for ( let m = 0, ml = morphAttribute.length; m < ml; m ++ ) {

						const name = morphAttribute[ m ].name || String( m );

						this.morphTargetInfluences.push( 0 );
						this.morphTargetDictionary[ name ] = m;

					}

				}

			}

		}

		/**
		 * Returns the local-space position of the vertex at the given index, taking into
		 * account the current animation state of both morph targets and skinning.
		 *
		 * @param {number} index - The vertex index.
		 * @param {Vector3} target - The target object that is used to store the method's result.
		 * @return {Vector3} The vertex position in local space.
		 */
		getVertexPosition( index, target ) {

			const geometry = this.geometry;
			const position = geometry.attributes.position;
			const morphPosition = geometry.morphAttributes.position;
			const morphTargetsRelative = geometry.morphTargetsRelative;

			target.fromBufferAttribute( position, index );

			const morphInfluences = this.morphTargetInfluences;

			if ( morphPosition && morphInfluences ) {

				_morphA.set( 0, 0, 0 );

				for ( let i = 0, il = morphPosition.length; i < il; i ++ ) {

					const influence = morphInfluences[ i ];
					const morphAttribute = morphPosition[ i ];

					if ( influence === 0 ) continue;

					_tempA.fromBufferAttribute( morphAttribute, index );

					if ( morphTargetsRelative ) {

						_morphA.addScaledVector( _tempA, influence );

					} else {

						_morphA.addScaledVector( _tempA.sub( target ), influence );

					}

				}

				target.add( _morphA );

			}

			return target;

		}

		/**
		 * Computes intersection points between a casted ray and this line.
		 *
		 * @param {Raycaster} raycaster - The raycaster.
		 * @param {Array<Object>} intersects - The target array that holds the intersection points.
		 */
		raycast( raycaster, intersects ) {

			const geometry = this.geometry;
			const material = this.material;
			const matrixWorld = this.matrixWorld;

			if ( material === undefined ) return;

			// test with bounding sphere in world space

			if ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();

			_sphere$6.copy( geometry.boundingSphere );
			_sphere$6.applyMatrix4( matrixWorld );

			// check distance from ray origin to bounding sphere

			_ray$3.copy( raycaster.ray ).recast( raycaster.near );

			if ( _sphere$6.containsPoint( _ray$3.origin ) === false ) {

				if ( _ray$3.intersectSphere( _sphere$6, _sphereHitAt ) === null ) return;

				if ( _ray$3.origin.distanceToSquared( _sphereHitAt ) > ( raycaster.far - raycaster.near ) ** 2 ) return;

			}

			// convert ray to local space of mesh

			_inverseMatrix$3.copy( matrixWorld ).invert();
			_ray$3.copy( raycaster.ray ).applyMatrix4( _inverseMatrix$3 );

			// test with bounding box in local space

			if ( geometry.boundingBox !== null ) {

				if ( _ray$3.intersectsBox( geometry.boundingBox ) === false ) return;

			}

			// test for intersections with geometry

			this._computeIntersections( raycaster, intersects, _ray$3 );

		}

		_computeIntersections( raycaster, intersects, rayLocalSpace ) {

			let intersection;

			const geometry = this.geometry;
			const material = this.material;

			const index = geometry.index;
			const position = geometry.attributes.position;
			const uv = geometry.attributes.uv;
			const uv1 = geometry.attributes.uv1;
			const normal = geometry.attributes.normal;
			const groups = geometry.groups;
			const drawRange = geometry.drawRange;

			if ( index !== null ) {

				// indexed buffer geometry

				if ( Array.isArray( material ) ) {

					for ( let i = 0, il = groups.length; i < il; i ++ ) {

						const group = groups[ i ];
						const groupMaterial = material[ group.materialIndex ];

						const start = Math.max( group.start, drawRange.start );
						const end = Math.min( index.count, Math.min( ( group.start + group.count ), ( drawRange.start + drawRange.count ) ) );

						for ( let j = start, jl = end; j < jl; j += 3 ) {

							const a = index.getX( j );
							const b = index.getX( j + 1 );
							const c = index.getX( j + 2 );

							intersection = checkGeometryIntersection( this, groupMaterial, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c );

							if ( intersection ) {

								intersection.faceIndex = Math.floor( j / 3 ); // triangle number in indexed buffer semantics
								intersection.face.materialIndex = group.materialIndex;
								intersects.push( intersection );

							}

						}

					}

				} else {

					const start = Math.max( 0, drawRange.start );
					const end = Math.min( index.count, ( drawRange.start + drawRange.count ) );

					for ( let i = start, il = end; i < il; i += 3 ) {

						const a = index.getX( i );
						const b = index.getX( i + 1 );
						const c = index.getX( i + 2 );

						intersection = checkGeometryIntersection( this, material, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c );

						if ( intersection ) {

							intersection.faceIndex = Math.floor( i / 3 ); // triangle number in indexed buffer semantics
							intersects.push( intersection );

						}

					}

				}

			} else if ( position !== undefined ) {

				// non-indexed buffer geometry

				if ( Array.isArray( material ) ) {

					for ( let i = 0, il = groups.length; i < il; i ++ ) {

						const group = groups[ i ];
						const groupMaterial = material[ group.materialIndex ];

						const start = Math.max( group.start, drawRange.start );
						const end = Math.min( position.count, Math.min( ( group.start + group.count ), ( drawRange.start + drawRange.count ) ) );

						for ( let j = start, jl = end; j < jl; j += 3 ) {

							const a = j;
							const b = j + 1;
							const c = j + 2;

							intersection = checkGeometryIntersection( this, groupMaterial, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c );

							if ( intersection ) {

								intersection.faceIndex = Math.floor( j / 3 ); // triangle number in non-indexed buffer semantics
								intersection.face.materialIndex = group.materialIndex;
								intersects.push( intersection );

							}

						}

					}

				} else {

					const start = Math.max( 0, drawRange.start );
					const end = Math.min( position.count, ( drawRange.start + drawRange.count ) );

					for ( let i = start, il = end; i < il; i += 3 ) {

						const a = i;
						const b = i + 1;
						const c = i + 2;

						intersection = checkGeometryIntersection( this, material, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c );

						if ( intersection ) {

							intersection.faceIndex = Math.floor( i / 3 ); // triangle number in non-indexed buffer semantics
							intersects.push( intersection );

						}

					}

				}

			}

		}

	}

	function checkIntersection$1( object, material, raycaster, ray, pA, pB, pC, point ) {

		let intersect;

		if ( material.side === BackSide ) {

			intersect = ray.intersectTriangle( pC, pB, pA, true, point );

		} else {

			intersect = ray.intersectTriangle( pA, pB, pC, ( material.side === FrontSide ), point );

		}

		if ( intersect === null ) return null;

		_intersectionPointWorld.copy( point );
		_intersectionPointWorld.applyMatrix4( object.matrixWorld );

		const distance = raycaster.ray.origin.distanceTo( _intersectionPointWorld );

		if ( distance < raycaster.near || distance > raycaster.far ) return null;

		return {
			distance: distance,
			point: _intersectionPointWorld.clone(),
			object: object
		};

	}

	function checkGeometryIntersection( object, material, raycaster, ray, uv, uv1, normal, a, b, c ) {

		object.getVertexPosition( a, _vA$1 );
		object.getVertexPosition( b, _vB$1 );
		object.getVertexPosition( c, _vC$1 );

		const intersection = checkIntersection$1( object, material, raycaster, ray, _vA$1, _vB$1, _vC$1, _intersectionPoint );

		if ( intersection ) {

			const barycoord = new Vector3();
			Triangle.getBarycoord( _intersectionPoint, _vA$1, _vB$1, _vC$1, barycoord );

			if ( uv ) {

				intersection.uv = Triangle.getInterpolatedAttribute( uv, a, b, c, barycoord, new Vector2() );

			}

			if ( uv1 ) {

				intersection.uv1 = Triangle.getInterpolatedAttribute( uv1, a, b, c, barycoord, new Vector2() );

			}

			if ( normal ) {

				intersection.normal = Triangle.getInterpolatedAttribute( normal, a, b, c, barycoord, new Vector3() );

				if ( intersection.normal.dot( ray.direction ) > 0 ) {

					intersection.normal.multiplyScalar( -1 );

				}

			}

			const face = {
				a: a,
				b: b,
				c: c,
				normal: new Vector3(),
				materialIndex: 0
			};

			Triangle.getNormal( _vA$1, _vB$1, _vC$1, face.normal );

			intersection.face = face;
			intersection.barycoord = barycoord;

		}

		return intersection;

	}

	/**
	 * A geometry class for a rectangular cuboid with a given width, height, and depth.
	 * On creation, the cuboid is centred on the origin, with each edge parallel to one
	 * of the axes.
	 *
	 * ```js
	 * const geometry = new THREE.BoxGeometry( 1, 1, 1 );
	 * const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );
	 * const cube = new THREE.Mesh( geometry, material );
	 * scene.add( cube );
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class BoxGeometry extends BufferGeometry {

		/**
		 * Constructs a new box geometry.
		 *
		 * @param {number} [width=1] - The width. That is, the length of the edges parallel to the X axis.
		 * @param {number} [height=1] - The height. That is, the length of the edges parallel to the Y axis.
		 * @param {number} [depth=1] - The depth. That is, the length of the edges parallel to the Z axis.
		 * @param {number} [widthSegments=1] - Number of segmented rectangular faces along the width of the sides.
		 * @param {number} [heightSegments=1] - Number of segmented rectangular faces along the height of the sides.
		 * @param {number} [depthSegments=1] - Number of segmented rectangular faces along the depth of the sides.
		 */
		constructor( width = 1, height = 1, depth = 1, widthSegments = 1, heightSegments = 1, depthSegments = 1 ) {

			super();

			this.type = 'BoxGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				width: width,
				height: height,
				depth: depth,
				widthSegments: widthSegments,
				heightSegments: heightSegments,
				depthSegments: depthSegments
			};

			const scope = this;

			// segments

			widthSegments = Math.floor( widthSegments );
			heightSegments = Math.floor( heightSegments );
			depthSegments = Math.floor( depthSegments );

			// buffers

			const indices = [];
			const vertices = [];
			const normals = [];
			const uvs = [];

			// helper variables

			let numberOfVertices = 0;
			let groupStart = 0;

			// build each side of the box geometry

			buildPlane( 'z', 'y', 'x', -1, -1, depth, height, width, depthSegments, heightSegments, 0 ); // px
			buildPlane( 'z', 'y', 'x', 1, -1, depth, height, - width, depthSegments, heightSegments, 1 ); // nx
			buildPlane( 'x', 'z', 'y', 1, 1, width, depth, height, widthSegments, depthSegments, 2 ); // py
			buildPlane( 'x', 'z', 'y', 1, -1, width, depth, - height, widthSegments, depthSegments, 3 ); // ny
			buildPlane( 'x', 'y', 'z', 1, -1, width, height, depth, widthSegments, heightSegments, 4 ); // pz
			buildPlane( 'x', 'y', 'z', -1, -1, width, height, - depth, widthSegments, heightSegments, 5 ); // nz

			// build geometry

			this.setIndex( indices );
			this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );

			function buildPlane( u, v, w, udir, vdir, width, height, depth, gridX, gridY, materialIndex ) {

				const segmentWidth = width / gridX;
				const segmentHeight = height / gridY;

				const widthHalf = width / 2;
				const heightHalf = height / 2;
				const depthHalf = depth / 2;

				const gridX1 = gridX + 1;
				const gridY1 = gridY + 1;

				let vertexCounter = 0;
				let groupCount = 0;

				const vector = new Vector3();

				// generate vertices, normals and uvs

				for ( let iy = 0; iy < gridY1; iy ++ ) {

					const y = iy * segmentHeight - heightHalf;

					for ( let ix = 0; ix < gridX1; ix ++ ) {

						const x = ix * segmentWidth - widthHalf;

						// set values to correct vector component

						vector[ u ] = x * udir;
						vector[ v ] = y * vdir;
						vector[ w ] = depthHalf;

						// now apply vector to vertex buffer

						vertices.push( vector.x, vector.y, vector.z );

						// set values to correct vector component

						vector[ u ] = 0;
						vector[ v ] = 0;
						vector[ w ] = depth > 0 ? 1 : -1;

						// now apply vector to normal buffer

						normals.push( vector.x, vector.y, vector.z );

						// uvs

						uvs.push( ix / gridX );
						uvs.push( 1 - ( iy / gridY ) );

						// counters

						vertexCounter += 1;

					}

				}

				// indices

				// 1. you need three indices to draw a single face
				// 2. a single segment consists of two faces
				// 3. so we need to generate six (2*3) indices per segment

				for ( let iy = 0; iy < gridY; iy ++ ) {

					for ( let ix = 0; ix < gridX; ix ++ ) {

						const a = numberOfVertices + ix + gridX1 * iy;
						const b = numberOfVertices + ix + gridX1 * ( iy + 1 );
						const c = numberOfVertices + ( ix + 1 ) + gridX1 * ( iy + 1 );
						const d = numberOfVertices + ( ix + 1 ) + gridX1 * iy;

						// faces

						indices.push( a, b, d );
						indices.push( b, c, d );

						// increase counter

						groupCount += 6;

					}

				}

				// add a group to the geometry. this will ensure multi material support

				scope.addGroup( groupStart, groupCount, materialIndex );

				// calculate new start value for groups

				groupStart += groupCount;

				// update total number of vertices

				numberOfVertices += vertexCounter;

			}

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {BoxGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new BoxGeometry( data.width, data.height, data.depth, data.widthSegments, data.heightSegments, data.depthSegments );

		}

	}

	// Uniform Utilities

	function cloneUniforms( src ) {

		const dst = {};

		for ( const u in src ) {

			dst[ u ] = {};

			for ( const p in src[ u ] ) {

				const property = src[ u ][ p ];

				if ( property && ( property.isColor ||
					property.isMatrix3 || property.isMatrix4 ||
					property.isVector2 || property.isVector3 || property.isVector4 ||
					property.isTexture || property.isQuaternion ) ) {

					if ( property.isRenderTargetTexture ) {

						console.warn( 'UniformsUtils: Textures of render targets cannot be cloned via cloneUniforms() or mergeUniforms().' );
						dst[ u ][ p ] = null;

					} else {

						dst[ u ][ p ] = property.clone();

					}

				} else if ( Array.isArray( property ) ) {

					dst[ u ][ p ] = property.slice();

				} else {

					dst[ u ][ p ] = property;

				}

			}

		}

		return dst;

	}

	function mergeUniforms( uniforms ) {

		const merged = {};

		for ( let u = 0; u < uniforms.length; u ++ ) {

			const tmp = cloneUniforms( uniforms[ u ] );

			for ( const p in tmp ) {

				merged[ p ] = tmp[ p ];

			}

		}

		return merged;

	}

	function cloneUniformsGroups( src ) {

		const dst = [];

		for ( let u = 0; u < src.length; u ++ ) {

			dst.push( src[ u ].clone() );

		}

		return dst;

	}

	function getUnlitUniformColorSpace( renderer ) {

		const currentRenderTarget = renderer.getRenderTarget();

		if ( currentRenderTarget === null ) {

			// https://github.com/mrdoob/three.js/pull/23937#issuecomment-1111067398
			return renderer.outputColorSpace;

		}

		// https://github.com/mrdoob/three.js/issues/27868
		if ( currentRenderTarget.isXRRenderTarget === true ) {

			return currentRenderTarget.texture.colorSpace;

		}

		return ColorManagement.workingColorSpace;

	}

	// Legacy

	const UniformsUtils = { clone: cloneUniforms, merge: mergeUniforms };

	var default_vertex = "void main() {\n\tgl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n}";

	var default_fragment = "void main() {\n\tgl_FragColor = vec4( 1.0, 0.0, 0.0, 1.0 );\n}";

	/**
	 * A material rendered with custom shaders. A shader is a small program written in GLSL.
	 * that runs on the GPU. You may want to use a custom shader if you need to implement an
	 * effect not included with any of the built-in materials.
	 *
	 * There are the following notes to bear in mind when using a `ShaderMaterial`:
	 *
	 * - `ShaderMaterial` can only be used with {@link WebGLRenderer}.
	 * - Built in attributes and uniforms are passed to the shaders along with your code. If
	 * you don't want that, use {@link RawShaderMaterial} instead.
	 * - You can use the directive `#pragma unroll_loop_start` and `#pragma unroll_loop_end`
	 * in order to unroll a `for` loop in GLSL by the shader preprocessor. The directive has
	 * to be placed right above the loop. The loop formatting has to correspond to a defined standard.
	 *   - The loop has to be [normalized]{@link https://en.wikipedia.org/wiki/Normalized_loop}.
	 *   - The loop variable has to be *i*.
	 *   - The value `UNROLLED_LOOP_INDEX` will be replaced with the explicitly
	 * value of *i* for the given iteration and can be used in preprocessor
	 * statements.
	 *
	 * ```js
	 * const material = new THREE.ShaderMaterial( {
	 * 	uniforms: {
	 * 		time: { value: 1.0 },
	 * 		resolution: { value: new THREE.Vector2() }
	 * 	},
	 * 	vertexShader: document.getElementById( 'vertexShader' ).textContent,
	 * 	fragmentShader: document.getElementById( 'fragmentShader' ).textContent
	 * } );
	 * ```
	 *
	 * @augments Material
	 */
	class ShaderMaterial extends Material {

		/**
		 * Constructs a new shader material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isShaderMaterial = true;

			this.type = 'ShaderMaterial';

			/**
			 * Defines custom constants using `#define` directives within the GLSL code
			 * for both the vertex shader and the fragment shader; each key/value pair
			 * yields another directive.
			 * ```js
			 * defines: {
			 * 	FOO: 15,
			 * 	BAR: true
			 * }
			 * ```
			 * Yields the lines:
			 * ```
			 * #define FOO 15
			 * #define BAR true
			 * ```
			 *
			 * @type {Object}
			 */
			this.defines = {};

			/**
			 * An object of the form:
			 * ```js
			 * {
			 * 	"uniform1": { value: 1.0 },
			 * 	"uniform2": { value: 2 }
			 * }
			 * ```
			 * specifying the uniforms to be passed to the shader code; keys are uniform
			 * names, values are definitions of the form
			 * ```
			 * {
			 * 	value: 1.0
			 * }
			 * ```
			 * where `value` is the value of the uniform. Names must match the name of
			 * the uniform, as defined in the GLSL code. Note that uniforms are refreshed
			 * on every frame, so updating the value of the uniform will immediately
			 * update the value available to the GLSL code.
			 *
			 * @type {Object}
			 */
			this.uniforms = {};

			/**
			 * An array holding uniforms groups for configuring UBOs.
			 *
			 * @type {Array<UniformsGroup>}
			 */
			this.uniformsGroups = [];

			/**
			 * Vertex shader GLSL code. This is the actual code for the shader.
			 *
			 * @type {string}
			 */
			this.vertexShader = default_vertex;

			/**
			 * Fragment shader GLSL code. This is the actual code for the shader.
			 *
			 * @type {string}
			 */
			this.fragmentShader = default_fragment;

			/**
			 * Controls line thickness or lines.
			 *
			 * WebGL and WebGPU ignore this setting and always render line primitives with a
			 * width of one pixel.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.linewidth = 1;

			/**
			 * Renders the geometry as a wireframe.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.wireframe = false;

			/**
			 * Controls the thickness of the wireframe.
			 *
			 * WebGL and WebGPU ignore this property and always render
			 * 1 pixel wide lines.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.wireframeLinewidth = 1;

			/**
			 * Define whether the material color is affected by global fog settings; `true`
			 * to pass fog uniforms to the shader.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.fog = false;

			/**
			 * Defines whether this material uses lighting; `true` to pass uniform data
			 * related to lighting to this shader.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.lights = false;

			/**
			 * Defines whether this material supports clipping; `true` to let the renderer
			 * pass the clippingPlanes uniform.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.clipping = false;

			/**
			 * Overwritten and set to `true` by default.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.forceSinglePass = true;

			/**
			 * This object allows to enable certain WebGL 2 extensions.
			 *
			 * - clipCullDistance: set to `true` to use vertex shader clipping
			 * - multiDraw: set to `true` to use vertex shader multi_draw / enable gl_DrawID
			 *
			 * @type {{clipCullDistance:false,multiDraw:false}}
			 */
			this.extensions = {
				clipCullDistance: false, // set to use vertex shader clipping
				multiDraw: false // set to use vertex shader multi_draw / enable gl_DrawID
			};

			/**
			 * When the rendered geometry doesn't include these attributes but the
			 * material does, these default values will be passed to the shaders. This
			 * avoids errors when buffer data is missing.
			 *
			 * - color: [ 1, 1, 1 ]
			 * - uv: [ 0, 0 ]
			 * - uv1: [ 0, 0 ]
			 *
			 * @type {Object}
			 */
			this.defaultAttributeValues = {
				'color': [ 1, 1, 1 ],
				'uv': [ 0, 0 ],
				'uv1': [ 0, 0 ]
			};

			/**
			 * If set, this calls [gl.bindAttribLocation]{@link https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindAttribLocation}
			 * to bind a generic vertex index to an attribute variable.
			 *
			 * @type {string|undefined}
			 * @default undefined
			 */
			this.index0AttributeName = undefined;

			/**
			 * Can be used to force a uniform update while changing uniforms in
			 * {@link Object3D#onBeforeRender}.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.uniformsNeedUpdate = false;

			/**
			 * Defines the GLSL version of custom shader code.
			 *
			 * @type {?(GLSL1|GLSL3)}
			 * @default null
			 */
			this.glslVersion = null;

			if ( parameters !== undefined ) {

				this.setValues( parameters );

			}

		}

		copy( source ) {

			super.copy( source );

			this.fragmentShader = source.fragmentShader;
			this.vertexShader = source.vertexShader;

			this.uniforms = cloneUniforms( source.uniforms );
			this.uniformsGroups = cloneUniformsGroups( source.uniformsGroups );

			this.defines = Object.assign( {}, source.defines );

			this.wireframe = source.wireframe;
			this.wireframeLinewidth = source.wireframeLinewidth;

			this.fog = source.fog;
			this.lights = source.lights;
			this.clipping = source.clipping;

			this.extensions = Object.assign( {}, source.extensions );

			this.glslVersion = source.glslVersion;

			return this;

		}

		toJSON( meta ) {

			const data = super.toJSON( meta );

			data.glslVersion = this.glslVersion;
			data.uniforms = {};

			for ( const name in this.uniforms ) {

				const uniform = this.uniforms[ name ];
				const value = uniform.value;

				if ( value && value.isTexture ) {

					data.uniforms[ name ] = {
						type: 't',
						value: value.toJSON( meta ).uuid
					};

				} else if ( value && value.isColor ) {

					data.uniforms[ name ] = {
						type: 'c',
						value: value.getHex()
					};

				} else if ( value && value.isVector2 ) {

					data.uniforms[ name ] = {
						type: 'v2',
						value: value.toArray()
					};

				} else if ( value && value.isVector3 ) {

					data.uniforms[ name ] = {
						type: 'v3',
						value: value.toArray()
					};

				} else if ( value && value.isVector4 ) {

					data.uniforms[ name ] = {
						type: 'v4',
						value: value.toArray()
					};

				} else if ( value && value.isMatrix3 ) {

					data.uniforms[ name ] = {
						type: 'm3',
						value: value.toArray()
					};

				} else if ( value && value.isMatrix4 ) {

					data.uniforms[ name ] = {
						type: 'm4',
						value: value.toArray()
					};

				} else {

					data.uniforms[ name ] = {
						value: value
					};

					// note: the array variants v2v, v3v, v4v, m4v and tv are not supported so far

				}

			}

			if ( Object.keys( this.defines ).length > 0 ) data.defines = this.defines;

			data.vertexShader = this.vertexShader;
			data.fragmentShader = this.fragmentShader;

			data.lights = this.lights;
			data.clipping = this.clipping;

			const extensions = {};

			for ( const key in this.extensions ) {

				if ( this.extensions[ key ] === true ) extensions[ key ] = true;

			}

			if ( Object.keys( extensions ).length > 0 ) data.extensions = extensions;

			return data;

		}

	}

	/**
	 * Abstract base class for cameras. This class should always be inherited
	 * when you build a new camera.
	 *
	 * @abstract
	 * @augments Object3D
	 */
	class Camera extends Object3D {

		/**
		 * Constructs a new camera.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isCamera = true;

			this.type = 'Camera';

			/**
			 * The inverse of the camera's world matrix.
			 *
			 * @type {Matrix4}
			 */
			this.matrixWorldInverse = new Matrix4();

			/**
			 * The camera's projection matrix.
			 *
			 * @type {Matrix4}
			 */
			this.projectionMatrix = new Matrix4();

			/**
			 * The inverse of the camera's projection matrix.
			 *
			 * @type {Matrix4}
			 */
			this.projectionMatrixInverse = new Matrix4();

			/**
			 * The coordinate system in which the camera is used.
			 *
			 * @type {(WebGLCoordinateSystem|WebGPUCoordinateSystem)}
			 */
			this.coordinateSystem = WebGLCoordinateSystem;

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.matrixWorldInverse.copy( source.matrixWorldInverse );

			this.projectionMatrix.copy( source.projectionMatrix );
			this.projectionMatrixInverse.copy( source.projectionMatrixInverse );

			this.coordinateSystem = source.coordinateSystem;

			return this;

		}

		/**
		 * Returns a vector representing the ("look") direction of the 3D object in world space.
		 *
		 * This method is overwritten since cameras have a different forward vector compared to other
		 * 3D objects. A camera looks down its local, negative z-axis by default.
		 *
		 * @param {Vector3} target - The target vector the result is stored to.
		 * @return {Vector3} The 3D object's direction in world space.
		 */
		getWorldDirection( target ) {

			return super.getWorldDirection( target ).negate();

		}

		updateMatrixWorld( force ) {

			super.updateMatrixWorld( force );

			this.matrixWorldInverse.copy( this.matrixWorld ).invert();

		}

		updateWorldMatrix( updateParents, updateChildren ) {

			super.updateWorldMatrix( updateParents, updateChildren );

			this.matrixWorldInverse.copy( this.matrixWorld ).invert();

		}

		clone() {

			return new this.constructor().copy( this );

		}

	}

	const _v3$1 = /*@__PURE__*/ new Vector3();
	const _minTarget = /*@__PURE__*/ new Vector2();
	const _maxTarget = /*@__PURE__*/ new Vector2();

	/**
	 * Camera that uses [perspective projection]{@link https://en.wikipedia.org/wiki/Perspective_(graphical)}.
	 *
	 * This projection mode is designed to mimic the way the human eye sees. It
	 * is the most common projection mode used for rendering a 3D scene.
	 *
	 * ```js
	 * const camera = new THREE.PerspectiveCamera( 45, width / height, 1, 1000 );
	 * scene.add( camera );
	 * ```
	 *
	 * @augments Camera
	 */
	class PerspectiveCamera extends Camera {

		/**
		 * Constructs a new perspective camera.
		 *
		 * @param {number} [fov=50] - The vertical field of view.
		 * @param {number} [aspect=1] - The aspect ratio.
		 * @param {number} [near=0.1] - The camera's near plane.
		 * @param {number} [far=2000] - The camera's far plane.
		 */
		constructor( fov = 50, aspect = 1, near = 0.1, far = 2000 ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isPerspectiveCamera = true;

			this.type = 'PerspectiveCamera';

			/**
			 * The vertical field of view, from bottom to top of view,
			 * in degrees.
			 *
			 * @type {number}
			 * @default 50
			 */
			this.fov = fov;

			/**
			 * The zoom factor of the camera.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.zoom = 1;

			/**
			 * The camera's near plane. The valid range is greater than `0`
			 * and less than the current value of {@link PerspectiveCamera#far}.
			 *
			 * Note that, unlike for the {@link OrthographicCamera}, `0` is <em>not</em> a
			 * valid value for a perspective camera's near plane.
			 *
			 * @type {number}
			 * @default 0.1
			 */
			this.near = near;

			/**
			 * The camera's far plane. Must be greater than the
			 * current value of {@link PerspectiveCamera#near}.
			 *
			 * @type {number}
			 * @default 2000
			 */
			this.far = far;

			/**
			 * Object distance used for stereoscopy and depth-of-field effects. This
			 * parameter does not influence the projection matrix unless a
			 * {@link StereoCamera} is being used.
			 *
			 * @type {number}
			 * @default 10
			 */
			this.focus = 10;

			/**
			 * The aspect ratio, usually the canvas width / canvas height.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.aspect = aspect;

			/**
			 * Represents the frustum window specification. This property should not be edited
			 * directly but via {@link PerspectiveCamera#setViewOffset} and {@link PerspectiveCamera#clearViewOffset}.
			 *
			 * @type {?Object}
			 * @default null
			 */
			this.view = null;

			/**
			 * Film size used for the larger axis. Default is `35` (millimeters). This
			 * parameter does not influence the projection matrix unless {@link PerspectiveCamera#filmOffset}
			 * is set to a nonzero value.
			 *
			 * @type {number}
			 * @default 35
			 */
			this.filmGauge = 35;

			/**
			 * Horizontal off-center offset in the same unit as {@link PerspectiveCamera#filmGauge}.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.filmOffset = 0;

			this.updateProjectionMatrix();

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.fov = source.fov;
			this.zoom = source.zoom;

			this.near = source.near;
			this.far = source.far;
			this.focus = source.focus;

			this.aspect = source.aspect;
			this.view = source.view === null ? null : Object.assign( {}, source.view );

			this.filmGauge = source.filmGauge;
			this.filmOffset = source.filmOffset;

			return this;

		}

		/**
		 * Sets the FOV by focal length in respect to the current {@link PerspectiveCamera#filmGauge}.
		 *
		 * The default film gauge is 35, so that the focal length can be specified for
		 * a 35mm (full frame) camera.
		 *
		 * @param {number} focalLength - Values for focal length and film gauge must have the same unit.
		 */
		setFocalLength( focalLength ) {

			/** see {@link http://www.bobatkins.com/photography/technical/field_of_view.html} */
			const vExtentSlope = 0.5 * this.getFilmHeight() / focalLength;

			this.fov = RAD2DEG * 2 * Math.atan( vExtentSlope );
			this.updateProjectionMatrix();

		}

		/**
		 * Returns the focal length from the current {@link PerspectiveCamera#fov} and
		 * {@link PerspectiveCamera#filmGauge}.
		 *
		 * @return {number} The computed focal length.
		 */
		getFocalLength() {

			const vExtentSlope = Math.tan( DEG2RAD * 0.5 * this.fov );

			return 0.5 * this.getFilmHeight() / vExtentSlope;

		}

		/**
		 * Returns the current vertical field of view angle in degrees considering {@link PerspectiveCamera#zoom}.
		 *
		 * @return {number} The effective FOV.
		 */
		getEffectiveFOV() {

			return RAD2DEG * 2 * Math.atan(
				Math.tan( DEG2RAD * 0.5 * this.fov ) / this.zoom );

		}

		/**
		 * Returns the width of the image on the film. If {@link PerspectiveCamera#aspect} is greater than or
		 * equal to one (landscape format), the result equals {@link PerspectiveCamera#filmGauge}.
		 *
		 * @return {number} The film width.
		 */
		getFilmWidth() {

			// film not completely covered in portrait format (aspect < 1)
			return this.filmGauge * Math.min( this.aspect, 1 );

		}

		/**
		 * Returns the height of the image on the film. If {@link PerspectiveCamera#aspect} is greater than or
		 * equal to one (landscape format), the result equals {@link PerspectiveCamera#filmGauge}.
		 *
		 * @return {number} The film width.
		 */
		getFilmHeight() {

			// film not completely covered in landscape format (aspect > 1)
			return this.filmGauge / Math.max( this.aspect, 1 );

		}

		/**
		 * Computes the 2D bounds of the camera's viewable rectangle at a given distance along the viewing direction.
		 * Sets `minTarget` and `maxTarget` to the coordinates of the lower-left and upper-right corners of the view rectangle.
		 *
		 * @param {number} distance - The viewing distance.
		 * @param {Vector2} minTarget - The lower-left corner of the view rectangle is written into this vector.
		 * @param {Vector2} maxTarget - The upper-right corner of the view rectangle is written into this vector.
		 */
		getViewBounds( distance, minTarget, maxTarget ) {

			_v3$1.set( -1, -1, 0.5 ).applyMatrix4( this.projectionMatrixInverse );

			minTarget.set( _v3$1.x, _v3$1.y ).multiplyScalar( - distance / _v3$1.z );

			_v3$1.set( 1, 1, 0.5 ).applyMatrix4( this.projectionMatrixInverse );

			maxTarget.set( _v3$1.x, _v3$1.y ).multiplyScalar( - distance / _v3$1.z );

		}

		/**
		 * Computes the width and height of the camera's viewable rectangle at a given distance along the viewing direction.
		 *
		 * @param {number} distance - The viewing distance.
		 * @param {Vector2} target - The target vector that is used to store result where x is width and y is height.
		 * @returns {Vector2} The view size.
		 */
		getViewSize( distance, target ) {

			this.getViewBounds( distance, _minTarget, _maxTarget );

			return target.subVectors( _maxTarget, _minTarget );

		}

		/**
		 * Sets an offset in a larger frustum. This is useful for multi-window or
		 * multi-monitor/multi-machine setups.
		 *
		 * For example, if you have 3x2 monitors and each monitor is 1920x1080 and
		 * the monitors are in grid like this
		 *```
		 *   +---+---+---+
		 *   | A | B | C |
		 *   +---+---+---+
		 *   | D | E | F |
		 *   +---+---+---+
		 *```
		 * then for each monitor you would call it like this:
		 *```js
		 * const w = 1920;
		 * const h = 1080;
		 * const fullWidth = w * 3;
		 * const fullHeight = h * 2;
		 *
		 * // --A--
		 * camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 0, w, h );
		 * // --B--
		 * camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 0, w, h );
		 * // --C--
		 * camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 0, w, h );
		 * // --D--
		 * camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 1, w, h );
		 * // --E--
		 * camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 1, w, h );
		 * // --F--
		 * camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 1, w, h );
		 * ```
		 *
		 * Note there is no reason monitors have to be the same size or in a grid.
		 *
		 * @param {number} fullWidth - The full width of multiview setup.
		 * @param {number} fullHeight - The full height of multiview setup.
		 * @param {number} x - The horizontal offset of the subcamera.
		 * @param {number} y - The vertical offset of the subcamera.
		 * @param {number} width - The width of subcamera.
		 * @param {number} height - The height of subcamera.
		 */
		setViewOffset( fullWidth, fullHeight, x, y, width, height ) {

			this.aspect = fullWidth / fullHeight;

			if ( this.view === null ) {

				this.view = {
					enabled: true,
					fullWidth: 1,
					fullHeight: 1,
					offsetX: 0,
					offsetY: 0,
					width: 1,
					height: 1
				};

			}

			this.view.enabled = true;
			this.view.fullWidth = fullWidth;
			this.view.fullHeight = fullHeight;
			this.view.offsetX = x;
			this.view.offsetY = y;
			this.view.width = width;
			this.view.height = height;

			this.updateProjectionMatrix();

		}

		/**
		 * Removes the view offset from the projection matrix.
		 */
		clearViewOffset() {

			if ( this.view !== null ) {

				this.view.enabled = false;

			}

			this.updateProjectionMatrix();

		}

		/**
		 * Updates the camera's projection matrix. Must be called after any change of
		 * camera properties.
		 */
		updateProjectionMatrix() {

			const near = this.near;
			let top = near * Math.tan( DEG2RAD * 0.5 * this.fov ) / this.zoom;
			let height = 2 * top;
			let width = this.aspect * height;
			let left = -0.5 * width;
			const view = this.view;

			if ( this.view !== null && this.view.enabled ) {

				const fullWidth = view.fullWidth,
					fullHeight = view.fullHeight;

				left += view.offsetX * width / fullWidth;
				top -= view.offsetY * height / fullHeight;
				width *= view.width / fullWidth;
				height *= view.height / fullHeight;

			}

			const skew = this.filmOffset;
			if ( skew !== 0 ) left += near * skew / this.getFilmWidth();

			this.projectionMatrix.makePerspective( left, left + width, top, top - height, near, this.far, this.coordinateSystem );

			this.projectionMatrixInverse.copy( this.projectionMatrix ).invert();

		}

		toJSON( meta ) {

			const data = super.toJSON( meta );

			data.object.fov = this.fov;
			data.object.zoom = this.zoom;

			data.object.near = this.near;
			data.object.far = this.far;
			data.object.focus = this.focus;

			data.object.aspect = this.aspect;

			if ( this.view !== null ) data.object.view = Object.assign( {}, this.view );

			data.object.filmGauge = this.filmGauge;
			data.object.filmOffset = this.filmOffset;

			return data;

		}

	}

	const fov = -90; // negative fov is not an error
	const aspect = 1;

	/**
	 * A special type of camera that is positioned in 3D space to render its surroundings into a
	 * cube render target. The render target can then be used as an environment map for rendering
	 * realtime reflections in your scene.
	 *
	 * ```js
	 * // Create cube render target
	 * const cubeRenderTarget = new THREE.WebGLCubeRenderTarget( 256, { generateMipmaps: true, minFilter: THREE.LinearMipmapLinearFilter } );
	 *
	 * // Create cube camera
	 * const cubeCamera = new THREE.CubeCamera( 1, 100000, cubeRenderTarget );
	 * scene.add( cubeCamera );
	 *
	 * // Create car
	 * const chromeMaterial = new THREE.MeshLambertMaterial( { color: 0xffffff, envMap: cubeRenderTarget.texture } );
	 * const car = new THREE.Mesh( carGeometry, chromeMaterial );
	 * scene.add( car );
	 *
	 * // Update the render target cube
	 * car.visible = false;
	 * cubeCamera.position.copy( car.position );
	 * cubeCamera.update( renderer, scene );
	 *
	 * // Render the scene
	 * car.visible = true;
	 * renderer.render( scene, camera );
	 * ```
	 *
	 * @augments Object3D
	 */
	class CubeCamera extends Object3D {

		/**
		 * Constructs a new cube camera.
		 *
		 * @param {number} near - The camera's near plane.
		 * @param {number} far - The camera's far plane.
		 * @param {WebGLCubeRenderTarget} renderTarget - The cube render target.
		 */
		constructor( near, far, renderTarget ) {

			super();

			this.type = 'CubeCamera';

			/**
			 * A reference to the cube render target.
			 *
			 * @type {WebGLCubeRenderTarget}
			 */
			this.renderTarget = renderTarget;

			/**
			 * The current active coordinate system.
			 *
			 * @type {?(WebGLCoordinateSystem|WebGPUCoordinateSystem)}
			 * @default null
			 */
			this.coordinateSystem = null;

			/**
			 * The current active mipmap level
			 *
			 * @type {number}
			 * @default 0
			 */
			this.activeMipmapLevel = 0;

			const cameraPX = new PerspectiveCamera( fov, aspect, near, far );
			cameraPX.layers = this.layers;
			this.add( cameraPX );

			const cameraNX = new PerspectiveCamera( fov, aspect, near, far );
			cameraNX.layers = this.layers;
			this.add( cameraNX );

			const cameraPY = new PerspectiveCamera( fov, aspect, near, far );
			cameraPY.layers = this.layers;
			this.add( cameraPY );

			const cameraNY = new PerspectiveCamera( fov, aspect, near, far );
			cameraNY.layers = this.layers;
			this.add( cameraNY );

			const cameraPZ = new PerspectiveCamera( fov, aspect, near, far );
			cameraPZ.layers = this.layers;
			this.add( cameraPZ );

			const cameraNZ = new PerspectiveCamera( fov, aspect, near, far );
			cameraNZ.layers = this.layers;
			this.add( cameraNZ );

		}

		/**
		 * Must be called when the coordinate system of the cube camera is changed.
		 */
		updateCoordinateSystem() {

			const coordinateSystem = this.coordinateSystem;

			const cameras = this.children.concat();

			const [ cameraPX, cameraNX, cameraPY, cameraNY, cameraPZ, cameraNZ ] = cameras;

			for ( const camera of cameras ) this.remove( camera );

			if ( coordinateSystem === WebGLCoordinateSystem ) {

				cameraPX.up.set( 0, 1, 0 );
				cameraPX.lookAt( 1, 0, 0 );

				cameraNX.up.set( 0, 1, 0 );
				cameraNX.lookAt( -1, 0, 0 );

				cameraPY.up.set( 0, 0, -1 );
				cameraPY.lookAt( 0, 1, 0 );

				cameraNY.up.set( 0, 0, 1 );
				cameraNY.lookAt( 0, -1, 0 );

				cameraPZ.up.set( 0, 1, 0 );
				cameraPZ.lookAt( 0, 0, 1 );

				cameraNZ.up.set( 0, 1, 0 );
				cameraNZ.lookAt( 0, 0, -1 );

			} else if ( coordinateSystem === WebGPUCoordinateSystem ) {

				cameraPX.up.set( 0, -1, 0 );
				cameraPX.lookAt( -1, 0, 0 );

				cameraNX.up.set( 0, -1, 0 );
				cameraNX.lookAt( 1, 0, 0 );

				cameraPY.up.set( 0, 0, 1 );
				cameraPY.lookAt( 0, 1, 0 );

				cameraNY.up.set( 0, 0, -1 );
				cameraNY.lookAt( 0, -1, 0 );

				cameraPZ.up.set( 0, -1, 0 );
				cameraPZ.lookAt( 0, 0, 1 );

				cameraNZ.up.set( 0, -1, 0 );
				cameraNZ.lookAt( 0, 0, -1 );

			} else {

				throw new Error( 'THREE.CubeCamera.updateCoordinateSystem(): Invalid coordinate system: ' + coordinateSystem );

			}

			for ( const camera of cameras ) {

				this.add( camera );

				camera.updateMatrixWorld();

			}

		}

		/**
		 * Calling this method will render the given scene with the given renderer
		 * into the cube render target of the camera.
		 *
		 * @param {(Renderer|WebGLRenderer)} renderer - The renderer.
		 * @param {Scene} scene - The scene to render.
		 */
		update( renderer, scene ) {

			if ( this.parent === null ) this.updateMatrixWorld();

			const { renderTarget, activeMipmapLevel } = this;

			if ( this.coordinateSystem !== renderer.coordinateSystem ) {

				this.coordinateSystem = renderer.coordinateSystem;

				this.updateCoordinateSystem();

			}

			const [ cameraPX, cameraNX, cameraPY, cameraNY, cameraPZ, cameraNZ ] = this.children;

			const currentRenderTarget = renderer.getRenderTarget();
			const currentActiveCubeFace = renderer.getActiveCubeFace();
			const currentActiveMipmapLevel = renderer.getActiveMipmapLevel();

			const currentXrEnabled = renderer.xr.enabled;

			renderer.xr.enabled = false;

			const generateMipmaps = renderTarget.texture.generateMipmaps;

			renderTarget.texture.generateMipmaps = false;

			renderer.setRenderTarget( renderTarget, 0, activeMipmapLevel );
			renderer.render( scene, cameraPX );

			renderer.setRenderTarget( renderTarget, 1, activeMipmapLevel );
			renderer.render( scene, cameraNX );

			renderer.setRenderTarget( renderTarget, 2, activeMipmapLevel );
			renderer.render( scene, cameraPY );

			renderer.setRenderTarget( renderTarget, 3, activeMipmapLevel );
			renderer.render( scene, cameraNY );

			renderer.setRenderTarget( renderTarget, 4, activeMipmapLevel );
			renderer.render( scene, cameraPZ );

			// mipmaps are generated during the last call of render()
			// at this point, all sides of the cube render target are defined

			renderTarget.texture.generateMipmaps = generateMipmaps;

			renderer.setRenderTarget( renderTarget, 5, activeMipmapLevel );
			renderer.render( scene, cameraNZ );

			renderer.setRenderTarget( currentRenderTarget, currentActiveCubeFace, currentActiveMipmapLevel );

			renderer.xr.enabled = currentXrEnabled;

			renderTarget.texture.needsPMREMUpdate = true;

		}

	}

	/**
	 * Creates a cube texture made up of six images.
	 *
	 * ```js
	 * const loader = new THREE.CubeTextureLoader();
	 * loader.setPath( 'textures/cube/pisa/' );
	 *
	 * const textureCube = loader.load( [
	 * 	'px.png', 'nx.png', 'py.png', 'ny.png', 'pz.png', 'nz.png'
	 * ] );
	 *
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffffff, envMap: textureCube } );
	 * ```
	 *
	 * @augments Texture
	 */
	class CubeTexture extends Texture {

		/**
		 * Constructs a new cube texture.
		 *
		 * @param {Array<Image>} [images=[]] - An array holding a image for each side of a cube.
		 * @param {number} [mapping=CubeReflectionMapping] - The texture mapping.
		 * @param {number} [wrapS=ClampToEdgeWrapping] - The wrapS value.
		 * @param {number} [wrapT=ClampToEdgeWrapping] - The wrapT value.
		 * @param {number} [magFilter=LinearFilter] - The mag filter value.
		 * @param {number} [minFilter=LinearMipmapLinearFilter] - The min filter value.
		 * @param {number} [format=RGBAFormat] - The texture format.
		 * @param {number} [type=UnsignedByteType] - The texture type.
		 * @param {number} [anisotropy=Texture.DEFAULT_ANISOTROPY] - The anisotropy value.
		 * @param {string} [colorSpace=NoColorSpace] - The color space value.
		 */
		constructor( images = [], mapping = CubeReflectionMapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace ) {

			super( images, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isCubeTexture = true;

			/**
			 * If set to `true`, the texture is flipped along the vertical axis when
			 * uploaded to the GPU.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.flipY = false;

		}

		/**
		 * Alias for {@link CubeTexture#image}.
		 *
		 * @type {Array<Image>}
		 */
		get images() {

			return this.image;

		}

		set images( value ) {

			this.image = value;

		}

	}

	/**
	 * A cube render target used in context of {@link WebGLRenderer}.
	 *
	 * @augments WebGLRenderTarget
	 */
	class WebGLCubeRenderTarget extends WebGLRenderTarget {

		/**
		 * Constructs a new cube render target.
		 *
		 * @param {number} [size=1] - The size of the render target.
		 * @param {RenderTarget~Options} [options] - The configuration object.
		 */
		constructor( size = 1, options = {} ) {

			super( size, size, options );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isWebGLCubeRenderTarget = true;

			const image = { width: size, height: size, depth: 1 };
			const images = [ image, image, image, image, image, image ];

			/**
			 * Overwritten with a different texture type.
			 *
			 * @type {DataArrayTexture}
			 */
			this.texture = new CubeTexture( images );
			this._setTextureOptions( options );

			// By convention -- likely based on the RenderMan spec from the 1990's -- cube maps are specified by WebGL (and three.js)
			// in a coordinate system in which positive-x is to the right when looking up the positive-z axis -- in other words,
			// in a left-handed coordinate system. By continuing this convention, preexisting cube maps continued to render correctly.

			// three.js uses a right-handed coordinate system. So environment maps used in three.js appear to have px and nx swapped
			// and the flag isRenderTargetTexture controls this conversion. The flip is not required when using WebGLCubeRenderTarget.texture
			// as a cube texture (this is detected when isRenderTargetTexture is set to true for cube textures).

			this.texture.isRenderTargetTexture = true;

		}

		/**
		 * Converts the given equirectangular texture to a cube map.
		 *
		 * @param {WebGLRenderer} renderer - The renderer.
		 * @param {Texture} texture - The equirectangular texture.
		 * @return {WebGLCubeRenderTarget} A reference to this cube render target.
		 */
		fromEquirectangularTexture( renderer, texture ) {

			this.texture.type = texture.type;
			this.texture.colorSpace = texture.colorSpace;

			this.texture.generateMipmaps = texture.generateMipmaps;
			this.texture.minFilter = texture.minFilter;
			this.texture.magFilter = texture.magFilter;

			const shader = {

				uniforms: {
					tEquirect: { value: null },
				},

				vertexShader: /* glsl */`

				varying vec3 vWorldDirection;

				vec3 transformDirection( in vec3 dir, in mat4 matrix ) {

					return normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );

				}

				void main() {

					vWorldDirection = transformDirection( position, modelMatrix );

					#include <begin_vertex>
					#include <project_vertex>

				}
			`,

				fragmentShader: /* glsl */`

				uniform sampler2D tEquirect;

				varying vec3 vWorldDirection;

				#include <common>

				void main() {

					vec3 direction = normalize( vWorldDirection );

					vec2 sampleUV = equirectUv( direction );

					gl_FragColor = texture2D( tEquirect, sampleUV );

				}
			`
			};

			const geometry = new BoxGeometry( 5, 5, 5 );

			const material = new ShaderMaterial( {

				name: 'CubemapFromEquirect',

				uniforms: cloneUniforms( shader.uniforms ),
				vertexShader: shader.vertexShader,
				fragmentShader: shader.fragmentShader,
				side: BackSide,
				blending: NoBlending

			} );

			material.uniforms.tEquirect.value = texture;

			const mesh = new Mesh( geometry, material );

			const currentMinFilter = texture.minFilter;

			// Avoid blurred poles
			if ( texture.minFilter === LinearMipmapLinearFilter ) texture.minFilter = LinearFilter;

			const camera = new CubeCamera( 1, 10, this );
			camera.update( renderer, mesh );

			texture.minFilter = currentMinFilter;

			mesh.geometry.dispose();
			mesh.material.dispose();

			return this;

		}

		/**
		 * Clears this cube render target.
		 *
		 * @param {WebGLRenderer} renderer - The renderer.
		 * @param {boolean} [color=true] - Whether the color buffer should be cleared or not.
		 * @param {boolean} [depth=true] - Whether the depth buffer should be cleared or not.
		 * @param {boolean} [stencil=true] - Whether the stencil buffer should be cleared or not.
		 */
		clear( renderer, color = true, depth = true, stencil = true ) {

			const currentRenderTarget = renderer.getRenderTarget();

			for ( let i = 0; i < 6; i ++ ) {

				renderer.setRenderTarget( this, i );

				renderer.clear( color, depth, stencil );

			}

			renderer.setRenderTarget( currentRenderTarget );

		}

	}

	/**
	 * This is almost identical to an {@link Object3D}. Its purpose is to
	 * make working with groups of objects syntactically clearer.
	 *
	 * ```js
	 * // Create a group and add the two cubes.
	 * // These cubes can now be rotated / scaled etc as a group.
	 * const group = new THREE.Group();
	 *
	 * group.add( meshA );
	 * group.add( meshB );
	 *
	 * scene.add( group );
	 * ```
	 *
	 * @augments Object3D
	 */
	class Group$1 extends Object3D {

		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isGroup = true;

			this.type = 'Group';

		}

	}

	const _moveEvent = { type: 'move' };

	/**
	 * Class for representing a XR controller with its
	 * different coordinate systems.
	 *
	 * @private
	 */
	class WebXRController {

		/**
		 * Constructs a new XR controller.
		 */
		constructor() {

			/**
			 * A group representing the target ray space
			 * of the XR controller.
			 *
			 * @private
			 * @type {?Group}
			 * @default null
			 */
			this._targetRay = null;

			/**
			 * A group representing the grip space
			 * of the XR controller.
			 *
			 * @private
			 * @type {?Group}
			 * @default null
			 */
			this._grip = null;

			/**
			 * A group representing the hand space
			 * of the XR controller.
			 *
			 * @private
			 * @type {?Group}
			 * @default null
			 */
			this._hand = null;

		}

		/**
		 * Returns a group representing the hand space of the XR controller.
		 *
		 * @return {Group} A group representing the hand space of the XR controller.
		 */
		getHandSpace() {

			if ( this._hand === null ) {

				this._hand = new Group$1();
				this._hand.matrixAutoUpdate = false;
				this._hand.visible = false;

				this._hand.joints = {};
				this._hand.inputState = { pinching: false };

			}

			return this._hand;

		}

		/**
		 * Returns a group representing the target ray space of the XR controller.
		 *
		 * @return {Group} A group representing the target ray space of the XR controller.
		 */
		getTargetRaySpace() {

			if ( this._targetRay === null ) {

				this._targetRay = new Group$1();
				this._targetRay.matrixAutoUpdate = false;
				this._targetRay.visible = false;
				this._targetRay.hasLinearVelocity = false;
				this._targetRay.linearVelocity = new Vector3();
				this._targetRay.hasAngularVelocity = false;
				this._targetRay.angularVelocity = new Vector3();

			}

			return this._targetRay;

		}

		/**
		 * Returns a group representing the grip space of the XR controller.
		 *
		 * @return {Group} A group representing the grip space of the XR controller.
		 */
		getGripSpace() {

			if ( this._grip === null ) {

				this._grip = new Group$1();
				this._grip.matrixAutoUpdate = false;
				this._grip.visible = false;
				this._grip.hasLinearVelocity = false;
				this._grip.linearVelocity = new Vector3();
				this._grip.hasAngularVelocity = false;
				this._grip.angularVelocity = new Vector3();

			}

			return this._grip;

		}

		/**
		 * Dispatches the given event to the groups representing
		 * the different coordinate spaces of the XR controller.
		 *
		 * @param {Object} event - The event to dispatch.
		 * @return {WebXRController} A reference to this instance.
		 */
		dispatchEvent( event ) {

			if ( this._targetRay !== null ) {

				this._targetRay.dispatchEvent( event );

			}

			if ( this._grip !== null ) {

				this._grip.dispatchEvent( event );

			}

			if ( this._hand !== null ) {

				this._hand.dispatchEvent( event );

			}

			return this;

		}

		/**
		 * Connects the controller with the given XR input source.
		 *
		 * @param {XRInputSource} inputSource - The input source.
		 * @return {WebXRController} A reference to this instance.
		 */
		connect( inputSource ) {

			if ( inputSource && inputSource.hand ) {

				const hand = this._hand;

				if ( hand ) {

					for ( const inputjoint of inputSource.hand.values() ) {

						// Initialize hand with joints when connected
						this._getHandJoint( hand, inputjoint );

					}

				}

			}

			this.dispatchEvent( { type: 'connected', data: inputSource } );

			return this;

		}

		/**
		 * Disconnects the controller from the given XR input source.
		 *
		 * @param {XRInputSource} inputSource - The input source.
		 * @return {WebXRController} A reference to this instance.
		 */
		disconnect( inputSource ) {

			this.dispatchEvent( { type: 'disconnected', data: inputSource } );

			if ( this._targetRay !== null ) {

				this._targetRay.visible = false;

			}

			if ( this._grip !== null ) {

				this._grip.visible = false;

			}

			if ( this._hand !== null ) {

				this._hand.visible = false;

			}

			return this;

		}

		/**
		 * Updates the controller with the given input source, XR frame and reference space.
		 * This updates the transformations of the groups that represent the different
		 * coordinate systems of the controller.
		 *
		 * @param {XRInputSource} inputSource - The input source.
		 * @param {XRFrame} frame - The XR frame.
		 * @param {XRReferenceSpace} referenceSpace - The reference space.
		 * @return {WebXRController} A reference to this instance.
		 */
		update( inputSource, frame, referenceSpace ) {

			let inputPose = null;
			let gripPose = null;
			let handPose = null;

			const targetRay = this._targetRay;
			const grip = this._grip;
			const hand = this._hand;

			if ( inputSource && frame.session.visibilityState !== 'visible-blurred' ) {

				if ( hand && inputSource.hand ) {

					handPose = true;

					for ( const inputjoint of inputSource.hand.values() ) {

						// Update the joints groups with the XRJoint poses
						const jointPose = frame.getJointPose( inputjoint, referenceSpace );

						// The transform of this joint will be updated with the joint pose on each frame
						const joint = this._getHandJoint( hand, inputjoint );

						if ( jointPose !== null ) {

							joint.matrix.fromArray( jointPose.transform.matrix );
							joint.matrix.decompose( joint.position, joint.rotation, joint.scale );
							joint.matrixWorldNeedsUpdate = true;
							joint.jointRadius = jointPose.radius;

						}

						joint.visible = jointPose !== null;

					}

					// Custom events

					// Check pinchz
					const indexTip = hand.joints[ 'index-finger-tip' ];
					const thumbTip = hand.joints[ 'thumb-tip' ];
					const distance = indexTip.position.distanceTo( thumbTip.position );

					const distanceToPinch = 0.02;
					const threshold = 0.005;

					if ( hand.inputState.pinching && distance > distanceToPinch + threshold ) {

						hand.inputState.pinching = false;
						this.dispatchEvent( {
							type: 'pinchend',
							handedness: inputSource.handedness,
							target: this
						} );

					} else if ( ! hand.inputState.pinching && distance <= distanceToPinch - threshold ) {

						hand.inputState.pinching = true;
						this.dispatchEvent( {
							type: 'pinchstart',
							handedness: inputSource.handedness,
							target: this
						} );

					}

				} else {

					if ( grip !== null && inputSource.gripSpace ) {

						gripPose = frame.getPose( inputSource.gripSpace, referenceSpace );

						if ( gripPose !== null ) {

							grip.matrix.fromArray( gripPose.transform.matrix );
							grip.matrix.decompose( grip.position, grip.rotation, grip.scale );
							grip.matrixWorldNeedsUpdate = true;

							if ( gripPose.linearVelocity ) {

								grip.hasLinearVelocity = true;
								grip.linearVelocity.copy( gripPose.linearVelocity );

							} else {

								grip.hasLinearVelocity = false;

							}

							if ( gripPose.angularVelocity ) {

								grip.hasAngularVelocity = true;
								grip.angularVelocity.copy( gripPose.angularVelocity );

							} else {

								grip.hasAngularVelocity = false;

							}

						}

					}

				}

				if ( targetRay !== null ) {

					inputPose = frame.getPose( inputSource.targetRaySpace, referenceSpace );

					// Some runtimes (namely Vive Cosmos with Vive OpenXR Runtime) have only grip space and ray space is equal to it
					if ( inputPose === null && gripPose !== null ) {

						inputPose = gripPose;

					}

					if ( inputPose !== null ) {

						targetRay.matrix.fromArray( inputPose.transform.matrix );
						targetRay.matrix.decompose( targetRay.position, targetRay.rotation, targetRay.scale );
						targetRay.matrixWorldNeedsUpdate = true;

						if ( inputPose.linearVelocity ) {

							targetRay.hasLinearVelocity = true;
							targetRay.linearVelocity.copy( inputPose.linearVelocity );

						} else {

							targetRay.hasLinearVelocity = false;

						}

						if ( inputPose.angularVelocity ) {

							targetRay.hasAngularVelocity = true;
							targetRay.angularVelocity.copy( inputPose.angularVelocity );

						} else {

							targetRay.hasAngularVelocity = false;

						}

						this.dispatchEvent( _moveEvent );

					}

				}


			}

			if ( targetRay !== null ) {

				targetRay.visible = ( inputPose !== null );

			}

			if ( grip !== null ) {

				grip.visible = ( gripPose !== null );

			}

			if ( hand !== null ) {

				hand.visible = ( handPose !== null );

			}

			return this;

		}

		/**
		 * Returns a group representing the hand joint for the given input joint.
		 *
		 * @private
		 * @param {Group} hand - The group representing the hand space.
		 * @param {XRJointSpace} inputjoint - The hand joint data.
		 * @return {Group} A group representing the hand joint for the given input joint.
		 */
		_getHandJoint( hand, inputjoint ) {

			if ( hand.joints[ inputjoint.jointName ] === undefined ) {

				const joint = new Group$1();
				joint.matrixAutoUpdate = false;
				joint.visible = false;
				hand.joints[ inputjoint.jointName ] = joint;

				hand.add( joint );

			}

			return hand.joints[ inputjoint.jointName ];

		}

	}

	/**
	 * Scenes allow you to set up what is to be rendered and where by three.js.
	 * This is where you place 3D objects like meshes, lines or lights.
	 *
	 * @augments Object3D
	 */
	class Scene extends Object3D {

		/**
		 * Constructs a new scene.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isScene = true;

			this.type = 'Scene';

			/**
			 * Defines the background of the scene. Valid inputs are:
			 *
			 * - A color for defining a uniform colored background.
			 * - A texture for defining a (flat) textured background.
			 * - Cube textures or equirectangular textures for defining a skybox.
			 *
			 * @type {?(Color|Texture)}
			 * @default null
			 */
			this.background = null;

			/**
			 * Sets the environment map for all physical materials in the scene. However,
			 * it's not possible to overwrite an existing texture assigned to the `envMap`
			 * material property.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.environment = null;

			/**
			 * A fog instance defining the type of fog that affects everything
			 * rendered in the scene.
			 *
			 * @type {?(Fog|FogExp2)}
			 * @default null
			 */
			this.fog = null;

			/**
			 * Sets the blurriness of the background. Only influences environment maps
			 * assigned to {@link Scene#background}. Valid input is a float between `0`
			 * and `1`.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.backgroundBlurriness = 0;

			/**
			 * Attenuates the color of the background. Only applies to background textures.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.backgroundIntensity = 1;

			/**
			 * The rotation of the background in radians. Only influences environment maps
			 * assigned to {@link Scene#background}.
			 *
			 * @type {Euler}
			 * @default (0,0,0)
			 */
			this.backgroundRotation = new Euler();

			/**
			 * Attenuates the color of the environment. Only influences environment maps
			 * assigned to {@link Scene#environment}.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.environmentIntensity = 1;

			/**
			 * The rotation of the environment map in radians. Only influences physical materials
			 * in the scene when {@link Scene#environment} is used.
			 *
			 * @type {Euler}
			 * @default (0,0,0)
			 */
			this.environmentRotation = new Euler();

			/**
			 * Forces everything in the scene to be rendered with the defined material. It is possible
			 * to exclude materials from override by setting {@link Material#allowOverride} to `false`.
			 *
			 * @type {?Material}
			 * @default null
			 */
			this.overrideMaterial = null;

			if ( typeof __THREE_DEVTOOLS__ !== 'undefined' ) {

				__THREE_DEVTOOLS__.dispatchEvent( new CustomEvent( 'observe', { detail: this } ) );

			}

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			if ( source.background !== null ) this.background = source.background.clone();
			if ( source.environment !== null ) this.environment = source.environment.clone();
			if ( source.fog !== null ) this.fog = source.fog.clone();

			this.backgroundBlurriness = source.backgroundBlurriness;
			this.backgroundIntensity = source.backgroundIntensity;
			this.backgroundRotation.copy( source.backgroundRotation );

			this.environmentIntensity = source.environmentIntensity;
			this.environmentRotation.copy( source.environmentRotation );

			if ( source.overrideMaterial !== null ) this.overrideMaterial = source.overrideMaterial.clone();

			this.matrixAutoUpdate = source.matrixAutoUpdate;

			return this;

		}

		toJSON( meta ) {

			const data = super.toJSON( meta );

			if ( this.fog !== null ) data.object.fog = this.fog.toJSON();

			if ( this.backgroundBlurriness > 0 ) data.object.backgroundBlurriness = this.backgroundBlurriness;
			if ( this.backgroundIntensity !== 1 ) data.object.backgroundIntensity = this.backgroundIntensity;
			data.object.backgroundRotation = this.backgroundRotation.toArray();

			if ( this.environmentIntensity !== 1 ) data.object.environmentIntensity = this.environmentIntensity;
			data.object.environmentRotation = this.environmentRotation.toArray();

			return data;

		}

	}

	/**
	 * "Interleaved" means that multiple attributes, possibly of different types,
	 * (e.g., position, normal, uv, color) are packed into a single array buffer.
	 *
	 * An introduction into interleaved arrays can be found here: [Interleaved array basics]{@link https://blog.tojicode.com/2011/05/interleaved-array-basics.html}
	 */
	class InterleavedBuffer {

		/**
		 * Constructs a new interleaved buffer.
		 *
		 * @param {TypedArray} array - A typed array with a shared buffer storing attribute data.
		 * @param {number} stride - The number of typed-array elements per vertex.
		 */
		constructor( array, stride ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isInterleavedBuffer = true;

			/**
			 * A typed array with a shared buffer storing attribute data.
			 *
			 * @type {TypedArray}
			 */
			this.array = array;

			/**
			 * The number of typed-array elements per vertex.
			 *
			 * @type {number}
			 */
			this.stride = stride;

			/**
			 * The total number of elements in the array
			 *
			 * @type {number}
			 * @readonly
			 */
			this.count = array !== undefined ? array.length / stride : 0;

			/**
			 * Defines the intended usage pattern of the data store for optimization purposes.
			 *
			 * Note: After the initial use of a buffer, its usage cannot be changed. Instead,
			 * instantiate a new one and set the desired usage before the next render.
			 *
			 * @type {(StaticDrawUsage|DynamicDrawUsage|StreamDrawUsage|StaticReadUsage|DynamicReadUsage|StreamReadUsage|StaticCopyUsage|DynamicCopyUsage|StreamCopyUsage)}
			 * @default StaticDrawUsage
			 */
			this.usage = StaticDrawUsage;

			/**
			 * This can be used to only update some components of stored vectors (for example, just the
			 * component related to color). Use the `addUpdateRange()` function to add ranges to this array.
			 *
			 * @type {Array<Object>}
			 */
			this.updateRanges = [];

			/**
			 * A version number, incremented every time the `needsUpdate` is set to `true`.
			 *
			 * @type {number}
			 */
			this.version = 0;

			/**
			 * The UUID of the interleaved buffer.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.uuid = generateUUID();

		}

		/**
		 * A callback function that is executed after the renderer has transferred the attribute array
		 * data to the GPU.
		 */
		onUploadCallback() {}

		/**
		 * Flag to indicate that this attribute has changed and should be re-sent to
		 * the GPU. Set this to `true` when you modify the value of the array.
		 *
		 * @type {number}
		 * @default false
		 * @param {boolean} value
		 */
		set needsUpdate( value ) {

			if ( value === true ) this.version ++;

		}

		/**
		 * Sets the usage of this interleaved buffer.
		 *
		 * @param {(StaticDrawUsage|DynamicDrawUsage|StreamDrawUsage|StaticReadUsage|DynamicReadUsage|StreamReadUsage|StaticCopyUsage|DynamicCopyUsage|StreamCopyUsage)} value - The usage to set.
		 * @return {InterleavedBuffer} A reference to this interleaved buffer.
		 */
		setUsage( value ) {

			this.usage = value;

			return this;

		}

		/**
		 * Adds a range of data in the data array to be updated on the GPU.
		 *
		 * @param {number} start - Position at which to start update.
		 * @param {number} count - The number of components to update.
		 */
		addUpdateRange( start, count ) {

			this.updateRanges.push( { start, count } );

		}

		/**
		 * Clears the update ranges.
		 */
		clearUpdateRanges() {

			this.updateRanges.length = 0;

		}

		/**
		 * Copies the values of the given interleaved buffer to this instance.
		 *
		 * @param {InterleavedBuffer} source - The interleaved buffer to copy.
		 * @return {InterleavedBuffer} A reference to this instance.
		 */
		copy( source ) {

			this.array = new source.array.constructor( source.array );
			this.count = source.count;
			this.stride = source.stride;
			this.usage = source.usage;

			return this;

		}

		/**
		 * Copies a vector from the given interleaved buffer to this one. The start
		 * and destination position in the attribute buffers are represented by the
		 * given indices.
		 *
		 * @param {number} index1 - The destination index into this interleaved buffer.
		 * @param {InterleavedBuffer} interleavedBuffer - The interleaved buffer to copy from.
		 * @param {number} index2 - The source index into the given interleaved buffer.
		 * @return {InterleavedBuffer} A reference to this instance.
		 */
		copyAt( index1, interleavedBuffer, index2 ) {

			index1 *= this.stride;
			index2 *= interleavedBuffer.stride;

			for ( let i = 0, l = this.stride; i < l; i ++ ) {

				this.array[ index1 + i ] = interleavedBuffer.array[ index2 + i ];

			}

			return this;

		}

		/**
		 * Sets the given array data in the interleaved buffer.
		 *
		 * @param {(TypedArray|Array)} value - The array data to set.
		 * @param {number} [offset=0] - The offset in this interleaved buffer's array.
		 * @return {InterleavedBuffer} A reference to this instance.
		 */
		set( value, offset = 0 ) {

			this.array.set( value, offset );

			return this;

		}

		/**
		 * Returns a new interleaved buffer with copied values from this instance.
		 *
		 * @param {Object} [data] - An object with shared array buffers that allows to retain shared structures.
		 * @return {InterleavedBuffer} A clone of this instance.
		 */
		clone( data ) {

			if ( data.arrayBuffers === undefined ) {

				data.arrayBuffers = {};

			}

			if ( this.array.buffer._uuid === undefined ) {

				this.array.buffer._uuid = generateUUID();

			}

			if ( data.arrayBuffers[ this.array.buffer._uuid ] === undefined ) {

				data.arrayBuffers[ this.array.buffer._uuid ] = this.array.slice( 0 ).buffer;

			}

			const array = new this.array.constructor( data.arrayBuffers[ this.array.buffer._uuid ] );

			const ib = new this.constructor( array, this.stride );
			ib.setUsage( this.usage );

			return ib;

		}

		/**
		 * Sets the given callback function that is executed after the Renderer has transferred
		 * the array data to the GPU. Can be used to perform clean-up operations after
		 * the upload when data are not needed anymore on the CPU side.
		 *
		 * @param {Function} callback - The `onUpload()` callback.
		 * @return {InterleavedBuffer} A reference to this instance.
		 */
		onUpload( callback ) {

			this.onUploadCallback = callback;

			return this;

		}

		/**
		 * Serializes the interleaved buffer into JSON.
		 *
		 * @param {Object} [data] - An optional value holding meta information about the serialization.
		 * @return {Object} A JSON object representing the serialized interleaved buffer.
		 */
		toJSON( data ) {

			if ( data.arrayBuffers === undefined ) {

				data.arrayBuffers = {};

			}

			// generate UUID for array buffer if necessary

			if ( this.array.buffer._uuid === undefined ) {

				this.array.buffer._uuid = generateUUID();

			}

			if ( data.arrayBuffers[ this.array.buffer._uuid ] === undefined ) {

				data.arrayBuffers[ this.array.buffer._uuid ] = Array.from( new Uint32Array( this.array.buffer ) );

			}

			//

			return {
				uuid: this.uuid,
				buffer: this.array.buffer._uuid,
				type: this.array.constructor.name,
				stride: this.stride
			};

		}

	}

	const _vector$7 = /*@__PURE__*/ new Vector3();

	/**
	 * An alternative version of a buffer attribute with interleaved data. Interleaved
	 * attributes share a common interleaved data storage ({@link InterleavedBuffer}) and refer with
	 * different offsets into the buffer.
	 */
	class InterleavedBufferAttribute {

		/**
		 * Constructs a new interleaved buffer attribute.
		 *
		 * @param {InterleavedBuffer} interleavedBuffer - The buffer holding the interleaved data.
		 * @param {number} itemSize - The item size.
		 * @param {number} offset - The attribute offset into the buffer.
		 * @param {boolean} [normalized=false] - Whether the data are normalized or not.
		 */
		constructor( interleavedBuffer, itemSize, offset, normalized = false ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isInterleavedBufferAttribute = true;

			/**
			 * The name of the buffer attribute.
			 *
			 * @type {string}
			 */
			this.name = '';

			/**
			 * The buffer holding the interleaved data.
			 *
			 * @type {InterleavedBuffer}
			 */
			this.data = interleavedBuffer;

			/**
			 * The item size, see {@link BufferAttribute#itemSize}.
			 *
			 * @type {number}
			 */
			this.itemSize = itemSize;

			/**
			 * The attribute offset into the buffer.
			 *
			 * @type {number}
			 */
			this.offset = offset;

			/**
			 * Whether the data are normalized or not, see {@link BufferAttribute#normalized}
			 *
			 * @type {InterleavedBuffer}
			 */
			this.normalized = normalized;

		}

		/**
		 * The item count of this buffer attribute.
		 *
		 * @type {number}
		 * @readonly
		 */
		get count() {

			return this.data.count;

		}

		/**
		 * The array holding the interleaved buffer attribute data.
		 *
		 * @type {TypedArray}
		 */
		get array() {

			return this.data.array;

		}

		/**
		 * Flag to indicate that this attribute has changed and should be re-sent to
		 * the GPU. Set this to `true` when you modify the value of the array.
		 *
		 * @type {number}
		 * @default false
		 * @param {boolean} value
		 */
		set needsUpdate( value ) {

			this.data.needsUpdate = value;

		}

		/**
		 * Applies the given 4x4 matrix to the given attribute. Only works with
		 * item size `3`.
		 *
		 * @param {Matrix4} m - The matrix to apply.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		applyMatrix4( m ) {

			for ( let i = 0, l = this.data.count; i < l; i ++ ) {

				_vector$7.fromBufferAttribute( this, i );

				_vector$7.applyMatrix4( m );

				this.setXYZ( i, _vector$7.x, _vector$7.y, _vector$7.z );

			}

			return this;

		}

		/**
		 * Applies the given 3x3 normal matrix to the given attribute. Only works with
		 * item size `3`.
		 *
		 * @param {Matrix3} m - The normal matrix to apply.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		applyNormalMatrix( m ) {

			for ( let i = 0, l = this.count; i < l; i ++ ) {

				_vector$7.fromBufferAttribute( this, i );

				_vector$7.applyNormalMatrix( m );

				this.setXYZ( i, _vector$7.x, _vector$7.y, _vector$7.z );

			}

			return this;

		}

		/**
		 * Applies the given 4x4 matrix to the given attribute. Only works with
		 * item size `3` and with direction vectors.
		 *
		 * @param {Matrix4} m - The matrix to apply.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		transformDirection( m ) {

			for ( let i = 0, l = this.count; i < l; i ++ ) {

				_vector$7.fromBufferAttribute( this, i );

				_vector$7.transformDirection( m );

				this.setXYZ( i, _vector$7.x, _vector$7.y, _vector$7.z );

			}

			return this;

		}

		/**
		 * Returns the given component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} component - The component index.
		 * @return {number} The returned value.
		 */
		getComponent( index, component ) {

			let value = this.array[ index * this.data.stride + this.offset + component ];

			if ( this.normalized ) value = denormalize( value, this.array );

			return value;

		}

		/**
		 * Sets the given value to the given component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} component - The component index.
		 * @param {number} value - The value to set.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		setComponent( index, component, value ) {

			if ( this.normalized ) value = normalize( value, this.array );

			this.data.array[ index * this.data.stride + this.offset + component ] = value;

			return this;

		}

		/**
		 * Sets the x component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} x - The value to set.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		setX( index, x ) {

			if ( this.normalized ) x = normalize( x, this.array );

			this.data.array[ index * this.data.stride + this.offset ] = x;

			return this;

		}

		/**
		 * Sets the y component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} y - The value to set.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		setY( index, y ) {

			if ( this.normalized ) y = normalize( y, this.array );

			this.data.array[ index * this.data.stride + this.offset + 1 ] = y;

			return this;

		}

		/**
		 * Sets the z component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} z - The value to set.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		setZ( index, z ) {

			if ( this.normalized ) z = normalize( z, this.array );

			this.data.array[ index * this.data.stride + this.offset + 2 ] = z;

			return this;

		}

		/**
		 * Sets the w component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} w - The value to set.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		setW( index, w ) {

			if ( this.normalized ) w = normalize( w, this.array );

			this.data.array[ index * this.data.stride + this.offset + 3 ] = w;

			return this;

		}

		/**
		 * Returns the x component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @return {number} The x component.
		 */
		getX( index ) {

			let x = this.data.array[ index * this.data.stride + this.offset ];

			if ( this.normalized ) x = denormalize( x, this.array );

			return x;

		}

		/**
		 * Returns the y component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @return {number} The y component.
		 */
		getY( index ) {

			let y = this.data.array[ index * this.data.stride + this.offset + 1 ];

			if ( this.normalized ) y = denormalize( y, this.array );

			return y;

		}

		/**
		 * Returns the z component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @return {number} The z component.
		 */
		getZ( index ) {

			let z = this.data.array[ index * this.data.stride + this.offset + 2 ];

			if ( this.normalized ) z = denormalize( z, this.array );

			return z;

		}

		/**
		 * Returns the w component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @return {number} The w component.
		 */
		getW( index ) {

			let w = this.data.array[ index * this.data.stride + this.offset + 3 ];

			if ( this.normalized ) w = denormalize( w, this.array );

			return w;

		}

		/**
		 * Sets the x and y component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} x - The value for the x component to set.
		 * @param {number} y - The value for the y component to set.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		setXY( index, x, y ) {

			index = index * this.data.stride + this.offset;

			if ( this.normalized ) {

				x = normalize( x, this.array );
				y = normalize( y, this.array );

			}

			this.data.array[ index + 0 ] = x;
			this.data.array[ index + 1 ] = y;

			return this;

		}

		/**
		 * Sets the x, y and z component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} x - The value for the x component to set.
		 * @param {number} y - The value for the y component to set.
		 * @param {number} z - The value for the z component to set.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		setXYZ( index, x, y, z ) {

			index = index * this.data.stride + this.offset;

			if ( this.normalized ) {

				x = normalize( x, this.array );
				y = normalize( y, this.array );
				z = normalize( z, this.array );

			}

			this.data.array[ index + 0 ] = x;
			this.data.array[ index + 1 ] = y;
			this.data.array[ index + 2 ] = z;

			return this;

		}

		/**
		 * Sets the x, y, z and w component of the vector at the given index.
		 *
		 * @param {number} index - The index into the buffer attribute.
		 * @param {number} x - The value for the x component to set.
		 * @param {number} y - The value for the y component to set.
		 * @param {number} z - The value for the z component to set.
		 * @param {number} w - The value for the w component to set.
		 * @return {InterleavedBufferAttribute} A reference to this instance.
		 */
		setXYZW( index, x, y, z, w ) {

			index = index * this.data.stride + this.offset;

			if ( this.normalized ) {

				x = normalize( x, this.array );
				y = normalize( y, this.array );
				z = normalize( z, this.array );
				w = normalize( w, this.array );

			}

			this.data.array[ index + 0 ] = x;
			this.data.array[ index + 1 ] = y;
			this.data.array[ index + 2 ] = z;
			this.data.array[ index + 3 ] = w;

			return this;

		}

		/**
		 * Returns a new buffer attribute with copied values from this instance.
		 *
		 * If no parameter is provided, cloning an interleaved buffer attribute will de-interleave buffer data.
		 *
		 * @param {Object} [data] - An object with interleaved buffers that allows to retain the interleaved property.
		 * @return {BufferAttribute|InterleavedBufferAttribute} A clone of this instance.
		 */
		clone( data ) {

			if ( data === undefined ) {

				console.log( 'THREE.InterleavedBufferAttribute.clone(): Cloning an interleaved buffer attribute will de-interleave buffer data.' );

				const array = [];

				for ( let i = 0; i < this.count; i ++ ) {

					const index = i * this.data.stride + this.offset;

					for ( let j = 0; j < this.itemSize; j ++ ) {

						array.push( this.data.array[ index + j ] );

					}

				}

				return new BufferAttribute( new this.array.constructor( array ), this.itemSize, this.normalized );

			} else {

				if ( data.interleavedBuffers === undefined ) {

					data.interleavedBuffers = {};

				}

				if ( data.interleavedBuffers[ this.data.uuid ] === undefined ) {

					data.interleavedBuffers[ this.data.uuid ] = this.data.clone( data );

				}

				return new InterleavedBufferAttribute( data.interleavedBuffers[ this.data.uuid ], this.itemSize, this.offset, this.normalized );

			}

		}

		/**
		 * Serializes the buffer attribute into JSON.
		 *
		 * If no parameter is provided, cloning an interleaved buffer attribute will de-interleave buffer data.
		 *
		 * @param {Object} [data] - An optional value holding meta information about the serialization.
		 * @return {Object} A JSON object representing the serialized buffer attribute.
		 */
		toJSON( data ) {

			if ( data === undefined ) {

				console.log( 'THREE.InterleavedBufferAttribute.toJSON(): Serializing an interleaved buffer attribute will de-interleave buffer data.' );

				const array = [];

				for ( let i = 0; i < this.count; i ++ ) {

					const index = i * this.data.stride + this.offset;

					for ( let j = 0; j < this.itemSize; j ++ ) {

						array.push( this.data.array[ index + j ] );

					}

				}

				// de-interleave data and save it as an ordinary buffer attribute for now

				return {
					itemSize: this.itemSize,
					type: this.array.constructor.name,
					array: array,
					normalized: this.normalized
				};

			} else {

				// save as true interleaved attribute

				if ( data.interleavedBuffers === undefined ) {

					data.interleavedBuffers = {};

				}

				if ( data.interleavedBuffers[ this.data.uuid ] === undefined ) {

					data.interleavedBuffers[ this.data.uuid ] = this.data.toJSON( data );

				}

				return {
					isInterleavedBufferAttribute: true,
					itemSize: this.itemSize,
					data: this.data.uuid,
					offset: this.offset,
					normalized: this.normalized
				};

			}

		}

	}

	const _basePosition = /*@__PURE__*/ new Vector3();

	const _skinIndex = /*@__PURE__*/ new Vector4();
	const _skinWeight = /*@__PURE__*/ new Vector4();

	const _vector3 = /*@__PURE__*/ new Vector3();
	const _matrix4 = /*@__PURE__*/ new Matrix4();
	const _vertex = /*@__PURE__*/ new Vector3();

	const _sphere$5 = /*@__PURE__*/ new Sphere();
	const _inverseMatrix$2 = /*@__PURE__*/ new Matrix4();
	const _ray$2 = /*@__PURE__*/ new Ray();

	/**
	 * A mesh that has a {@link Skeleton} that can then be used to animate the
	 * vertices of the geometry with skinning/skeleton animation.
	 *
	 * Next to a valid skeleton, the skinned mesh requires skin indices and weights
	 * as buffer attributes in its geometry. These attribute define which bones affect a single
	 * vertex to a certain extend.
	 *
	 * Typically skinned meshes are not created manually but loaders like {@link GLTFLoader}
	 * or {@link FBXLoader } import respective models.
	 *
	 * @augments Mesh
	 */
	class SkinnedMesh extends Mesh {

		/**
		 * Constructs a new skinned mesh.
		 *
		 * @param {BufferGeometry} [geometry] - The mesh geometry.
		 * @param {Material|Array<Material>} [material] - The mesh material.
		 */
		constructor( geometry, material ) {

			super( geometry, material );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isSkinnedMesh = true;

			this.type = 'SkinnedMesh';

			/**
			 * `AttachedBindMode` means the skinned mesh shares the same world space as the skeleton.
			 * This is not true when using `DetachedBindMode` which is useful when sharing a skeleton
			 * across multiple skinned meshes.
			 *
			 * @type {(AttachedBindMode|DetachedBindMode)}
			 * @default AttachedBindMode
			 */
			this.bindMode = AttachedBindMode;

			/**
			 * The base matrix that is used for the bound bone transforms.
			 *
			 * @type {Matrix4}
			 */
			this.bindMatrix = new Matrix4();

			/**
			 * The base matrix that is used for resetting the bound bone transforms.
			 *
			 * @type {Matrix4}
			 */
			this.bindMatrixInverse = new Matrix4();

			/**
			 * The bounding box of the skinned mesh. Can be computed via {@link SkinnedMesh#computeBoundingBox}.
			 *
			 * @type {?Box3}
			 * @default null
			 */
			this.boundingBox = null;

			/**
			 * The bounding sphere of the skinned mesh. Can be computed via {@link SkinnedMesh#computeBoundingSphere}.
			 *
			 * @type {?Sphere}
			 * @default null
			 */
			this.boundingSphere = null;

		}

		/**
		 * Computes the bounding box of the skinned mesh, and updates {@link SkinnedMesh#boundingBox}.
		 * The bounding box is not automatically computed by the engine; this method must be called by your app.
		 * If the skinned mesh is animated, the bounding box should be recomputed per frame in order to reflect
		 * the current animation state.
		 */
		computeBoundingBox() {

			const geometry = this.geometry;

			if ( this.boundingBox === null ) {

				this.boundingBox = new Box3();

			}

			this.boundingBox.makeEmpty();

			const positionAttribute = geometry.getAttribute( 'position' );

			for ( let i = 0; i < positionAttribute.count; i ++ ) {

				this.getVertexPosition( i, _vertex );
				this.boundingBox.expandByPoint( _vertex );

			}

		}

		/**
		 * Computes the bounding sphere of the skinned mesh, and updates {@link SkinnedMesh#boundingSphere}.
		 * The bounding sphere is automatically computed by the engine once when it is needed, e.g., for ray casting
		 * and view frustum culling. If the skinned mesh is animated, the bounding sphere should be recomputed
		 * per frame in order to reflect the current animation state.
		 */
		computeBoundingSphere() {

			const geometry = this.geometry;

			if ( this.boundingSphere === null ) {

				this.boundingSphere = new Sphere();

			}

			this.boundingSphere.makeEmpty();

			const positionAttribute = geometry.getAttribute( 'position' );

			for ( let i = 0; i < positionAttribute.count; i ++ ) {

				this.getVertexPosition( i, _vertex );
				this.boundingSphere.expandByPoint( _vertex );

			}

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.bindMode = source.bindMode;
			this.bindMatrix.copy( source.bindMatrix );
			this.bindMatrixInverse.copy( source.bindMatrixInverse );

			this.skeleton = source.skeleton;

			if ( source.boundingBox !== null ) this.boundingBox = source.boundingBox.clone();
			if ( source.boundingSphere !== null ) this.boundingSphere = source.boundingSphere.clone();

			return this;

		}

		raycast( raycaster, intersects ) {

			const material = this.material;
			const matrixWorld = this.matrixWorld;

			if ( material === undefined ) return;

			// test with bounding sphere in world space

			if ( this.boundingSphere === null ) this.computeBoundingSphere();

			_sphere$5.copy( this.boundingSphere );
			_sphere$5.applyMatrix4( matrixWorld );

			if ( raycaster.ray.intersectsSphere( _sphere$5 ) === false ) return;

			// convert ray to local space of skinned mesh

			_inverseMatrix$2.copy( matrixWorld ).invert();
			_ray$2.copy( raycaster.ray ).applyMatrix4( _inverseMatrix$2 );

			// test with bounding box in local space

			if ( this.boundingBox !== null ) {

				if ( _ray$2.intersectsBox( this.boundingBox ) === false ) return;

			}

			// test for intersections with geometry

			this._computeIntersections( raycaster, intersects, _ray$2 );

		}

		getVertexPosition( index, target ) {

			super.getVertexPosition( index, target );

			this.applyBoneTransform( index, target );

			return target;

		}

		/**
		 * Binds the given skeleton to the skinned mesh.
		 *
		 * @param {Skeleton} skeleton - The skeleton to bind.
		 * @param {Matrix4} [bindMatrix] - The bind matrix. If no bind matrix is provided,
		 * the skinned mesh's world matrix will be used instead.
		 */
		bind( skeleton, bindMatrix ) {

			this.skeleton = skeleton;

			if ( bindMatrix === undefined ) {

				this.updateMatrixWorld( true );

				this.skeleton.calculateInverses();

				bindMatrix = this.matrixWorld;

			}

			this.bindMatrix.copy( bindMatrix );
			this.bindMatrixInverse.copy( bindMatrix ).invert();

		}

		/**
		 * This method sets the skinned mesh in the rest pose).
		 */
		pose() {

			this.skeleton.pose();

		}

		/**
		 * Normalizes the skin weights which are defined as a buffer attribute
		 * in the skinned mesh's geometry.
		 */
		normalizeSkinWeights() {

			const vector = new Vector4();

			const skinWeight = this.geometry.attributes.skinWeight;

			for ( let i = 0, l = skinWeight.count; i < l; i ++ ) {

				vector.fromBufferAttribute( skinWeight, i );

				const scale = 1.0 / vector.manhattanLength();

				if ( scale !== Infinity ) {

					vector.multiplyScalar( scale );

				} else {

					vector.set( 1, 0, 0, 0 ); // do something reasonable

				}

				skinWeight.setXYZW( i, vector.x, vector.y, vector.z, vector.w );

			}

		}

		updateMatrixWorld( force ) {

			super.updateMatrixWorld( force );

			if ( this.bindMode === AttachedBindMode ) {

				this.bindMatrixInverse.copy( this.matrixWorld ).invert();

			} else if ( this.bindMode === DetachedBindMode ) {

				this.bindMatrixInverse.copy( this.bindMatrix ).invert();

			} else {

				console.warn( 'THREE.SkinnedMesh: Unrecognized bindMode: ' + this.bindMode );

			}

		}

		/**
		 * Applies the bone transform associated with the given index to the given
		 * vertex position. Returns the updated vector.
		 *
		 * @param {number} index - The vertex index.
		 * @param {Vector3} target - The target object that is used to store the method's result.
		 * the skinned mesh's world matrix will be used instead.
		 * @return {Vector3} The updated vertex position.
		 */
		applyBoneTransform( index, target ) {

			const skeleton = this.skeleton;
			const geometry = this.geometry;

			_skinIndex.fromBufferAttribute( geometry.attributes.skinIndex, index );
			_skinWeight.fromBufferAttribute( geometry.attributes.skinWeight, index );

			_basePosition.copy( target ).applyMatrix4( this.bindMatrix );

			target.set( 0, 0, 0 );

			for ( let i = 0; i < 4; i ++ ) {

				const weight = _skinWeight.getComponent( i );

				if ( weight !== 0 ) {

					const boneIndex = _skinIndex.getComponent( i );

					_matrix4.multiplyMatrices( skeleton.bones[ boneIndex ].matrixWorld, skeleton.boneInverses[ boneIndex ] );

					target.addScaledVector( _vector3.copy( _basePosition ).applyMatrix4( _matrix4 ), weight );

				}

			}

			return target.applyMatrix4( this.bindMatrixInverse );

		}

	}

	/**
	 * A bone which is part of a {@link Skeleton}. The skeleton in turn is used by
	 * the {@link SkinnedMesh}.
	 *
	 * ```js
	 * const root = new THREE.Bone();
	 * const child = new THREE.Bone();
	 *
	 * root.add( child );
	 * child.position.y = 5;
	 * ```
	 *
	 * @augments Object3D
	 */
	class Bone extends Object3D {

		/**
		 * Constructs a new bone.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isBone = true;

			this.type = 'Bone';

		}

	}

	/**
	 * Creates a texture directly from raw buffer data.
	 *
	 * The interpretation of the data depends on type and format: If the type is
	 * `UnsignedByteType`, a `Uint8Array` will be useful for addressing the
	 * texel data. If the format is `RGBAFormat`, data needs four values for
	 * one texel; Red, Green, Blue and Alpha (typically the opacity).
	 *
	 * @augments Texture
	 */
	class DataTexture extends Texture {

		/**
		 * Constructs a new data texture.
		 *
		 * @param {?TypedArray} [data=null] - The buffer data.
		 * @param {number} [width=1] - The width of the texture.
		 * @param {number} [height=1] - The height of the texture.
		 * @param {number} [format=RGBAFormat] - The texture format.
		 * @param {number} [type=UnsignedByteType] - The texture type.
		 * @param {number} [mapping=Texture.DEFAULT_MAPPING] - The texture mapping.
		 * @param {number} [wrapS=ClampToEdgeWrapping] - The wrapS value.
		 * @param {number} [wrapT=ClampToEdgeWrapping] - The wrapT value.
		 * @param {number} [magFilter=NearestFilter] - The mag filter value.
		 * @param {number} [minFilter=NearestFilter] - The min filter value.
		 * @param {number} [anisotropy=Texture.DEFAULT_ANISOTROPY] - The anisotropy value.
		 * @param {string} [colorSpace=NoColorSpace] - The color space.
		 */
		constructor( data = null, width = 1, height = 1, format, type, mapping, wrapS, wrapT, magFilter = NearestFilter, minFilter = NearestFilter, anisotropy, colorSpace ) {

			super( null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isDataTexture = true;

			/**
			 * The image definition of a data texture.
			 *
			 * @type {{data:TypedArray,width:number,height:number}}
			 */
			this.image = { data: data, width: width, height: height };

			/**
			 * Whether to generate mipmaps (if possible) for a texture.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.generateMipmaps = false;

			/**
			 * If set to `true`, the texture is flipped along the vertical axis when
			 * uploaded to the GPU.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.flipY = false;

			/**
			 * Specifies the alignment requirements for the start of each pixel row in memory.
			 *
			 * Overwritten and set to `1` by default.
			 *
			 * @type {boolean}
			 * @default 1
			 */
			this.unpackAlignment = 1;

		}

	}

	const _offsetMatrix = /*@__PURE__*/ new Matrix4();
	const _identityMatrix = /*@__PURE__*/ new Matrix4();

	/**
	 * Class for representing the armatures in `three.js`. The skeleton
	 * is defined by a hierarchy of bones.
	 *
	 * ```js
	 * const bones = [];
	 *
	 * const shoulder = new THREE.Bone();
	 * const elbow = new THREE.Bone();
	 * const hand = new THREE.Bone();
	 *
	 * shoulder.add( elbow );
	 * elbow.add( hand );
	 *
	 * bones.push( shoulder , elbow, hand);
	 *
	 * shoulder.position.y = -5;
	 * elbow.position.y = 0;
	 * hand.position.y = 5;
	 *
	 * const armSkeleton = new THREE.Skeleton( bones );
	 * ```
	 */
	class Skeleton {

		/**
		 * Constructs a new skeleton.
		 *
		 * @param {Array<Bone>} [bones] - An array of bones.
		 * @param {Array<Matrix4>} [boneInverses] - An array of bone inverse matrices.
		 * If not provided, these matrices will be computed automatically via {@link Skeleton#calculateInverses}.
		 */
		constructor( bones = [], boneInverses = [] ) {

			this.uuid = generateUUID();

			/**
			 * An array of bones defining the skeleton.
			 *
			 * @type {Array<Bone>}
			 */
			this.bones = bones.slice( 0 );

			/**
			 * An array of bone inverse matrices.
			 *
			 * @type {Array<Matrix4>}
			 */
			this.boneInverses = boneInverses;

			/**
			 * An array buffer holding the bone data.
			 * Input data for {@link Skeleton#boneTexture}.
			 *
			 * @type {?Float32Array}
			 * @default null
			 */
			this.boneMatrices = null;

			/**
			 * A texture holding the bone data for use
			 * in the vertex shader.
			 *
			 * @type {?DataTexture}
			 * @default null
			 */
			this.boneTexture = null;

			this.init();

		}

		/**
		 * Initializes the skeleton. This method gets automatically called by the constructor
		 * but depending on how the skeleton is created it might be necessary to call this method
		 * manually.
		 */
		init() {

			const bones = this.bones;
			const boneInverses = this.boneInverses;

			this.boneMatrices = new Float32Array( bones.length * 16 );

			// calculate inverse bone matrices if necessary

			if ( boneInverses.length === 0 ) {

				this.calculateInverses();

			} else {

				// handle special case

				if ( bones.length !== boneInverses.length ) {

					console.warn( 'THREE.Skeleton: Number of inverse bone matrices does not match amount of bones.' );

					this.boneInverses = [];

					for ( let i = 0, il = this.bones.length; i < il; i ++ ) {

						this.boneInverses.push( new Matrix4() );

					}

				}

			}

		}

		/**
		 * Computes the bone inverse matrices. This method resets {@link Skeleton#boneInverses}
		 * and fills it with new matrices.
		 */
		calculateInverses() {

			this.boneInverses.length = 0;

			for ( let i = 0, il = this.bones.length; i < il; i ++ ) {

				const inverse = new Matrix4();

				if ( this.bones[ i ] ) {

					inverse.copy( this.bones[ i ].matrixWorld ).invert();

				}

				this.boneInverses.push( inverse );

			}

		}

		/**
		 * Resets the skeleton to the base pose.
		 */
		pose() {

			// recover the bind-time world matrices

			for ( let i = 0, il = this.bones.length; i < il; i ++ ) {

				const bone = this.bones[ i ];

				if ( bone ) {

					bone.matrixWorld.copy( this.boneInverses[ i ] ).invert();

				}

			}

			// compute the local matrices, positions, rotations and scales

			for ( let i = 0, il = this.bones.length; i < il; i ++ ) {

				const bone = this.bones[ i ];

				if ( bone ) {

					if ( bone.parent && bone.parent.isBone ) {

						bone.matrix.copy( bone.parent.matrixWorld ).invert();
						bone.matrix.multiply( bone.matrixWorld );

					} else {

						bone.matrix.copy( bone.matrixWorld );

					}

					bone.matrix.decompose( bone.position, bone.quaternion, bone.scale );

				}

			}

		}

		/**
		 * Resets the skeleton to the base pose.
		 */
		update() {

			const bones = this.bones;
			const boneInverses = this.boneInverses;
			const boneMatrices = this.boneMatrices;
			const boneTexture = this.boneTexture;

			// flatten bone matrices to array

			for ( let i = 0, il = bones.length; i < il; i ++ ) {

				// compute the offset between the current and the original transform

				const matrix = bones[ i ] ? bones[ i ].matrixWorld : _identityMatrix;

				_offsetMatrix.multiplyMatrices( matrix, boneInverses[ i ] );
				_offsetMatrix.toArray( boneMatrices, i * 16 );

			}

			if ( boneTexture !== null ) {

				boneTexture.needsUpdate = true;

			}

		}

		/**
		 * Returns a new skeleton with copied values from this instance.
		 *
		 * @return {Skeleton} A clone of this instance.
		 */
		clone() {

			return new Skeleton( this.bones, this.boneInverses );

		}

		/**
		 * Computes a data texture for passing bone data to the vertex shader.
		 *
		 * @return {Skeleton} A reference of this instance.
		 */
		computeBoneTexture() {

			// layout (1 matrix = 4 pixels)
			//      RGBA RGBA RGBA RGBA (=> column1, column2, column3, column4)
			//  with  8x8  pixel texture max   16 bones * 4 pixels =  (8 * 8)
			//       16x16 pixel texture max   64 bones * 4 pixels = (16 * 16)
			//       32x32 pixel texture max  256 bones * 4 pixels = (32 * 32)
			//       64x64 pixel texture max 1024 bones * 4 pixels = (64 * 64)

			let size = Math.sqrt( this.bones.length * 4 ); // 4 pixels needed for 1 matrix
			size = Math.ceil( size / 4 ) * 4;
			size = Math.max( size, 4 );

			const boneMatrices = new Float32Array( size * size * 4 ); // 4 floats per RGBA pixel
			boneMatrices.set( this.boneMatrices ); // copy current values

			const boneTexture = new DataTexture( boneMatrices, size, size, RGBAFormat, FloatType );
			boneTexture.needsUpdate = true;

			this.boneMatrices = boneMatrices;
			this.boneTexture = boneTexture;

			return this;

		}

		/**
		 * Searches through the skeleton's bone array and returns the first with a
		 * matching name.
		 *
		 * @param {string} name - The name of the bone.
		 * @return {Bone|undefined} The found bone. `undefined` if no bone has been found.
		 */
		getBoneByName( name ) {

			for ( let i = 0, il = this.bones.length; i < il; i ++ ) {

				const bone = this.bones[ i ];

				if ( bone.name === name ) {

					return bone;

				}

			}

			return undefined;

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 */
		dispose( ) {

			if ( this.boneTexture !== null ) {

				this.boneTexture.dispose();

				this.boneTexture = null;

			}

		}

		/**
		 * Setups the skeleton by the given JSON and bones.
		 *
		 * @param {Object} json - The skeleton as serialized JSON.
		 * @param {Object<string, Bone>} bones - An array of bones.
		 * @return {Skeleton} A reference of this instance.
		 */
		fromJSON( json, bones ) {

			this.uuid = json.uuid;

			for ( let i = 0, l = json.bones.length; i < l; i ++ ) {

				const uuid = json.bones[ i ];
				let bone = bones[ uuid ];

				if ( bone === undefined ) {

					console.warn( 'THREE.Skeleton: No bone found with UUID:', uuid );
					bone = new Bone();

				}

				this.bones.push( bone );
				this.boneInverses.push( new Matrix4().fromArray( json.boneInverses[ i ] ) );

			}

			this.init();

			return this;

		}

		/**
		 * Serializes the skeleton into JSON.
		 *
		 * @return {Object} A JSON object representing the serialized skeleton.
		 * @see {@link ObjectLoader#parse}
		 */
		toJSON() {

			const data = {
				metadata: {
					version: 4.7,
					type: 'Skeleton',
					generator: 'Skeleton.toJSON'
				},
				bones: [],
				boneInverses: []
			};

			data.uuid = this.uuid;

			const bones = this.bones;
			const boneInverses = this.boneInverses;

			for ( let i = 0, l = bones.length; i < l; i ++ ) {

				const bone = bones[ i ];
				data.bones.push( bone.uuid );

				const boneInverse = boneInverses[ i ];
				data.boneInverses.push( boneInverse.toArray() );

			}

			return data;

		}

	}

	/**
	 * An instanced version of a buffer attribute.
	 *
	 * @augments BufferAttribute
	 */
	class InstancedBufferAttribute extends BufferAttribute {

		/**
		 * Constructs a new instanced buffer attribute.
		 *
		 * @param {TypedArray} array - The array holding the attribute data.
		 * @param {number} itemSize - The item size.
		 * @param {boolean} [normalized=false] - Whether the data are normalized or not.
		 * @param {number} [meshPerAttribute=1] - How often a value of this buffer attribute should be repeated.
		 */
		constructor( array, itemSize, normalized, meshPerAttribute = 1 ) {

			super( array, itemSize, normalized );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isInstancedBufferAttribute = true;

			/**
			 * Defines how often a value of this buffer attribute should be repeated. A
			 * value of one means that each value of the instanced attribute is used for
			 * a single instance. A value of two means that each value is used for two
			 * consecutive instances (and so on).
			 *
			 * @type {number}
			 * @default 1
			 */
			this.meshPerAttribute = meshPerAttribute;

		}

		copy( source ) {

			super.copy( source );

			this.meshPerAttribute = source.meshPerAttribute;

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.meshPerAttribute = this.meshPerAttribute;

			data.isInstancedBufferAttribute = true;

			return data;

		}

	}

	const _instanceLocalMatrix = /*@__PURE__*/ new Matrix4();
	const _instanceWorldMatrix = /*@__PURE__*/ new Matrix4();

	const _instanceIntersects = [];

	const _box3 = /*@__PURE__*/ new Box3();
	const _identity = /*@__PURE__*/ new Matrix4();
	const _mesh$1 = /*@__PURE__*/ new Mesh();
	const _sphere$4 = /*@__PURE__*/ new Sphere();

	/**
	 * A special version of a mesh with instanced rendering support. Use
	 * this class if you have to render a large number of objects with the same
	 * geometry and material(s) but with different world transformations. The usage
	 * of 'InstancedMesh' will help you to reduce the number of draw calls and thus
	 * improve the overall rendering performance in your application.
	 *
	 * @augments Mesh
	 */
	class InstancedMesh extends Mesh {

		/**
		 * Constructs a new instanced mesh.
		 *
		 * @param {BufferGeometry} [geometry] - The mesh geometry.
		 * @param {Material|Array<Material>} [material] - The mesh material.
		 * @param {number} count - The number of instances.
		 */
		constructor( geometry, material, count ) {

			super( geometry, material );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isInstancedMesh = true;

			/**
			 * Represents the local transformation of all instances. You have to set its
			 * {@link BufferAttribute#needsUpdate} flag to true if you modify instanced data
			 * via {@link InstancedMesh#setMatrixAt}.
			 *
			 * @type {InstancedBufferAttribute}
			 */
			this.instanceMatrix = new InstancedBufferAttribute( new Float32Array( count * 16 ), 16 );

			/**
			 * Represents the color of all instances. You have to set its
			 * {@link BufferAttribute#needsUpdate} flag to true if you modify instanced data
			 * via {@link InstancedMesh#setColorAt}.
			 *
			 * @type {?InstancedBufferAttribute}
			 * @default null
			 */
			this.instanceColor = null;

			/**
			 * Represents the morph target weights of all instances. You have to set its
			 * {@link Texture#needsUpdate} flag to true if you modify instanced data
			 * via {@link InstancedMesh#setMorphAt}.
			 *
			 * @type {?DataTexture}
			 * @default null
			 */
			this.morphTexture = null;

			/**
			 * The number of instances.
			 *
			 * @type {number}
			 */
			this.count = count;

			/**
			 * The bounding box of the instanced mesh. Can be computed via {@link InstancedMesh#computeBoundingBox}.
			 *
			 * @type {?Box3}
			 * @default null
			 */
			this.boundingBox = null;

			/**
			 * The bounding sphere of the instanced mesh. Can be computed via {@link InstancedMesh#computeBoundingSphere}.
			 *
			 * @type {?Sphere}
			 * @default null
			 */
			this.boundingSphere = null;

			for ( let i = 0; i < count; i ++ ) {

				this.setMatrixAt( i, _identity );

			}

		}

		/**
		 * Computes the bounding box of the instanced mesh, and updates {@link InstancedMesh#boundingBox}.
		 * The bounding box is not automatically computed by the engine; this method must be called by your app.
		 * You may need to recompute the bounding box if an instance is transformed via {@link InstancedMesh#setMatrixAt}.
		 */
		computeBoundingBox() {

			const geometry = this.geometry;
			const count = this.count;

			if ( this.boundingBox === null ) {

				this.boundingBox = new Box3();

			}

			if ( geometry.boundingBox === null ) {

				geometry.computeBoundingBox();

			}

			this.boundingBox.makeEmpty();

			for ( let i = 0; i < count; i ++ ) {

				this.getMatrixAt( i, _instanceLocalMatrix );

				_box3.copy( geometry.boundingBox ).applyMatrix4( _instanceLocalMatrix );

				this.boundingBox.union( _box3 );

			}

		}

		/**
		 * Computes the bounding sphere of the instanced mesh, and updates {@link InstancedMesh#boundingSphere}
		 * The engine automatically computes the bounding sphere when it is needed, e.g., for ray casting or view frustum culling.
		 * You may need to recompute the bounding sphere if an instance is transformed via {@link InstancedMesh#setMatrixAt}.
		 */
		computeBoundingSphere() {

			const geometry = this.geometry;
			const count = this.count;

			if ( this.boundingSphere === null ) {

				this.boundingSphere = new Sphere();

			}

			if ( geometry.boundingSphere === null ) {

				geometry.computeBoundingSphere();

			}

			this.boundingSphere.makeEmpty();

			for ( let i = 0; i < count; i ++ ) {

				this.getMatrixAt( i, _instanceLocalMatrix );

				_sphere$4.copy( geometry.boundingSphere ).applyMatrix4( _instanceLocalMatrix );

				this.boundingSphere.union( _sphere$4 );

			}

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.instanceMatrix.copy( source.instanceMatrix );

			if ( source.morphTexture !== null ) this.morphTexture = source.morphTexture.clone();
			if ( source.instanceColor !== null ) this.instanceColor = source.instanceColor.clone();

			this.count = source.count;

			if ( source.boundingBox !== null ) this.boundingBox = source.boundingBox.clone();
			if ( source.boundingSphere !== null ) this.boundingSphere = source.boundingSphere.clone();

			return this;

		}

		/**
		 * Gets the color of the defined instance.
		 *
		 * @param {number} index - The instance index.
		 * @param {Color} color - The target object that is used to store the method's result.
		 */
		getColorAt( index, color ) {

			color.fromArray( this.instanceColor.array, index * 3 );

		}

		/**
		 * Gets the local transformation matrix of the defined instance.
		 *
		 * @param {number} index - The instance index.
		 * @param {Matrix4} matrix - The target object that is used to store the method's result.
		 */
		getMatrixAt( index, matrix ) {

			matrix.fromArray( this.instanceMatrix.array, index * 16 );

		}

		/**
		 * Gets the morph target weights of the defined instance.
		 *
		 * @param {number} index - The instance index.
		 * @param {Mesh} object - The target object that is used to store the method's result.
		 */
		getMorphAt( index, object ) {

			const objectInfluences = object.morphTargetInfluences;

			const array = this.morphTexture.source.data.data;

			const len = objectInfluences.length + 1; // All influences + the baseInfluenceSum

			const dataIndex = index * len + 1; // Skip the baseInfluenceSum at the beginning

			for ( let i = 0; i < objectInfluences.length; i ++ ) {

				objectInfluences[ i ] = array[ dataIndex + i ];

			}

		}

		raycast( raycaster, intersects ) {

			const matrixWorld = this.matrixWorld;
			const raycastTimes = this.count;

			_mesh$1.geometry = this.geometry;
			_mesh$1.material = this.material;

			if ( _mesh$1.material === undefined ) return;

			// test with bounding sphere first

			if ( this.boundingSphere === null ) this.computeBoundingSphere();

			_sphere$4.copy( this.boundingSphere );
			_sphere$4.applyMatrix4( matrixWorld );

			if ( raycaster.ray.intersectsSphere( _sphere$4 ) === false ) return;

			// now test each instance

			for ( let instanceId = 0; instanceId < raycastTimes; instanceId ++ ) {

				// calculate the world matrix for each instance

				this.getMatrixAt( instanceId, _instanceLocalMatrix );

				_instanceWorldMatrix.multiplyMatrices( matrixWorld, _instanceLocalMatrix );

				// the mesh represents this single instance

				_mesh$1.matrixWorld = _instanceWorldMatrix;

				_mesh$1.raycast( raycaster, _instanceIntersects );

				// process the result of raycast

				for ( let i = 0, l = _instanceIntersects.length; i < l; i ++ ) {

					const intersect = _instanceIntersects[ i ];
					intersect.instanceId = instanceId;
					intersect.object = this;
					intersects.push( intersect );

				}

				_instanceIntersects.length = 0;

			}

		}

		/**
		 * Sets the given color to the defined instance. Make sure you set the `needsUpdate` flag of
		 * {@link InstancedMesh#instanceColor} to `true` after updating all the colors.
		 *
		 * @param {number} index - The instance index.
		 * @param {Color} color - The instance color.
		 */
		setColorAt( index, color ) {

			if ( this.instanceColor === null ) {

				this.instanceColor = new InstancedBufferAttribute( new Float32Array( this.instanceMatrix.count * 3 ).fill( 1 ), 3 );

			}

			color.toArray( this.instanceColor.array, index * 3 );

		}

		/**
		 * Sets the given local transformation matrix to the defined instance. Make sure you set the `needsUpdate` flag of
		 * {@link InstancedMesh#instanceMatrix} to `true` after updating all the colors.
		 *
		 * @param {number} index - The instance index.
		 * @param {Matrix4} matrix - The local transformation.
		 */
		setMatrixAt( index, matrix ) {

			matrix.toArray( this.instanceMatrix.array, index * 16 );

		}

		/**
		 * Sets the morph target weights to the defined instance. Make sure you set the `needsUpdate` flag of
		 * {@link InstancedMesh#morphTexture} to `true` after updating all the influences.
		 *
		 * @param {number} index - The instance index.
		 * @param {Mesh} object -  A mesh which `morphTargetInfluences` property containing the morph target weights
		 * of a single instance.
		 */
		setMorphAt( index, object ) {

			const objectInfluences = object.morphTargetInfluences;

			const len = objectInfluences.length + 1; // morphBaseInfluence + all influences

			if ( this.morphTexture === null ) {

				this.morphTexture = new DataTexture( new Float32Array( len * this.count ), len, this.count, RedFormat, FloatType );

			}

			const array = this.morphTexture.source.data.data;

			let morphInfluencesSum = 0;

			for ( let i = 0; i < objectInfluences.length; i ++ ) {

				morphInfluencesSum += objectInfluences[ i ];

			}

			const morphBaseInfluence = this.geometry.morphTargetsRelative ? 1 : 1 - morphInfluencesSum;

			const dataIndex = len * index;

			array[ dataIndex ] = morphBaseInfluence;

			array.set( objectInfluences, dataIndex + 1 );

		}

		updateMorphTargets() {

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 */
		dispose() {

			this.dispatchEvent( { type: 'dispose' } );

			if ( this.morphTexture !== null ) {

				this.morphTexture.dispose();
				this.morphTexture = null;

			}

		}

	}

	const _vector1 = /*@__PURE__*/ new Vector3();
	const _vector2 = /*@__PURE__*/ new Vector3();
	const _normalMatrix = /*@__PURE__*/ new Matrix3();

	/**
	 * A two dimensional surface that extends infinitely in 3D space, represented
	 * in [Hessian normal form]{@link http://mathworld.wolfram.com/HessianNormalForm.html}
	 * by a unit length normal vector and a constant.
	 */
	class Plane {

		/**
		 * Constructs a new plane.
		 *
		 * @param {Vector3} [normal=(1,0,0)] - A unit length vector defining the normal of the plane.
		 * @param {number} [constant=0] - The signed distance from the origin to the plane.
		 */
		constructor( normal = new Vector3( 1, 0, 0 ), constant = 0 ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isPlane = true;

			/**
			 * A unit length vector defining the normal of the plane.
			 *
			 * @type {Vector3}
			 */
			this.normal = normal;

			/**
			 * The signed distance from the origin to the plane.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.constant = constant;

		}

		/**
		 * Sets the plane components by copying the given values.
		 *
		 * @param {Vector3} normal - The normal.
		 * @param {number} constant - The constant.
		 * @return {Plane} A reference to this plane.
		 */
		set( normal, constant ) {

			this.normal.copy( normal );
			this.constant = constant;

			return this;

		}

		/**
		 * Sets the plane components by defining `x`, `y`, `z` as the
		 * plane normal and `w` as the constant.
		 *
		 * @param {number} x - The value for the normal's x component.
		 * @param {number} y - The value for the normal's y component.
		 * @param {number} z - The value for the normal's z component.
		 * @param {number} w - The constant value.
		 * @return {Plane} A reference to this plane.
		 */
		setComponents( x, y, z, w ) {

			this.normal.set( x, y, z );
			this.constant = w;

			return this;

		}

		/**
		 * Sets the plane from the given normal and coplanar point (that is a point
		 * that lies onto the plane).
		 *
		 * @param {Vector3} normal - The normal.
		 * @param {Vector3} point - A coplanar point.
		 * @return {Plane} A reference to this plane.
		 */
		setFromNormalAndCoplanarPoint( normal, point ) {

			this.normal.copy( normal );
			this.constant = - point.dot( this.normal );

			return this;

		}

		/**
		 * Sets the plane from three coplanar points. The winding order is
		 * assumed to be counter-clockwise, and determines the direction of
		 * the plane normal.
		 *
		 * @param {Vector3} a - The first coplanar point.
		 * @param {Vector3} b - The second coplanar point.
		 * @param {Vector3} c - The third coplanar point.
		 * @return {Plane} A reference to this plane.
		 */
		setFromCoplanarPoints( a, b, c ) {

			const normal = _vector1.subVectors( c, b ).cross( _vector2.subVectors( a, b ) ).normalize();

			// Q: should an error be thrown if normal is zero (e.g. degenerate plane)?

			this.setFromNormalAndCoplanarPoint( normal, a );

			return this;

		}

		/**
		 * Copies the values of the given plane to this instance.
		 *
		 * @param {Plane} plane - The plane to copy.
		 * @return {Plane} A reference to this plane.
		 */
		copy( plane ) {

			this.normal.copy( plane.normal );
			this.constant = plane.constant;

			return this;

		}

		/**
		 * Normalizes the plane normal and adjusts the constant accordingly.
		 *
		 * @return {Plane} A reference to this plane.
		 */
		normalize() {

			// Note: will lead to a divide by zero if the plane is invalid.

			const inverseNormalLength = 1.0 / this.normal.length();
			this.normal.multiplyScalar( inverseNormalLength );
			this.constant *= inverseNormalLength;

			return this;

		}

		/**
		 * Negates both the plane normal and the constant.
		 *
		 * @return {Plane} A reference to this plane.
		 */
		negate() {

			this.constant *= -1;
			this.normal.negate();

			return this;

		}

		/**
		 * Returns the signed distance from the given point to this plane.
		 *
		 * @param {Vector3} point - The point to compute the distance for.
		 * @return {number} The signed distance.
		 */
		distanceToPoint( point ) {

			return this.normal.dot( point ) + this.constant;

		}

		/**
		 * Returns the signed distance from the given sphere to this plane.
		 *
		 * @param {Sphere} sphere - The sphere to compute the distance for.
		 * @return {number} The signed distance.
		 */
		distanceToSphere( sphere ) {

			return this.distanceToPoint( sphere.center ) - sphere.radius;

		}

		/**
		 * Projects a the given point onto the plane.
		 *
		 * @param {Vector3} point - The point to project.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The projected point on the plane.
		 */
		projectPoint( point, target ) {

			return target.copy( point ).addScaledVector( this.normal, - this.distanceToPoint( point ) );

		}

		/**
		 * Returns the intersection point of the passed line and the plane. Returns
		 * `null` if the line does not intersect. Returns the line's starting point if
		 * the line is coplanar with the plane.
		 *
		 * @param {Line3} line - The line to compute the intersection for.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {?Vector3} The intersection point.
		 */
		intersectLine( line, target ) {

			const direction = line.delta( _vector1 );

			const denominator = this.normal.dot( direction );

			if ( denominator === 0 ) {

				// line is coplanar, return origin
				if ( this.distanceToPoint( line.start ) === 0 ) {

					return target.copy( line.start );

				}

				// Unsure if this is the correct method to handle this case.
				return null;

			}

			const t = - ( line.start.dot( this.normal ) + this.constant ) / denominator;

			if ( t < 0 || t > 1 ) {

				return null;

			}

			return target.copy( line.start ).addScaledVector( direction, t );

		}

		/**
		 * Returns `true` if the given line segment intersects with (passes through) the plane.
		 *
		 * @param {Line3} line - The line to test.
		 * @return {boolean} Whether the given line segment intersects with the plane or not.
		 */
		intersectsLine( line ) {

			// Note: this tests if a line intersects the plane, not whether it (or its end-points) are coplanar with it.

			const startSign = this.distanceToPoint( line.start );
			const endSign = this.distanceToPoint( line.end );

			return ( startSign < 0 && endSign > 0 ) || ( endSign < 0 && startSign > 0 );

		}

		/**
		 * Returns `true` if the given bounding box intersects with the plane.
		 *
		 * @param {Box3} box - The bounding box to test.
		 * @return {boolean} Whether the given bounding box intersects with the plane or not.
		 */
		intersectsBox( box ) {

			return box.intersectsPlane( this );

		}

		/**
		 * Returns `true` if the given bounding sphere intersects with the plane.
		 *
		 * @param {Sphere} sphere - The bounding sphere to test.
		 * @return {boolean} Whether the given bounding sphere intersects with the plane or not.
		 */
		intersectsSphere( sphere ) {

			return sphere.intersectsPlane( this );

		}

		/**
		 * Returns a coplanar vector to the plane, by calculating the
		 * projection of the normal at the origin onto the plane.
		 *
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The coplanar point.
		 */
		coplanarPoint( target ) {

			return target.copy( this.normal ).multiplyScalar( - this.constant );

		}

		/**
		 * Apply a 4x4 matrix to the plane. The matrix must be an affine, homogeneous transform.
		 *
		 * The optional normal matrix can be pre-computed like so:
		 * ```js
		 * const optionalNormalMatrix = new THREE.Matrix3().getNormalMatrix( matrix );
		 * ```
		 *
		 * @param {Matrix4} matrix - The transformation matrix.
		 * @param {Matrix4} [optionalNormalMatrix] - A pre-computed normal matrix.
		 * @return {Plane} A reference to this plane.
		 */
		applyMatrix4( matrix, optionalNormalMatrix ) {

			const normalMatrix = optionalNormalMatrix || _normalMatrix.getNormalMatrix( matrix );

			const referencePoint = this.coplanarPoint( _vector1 ).applyMatrix4( matrix );

			const normal = this.normal.applyMatrix3( normalMatrix ).normalize();

			this.constant = - referencePoint.dot( normal );

			return this;

		}

		/**
		 * Translates the plane by the distance defined by the given offset vector.
		 * Note that this only affects the plane constant and will not affect the normal vector.
		 *
		 * @param {Vector3} offset - The offset vector.
		 * @return {Plane} A reference to this plane.
		 */
		translate( offset ) {

			this.constant -= offset.dot( this.normal );

			return this;

		}

		/**
		 * Returns `true` if this plane is equal with the given one.
		 *
		 * @param {Plane} plane - The plane to test for equality.
		 * @return {boolean} Whether this plane is equal with the given one.
		 */
		equals( plane ) {

			return plane.normal.equals( this.normal ) && ( plane.constant === this.constant );

		}

		/**
		 * Returns a new plane with copied values from this instance.
		 *
		 * @return {Plane} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

	}

	const _sphere$3 = /*@__PURE__*/ new Sphere();
	const _vector$6 = /*@__PURE__*/ new Vector3();

	/**
	 * Frustums are used to determine what is inside the camera's field of view.
	 * They help speed up the rendering process - objects which lie outside a camera's
	 * frustum can safely be excluded from rendering.
	 *
	 * This class is mainly intended for use internally by a renderer.
	 */
	class Frustum {

		/**
		 * Constructs a new frustum.
		 *
		 * @param {Plane} [p0] - The first plane that encloses the frustum.
		 * @param {Plane} [p1] - The second plane that encloses the frustum.
		 * @param {Plane} [p2] - The third plane that encloses the frustum.
		 * @param {Plane} [p3] - The fourth plane that encloses the frustum.
		 * @param {Plane} [p4] - The fifth plane that encloses the frustum.
		 * @param {Plane} [p5] - The sixth plane that encloses the frustum.
		 */
		constructor( p0 = new Plane(), p1 = new Plane(), p2 = new Plane(), p3 = new Plane(), p4 = new Plane(), p5 = new Plane() ) {

			/**
			 * This array holds the planes that enclose the frustum.
			 *
			 * @type {Array<Plane>}
			 */
			this.planes = [ p0, p1, p2, p3, p4, p5 ];

		}

		/**
		 * Sets the frustum planes by copying the given planes.
		 *
		 * @param {Plane} [p0] - The first plane that encloses the frustum.
		 * @param {Plane} [p1] - The second plane that encloses the frustum.
		 * @param {Plane} [p2] - The third plane that encloses the frustum.
		 * @param {Plane} [p3] - The fourth plane that encloses the frustum.
		 * @param {Plane} [p4] - The fifth plane that encloses the frustum.
		 * @param {Plane} [p5] - The sixth plane that encloses the frustum.
		 * @return {Frustum} A reference to this frustum.
		 */
		set( p0, p1, p2, p3, p4, p5 ) {

			const planes = this.planes;

			planes[ 0 ].copy( p0 );
			planes[ 1 ].copy( p1 );
			planes[ 2 ].copy( p2 );
			planes[ 3 ].copy( p3 );
			planes[ 4 ].copy( p4 );
			planes[ 5 ].copy( p5 );

			return this;

		}

		/**
		 * Copies the values of the given frustum to this instance.
		 *
		 * @param {Frustum} frustum - The frustum to copy.
		 * @return {Frustum} A reference to this frustum.
		 */
		copy( frustum ) {

			const planes = this.planes;

			for ( let i = 0; i < 6; i ++ ) {

				planes[ i ].copy( frustum.planes[ i ] );

			}

			return this;

		}

		/**
		 * Sets the frustum planes from the given projection matrix.
		 *
		 * @param {Matrix4} m - The projection matrix.
		 * @param {(WebGLCoordinateSystem|WebGPUCoordinateSystem)} coordinateSystem - The coordinate system.
		 * @return {Frustum} A reference to this frustum.
		 */
		setFromProjectionMatrix( m, coordinateSystem = WebGLCoordinateSystem ) {

			const planes = this.planes;
			const me = m.elements;
			const me0 = me[ 0 ], me1 = me[ 1 ], me2 = me[ 2 ], me3 = me[ 3 ];
			const me4 = me[ 4 ], me5 = me[ 5 ], me6 = me[ 6 ], me7 = me[ 7 ];
			const me8 = me[ 8 ], me9 = me[ 9 ], me10 = me[ 10 ], me11 = me[ 11 ];
			const me12 = me[ 12 ], me13 = me[ 13 ], me14 = me[ 14 ], me15 = me[ 15 ];

			planes[ 0 ].setComponents( me3 - me0, me7 - me4, me11 - me8, me15 - me12 ).normalize();
			planes[ 1 ].setComponents( me3 + me0, me7 + me4, me11 + me8, me15 + me12 ).normalize();
			planes[ 2 ].setComponents( me3 + me1, me7 + me5, me11 + me9, me15 + me13 ).normalize();
			planes[ 3 ].setComponents( me3 - me1, me7 - me5, me11 - me9, me15 - me13 ).normalize();
			planes[ 4 ].setComponents( me3 - me2, me7 - me6, me11 - me10, me15 - me14 ).normalize();

			if ( coordinateSystem === WebGLCoordinateSystem ) {

				planes[ 5 ].setComponents( me3 + me2, me7 + me6, me11 + me10, me15 + me14 ).normalize();

			} else if ( coordinateSystem === WebGPUCoordinateSystem ) {

				planes[ 5 ].setComponents( me2, me6, me10, me14 ).normalize();

			} else {

				throw new Error( 'THREE.Frustum.setFromProjectionMatrix(): Invalid coordinate system: ' + coordinateSystem );

			}

			return this;

		}

		/**
		 * Returns `true` if the 3D object's bounding sphere is intersecting this frustum.
		 *
		 * Note that the 3D object must have a geometry so that the bounding sphere can be calculated.
		 *
		 * @param {Object3D} object - The 3D object to test.
		 * @return {boolean} Whether the 3D object's bounding sphere is intersecting this frustum or not.
		 */
		intersectsObject( object ) {

			if ( object.boundingSphere !== undefined ) {

				if ( object.boundingSphere === null ) object.computeBoundingSphere();

				_sphere$3.copy( object.boundingSphere ).applyMatrix4( object.matrixWorld );

			} else {

				const geometry = object.geometry;

				if ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();

				_sphere$3.copy( geometry.boundingSphere ).applyMatrix4( object.matrixWorld );

			}

			return this.intersectsSphere( _sphere$3 );

		}

		/**
		 * Returns `true` if the given sprite is intersecting this frustum.
		 *
		 * @param {Sprite} sprite - The sprite to test.
		 * @return {boolean} Whether the sprite is intersecting this frustum or not.
		 */
		intersectsSprite( sprite ) {

			_sphere$3.center.set( 0, 0, 0 );
			_sphere$3.radius = 0.7071067811865476;
			_sphere$3.applyMatrix4( sprite.matrixWorld );

			return this.intersectsSphere( _sphere$3 );

		}

		/**
		 * Returns `true` if the given bounding sphere is intersecting this frustum.
		 *
		 * @param {Sphere} sphere - The bounding sphere to test.
		 * @return {boolean} Whether the bounding sphere is intersecting this frustum or not.
		 */
		intersectsSphere( sphere ) {

			const planes = this.planes;
			const center = sphere.center;
			const negRadius = - sphere.radius;

			for ( let i = 0; i < 6; i ++ ) {

				const distance = planes[ i ].distanceToPoint( center );

				if ( distance < negRadius ) {

					return false;

				}

			}

			return true;

		}

		/**
		 * Returns `true` if the given bounding box is intersecting this frustum.
		 *
		 * @param {Box3} box - The bounding box to test.
		 * @return {boolean} Whether the bounding box is intersecting this frustum or not.
		 */
		intersectsBox( box ) {

			const planes = this.planes;

			for ( let i = 0; i < 6; i ++ ) {

				const plane = planes[ i ];

				// corner at max distance

				_vector$6.x = plane.normal.x > 0 ? box.max.x : box.min.x;
				_vector$6.y = plane.normal.y > 0 ? box.max.y : box.min.y;
				_vector$6.z = plane.normal.z > 0 ? box.max.z : box.min.z;

				if ( plane.distanceToPoint( _vector$6 ) < 0 ) {

					return false;

				}

			}

			return true;

		}

		/**
		 * Returns `true` if the given point lies within the frustum.
		 *
		 * @param {Vector3} point - The point to test.
		 * @return {boolean} Whether the point lies within this frustum or not.
		 */
		containsPoint( point ) {

			const planes = this.planes;

			for ( let i = 0; i < 6; i ++ ) {

				if ( planes[ i ].distanceToPoint( point ) < 0 ) {

					return false;

				}

			}

			return true;

		}

		/**
		 * Returns a new frustum with copied values from this instance.
		 *
		 * @return {Frustum} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

	}

	/**
	 * A material for rendering line primitives.
	 *
	 * Materials define the appearance of renderable 3D objects.
	 *
	 * ```js
	 * const material = new THREE.LineBasicMaterial( { color: 0xffffff } );
	 * ```
	 *
	 * @augments Material
	 */
	class LineBasicMaterial extends Material {

		/**
		 * Constructs a new line basic material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineBasicMaterial = true;

			this.type = 'LineBasicMaterial';

			/**
			 * Color of the material.
			 *
			 * @type {Color}
			 * @default (1,1,1)
			 */
			this.color = new Color( 0xffffff );

			/**
			 * Sets the color of the lines using data from a texture. The texture map
			 * color is modulated by the diffuse `color`.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.map = null;

			/**
			 * Controls line thickness or lines.
			 *
			 * Can only be used with {@link SVGRenderer}. WebGL and WebGPU
			 * ignore this setting and always render line primitives with a
			 * width of one pixel.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.linewidth = 1;

			/**
			 * Defines appearance of line ends.
			 *
			 * Can only be used with {@link SVGRenderer}.
			 *
			 * @type {('butt'|'round'|'square')}
			 * @default 'round'
			 */
			this.linecap = 'round';

			/**
			 * Defines appearance of line joints.
			 *
			 * Can only be used with {@link SVGRenderer}.
			 *
			 * @type {('round'|'bevel'|'miter')}
			 * @default 'round'
			 */
			this.linejoin = 'round';

			/**
			 * Whether the material is affected by fog or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.fog = true;

			this.setValues( parameters );

		}

		copy( source ) {

			super.copy( source );

			this.color.copy( source.color );

			this.map = source.map;

			this.linewidth = source.linewidth;
			this.linecap = source.linecap;
			this.linejoin = source.linejoin;

			this.fog = source.fog;

			return this;

		}

	}

	const _vStart = /*@__PURE__*/ new Vector3();
	const _vEnd = /*@__PURE__*/ new Vector3();

	const _inverseMatrix$1 = /*@__PURE__*/ new Matrix4();
	const _ray$1 = /*@__PURE__*/ new Ray();
	const _sphere$1 = /*@__PURE__*/ new Sphere();

	const _intersectPointOnRay = /*@__PURE__*/ new Vector3();
	const _intersectPointOnSegment = /*@__PURE__*/ new Vector3();

	/**
	 * A continuous line. The line are rendered by connecting consecutive
	 * vertices with straight lines.
	 *
	 * ```js
	 * const material = new THREE.LineBasicMaterial( { color: 0x0000ff } );
	 *
	 * const points = [];
	 * points.push( new THREE.Vector3( - 10, 0, 0 ) );
	 * points.push( new THREE.Vector3( 0, 10, 0 ) );
	 * points.push( new THREE.Vector3( 10, 0, 0 ) );
	 *
	 * const geometry = new THREE.BufferGeometry().setFromPoints( points );
	 *
	 * const line = new THREE.Line( geometry, material );
	 * scene.add( line );
	 * ```
	 *
	 * @augments Object3D
	 */
	class Line extends Object3D {

		/**
		 * Constructs a new line.
		 *
		 * @param {BufferGeometry} [geometry] - The line geometry.
		 * @param {Material|Array<Material>} [material] - The line material.
		 */
		constructor( geometry = new BufferGeometry(), material = new LineBasicMaterial() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLine = true;

			this.type = 'Line';

			/**
			 * The line geometry.
			 *
			 * @type {BufferGeometry}
			 */
			this.geometry = geometry;

			/**
			 * The line material.
			 *
			 * @type {Material|Array<Material>}
			 * @default LineBasicMaterial
			 */
			this.material = material;

			/**
			 * A dictionary representing the morph targets in the geometry. The key is the
			 * morph targets name, the value its attribute index. This member is `undefined`
			 * by default and only set when morph targets are detected in the geometry.
			 *
			 * @type {Object<String,number>|undefined}
			 * @default undefined
			 */
			this.morphTargetDictionary = undefined;

			/**
			 * An array of weights typically in the range `[0,1]` that specify how much of the morph
			 * is applied. This member is `undefined` by default and only set when morph targets are
			 * detected in the geometry.
			 *
			 * @type {Array<number>|undefined}
			 * @default undefined
			 */
			this.morphTargetInfluences = undefined;

			this.updateMorphTargets();

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.material = Array.isArray( source.material ) ? source.material.slice() : source.material;
			this.geometry = source.geometry;

			return this;

		}

		/**
		 * Computes an array of distance values which are necessary for rendering dashed lines.
		 * For each vertex in the geometry, the method calculates the cumulative length from the
		 * current point to the very beginning of the line.
		 *
		 * @return {Line} A reference to this line.
		 */
		computeLineDistances() {

			const geometry = this.geometry;

			// we assume non-indexed geometry

			if ( geometry.index === null ) {

				const positionAttribute = geometry.attributes.position;
				const lineDistances = [ 0 ];

				for ( let i = 1, l = positionAttribute.count; i < l; i ++ ) {

					_vStart.fromBufferAttribute( positionAttribute, i - 1 );
					_vEnd.fromBufferAttribute( positionAttribute, i );

					lineDistances[ i ] = lineDistances[ i - 1 ];
					lineDistances[ i ] += _vStart.distanceTo( _vEnd );

				}

				geometry.setAttribute( 'lineDistance', new Float32BufferAttribute( lineDistances, 1 ) );

			} else {

				console.warn( 'THREE.Line.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.' );

			}

			return this;

		}

		/**
		 * Computes intersection points between a casted ray and this line.
		 *
		 * @param {Raycaster} raycaster - The raycaster.
		 * @param {Array<Object>} intersects - The target array that holds the intersection points.
		 */
		raycast( raycaster, intersects ) {

			const geometry = this.geometry;
			const matrixWorld = this.matrixWorld;
			const threshold = raycaster.params.Line.threshold;
			const drawRange = geometry.drawRange;

			// Checking boundingSphere distance to ray

			if ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();

			_sphere$1.copy( geometry.boundingSphere );
			_sphere$1.applyMatrix4( matrixWorld );
			_sphere$1.radius += threshold;

			if ( raycaster.ray.intersectsSphere( _sphere$1 ) === false ) return;

			//

			_inverseMatrix$1.copy( matrixWorld ).invert();
			_ray$1.copy( raycaster.ray ).applyMatrix4( _inverseMatrix$1 );

			const localThreshold = threshold / ( ( this.scale.x + this.scale.y + this.scale.z ) / 3 );
			const localThresholdSq = localThreshold * localThreshold;

			const step = this.isLineSegments ? 2 : 1;

			const index = geometry.index;
			const attributes = geometry.attributes;
			const positionAttribute = attributes.position;

			if ( index !== null ) {

				const start = Math.max( 0, drawRange.start );
				const end = Math.min( index.count, ( drawRange.start + drawRange.count ) );

				for ( let i = start, l = end - 1; i < l; i += step ) {

					const a = index.getX( i );
					const b = index.getX( i + 1 );

					const intersect = checkIntersection( this, raycaster, _ray$1, localThresholdSq, a, b, i );

					if ( intersect ) {

						intersects.push( intersect );

					}

				}

				if ( this.isLineLoop ) {

					const a = index.getX( end - 1 );
					const b = index.getX( start );

					const intersect = checkIntersection( this, raycaster, _ray$1, localThresholdSq, a, b, end - 1 );

					if ( intersect ) {

						intersects.push( intersect );

					}

				}

			} else {

				const start = Math.max( 0, drawRange.start );
				const end = Math.min( positionAttribute.count, ( drawRange.start + drawRange.count ) );

				for ( let i = start, l = end - 1; i < l; i += step ) {

					const intersect = checkIntersection( this, raycaster, _ray$1, localThresholdSq, i, i + 1, i );

					if ( intersect ) {

						intersects.push( intersect );

					}

				}

				if ( this.isLineLoop ) {

					const intersect = checkIntersection( this, raycaster, _ray$1, localThresholdSq, end - 1, start, end - 1 );

					if ( intersect ) {

						intersects.push( intersect );

					}

				}

			}

		}

		/**
		 * Sets the values of {@link Line#morphTargetDictionary} and {@link Line#morphTargetInfluences}
		 * to make sure existing morph targets can influence this 3D object.
		 */
		updateMorphTargets() {

			const geometry = this.geometry;

			const morphAttributes = geometry.morphAttributes;
			const keys = Object.keys( morphAttributes );

			if ( keys.length > 0 ) {

				const morphAttribute = morphAttributes[ keys[ 0 ] ];

				if ( morphAttribute !== undefined ) {

					this.morphTargetInfluences = [];
					this.morphTargetDictionary = {};

					for ( let m = 0, ml = morphAttribute.length; m < ml; m ++ ) {

						const name = morphAttribute[ m ].name || String( m );

						this.morphTargetInfluences.push( 0 );
						this.morphTargetDictionary[ name ] = m;

					}

				}

			}

		}

	}

	function checkIntersection( object, raycaster, ray, thresholdSq, a, b, i ) {

		const positionAttribute = object.geometry.attributes.position;

		_vStart.fromBufferAttribute( positionAttribute, a );
		_vEnd.fromBufferAttribute( positionAttribute, b );

		const distSq = ray.distanceSqToSegment( _vStart, _vEnd, _intersectPointOnRay, _intersectPointOnSegment );

		if ( distSq > thresholdSq ) return;

		_intersectPointOnRay.applyMatrix4( object.matrixWorld ); // Move back to world space for distance calculation

		const distance = raycaster.ray.origin.distanceTo( _intersectPointOnRay );

		if ( distance < raycaster.near || distance > raycaster.far ) return;

		return {

			distance: distance,
			// What do we want? intersection point on the ray or on the segment??
			// point: raycaster.ray.at( distance ),
			point: _intersectPointOnSegment.clone().applyMatrix4( object.matrixWorld ),
			index: i,
			face: null,
			faceIndex: null,
			barycoord: null,
			object: object

		};

	}

	const _start = /*@__PURE__*/ new Vector3();
	const _end = /*@__PURE__*/ new Vector3();

	/**
	 * A series of lines drawn between pairs of vertices.
	 *
	 * @augments Line
	 */
	class LineSegments extends Line {

		/**
		 * Constructs a new line segments.
		 *
		 * @param {BufferGeometry} [geometry] - The line geometry.
		 * @param {Material|Array<Material>} [material] - The line material.
		 */
		constructor( geometry, material ) {

			super( geometry, material );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineSegments = true;

			this.type = 'LineSegments';

		}

		computeLineDistances() {

			const geometry = this.geometry;

			// we assume non-indexed geometry

			if ( geometry.index === null ) {

				const positionAttribute = geometry.attributes.position;
				const lineDistances = [];

				for ( let i = 0, l = positionAttribute.count; i < l; i += 2 ) {

					_start.fromBufferAttribute( positionAttribute, i );
					_end.fromBufferAttribute( positionAttribute, i + 1 );

					lineDistances[ i ] = ( i === 0 ) ? 0 : lineDistances[ i - 1 ];
					lineDistances[ i + 1 ] = lineDistances[ i ] + _start.distanceTo( _end );

				}

				geometry.setAttribute( 'lineDistance', new Float32BufferAttribute( lineDistances, 1 ) );

			} else {

				console.warn( 'THREE.LineSegments.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.' );

			}

			return this;

		}

	}

	/**
	 * A continuous line. This is nearly the same as {@link Line} the only difference
	 * is that the last vertex is connected with the first vertex in order to close
	 * the line to form a loop.
	 *
	 * @augments Line
	 */
	class LineLoop extends Line {

		/**
		 * Constructs a new line loop.
		 *
		 * @param {BufferGeometry} [geometry] - The line geometry.
		 * @param {Material|Array<Material>} [material] - The line material.
		 */
		constructor( geometry, material ) {

			super( geometry, material );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineLoop = true;

			this.type = 'LineLoop';

		}

	}

	/**
	 * A material for rendering point primitives.
	 *
	 * Materials define the appearance of renderable 3D objects.
	 *
	 * ```js
	 * const vertices = [];
	 *
	 * for ( let i = 0; i < 10000; i ++ ) {
	 * 	const x = THREE.MathUtils.randFloatSpread( 2000 );
	 * 	const y = THREE.MathUtils.randFloatSpread( 2000 );
	 * 	const z = THREE.MathUtils.randFloatSpread( 2000 );
	 *
	 * 	vertices.push( x, y, z );
	 * }
	 *
	 * const geometry = new THREE.BufferGeometry();
	 * geometry.setAttribute( 'position', new THREE.Float32BufferAttribute( vertices, 3 ) );
	 * const material = new THREE.PointsMaterial( { color: 0x888888 } );
	 * const points = new THREE.Points( geometry, material );
	 * scene.add( points );
	 * ```
	 *
	 * @augments Material
	 */
	class PointsMaterial extends Material {

		/**
		 * Constructs a new points material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isPointsMaterial = true;

			this.type = 'PointsMaterial';

			/**
			 * Color of the material.
			 *
			 * @type {Color}
			 * @default (1,1,1)
			 */
			this.color = new Color( 0xffffff );

			/**
			 * The color map. May optionally include an alpha channel, typically combined
			 * with {@link Material#transparent} or {@link Material#alphaTest}. The texture map
			 * color is modulated by the diffuse `color`.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.map = null;

			/**
			 * The alpha map is a grayscale texture that controls the opacity across the
			 * surface (black: fully transparent; white: fully opaque).
			 *
			 * Only the color of the texture is used, ignoring the alpha channel if one
			 * exists. For RGB and RGBA textures, the renderer will use the green channel
			 * when sampling this texture due to the extra bit of precision provided for
			 * green in DXT-compressed and uncompressed RGB 565 formats. Luminance-only and
			 * luminance/alpha textures will also still work as expected.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.alphaMap = null;

			/**
			 * Defines the size of the points in pixels.
			 *
			 * Might be capped if the value exceeds hardware dependent parameters like [gl.ALIASED_POINT_SIZE_RANGE]{@link https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/getParamete}.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.size = 1;

			/**
			 * Specifies whether size of individual points is attenuated by the camera depth (perspective camera only).
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.sizeAttenuation = true;

			/**
			 * Whether the material is affected by fog or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.fog = true;

			this.setValues( parameters );

		}

		copy( source ) {

			super.copy( source );

			this.color.copy( source.color );

			this.map = source.map;

			this.alphaMap = source.alphaMap;

			this.size = source.size;
			this.sizeAttenuation = source.sizeAttenuation;

			this.fog = source.fog;

			return this;

		}

	}

	const _inverseMatrix = /*@__PURE__*/ new Matrix4();
	const _ray = /*@__PURE__*/ new Ray();
	const _sphere = /*@__PURE__*/ new Sphere();
	const _position$2 = /*@__PURE__*/ new Vector3();

	/**
	 * A class for displaying points or point clouds.
	 *
	 * @augments Object3D
	 */
	class Points extends Object3D {

		/**
		 * Constructs a new point cloud.
		 *
		 * @param {BufferGeometry} [geometry] - The points geometry.
		 * @param {Material|Array<Material>} [material] - The points material.
		 */
		constructor( geometry = new BufferGeometry(), material = new PointsMaterial() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isPoints = true;

			this.type = 'Points';

			/**
			 * The points geometry.
			 *
			 * @type {BufferGeometry}
			 */
			this.geometry = geometry;

			/**
			 * The line material.
			 *
			 * @type {Material|Array<Material>}
			 * @default PointsMaterial
			 */
			this.material = material;

			/**
			 * A dictionary representing the morph targets in the geometry. The key is the
			 * morph targets name, the value its attribute index. This member is `undefined`
			 * by default and only set when morph targets are detected in the geometry.
			 *
			 * @type {Object<String,number>|undefined}
			 * @default undefined
			 */
			this.morphTargetDictionary = undefined;

			/**
			 * An array of weights typically in the range `[0,1]` that specify how much of the morph
			 * is applied. This member is `undefined` by default and only set when morph targets are
			 * detected in the geometry.
			 *
			 * @type {Array<number>|undefined}
			 * @default undefined
			 */
			this.morphTargetInfluences = undefined;

			this.updateMorphTargets();

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.material = Array.isArray( source.material ) ? source.material.slice() : source.material;
			this.geometry = source.geometry;

			return this;

		}

		/**
		 * Computes intersection points between a casted ray and this point cloud.
		 *
		 * @param {Raycaster} raycaster - The raycaster.
		 * @param {Array<Object>} intersects - The target array that holds the intersection points.
		 */
		raycast( raycaster, intersects ) {

			const geometry = this.geometry;
			const matrixWorld = this.matrixWorld;
			const threshold = raycaster.params.Points.threshold;
			const drawRange = geometry.drawRange;

			// Checking boundingSphere distance to ray

			if ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();

			_sphere.copy( geometry.boundingSphere );
			_sphere.applyMatrix4( matrixWorld );
			_sphere.radius += threshold;

			if ( raycaster.ray.intersectsSphere( _sphere ) === false ) return;

			//

			_inverseMatrix.copy( matrixWorld ).invert();
			_ray.copy( raycaster.ray ).applyMatrix4( _inverseMatrix );

			const localThreshold = threshold / ( ( this.scale.x + this.scale.y + this.scale.z ) / 3 );
			const localThresholdSq = localThreshold * localThreshold;

			const index = geometry.index;
			const attributes = geometry.attributes;
			const positionAttribute = attributes.position;

			if ( index !== null ) {

				const start = Math.max( 0, drawRange.start );
				const end = Math.min( index.count, ( drawRange.start + drawRange.count ) );

				for ( let i = start, il = end; i < il; i ++ ) {

					const a = index.getX( i );

					_position$2.fromBufferAttribute( positionAttribute, a );

					testPoint( _position$2, a, localThresholdSq, matrixWorld, raycaster, intersects, this );

				}

			} else {

				const start = Math.max( 0, drawRange.start );
				const end = Math.min( positionAttribute.count, ( drawRange.start + drawRange.count ) );

				for ( let i = start, l = end; i < l; i ++ ) {

					_position$2.fromBufferAttribute( positionAttribute, i );

					testPoint( _position$2, i, localThresholdSq, matrixWorld, raycaster, intersects, this );

				}

			}

		}

		/**
		 * Sets the values of {@link Points#morphTargetDictionary} and {@link Points#morphTargetInfluences}
		 * to make sure existing morph targets can influence this 3D object.
		 */
		updateMorphTargets() {

			const geometry = this.geometry;

			const morphAttributes = geometry.morphAttributes;
			const keys = Object.keys( morphAttributes );

			if ( keys.length > 0 ) {

				const morphAttribute = morphAttributes[ keys[ 0 ] ];

				if ( morphAttribute !== undefined ) {

					this.morphTargetInfluences = [];
					this.morphTargetDictionary = {};

					for ( let m = 0, ml = morphAttribute.length; m < ml; m ++ ) {

						const name = morphAttribute[ m ].name || String( m );

						this.morphTargetInfluences.push( 0 );
						this.morphTargetDictionary[ name ] = m;

					}

				}

			}

		}

	}

	function testPoint( point, index, localThresholdSq, matrixWorld, raycaster, intersects, object ) {

		const rayPointDistanceSq = _ray.distanceSqToPoint( point );

		if ( rayPointDistanceSq < localThresholdSq ) {

			const intersectPoint = new Vector3();

			_ray.closestPointToPoint( point, intersectPoint );
			intersectPoint.applyMatrix4( matrixWorld );

			const distance = raycaster.ray.origin.distanceTo( intersectPoint );

			if ( distance < raycaster.near || distance > raycaster.far ) return;

			intersects.push( {

				distance: distance,
				distanceToRay: Math.sqrt( rayPointDistanceSq ),
				point: intersectPoint,
				index: index,
				face: null,
				faceIndex: null,
				barycoord: null,
				object: object

			} );

		}

	}

	/**
	 * Creates a texture from a canvas element.
	 *
	 * This is almost the same as the base texture class, except that it sets {@link Texture#needsUpdate}
	 * to `true` immediately since a canvas can directly be used for rendering.
	 *
	 * @augments Texture
	 */
	class CanvasTexture extends Texture {

		/**
		 * Constructs a new texture.
		 *
		 * @param {HTMLCanvasElement} [canvas] - The HTML canvas element.
		 * @param {number} [mapping=Texture.DEFAULT_MAPPING] - The texture mapping.
		 * @param {number} [wrapS=ClampToEdgeWrapping] - The wrapS value.
		 * @param {number} [wrapT=ClampToEdgeWrapping] - The wrapT value.
		 * @param {number} [magFilter=LinearFilter] - The mag filter value.
		 * @param {number} [minFilter=LinearMipmapLinearFilter] - The min filter value.
		 * @param {number} [format=RGBAFormat] - The texture format.
		 * @param {number} [type=UnsignedByteType] - The texture type.
		 * @param {number} [anisotropy=Texture.DEFAULT_ANISOTROPY] - The anisotropy value.
		 */
		constructor( canvas, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy ) {

			super( canvas, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isCanvasTexture = true;

			this.needsUpdate = true;

		}

	}

	/**
	 * This class can be used to automatically save the depth information of a
	 * rendering into a texture.
	 *
	 * @augments Texture
	 */
	class DepthTexture extends Texture {

		/**
		 * Constructs a new depth texture.
		 *
		 * @param {number} width - The width of the texture.
		 * @param {number} height - The height of the texture.
		 * @param {number} [type=UnsignedIntType] - The texture type.
		 * @param {number} [mapping=Texture.DEFAULT_MAPPING] - The texture mapping.
		 * @param {number} [wrapS=ClampToEdgeWrapping] - The wrapS value.
		 * @param {number} [wrapT=ClampToEdgeWrapping] - The wrapT value.
		 * @param {number} [magFilter=LinearFilter] - The mag filter value.
		 * @param {number} [minFilter=LinearFilter] - The min filter value.
		 * @param {number} [anisotropy=Texture.DEFAULT_ANISOTROPY] - The anisotropy value.
		 * @param {number} [format=DepthFormat] - The texture format.
		 * @param {number} [depth=1] - The depth of the texture.
		 */
		constructor( width, height, type = UnsignedIntType, mapping, wrapS, wrapT, magFilter = NearestFilter, minFilter = NearestFilter, anisotropy, format = DepthFormat, depth = 1 ) {

			if ( format !== DepthFormat && format !== DepthStencilFormat ) {

				throw new Error( 'DepthTexture format must be either THREE.DepthFormat or THREE.DepthStencilFormat' );

			}

			const image = { width: width, height: height, depth: depth };

			super( image, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isDepthTexture = true;

			/**
			 * If set to `true`, the texture is flipped along the vertical axis when
			 * uploaded to the GPU.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.flipY = false;

			/**
			 * Whether to generate mipmaps (if possible) for a texture.
			 *
			 * Overwritten and set to `false` by default.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.generateMipmaps = false;

			/**
			 * Code corresponding to the depth compare function.
			 *
			 * @type {?(NeverCompare|LessCompare|EqualCompare|LessEqualCompare|GreaterCompare|NotEqualCompare|GreaterEqualCompare|AlwaysCompare)}
			 * @default null
			 */
			this.compareFunction = null;

		}


		copy( source ) {

			super.copy( source );

			this.source = new Source( Object.assign( {}, source.image ) ); // see #30540
			this.compareFunction = source.compareFunction;

			return this;

		}

		toJSON( meta ) {

			const data = super.toJSON( meta );

			if ( this.compareFunction !== null ) data.compareFunction = this.compareFunction;

			return data;

		}

	}

	/**
	 * A geometry class for representing a capsule.
	 *
	 * ```js
	 * const geometry = new THREE.CapsuleGeometry( 1, 1, 4, 8, 1 );
	 * const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );
	 * const capsule = new THREE.Mesh( geometry, material );
	 * scene.add( capsule );
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class CapsuleGeometry extends BufferGeometry {

		/**
		 * Constructs a new capsule geometry.
		 *
		 * @param {number} [radius=1] - Radius of the capsule.
		 * @param {number} [height=1] - Height of the middle section.
		 * @param {number} [capSegments=4] - Number of curve segments used to build each cap.
		 * @param {number} [radialSegments=8] - Number of segmented faces around the circumference of the capsule. Must be an integer >= 3.
		 * @param {number} [heightSegments=1] - Number of rows of faces along the height of the middle section. Must be an integer >= 1.
		 */
		constructor( radius = 1, height = 1, capSegments = 4, radialSegments = 8, heightSegments = 1 ) {

			super();

			this.type = 'CapsuleGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				radius: radius,
				height: height,
				capSegments: capSegments,
				radialSegments: radialSegments,
				heightSegments: heightSegments,
			};

			height = Math.max( 0, height );
			capSegments = Math.max( 1, Math.floor( capSegments ) );
			radialSegments = Math.max( 3, Math.floor( radialSegments ) );
			heightSegments = Math.max( 1, Math.floor( heightSegments ) );

			// buffers

			const indices = [];
			const vertices = [];
			const normals = [];
			const uvs = [];

			// helper variables

			const halfHeight = height / 2;
			const capArcLength = ( Math.PI / 2 ) * radius;
			const cylinderPartLength = height;
			const totalArcLength = 2 * capArcLength + cylinderPartLength;

			const numVerticalSegments = capSegments * 2 + heightSegments;
			const verticesPerRow = radialSegments + 1;

			const normal = new Vector3();
			const vertex = new Vector3();

			// generate vertices, normals, and uvs

			for ( let iy = 0; iy <= numVerticalSegments; iy ++ ) {

				let currentArcLength = 0;
				let profileY = 0;
				let profileRadius = 0;
				let normalYComponent = 0;

				if ( iy <= capSegments ) {

					// bottom cap
					const segmentProgress = iy / capSegments;
					const angle = ( segmentProgress * Math.PI ) / 2;
					profileY = - halfHeight - radius * Math.cos( angle );
					profileRadius = radius * Math.sin( angle );
					normalYComponent = - radius * Math.cos( angle );
					currentArcLength = segmentProgress * capArcLength;

				} else if ( iy <= capSegments + heightSegments ) {

					// middle section
					const segmentProgress = ( iy - capSegments ) / heightSegments;
					profileY = - halfHeight + segmentProgress * height;
					profileRadius = radius;
					normalYComponent = 0;
					currentArcLength = capArcLength + segmentProgress * cylinderPartLength;

				} else {

					// top cap
					const segmentProgress =
						( iy - capSegments - heightSegments ) / capSegments;
					const angle = ( segmentProgress * Math.PI ) / 2;
					profileY = halfHeight + radius * Math.sin( angle );
					profileRadius = radius * Math.cos( angle );
					normalYComponent = radius * Math.sin( angle );
					currentArcLength =
						capArcLength + cylinderPartLength + segmentProgress * capArcLength;

				}

				const v = Math.max( 0, Math.min( 1, currentArcLength / totalArcLength ) );


				// special case for the poles

				let uOffset = 0;

				if ( iy === 0 ) {

					uOffset = 0.5 / radialSegments;

				} else if ( iy === numVerticalSegments ) {

					uOffset = -0.5 / radialSegments;

				}

				for ( let ix = 0; ix <= radialSegments; ix ++ ) {

					const u = ix / radialSegments;
					const theta = u * Math.PI * 2;

					const sinTheta = Math.sin( theta );
					const cosTheta = Math.cos( theta );

					// vertex

					vertex.x = - profileRadius * cosTheta;
					vertex.y = profileY;
					vertex.z = profileRadius * sinTheta;
					vertices.push( vertex.x, vertex.y, vertex.z );

					// normal

					normal.set(
						- profileRadius * cosTheta,
						normalYComponent,
						profileRadius * sinTheta
					);
					normal.normalize();
					normals.push( normal.x, normal.y, normal.z );

					// uv

					uvs.push( u + uOffset, v );

				}

				if ( iy > 0 ) {

					const prevIndexRow = ( iy - 1 ) * verticesPerRow;
					for ( let ix = 0; ix < radialSegments; ix ++ ) {

						const i1 = prevIndexRow + ix;
						const i2 = prevIndexRow + ix + 1;
						const i3 = iy * verticesPerRow + ix;
						const i4 = iy * verticesPerRow + ix + 1;

						indices.push( i1, i2, i3 );
						indices.push( i2, i4, i3 );

					}

				}

			}

			// build geometry

			this.setIndex( indices );
			this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {CapsuleGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new CapsuleGeometry( data.radius, data.height, data.capSegments, data.radialSegments, data.heightSegments );

		}

	}

	/**
	 * A simple shape of Euclidean geometry. It is constructed from a
	 * number of triangular segments that are oriented around a central point and
	 * extend as far out as a given radius. It is built counter-clockwise from a
	 * start angle and a given central angle. It can also be used to create
	 * regular polygons, where the number of segments determines the number of
	 * sides.
	 *
	 * ```js
	 * const geometry = new THREE.CircleGeometry( 5, 32 );
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffff00 } );
	 * const circle = new THREE.Mesh( geometry, material );
	 * scene.add( circle )
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class CircleGeometry extends BufferGeometry {

		/**
		 * Constructs a new circle geometry.
		 *
		 * @param {number} [radius=1] - Radius of the circle.
		 * @param {number} [segments=32] - Number of segments (triangles), minimum = `3`.
		 * @param {number} [thetaStart=0] - Start angle for first segment in radians.
		 * @param {number} [thetaLength=Math.PI*2] - The central angle, often called theta,
		 * of the circular sector in radians. The default value results in a complete circle.
		 */
		constructor( radius = 1, segments = 32, thetaStart = 0, thetaLength = Math.PI * 2 ) {

			super();

			this.type = 'CircleGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				radius: radius,
				segments: segments,
				thetaStart: thetaStart,
				thetaLength: thetaLength
			};

			segments = Math.max( 3, segments );

			// buffers

			const indices = [];
			const vertices = [];
			const normals = [];
			const uvs = [];

			// helper variables

			const vertex = new Vector3();
			const uv = new Vector2();

			// center point

			vertices.push( 0, 0, 0 );
			normals.push( 0, 0, 1 );
			uvs.push( 0.5, 0.5 );

			for ( let s = 0, i = 3; s <= segments; s ++, i += 3 ) {

				const segment = thetaStart + s / segments * thetaLength;

				// vertex

				vertex.x = radius * Math.cos( segment );
				vertex.y = radius * Math.sin( segment );

				vertices.push( vertex.x, vertex.y, vertex.z );

				// normal

				normals.push( 0, 0, 1 );

				// uvs

				uv.x = ( vertices[ i ] / radius + 1 ) / 2;
				uv.y = ( vertices[ i + 1 ] / radius + 1 ) / 2;

				uvs.push( uv.x, uv.y );

			}

			// indices

			for ( let i = 1; i <= segments; i ++ ) {

				indices.push( i, i + 1, 0 );

			}

			// build geometry

			this.setIndex( indices );
			this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {CircleGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new CircleGeometry( data.radius, data.segments, data.thetaStart, data.thetaLength );

		}

	}

	/**
	 * A geometry class for representing a cylinder.
	 *
	 * ```js
	 * const geometry = new THREE.CylinderGeometry( 5, 5, 20, 32 );
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffff00 } );
	 * const cylinder = new THREE.Mesh( geometry, material );
	 * scene.add( cylinder );
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class CylinderGeometry extends BufferGeometry {

		/**
		 * Constructs a new cylinder geometry.
		 *
		 * @param {number} [radiusTop=1] - Radius of the cylinder at the top.
		 * @param {number} [radiusBottom=1] - Radius of the cylinder at the bottom.
		 * @param {number} [height=1] - Height of the cylinder.
		 * @param {number} [radialSegments=32] - Number of segmented faces around the circumference of the cylinder.
		 * @param {number} [heightSegments=1] - Number of rows of faces along the height of the cylinder.
		 * @param {boolean} [openEnded=false] - Whether the base of the cylinder is open or capped.
		 * @param {number} [thetaStart=0] - Start angle for first segment, in radians.
		 * @param {number} [thetaLength=Math.PI*2] - The central angle, often called theta, of the circular sector, in radians.
		 * The default value results in a complete cylinder.
		 */
		constructor( radiusTop = 1, radiusBottom = 1, height = 1, radialSegments = 32, heightSegments = 1, openEnded = false, thetaStart = 0, thetaLength = Math.PI * 2 ) {

			super();

			this.type = 'CylinderGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				radiusTop: radiusTop,
				radiusBottom: radiusBottom,
				height: height,
				radialSegments: radialSegments,
				heightSegments: heightSegments,
				openEnded: openEnded,
				thetaStart: thetaStart,
				thetaLength: thetaLength
			};

			const scope = this;

			radialSegments = Math.floor( radialSegments );
			heightSegments = Math.floor( heightSegments );

			// buffers

			const indices = [];
			const vertices = [];
			const normals = [];
			const uvs = [];

			// helper variables

			let index = 0;
			const indexArray = [];
			const halfHeight = height / 2;
			let groupStart = 0;

			// generate geometry

			generateTorso();

			if ( openEnded === false ) {

				if ( radiusTop > 0 ) generateCap( true );
				if ( radiusBottom > 0 ) generateCap( false );

			}

			// build geometry

			this.setIndex( indices );
			this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );

			function generateTorso() {

				const normal = new Vector3();
				const vertex = new Vector3();

				let groupCount = 0;

				// this will be used to calculate the normal
				const slope = ( radiusBottom - radiusTop ) / height;

				// generate vertices, normals and uvs

				for ( let y = 0; y <= heightSegments; y ++ ) {

					const indexRow = [];

					const v = y / heightSegments;

					// calculate the radius of the current row

					const radius = v * ( radiusBottom - radiusTop ) + radiusTop;

					for ( let x = 0; x <= radialSegments; x ++ ) {

						const u = x / radialSegments;

						const theta = u * thetaLength + thetaStart;

						const sinTheta = Math.sin( theta );
						const cosTheta = Math.cos( theta );

						// vertex

						vertex.x = radius * sinTheta;
						vertex.y = - v * height + halfHeight;
						vertex.z = radius * cosTheta;
						vertices.push( vertex.x, vertex.y, vertex.z );

						// normal

						normal.set( sinTheta, slope, cosTheta ).normalize();
						normals.push( normal.x, normal.y, normal.z );

						// uv

						uvs.push( u, 1 - v );

						// save index of vertex in respective row

						indexRow.push( index ++ );

					}

					// now save vertices of the row in our index array

					indexArray.push( indexRow );

				}

				// generate indices

				for ( let x = 0; x < radialSegments; x ++ ) {

					for ( let y = 0; y < heightSegments; y ++ ) {

						// we use the index array to access the correct indices

						const a = indexArray[ y ][ x ];
						const b = indexArray[ y + 1 ][ x ];
						const c = indexArray[ y + 1 ][ x + 1 ];
						const d = indexArray[ y ][ x + 1 ];

						// faces

						if ( radiusTop > 0 || y !== 0 ) {

							indices.push( a, b, d );
							groupCount += 3;

						}

						if ( radiusBottom > 0 || y !== heightSegments - 1 ) {

							indices.push( b, c, d );
							groupCount += 3;

						}

					}

				}

				// add a group to the geometry. this will ensure multi material support

				scope.addGroup( groupStart, groupCount, 0 );

				// calculate new start value for groups

				groupStart += groupCount;

			}

			function generateCap( top ) {

				// save the index of the first center vertex
				const centerIndexStart = index;

				const uv = new Vector2();
				const vertex = new Vector3();

				let groupCount = 0;

				const radius = ( top === true ) ? radiusTop : radiusBottom;
				const sign = ( top === true ) ? 1 : -1;

				// first we generate the center vertex data of the cap.
				// because the geometry needs one set of uvs per face,
				// we must generate a center vertex per face/segment

				for ( let x = 1; x <= radialSegments; x ++ ) {

					// vertex

					vertices.push( 0, halfHeight * sign, 0 );

					// normal

					normals.push( 0, sign, 0 );

					// uv

					uvs.push( 0.5, 0.5 );

					// increase index

					index ++;

				}

				// save the index of the last center vertex
				const centerIndexEnd = index;

				// now we generate the surrounding vertices, normals and uvs

				for ( let x = 0; x <= radialSegments; x ++ ) {

					const u = x / radialSegments;
					const theta = u * thetaLength + thetaStart;

					const cosTheta = Math.cos( theta );
					const sinTheta = Math.sin( theta );

					// vertex

					vertex.x = radius * sinTheta;
					vertex.y = halfHeight * sign;
					vertex.z = radius * cosTheta;
					vertices.push( vertex.x, vertex.y, vertex.z );

					// normal

					normals.push( 0, sign, 0 );

					// uv

					uv.x = ( cosTheta * 0.5 ) + 0.5;
					uv.y = ( sinTheta * 0.5 * sign ) + 0.5;
					uvs.push( uv.x, uv.y );

					// increase index

					index ++;

				}

				// generate indices

				for ( let x = 0; x < radialSegments; x ++ ) {

					const c = centerIndexStart + x;
					const i = centerIndexEnd + x;

					if ( top === true ) {

						// face top

						indices.push( i, i + 1, c );

					} else {

						// face bottom

						indices.push( i + 1, i, c );

					}

					groupCount += 3;

				}

				// add a group to the geometry. this will ensure multi material support

				scope.addGroup( groupStart, groupCount, top === true ? 1 : 2 );

				// calculate new start value for groups

				groupStart += groupCount;

			}

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {CylinderGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new CylinderGeometry( data.radiusTop, data.radiusBottom, data.height, data.radialSegments, data.heightSegments, data.openEnded, data.thetaStart, data.thetaLength );

		}

	}

	/**
	 * A polyhedron is a solid in three dimensions with flat faces. This class
	 * will take an array of vertices, project them onto a sphere, and then
	 * divide them up to the desired level of detail.
	 *
	 * @augments BufferGeometry
	 */
	class PolyhedronGeometry extends BufferGeometry {

		/**
		 * Constructs a new polyhedron geometry.
		 *
		 * @param {Array<number>} [vertices] - A flat array of vertices describing the base shape.
		 * @param {Array<number>} [indices] - A flat array of indices describing the base shape.
		 * @param {number} [radius=1] - The radius of the shape.
		 * @param {number} [detail=0] - How many levels to subdivide the geometry. The more detail, the smoother the shape.
		 */
		constructor( vertices = [], indices = [], radius = 1, detail = 0 ) {

			super();

			this.type = 'PolyhedronGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				vertices: vertices,
				indices: indices,
				radius: radius,
				detail: detail
			};

			// default buffer data

			const vertexBuffer = [];
			const uvBuffer = [];

			// the subdivision creates the vertex buffer data

			subdivide( detail );

			// all vertices should lie on a conceptual sphere with a given radius

			applyRadius( radius );

			// finally, create the uv data

			generateUVs();

			// build non-indexed geometry

			this.setAttribute( 'position', new Float32BufferAttribute( vertexBuffer, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( vertexBuffer.slice(), 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvBuffer, 2 ) );

			if ( detail === 0 ) {

				this.computeVertexNormals(); // flat normals

			} else {

				this.normalizeNormals(); // smooth normals

			}

			// helper functions

			function subdivide( detail ) {

				const a = new Vector3();
				const b = new Vector3();
				const c = new Vector3();

				// iterate over all faces and apply a subdivision with the given detail value

				for ( let i = 0; i < indices.length; i += 3 ) {

					// get the vertices of the face

					getVertexByIndex( indices[ i + 0 ], a );
					getVertexByIndex( indices[ i + 1 ], b );
					getVertexByIndex( indices[ i + 2 ], c );

					// perform subdivision

					subdivideFace( a, b, c, detail );

				}

			}

			function subdivideFace( a, b, c, detail ) {

				const cols = detail + 1;

				// we use this multidimensional array as a data structure for creating the subdivision

				const v = [];

				// construct all of the vertices for this subdivision

				for ( let i = 0; i <= cols; i ++ ) {

					v[ i ] = [];

					const aj = a.clone().lerp( c, i / cols );
					const bj = b.clone().lerp( c, i / cols );

					const rows = cols - i;

					for ( let j = 0; j <= rows; j ++ ) {

						if ( j === 0 && i === cols ) {

							v[ i ][ j ] = aj;

						} else {

							v[ i ][ j ] = aj.clone().lerp( bj, j / rows );

						}

					}

				}

				// construct all of the faces

				for ( let i = 0; i < cols; i ++ ) {

					for ( let j = 0; j < 2 * ( cols - i ) - 1; j ++ ) {

						const k = Math.floor( j / 2 );

						if ( j % 2 === 0 ) {

							pushVertex( v[ i ][ k + 1 ] );
							pushVertex( v[ i + 1 ][ k ] );
							pushVertex( v[ i ][ k ] );

						} else {

							pushVertex( v[ i ][ k + 1 ] );
							pushVertex( v[ i + 1 ][ k + 1 ] );
							pushVertex( v[ i + 1 ][ k ] );

						}

					}

				}

			}

			function applyRadius( radius ) {

				const vertex = new Vector3();

				// iterate over the entire buffer and apply the radius to each vertex

				for ( let i = 0; i < vertexBuffer.length; i += 3 ) {

					vertex.x = vertexBuffer[ i + 0 ];
					vertex.y = vertexBuffer[ i + 1 ];
					vertex.z = vertexBuffer[ i + 2 ];

					vertex.normalize().multiplyScalar( radius );

					vertexBuffer[ i + 0 ] = vertex.x;
					vertexBuffer[ i + 1 ] = vertex.y;
					vertexBuffer[ i + 2 ] = vertex.z;

				}

			}

			function generateUVs() {

				const vertex = new Vector3();

				for ( let i = 0; i < vertexBuffer.length; i += 3 ) {

					vertex.x = vertexBuffer[ i + 0 ];
					vertex.y = vertexBuffer[ i + 1 ];
					vertex.z = vertexBuffer[ i + 2 ];

					const u = azimuth( vertex ) / 2 / Math.PI + 0.5;
					const v = inclination( vertex ) / Math.PI + 0.5;
					uvBuffer.push( u, 1 - v );

				}

				correctUVs();

				correctSeam();

			}

			function correctSeam() {

				// handle case when face straddles the seam, see #3269

				for ( let i = 0; i < uvBuffer.length; i += 6 ) {

					// uv data of a single face

					const x0 = uvBuffer[ i + 0 ];
					const x1 = uvBuffer[ i + 2 ];
					const x2 = uvBuffer[ i + 4 ];

					const max = Math.max( x0, x1, x2 );
					const min = Math.min( x0, x1, x2 );

					// 0.9 is somewhat arbitrary

					if ( max > 0.9 && min < 0.1 ) {

						if ( x0 < 0.2 ) uvBuffer[ i + 0 ] += 1;
						if ( x1 < 0.2 ) uvBuffer[ i + 2 ] += 1;
						if ( x2 < 0.2 ) uvBuffer[ i + 4 ] += 1;

					}

				}

			}

			function pushVertex( vertex ) {

				vertexBuffer.push( vertex.x, vertex.y, vertex.z );

			}

			function getVertexByIndex( index, vertex ) {

				const stride = index * 3;

				vertex.x = vertices[ stride + 0 ];
				vertex.y = vertices[ stride + 1 ];
				vertex.z = vertices[ stride + 2 ];

			}

			function correctUVs() {

				const a = new Vector3();
				const b = new Vector3();
				const c = new Vector3();

				const centroid = new Vector3();

				const uvA = new Vector2();
				const uvB = new Vector2();
				const uvC = new Vector2();

				for ( let i = 0, j = 0; i < vertexBuffer.length; i += 9, j += 6 ) {

					a.set( vertexBuffer[ i + 0 ], vertexBuffer[ i + 1 ], vertexBuffer[ i + 2 ] );
					b.set( vertexBuffer[ i + 3 ], vertexBuffer[ i + 4 ], vertexBuffer[ i + 5 ] );
					c.set( vertexBuffer[ i + 6 ], vertexBuffer[ i + 7 ], vertexBuffer[ i + 8 ] );

					uvA.set( uvBuffer[ j + 0 ], uvBuffer[ j + 1 ] );
					uvB.set( uvBuffer[ j + 2 ], uvBuffer[ j + 3 ] );
					uvC.set( uvBuffer[ j + 4 ], uvBuffer[ j + 5 ] );

					centroid.copy( a ).add( b ).add( c ).divideScalar( 3 );

					const azi = azimuth( centroid );

					correctUV( uvA, j + 0, a, azi );
					correctUV( uvB, j + 2, b, azi );
					correctUV( uvC, j + 4, c, azi );

				}

			}

			function correctUV( uv, stride, vector, azimuth ) {

				if ( ( azimuth < 0 ) && ( uv.x === 1 ) ) {

					uvBuffer[ stride ] = uv.x - 1;

				}

				if ( ( vector.x === 0 ) && ( vector.z === 0 ) ) {

					uvBuffer[ stride ] = azimuth / 2 / Math.PI + 0.5;

				}

			}

			// Angle around the Y axis, counter-clockwise when looking from above.

			function azimuth( vector ) {

				return Math.atan2( vector.z, - vector.x );

			}


			// Angle above the XZ plane.

			function inclination( vector ) {

				return Math.atan2( - vector.y, Math.sqrt( ( vector.x * vector.x ) + ( vector.z * vector.z ) ) );

			}

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {PolyhedronGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new PolyhedronGeometry( data.vertices, data.indices, data.radius, data.details );

		}

	}

	/**
	 * An abstract base class for creating an analytic curve object that contains methods
	 * for interpolation.
	 *
	 * @abstract
	 */
	class Curve {

		/**
		 * Constructs a new curve.
		 */
		constructor() {

			/**
			 * The type property is used for detecting the object type
			 * in context of serialization/deserialization.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.type = 'Curve';

			/**
			 * This value determines the amount of divisions when calculating the
			 * cumulative segment lengths of a curve via {@link Curve#getLengths}. To ensure
			 * precision when using methods like {@link Curve#getSpacedPoints}, it is
			 * recommended to increase the value of this property if the curve is very large.
			 *
			 * @type {number}
			 * @default 200
			 */
			this.arcLengthDivisions = 200;

			/**
			 * Must be set to `true` if the curve parameters have changed.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.needsUpdate = false;

			/**
			 * An internal cache that holds precomputed curve length values.
			 *
			 * @private
			 * @type {?Array<number>}
			 * @default null
			 */
			this.cacheArcLengths = null;

		}

		/**
		 * This method returns a vector in 2D or 3D space (depending on the curve definition)
		 * for the given interpolation factor.
		 *
		 * @abstract
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {(Vector2|Vector3)} [optionalTarget] - The optional target vector the result is written to.
		 * @return {(Vector2|Vector3)} The position on the curve. It can be a 2D or 3D vector depending on the curve definition.
		 */
		getPoint( /* t, optionalTarget */ ) {

			console.warn( 'THREE.Curve: .getPoint() not implemented.' );

		}

		/**
		 * This method returns a vector in 2D or 3D space (depending on the curve definition)
		 * for the given interpolation factor. Unlike {@link Curve#getPoint}, this method honors the length
		 * of the curve which equidistant samples.
		 *
		 * @param {number} u - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {(Vector2|Vector3)} [optionalTarget] - The optional target vector the result is written to.
		 * @return {(Vector2|Vector3)} The position on the curve. It can be a 2D or 3D vector depending on the curve definition.
		 */
		getPointAt( u, optionalTarget ) {

			const t = this.getUtoTmapping( u );
			return this.getPoint( t, optionalTarget );

		}

		/**
		 * This method samples the curve via {@link Curve#getPoint} and returns an array of points representing
		 * the curve shape.
		 *
		 * @param {number} [divisions=5] - The number of divisions.
		 * @return {Array<(Vector2|Vector3)>} An array holding the sampled curve values. The number of points is `divisions + 1`.
		 */
		getPoints( divisions = 5 ) {

			const points = [];

			for ( let d = 0; d <= divisions; d ++ ) {

				points.push( this.getPoint( d / divisions ) );

			}

			return points;

		}

		// Get sequence of points using getPointAt( u )

		/**
		 * This method samples the curve via {@link Curve#getPointAt} and returns an array of points representing
		 * the curve shape. Unlike {@link Curve#getPoints}, this method returns equi-spaced points across the entire
		 * curve.
		 *
		 * @param {number} [divisions=5] - The number of divisions.
		 * @return {Array<(Vector2|Vector3)>} An array holding the sampled curve values. The number of points is `divisions + 1`.
		 */
		getSpacedPoints( divisions = 5 ) {

			const points = [];

			for ( let d = 0; d <= divisions; d ++ ) {

				points.push( this.getPointAt( d / divisions ) );

			}

			return points;

		}

		/**
		 * Returns the total arc length of the curve.
		 *
		 * @return {number} The length of the curve.
		 */
		getLength() {

			const lengths = this.getLengths();
			return lengths[ lengths.length - 1 ];

		}

		/**
		 * Returns an array of cumulative segment lengths of the curve.
		 *
		 * @param {number} [divisions=this.arcLengthDivisions] - The number of divisions.
		 * @return {Array<number>} An array holding the cumulative segment lengths.
		 */
		getLengths( divisions = this.arcLengthDivisions ) {

			if ( this.cacheArcLengths &&
				( this.cacheArcLengths.length === divisions + 1 ) &&
				! this.needsUpdate ) {

				return this.cacheArcLengths;

			}

			this.needsUpdate = false;

			const cache = [];
			let current, last = this.getPoint( 0 );
			let sum = 0;

			cache.push( 0 );

			for ( let p = 1; p <= divisions; p ++ ) {

				current = this.getPoint( p / divisions );
				sum += current.distanceTo( last );
				cache.push( sum );
				last = current;

			}

			this.cacheArcLengths = cache;

			return cache; // { sums: cache, sum: sum }; Sum is in the last element.

		}

		/**
		 * Update the cumulative segment distance cache. The method must be called
		 * every time curve parameters are changed. If an updated curve is part of a
		 * composed curve like {@link CurvePath}, this method must be called on the
		 * composed curve, too.
		 */
		updateArcLengths() {

			this.needsUpdate = true;
			this.getLengths();

		}

		/**
		 * Given an interpolation factor in the range `[0,1]`, this method returns an updated
		 * interpolation factor in the same range that can be ued to sample equidistant points
		 * from a curve.
		 *
		 * @param {number} u - The interpolation factor.
		 * @param {?number} distance - An optional distance on the curve.
		 * @return {number} The updated interpolation factor.
		 */
		getUtoTmapping( u, distance = null ) {

			const arcLengths = this.getLengths();

			let i = 0;
			const il = arcLengths.length;

			let targetArcLength; // The targeted u distance value to get

			if ( distance ) {

				targetArcLength = distance;

			} else {

				targetArcLength = u * arcLengths[ il - 1 ];

			}

			// binary search for the index with largest value smaller than target u distance

			let low = 0, high = il - 1, comparison;

			while ( low <= high ) {

				i = Math.floor( low + ( high - low ) / 2 ); // less likely to overflow, though probably not issue here, JS doesn't really have integers, all numbers are floats

				comparison = arcLengths[ i ] - targetArcLength;

				if ( comparison < 0 ) {

					low = i + 1;

				} else if ( comparison > 0 ) {

					high = i - 1;

				} else {

					high = i;
					break;

					// DONE

				}

			}

			i = high;

			if ( arcLengths[ i ] === targetArcLength ) {

				return i / ( il - 1 );

			}

			// we could get finer grain at lengths, or use simple interpolation between two points

			const lengthBefore = arcLengths[ i ];
			const lengthAfter = arcLengths[ i + 1 ];

			const segmentLength = lengthAfter - lengthBefore;

			// determine where we are between the 'before' and 'after' points

			const segmentFraction = ( targetArcLength - lengthBefore ) / segmentLength;

			// add that fractional amount to t

			const t = ( i + segmentFraction ) / ( il - 1 );

			return t;

		}

		/**
		 * Returns a unit vector tangent for the given interpolation factor.
		 * If the derived curve does not implement its tangent derivation,
		 * two points a small delta apart will be used to find its gradient
		 * which seems to give a reasonable approximation.
		 *
		 * @param {number} t - The interpolation factor.
		 * @param {(Vector2|Vector3)} [optionalTarget] - The optional target vector the result is written to.
		 * @return {(Vector2|Vector3)} The tangent vector.
		 */
		getTangent( t, optionalTarget ) {

			const delta = 0.0001;
			let t1 = t - delta;
			let t2 = t + delta;

			// Capping in case of danger

			if ( t1 < 0 ) t1 = 0;
			if ( t2 > 1 ) t2 = 1;

			const pt1 = this.getPoint( t1 );
			const pt2 = this.getPoint( t2 );

			const tangent = optionalTarget || ( ( pt1.isVector2 ) ? new Vector2() : new Vector3() );

			tangent.copy( pt2 ).sub( pt1 ).normalize();

			return tangent;

		}

		/**
		 * Same as {@link Curve#getTangent} but with equidistant samples.
		 *
		 * @param {number} u - The interpolation factor.
		 * @param {(Vector2|Vector3)} [optionalTarget] - The optional target vector the result is written to.
		 * @return {(Vector2|Vector3)} The tangent vector.
		 * @see {@link Curve#getPointAt}
		 */
		getTangentAt( u, optionalTarget ) {

			const t = this.getUtoTmapping( u );
			return this.getTangent( t, optionalTarget );

		}

		/**
		 * Generates the Frenet Frames. Requires a curve definition in 3D space. Used
		 * in geometries like {@link TubeGeometry} or {@link ExtrudeGeometry}.
		 *
		 * @param {number} segments - The number of segments.
		 * @param {boolean} [closed=false] - Whether the curve is closed or not.
		 * @return {{tangents: Array<Vector3>, normals: Array<Vector3>, binormals: Array<Vector3>}} The Frenet Frames.
		 */
		computeFrenetFrames( segments, closed = false ) {

			// see http://www.cs.indiana.edu/pub/techreports/TR425.pdf

			const normal = new Vector3();

			const tangents = [];
			const normals = [];
			const binormals = [];

			const vec = new Vector3();
			const mat = new Matrix4();

			// compute the tangent vectors for each segment on the curve

			for ( let i = 0; i <= segments; i ++ ) {

				const u = i / segments;

				tangents[ i ] = this.getTangentAt( u, new Vector3() );

			}

			// select an initial normal vector perpendicular to the first tangent vector,
			// and in the direction of the minimum tangent xyz component

			normals[ 0 ] = new Vector3();
			binormals[ 0 ] = new Vector3();
			let min = Number.MAX_VALUE;
			const tx = Math.abs( tangents[ 0 ].x );
			const ty = Math.abs( tangents[ 0 ].y );
			const tz = Math.abs( tangents[ 0 ].z );

			if ( tx <= min ) {

				min = tx;
				normal.set( 1, 0, 0 );

			}

			if ( ty <= min ) {

				min = ty;
				normal.set( 0, 1, 0 );

			}

			if ( tz <= min ) {

				normal.set( 0, 0, 1 );

			}

			vec.crossVectors( tangents[ 0 ], normal ).normalize();

			normals[ 0 ].crossVectors( tangents[ 0 ], vec );
			binormals[ 0 ].crossVectors( tangents[ 0 ], normals[ 0 ] );


			// compute the slowly-varying normal and binormal vectors for each segment on the curve

			for ( let i = 1; i <= segments; i ++ ) {

				normals[ i ] = normals[ i - 1 ].clone();

				binormals[ i ] = binormals[ i - 1 ].clone();

				vec.crossVectors( tangents[ i - 1 ], tangents[ i ] );

				if ( vec.length() > Number.EPSILON ) {

					vec.normalize();

					const theta = Math.acos( clamp( tangents[ i - 1 ].dot( tangents[ i ] ), -1, 1 ) ); // clamp for floating pt errors

					normals[ i ].applyMatrix4( mat.makeRotationAxis( vec, theta ) );

				}

				binormals[ i ].crossVectors( tangents[ i ], normals[ i ] );

			}

			// if the curve is closed, postprocess the vectors so the first and last normal vectors are the same

			if ( closed === true ) {

				let theta = Math.acos( clamp( normals[ 0 ].dot( normals[ segments ] ), -1, 1 ) );
				theta /= segments;

				if ( tangents[ 0 ].dot( vec.crossVectors( normals[ 0 ], normals[ segments ] ) ) > 0 ) {

					theta = - theta;

				}

				for ( let i = 1; i <= segments; i ++ ) {

					// twist a little...
					normals[ i ].applyMatrix4( mat.makeRotationAxis( tangents[ i ], theta * i ) );
					binormals[ i ].crossVectors( tangents[ i ], normals[ i ] );

				}

			}

			return {
				tangents: tangents,
				normals: normals,
				binormals: binormals
			};

		}

		/**
		 * Returns a new curve with copied values from this instance.
		 *
		 * @return {Curve} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Copies the values of the given curve to this instance.
		 *
		 * @param {Curve} source - The curve to copy.
		 * @return {Curve} A reference to this curve.
		 */
		copy( source ) {

			this.arcLengthDivisions = source.arcLengthDivisions;

			return this;

		}

		/**
		 * Serializes the curve into JSON.
		 *
		 * @return {Object} A JSON object representing the serialized curve.
		 * @see {@link ObjectLoader#parse}
		 */
		toJSON() {

			const data = {
				metadata: {
					version: 4.7,
					type: 'Curve',
					generator: 'Curve.toJSON'
				}
			};

			data.arcLengthDivisions = this.arcLengthDivisions;
			data.type = this.type;

			return data;

		}

		/**
		 * Deserializes the curve from the given JSON.
		 *
		 * @param {Object} json - The JSON holding the serialized curve.
		 * @return {Curve} A reference to this curve.
		 */
		fromJSON( json ) {

			this.arcLengthDivisions = json.arcLengthDivisions;

			return this;

		}

	}

	/**
	 * A curve representing an ellipse.
	 *
	 * ```js
	 * const curve = new THREE.EllipseCurve(
	 * 	0, 0,
	 * 	10, 10,
	 * 	0, 2 * Math.PI,
	 * 	false,
	 * 	0
	 * );
	 *
	 * const points = curve.getPoints( 50 );
	 * const geometry = new THREE.BufferGeometry().setFromPoints( points );
	 *
	 * const material = new THREE.LineBasicMaterial( { color: 0xff0000 } );
	 *
	 * // Create the final object to add to the scene
	 * const ellipse = new THREE.Line( geometry, material );
	 * ```
	 *
	 * @augments Curve
	 */
	class EllipseCurve extends Curve {

		/**
		 * Constructs a new ellipse curve.
		 *
		 * @param {number} [aX=0] - The X center of the ellipse.
		 * @param {number} [aY=0] - The Y center of the ellipse.
		 * @param {number} [xRadius=1] - The radius of the ellipse in the x direction.
		 * @param {number} [yRadius=1] - The radius of the ellipse in the y direction.
		 * @param {number} [aStartAngle=0] - The start angle of the curve in radians starting from the positive X axis.
		 * @param {number} [aEndAngle=Math.PI*2] - The end angle of the curve in radians starting from the positive X axis.
		 * @param {boolean} [aClockwise=false] - Whether the ellipse is drawn clockwise or not.
		 * @param {number} [aRotation=0] - The rotation angle of the ellipse in radians, counterclockwise from the positive X axis.
		 */
		constructor( aX = 0, aY = 0, xRadius = 1, yRadius = 1, aStartAngle = 0, aEndAngle = Math.PI * 2, aClockwise = false, aRotation = 0 ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isEllipseCurve = true;

			this.type = 'EllipseCurve';

			/**
			 * The X center of the ellipse.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.aX = aX;

			/**
			 * The Y center of the ellipse.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.aY = aY;

			/**
			 * The radius of the ellipse in the x direction.
			 * Setting the this value equal to the {@link EllipseCurve#yRadius} will result in a circle.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.xRadius = xRadius;

			/**
			 * The radius of the ellipse in the y direction.
			 * Setting the this value equal to the {@link EllipseCurve#xRadius} will result in a circle.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.yRadius = yRadius;

			/**
			 * The start angle of the curve in radians starting from the positive X axis.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.aStartAngle = aStartAngle;

			/**
			 * The end angle of the curve in radians starting from the positive X axis.
			 *
			 * @type {number}
			 * @default Math.PI*2
			 */
			this.aEndAngle = aEndAngle;

			/**
			 * Whether the ellipse is drawn clockwise or not.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.aClockwise = aClockwise;

			/**
			 * The rotation angle of the ellipse in radians, counterclockwise from the positive X axis.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.aRotation = aRotation;

		}

		/**
		 * Returns a point on the curve.
		 *
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {Vector2} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector2} The position on the curve.
		 */
		getPoint( t, optionalTarget = new Vector2() ) {

			const point = optionalTarget;

			const twoPi = Math.PI * 2;
			let deltaAngle = this.aEndAngle - this.aStartAngle;
			const samePoints = Math.abs( deltaAngle ) < Number.EPSILON;

			// ensures that deltaAngle is 0 .. 2 PI
			while ( deltaAngle < 0 ) deltaAngle += twoPi;
			while ( deltaAngle > twoPi ) deltaAngle -= twoPi;

			if ( deltaAngle < Number.EPSILON ) {

				if ( samePoints ) {

					deltaAngle = 0;

				} else {

					deltaAngle = twoPi;

				}

			}

			if ( this.aClockwise === true && ! samePoints ) {

				if ( deltaAngle === twoPi ) {

					deltaAngle = - twoPi;

				} else {

					deltaAngle = deltaAngle - twoPi;

				}

			}

			const angle = this.aStartAngle + t * deltaAngle;
			let x = this.aX + this.xRadius * Math.cos( angle );
			let y = this.aY + this.yRadius * Math.sin( angle );

			if ( this.aRotation !== 0 ) {

				const cos = Math.cos( this.aRotation );
				const sin = Math.sin( this.aRotation );

				const tx = x - this.aX;
				const ty = y - this.aY;

				// Rotate the point about the center of the ellipse.
				x = tx * cos - ty * sin + this.aX;
				y = tx * sin + ty * cos + this.aY;

			}

			return point.set( x, y );

		}

		copy( source ) {

			super.copy( source );

			this.aX = source.aX;
			this.aY = source.aY;

			this.xRadius = source.xRadius;
			this.yRadius = source.yRadius;

			this.aStartAngle = source.aStartAngle;
			this.aEndAngle = source.aEndAngle;

			this.aClockwise = source.aClockwise;

			this.aRotation = source.aRotation;

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.aX = this.aX;
			data.aY = this.aY;

			data.xRadius = this.xRadius;
			data.yRadius = this.yRadius;

			data.aStartAngle = this.aStartAngle;
			data.aEndAngle = this.aEndAngle;

			data.aClockwise = this.aClockwise;

			data.aRotation = this.aRotation;

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.aX = json.aX;
			this.aY = json.aY;

			this.xRadius = json.xRadius;
			this.yRadius = json.yRadius;

			this.aStartAngle = json.aStartAngle;
			this.aEndAngle = json.aEndAngle;

			this.aClockwise = json.aClockwise;

			this.aRotation = json.aRotation;

			return this;

		}

	}

	/**
	 * A curve representing an arc.
	 *
	 * @augments EllipseCurve
	 */
	class ArcCurve extends EllipseCurve {

		/**
		 * Constructs a new arc curve.
		 *
		 * @param {number} [aX=0] - The X center of the ellipse.
		 * @param {number} [aY=0] - The Y center of the ellipse.
		 * @param {number} [aRadius=1] - The radius of the ellipse in the x direction.
		 * @param {number} [aStartAngle=0] - The start angle of the curve in radians starting from the positive X axis.
		 * @param {number} [aEndAngle=Math.PI*2] - The end angle of the curve in radians starting from the positive X axis.
		 * @param {boolean} [aClockwise=false] - Whether the ellipse is drawn clockwise or not.
		 */
		constructor( aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise ) {

			super( aX, aY, aRadius, aRadius, aStartAngle, aEndAngle, aClockwise );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isArcCurve = true;

			this.type = 'ArcCurve';

		}

	}

	function CubicPoly() {

		/**
		 * Centripetal CatmullRom Curve - which is useful for avoiding
		* cusps and self-intersections in non-uniform catmull rom curves.
		* http://www.cemyuksel.com/research/catmullrom_param/catmullrom.pdf
		*
		* curve.type accepts centripetal(default), chordal and catmullrom
		* curve.tension is used for catmullrom which defaults to 0.5
		*/

		/*
		Based on an optimized c++ solution in
		- http://stackoverflow.com/questions/9489736/catmull-rom-curve-with-no-cusps-and-no-self-intersections/
		- http://ideone.com/NoEbVM

		This CubicPoly class could be used for reusing some variables and calculations,
		but for three.js curve use, it could be possible inlined and flatten into a single function call
		which can be placed in CurveUtils.
		*/

		let c0 = 0, c1 = 0, c2 = 0, c3 = 0;

		/*
		 * Compute coefficients for a cubic polynomial
		 *   p(s) = c0 + c1*s + c2*s^2 + c3*s^3
		 * such that
		 *   p(0) = x0, p(1) = x1
		 *  and
		 *   p'(0) = t0, p'(1) = t1.
		 */
		function init( x0, x1, t0, t1 ) {

			c0 = x0;
			c1 = t0;
			c2 = -3 * x0 + 3 * x1 - 2 * t0 - t1;
			c3 = 2 * x0 - 2 * x1 + t0 + t1;

		}

		return {

			initCatmullRom: function ( x0, x1, x2, x3, tension ) {

				init( x1, x2, tension * ( x2 - x0 ), tension * ( x3 - x1 ) );

			},

			initNonuniformCatmullRom: function ( x0, x1, x2, x3, dt0, dt1, dt2 ) {

				// compute tangents when parameterized in [t1,t2]
				let t1 = ( x1 - x0 ) / dt0 - ( x2 - x0 ) / ( dt0 + dt1 ) + ( x2 - x1 ) / dt1;
				let t2 = ( x2 - x1 ) / dt1 - ( x3 - x1 ) / ( dt1 + dt2 ) + ( x3 - x2 ) / dt2;

				// rescale tangents for parametrization in [0,1]
				t1 *= dt1;
				t2 *= dt1;

				init( x1, x2, t1, t2 );

			},

			calc: function ( t ) {

				const t2 = t * t;
				const t3 = t2 * t;
				return c0 + c1 * t + c2 * t2 + c3 * t3;

			}

		};

	}

	//

	const tmp = /*@__PURE__*/ new Vector3();
	const px = /*@__PURE__*/ new CubicPoly();
	const py = /*@__PURE__*/ new CubicPoly();
	const pz = /*@__PURE__*/ new CubicPoly();

	/**
	 * A curve representing a Catmull-Rom spline.
	 *
	 * ```js
	 * //Create a closed wavey loop
	 * const curve = new THREE.CatmullRomCurve3( [
	 * 	new THREE.Vector3( -10, 0, 10 ),
	 * 	new THREE.Vector3( -5, 5, 5 ),
	 * 	new THREE.Vector3( 0, 0, 0 ),
	 * 	new THREE.Vector3( 5, -5, 5 ),
	 * 	new THREE.Vector3( 10, 0, 10 )
	 * ] );
	 *
	 * const points = curve.getPoints( 50 );
	 * const geometry = new THREE.BufferGeometry().setFromPoints( points );
	 *
	 * const material = new THREE.LineBasicMaterial( { color: 0xff0000 } );
	 *
	 * // Create the final object to add to the scene
	 * const curveObject = new THREE.Line( geometry, material );
	 * ```
	 *
	 * @augments Curve
	 */
	class CatmullRomCurve3 extends Curve {

		/**
		 * Constructs a new Catmull-Rom curve.
		 *
		 * @param {Array<Vector3>} [points] - An array of 3D points defining the curve.
		 * @param {boolean} [closed=false] - Whether the curve is closed or not.
		 * @param {('centripetal'|'chordal'|'catmullrom')} [curveType='centripetal'] - The curve type.
		 * @param {number} [tension=0.5] - Tension of the curve.
		 */
		constructor( points = [], closed = false, curveType = 'centripetal', tension = 0.5 ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isCatmullRomCurve3 = true;

			this.type = 'CatmullRomCurve3';

			/**
			 * An array of 3D points defining the curve.
			 *
			 * @type {Array<Vector3>}
			 */
			this.points = points;

			/**
			 * Whether the curve is closed or not.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.closed = closed;

			/**
			 * The curve type.
			 *
			 * @type {('centripetal'|'chordal'|'catmullrom')}
			 * @default 'centripetal'
			 */
			this.curveType = curveType;

			/**
			 * Tension of the curve.
			 *
			 * @type {number}
			 * @default 0.5
			 */
			this.tension = tension;

		}

		/**
		 * Returns a point on the curve.
		 *
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {Vector3} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector3} The position on the curve.
		 */
		getPoint( t, optionalTarget = new Vector3() ) {

			const point = optionalTarget;

			const points = this.points;
			const l = points.length;

			const p = ( l - ( this.closed ? 0 : 1 ) ) * t;
			let intPoint = Math.floor( p );
			let weight = p - intPoint;

			if ( this.closed ) {

				intPoint += intPoint > 0 ? 0 : ( Math.floor( Math.abs( intPoint ) / l ) + 1 ) * l;

			} else if ( weight === 0 && intPoint === l - 1 ) {

				intPoint = l - 2;
				weight = 1;

			}

			let p0, p3; // 4 points (p1 & p2 defined below)

			if ( this.closed || intPoint > 0 ) {

				p0 = points[ ( intPoint - 1 ) % l ];

			} else {

				// extrapolate first point
				tmp.subVectors( points[ 0 ], points[ 1 ] ).add( points[ 0 ] );
				p0 = tmp;

			}

			const p1 = points[ intPoint % l ];
			const p2 = points[ ( intPoint + 1 ) % l ];

			if ( this.closed || intPoint + 2 < l ) {

				p3 = points[ ( intPoint + 2 ) % l ];

			} else {

				// extrapolate last point
				tmp.subVectors( points[ l - 1 ], points[ l - 2 ] ).add( points[ l - 1 ] );
				p3 = tmp;

			}

			if ( this.curveType === 'centripetal' || this.curveType === 'chordal' ) {

				// init Centripetal / Chordal Catmull-Rom
				const pow = this.curveType === 'chordal' ? 0.5 : 0.25;
				let dt0 = Math.pow( p0.distanceToSquared( p1 ), pow );
				let dt1 = Math.pow( p1.distanceToSquared( p2 ), pow );
				let dt2 = Math.pow( p2.distanceToSquared( p3 ), pow );

				// safety check for repeated points
				if ( dt1 < 1e-4 ) dt1 = 1.0;
				if ( dt0 < 1e-4 ) dt0 = dt1;
				if ( dt2 < 1e-4 ) dt2 = dt1;

				px.initNonuniformCatmullRom( p0.x, p1.x, p2.x, p3.x, dt0, dt1, dt2 );
				py.initNonuniformCatmullRom( p0.y, p1.y, p2.y, p3.y, dt0, dt1, dt2 );
				pz.initNonuniformCatmullRom( p0.z, p1.z, p2.z, p3.z, dt0, dt1, dt2 );

			} else if ( this.curveType === 'catmullrom' ) {

				px.initCatmullRom( p0.x, p1.x, p2.x, p3.x, this.tension );
				py.initCatmullRom( p0.y, p1.y, p2.y, p3.y, this.tension );
				pz.initCatmullRom( p0.z, p1.z, p2.z, p3.z, this.tension );

			}

			point.set(
				px.calc( weight ),
				py.calc( weight ),
				pz.calc( weight )
			);

			return point;

		}

		copy( source ) {

			super.copy( source );

			this.points = [];

			for ( let i = 0, l = source.points.length; i < l; i ++ ) {

				const point = source.points[ i ];

				this.points.push( point.clone() );

			}

			this.closed = source.closed;
			this.curveType = source.curveType;
			this.tension = source.tension;

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.points = [];

			for ( let i = 0, l = this.points.length; i < l; i ++ ) {

				const point = this.points[ i ];
				data.points.push( point.toArray() );

			}

			data.closed = this.closed;
			data.curveType = this.curveType;
			data.tension = this.tension;

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.points = [];

			for ( let i = 0, l = json.points.length; i < l; i ++ ) {

				const point = json.points[ i ];
				this.points.push( new Vector3().fromArray( point ) );

			}

			this.closed = json.closed;
			this.curveType = json.curveType;
			this.tension = json.tension;

			return this;

		}

	}

	// Bezier Curves formulas obtained from: https://en.wikipedia.org/wiki/B%C3%A9zier_curve

	/**
	 * Computes a point on a Catmull-Rom spline.
	 *
	 * @param {number} t - The interpolation factor.
	 * @param {number} p0 - The first control point.
	 * @param {number} p1 - The second control point.
	 * @param {number} p2 - The third control point.
	 * @param {number} p3 - The fourth control point.
	 * @return {number} The calculated point on a Catmull-Rom spline.
	 */
	function CatmullRom( t, p0, p1, p2, p3 ) {

		const v0 = ( p2 - p0 ) * 0.5;
		const v1 = ( p3 - p1 ) * 0.5;
		const t2 = t * t;
		const t3 = t * t2;
		return ( 2 * p1 - 2 * p2 + v0 + v1 ) * t3 + ( -3 * p1 + 3 * p2 - 2 * v0 - v1 ) * t2 + v0 * t + p1;

	}

	//

	function QuadraticBezierP0( t, p ) {

		const k = 1 - t;
		return k * k * p;

	}

	function QuadraticBezierP1( t, p ) {

		return 2 * ( 1 - t ) * t * p;

	}

	function QuadraticBezierP2( t, p ) {

		return t * t * p;

	}

	/**
	 * Computes a point on a Quadratic Bezier curve.
	 *
	 * @param {number} t - The interpolation factor.
	 * @param {number} p0 - The first control point.
	 * @param {number} p1 - The second control point.
	 * @param {number} p2 - The third control point.
	 * @return {number} The calculated point on a Quadratic Bezier curve.
	 */
	function QuadraticBezier( t, p0, p1, p2 ) {

		return QuadraticBezierP0( t, p0 ) + QuadraticBezierP1( t, p1 ) +
			QuadraticBezierP2( t, p2 );

	}

	//

	function CubicBezierP0( t, p ) {

		const k = 1 - t;
		return k * k * k * p;

	}

	function CubicBezierP1( t, p ) {

		const k = 1 - t;
		return 3 * k * k * t * p;

	}

	function CubicBezierP2( t, p ) {

		return 3 * ( 1 - t ) * t * t * p;

	}

	function CubicBezierP3( t, p ) {

		return t * t * t * p;

	}

	/**
	 * Computes a point on a Cubic Bezier curve.
	 *
	 * @param {number} t - The interpolation factor.
	 * @param {number} p0 - The first control point.
	 * @param {number} p1 - The second control point.
	 * @param {number} p2 - The third control point.
	 * @param {number} p3 - The fourth control point.
	 * @return {number} The calculated point on a Cubic Bezier curve.
	 */
	function CubicBezier( t, p0, p1, p2, p3 ) {

		return CubicBezierP0( t, p0 ) + CubicBezierP1( t, p1 ) + CubicBezierP2( t, p2 ) +
			CubicBezierP3( t, p3 );

	}

	/**
	 * A curve representing a 2D Cubic Bezier curve.
	 *
	 * ```js
	 * const curve = new THREE.CubicBezierCurve(
	 * 	new THREE.Vector2( - 0, 0 ),
	 * 	new THREE.Vector2( - 5, 15 ),
	 * 	new THREE.Vector2( 20, 15 ),
	 * 	new THREE.Vector2( 10, 0 )
	 * );
	 *
	 * const points = curve.getPoints( 50 );
	 * const geometry = new THREE.BufferGeometry().setFromPoints( points );
	 *
	 * const material = new THREE.LineBasicMaterial( { color: 0xff0000 } );
	 *
	 * // Create the final object to add to the scene
	 * const curveObject = new THREE.Line( geometry, material );
	 * ```
	 *
	 * @augments Curve
	 */
	class CubicBezierCurve extends Curve {

		/**
		 * Constructs a new Cubic Bezier curve.
		 *
		 * @param {Vector2} [v0] - The start point.
		 * @param {Vector2} [v1] - The first control point.
		 * @param {Vector2} [v2] - The second control point.
		 * @param {Vector2} [v3] - The end point.
		 */
		constructor( v0 = new Vector2(), v1 = new Vector2(), v2 = new Vector2(), v3 = new Vector2() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isCubicBezierCurve = true;

			this.type = 'CubicBezierCurve';

			/**
			 * The start point.
			 *
			 * @type {Vector2}
			 */
			this.v0 = v0;

			/**
			 * The first control point.
			 *
			 * @type {Vector2}
			 */
			this.v1 = v1;

			/**
			 * The second control point.
			 *
			 * @type {Vector2}
			 */
			this.v2 = v2;

			/**
			 * The end point.
			 *
			 * @type {Vector2}
			 */
			this.v3 = v3;

		}

		/**
		 * Returns a point on the curve.
		 *
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {Vector2} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector2} The position on the curve.
		 */
		getPoint( t, optionalTarget = new Vector2() ) {

			const point = optionalTarget;

			const v0 = this.v0, v1 = this.v1, v2 = this.v2, v3 = this.v3;

			point.set(
				CubicBezier( t, v0.x, v1.x, v2.x, v3.x ),
				CubicBezier( t, v0.y, v1.y, v2.y, v3.y )
			);

			return point;

		}

		copy( source ) {

			super.copy( source );

			this.v0.copy( source.v0 );
			this.v1.copy( source.v1 );
			this.v2.copy( source.v2 );
			this.v3.copy( source.v3 );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.v0 = this.v0.toArray();
			data.v1 = this.v1.toArray();
			data.v2 = this.v2.toArray();
			data.v3 = this.v3.toArray();

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.v0.fromArray( json.v0 );
			this.v1.fromArray( json.v1 );
			this.v2.fromArray( json.v2 );
			this.v3.fromArray( json.v3 );

			return this;

		}

	}

	/**
	 * A curve representing a 3D Cubic Bezier curve.
	 *
	 * @augments Curve
	 */
	class CubicBezierCurve3 extends Curve {

		/**
		 * Constructs a new Cubic Bezier curve.
		 *
		 * @param {Vector3} [v0] - The start point.
		 * @param {Vector3} [v1] - The first control point.
		 * @param {Vector3} [v2] - The second control point.
		 * @param {Vector3} [v3] - The end point.
		 */
		constructor( v0 = new Vector3(), v1 = new Vector3(), v2 = new Vector3(), v3 = new Vector3() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isCubicBezierCurve3 = true;

			this.type = 'CubicBezierCurve3';

			/**
			 * The start point.
			 *
			 * @type {Vector3}
			 */
			this.v0 = v0;

			/**
			 * The first control point.
			 *
			 * @type {Vector3}
			 */
			this.v1 = v1;

			/**
			 * The second control point.
			 *
			 * @type {Vector3}
			 */
			this.v2 = v2;

			/**
			 * The end point.
			 *
			 * @type {Vector3}
			 */
			this.v3 = v3;

		}

		/**
		 * Returns a point on the curve.
		 *
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {Vector3} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector3} The position on the curve.
		 */
		getPoint( t, optionalTarget = new Vector3() ) {

			const point = optionalTarget;

			const v0 = this.v0, v1 = this.v1, v2 = this.v2, v3 = this.v3;

			point.set(
				CubicBezier( t, v0.x, v1.x, v2.x, v3.x ),
				CubicBezier( t, v0.y, v1.y, v2.y, v3.y ),
				CubicBezier( t, v0.z, v1.z, v2.z, v3.z )
			);

			return point;

		}

		copy( source ) {

			super.copy( source );

			this.v0.copy( source.v0 );
			this.v1.copy( source.v1 );
			this.v2.copy( source.v2 );
			this.v3.copy( source.v3 );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.v0 = this.v0.toArray();
			data.v1 = this.v1.toArray();
			data.v2 = this.v2.toArray();
			data.v3 = this.v3.toArray();

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.v0.fromArray( json.v0 );
			this.v1.fromArray( json.v1 );
			this.v2.fromArray( json.v2 );
			this.v3.fromArray( json.v3 );

			return this;

		}

	}

	/**
	 * A curve representing a 2D line segment.
	 *
	 * @augments Curve
	 */
	class LineCurve extends Curve {

		/**
		 * Constructs a new line curve.
		 *
		 * @param {Vector2} [v1] - The start point.
		 * @param {Vector2} [v2] - The end point.
		 */
		constructor( v1 = new Vector2(), v2 = new Vector2() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineCurve = true;

			this.type = 'LineCurve';

			/**
			 * The start point.
			 *
			 * @type {Vector2}
			 */
			this.v1 = v1;

			/**
			 * The end point.
			 *
			 * @type {Vector2}
			 */
			this.v2 = v2;

		}

		/**
		 * Returns a point on the line.
		 *
		 * @param {number} t - A interpolation factor representing a position on the line. Must be in the range `[0,1]`.
		 * @param {Vector2} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector2} The position on the line.
		 */
		getPoint( t, optionalTarget = new Vector2() ) {

			const point = optionalTarget;

			if ( t === 1 ) {

				point.copy( this.v2 );

			} else {

				point.copy( this.v2 ).sub( this.v1 );
				point.multiplyScalar( t ).add( this.v1 );

			}

			return point;

		}

		// Line curve is linear, so we can overwrite default getPointAt
		getPointAt( u, optionalTarget ) {

			return this.getPoint( u, optionalTarget );

		}

		getTangent( t, optionalTarget = new Vector2() ) {

			return optionalTarget.subVectors( this.v2, this.v1 ).normalize();

		}

		getTangentAt( u, optionalTarget ) {

			return this.getTangent( u, optionalTarget );

		}

		copy( source ) {

			super.copy( source );

			this.v1.copy( source.v1 );
			this.v2.copy( source.v2 );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.v1 = this.v1.toArray();
			data.v2 = this.v2.toArray();

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.v1.fromArray( json.v1 );
			this.v2.fromArray( json.v2 );

			return this;

		}

	}

	/**
	 * A curve representing a 3D line segment.
	 *
	 * @augments Curve
	 */
	class LineCurve3 extends Curve {

		/**
		 * Constructs a new line curve.
		 *
		 * @param {Vector3} [v1] - The start point.
		 * @param {Vector3} [v2] - The end point.
		 */
		constructor( v1 = new Vector3(), v2 = new Vector3() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineCurve3 = true;

			this.type = 'LineCurve3';

			/**
			 * The start point.
			 *
			 * @type {Vector3}
			 */
			this.v1 = v1;

			/**
			 * The end point.
			 *
			 * @type {Vector2}
			 */
			this.v2 = v2;

		}

		/**
		 * Returns a point on the line.
		 *
		 * @param {number} t - A interpolation factor representing a position on the line. Must be in the range `[0,1]`.
		 * @param {Vector3} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector3} The position on the line.
		 */
		getPoint( t, optionalTarget = new Vector3() ) {

			const point = optionalTarget;

			if ( t === 1 ) {

				point.copy( this.v2 );

			} else {

				point.copy( this.v2 ).sub( this.v1 );
				point.multiplyScalar( t ).add( this.v1 );

			}

			return point;

		}

		// Line curve is linear, so we can overwrite default getPointAt
		getPointAt( u, optionalTarget ) {

			return this.getPoint( u, optionalTarget );

		}

		getTangent( t, optionalTarget = new Vector3() ) {

			return optionalTarget.subVectors( this.v2, this.v1 ).normalize();

		}

		getTangentAt( u, optionalTarget ) {

			return this.getTangent( u, optionalTarget );

		}

		copy( source ) {

			super.copy( source );

			this.v1.copy( source.v1 );
			this.v2.copy( source.v2 );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.v1 = this.v1.toArray();
			data.v2 = this.v2.toArray();

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.v1.fromArray( json.v1 );
			this.v2.fromArray( json.v2 );

			return this;

		}

	}

	/**
	 * A curve representing a 2D Quadratic Bezier curve.
	 *
	 * ```js
	 * const curve = new THREE.QuadraticBezierCurve(
	 * 	new THREE.Vector2( - 10, 0 ),
	 * 	new THREE.Vector2( 20, 15 ),
	 * 	new THREE.Vector2( 10, 0 )
	 * )
	 *
	 * const points = curve.getPoints( 50 );
	 * const geometry = new THREE.BufferGeometry().setFromPoints( points );
	 *
	 * const material = new THREE.LineBasicMaterial( { color: 0xff0000 } );
	 *
	 * // Create the final object to add to the scene
	 * const curveObject = new THREE.Line( geometry, material );
	 * ```
	 *
	 * @augments Curve
	 */
	class QuadraticBezierCurve extends Curve {

		/**
		 * Constructs a new Quadratic Bezier curve.
		 *
		 * @param {Vector2} [v0] - The start point.
		 * @param {Vector2} [v1] - The control point.
		 * @param {Vector2} [v2] - The end point.
		 */
		constructor( v0 = new Vector2(), v1 = new Vector2(), v2 = new Vector2() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isQuadraticBezierCurve = true;

			this.type = 'QuadraticBezierCurve';

			/**
			 * The start point.
			 *
			 * @type {Vector2}
			 */
			this.v0 = v0;

			/**
			 * The control point.
			 *
			 * @type {Vector2}
			 */
			this.v1 = v1;

			/**
			 * The end point.
			 *
			 * @type {Vector2}
			 */
			this.v2 = v2;

		}

		/**
		 * Returns a point on the curve.
		 *
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {Vector2} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector2} The position on the curve.
		 */
		getPoint( t, optionalTarget = new Vector2() ) {

			const point = optionalTarget;

			const v0 = this.v0, v1 = this.v1, v2 = this.v2;

			point.set(
				QuadraticBezier( t, v0.x, v1.x, v2.x ),
				QuadraticBezier( t, v0.y, v1.y, v2.y )
			);

			return point;

		}

		copy( source ) {

			super.copy( source );

			this.v0.copy( source.v0 );
			this.v1.copy( source.v1 );
			this.v2.copy( source.v2 );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.v0 = this.v0.toArray();
			data.v1 = this.v1.toArray();
			data.v2 = this.v2.toArray();

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.v0.fromArray( json.v0 );
			this.v1.fromArray( json.v1 );
			this.v2.fromArray( json.v2 );

			return this;

		}

	}

	/**
	 * A curve representing a 3D Quadratic Bezier curve.
	 *
	 * @augments Curve
	 */
	class QuadraticBezierCurve3 extends Curve {

		/**
		 * Constructs a new Quadratic Bezier curve.
		 *
		 * @param {Vector3} [v0] - The start point.
		 * @param {Vector3} [v1] - The control point.
		 * @param {Vector3} [v2] - The end point.
		 */
		constructor( v0 = new Vector3(), v1 = new Vector3(), v2 = new Vector3() ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isQuadraticBezierCurve3 = true;

			this.type = 'QuadraticBezierCurve3';

			/**
			 * The start point.
			 *
			 * @type {Vector3}
			 */
			this.v0 = v0;

			/**
			 * The control point.
			 *
			 * @type {Vector3}
			 */
			this.v1 = v1;

			/**
			 * The end point.
			 *
			 * @type {Vector3}
			 */
			this.v2 = v2;

		}

		/**
		 * Returns a point on the curve.
		 *
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {Vector3} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector3} The position on the curve.
		 */
		getPoint( t, optionalTarget = new Vector3() ) {

			const point = optionalTarget;

			const v0 = this.v0, v1 = this.v1, v2 = this.v2;

			point.set(
				QuadraticBezier( t, v0.x, v1.x, v2.x ),
				QuadraticBezier( t, v0.y, v1.y, v2.y ),
				QuadraticBezier( t, v0.z, v1.z, v2.z )
			);

			return point;

		}

		copy( source ) {

			super.copy( source );

			this.v0.copy( source.v0 );
			this.v1.copy( source.v1 );
			this.v2.copy( source.v2 );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.v0 = this.v0.toArray();
			data.v1 = this.v1.toArray();
			data.v2 = this.v2.toArray();

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.v0.fromArray( json.v0 );
			this.v1.fromArray( json.v1 );
			this.v2.fromArray( json.v2 );

			return this;

		}

	}

	/**
	 * A curve representing a 2D spline curve.
	 *
	 * ```js
	 * // Create a sine-like wave
	 * const curve = new THREE.SplineCurve( [
	 * 	new THREE.Vector2( -10, 0 ),
	 * 	new THREE.Vector2( -5, 5 ),
	 * 	new THREE.Vector2( 0, 0 ),
	 * 	new THREE.Vector2( 5, -5 ),
	 * 	new THREE.Vector2( 10, 0 )
	 * ] );
	 *
	 * const points = curve.getPoints( 50 );
	 * const geometry = new THREE.BufferGeometry().setFromPoints( points );
	 *
	 * const material = new THREE.LineBasicMaterial( { color: 0xff0000 } );
	 *
	 * // Create the final object to add to the scene
	 * const splineObject = new THREE.Line( geometry, material );
	 * ```
	 *
	 * @augments Curve
	 */
	class SplineCurve extends Curve {

		/**
		 * Constructs a new 2D spline curve.
		 *
		 * @param {Array<Vector2>} [points] -  An array of 2D points defining the curve.
		 */
		constructor( points = [] ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isSplineCurve = true;

			this.type = 'SplineCurve';

			/**
			 * An array of 2D points defining the curve.
			 *
			 * @type {Array<Vector2>}
			 */
			this.points = points;

		}

		/**
		 * Returns a point on the curve.
		 *
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {Vector2} [optionalTarget] - The optional target vector the result is written to.
		 * @return {Vector2} The position on the curve.
		 */
		getPoint( t, optionalTarget = new Vector2() ) {

			const point = optionalTarget;

			const points = this.points;
			const p = ( points.length - 1 ) * t;

			const intPoint = Math.floor( p );
			const weight = p - intPoint;

			const p0 = points[ intPoint === 0 ? intPoint : intPoint - 1 ];
			const p1 = points[ intPoint ];
			const p2 = points[ intPoint > points.length - 2 ? points.length - 1 : intPoint + 1 ];
			const p3 = points[ intPoint > points.length - 3 ? points.length - 1 : intPoint + 2 ];

			point.set(
				CatmullRom( weight, p0.x, p1.x, p2.x, p3.x ),
				CatmullRom( weight, p0.y, p1.y, p2.y, p3.y )
			);

			return point;

		}

		copy( source ) {

			super.copy( source );

			this.points = [];

			for ( let i = 0, l = source.points.length; i < l; i ++ ) {

				const point = source.points[ i ];

				this.points.push( point.clone() );

			}

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.points = [];

			for ( let i = 0, l = this.points.length; i < l; i ++ ) {

				const point = this.points[ i ];
				data.points.push( point.toArray() );

			}

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.points = [];

			for ( let i = 0, l = json.points.length; i < l; i ++ ) {

				const point = json.points[ i ];
				this.points.push( new Vector2().fromArray( point ) );

			}

			return this;

		}

	}

	var Curves = /*#__PURE__*/Object.freeze({
		__proto__: null,
		ArcCurve: ArcCurve,
		CatmullRomCurve3: CatmullRomCurve3,
		CubicBezierCurve: CubicBezierCurve,
		CubicBezierCurve3: CubicBezierCurve3,
		EllipseCurve: EllipseCurve,
		LineCurve: LineCurve,
		LineCurve3: LineCurve3,
		QuadraticBezierCurve: QuadraticBezierCurve,
		QuadraticBezierCurve3: QuadraticBezierCurve3,
		SplineCurve: SplineCurve
	});

	/**
	 * A base class extending {@link Curve}. `CurvePath` is simply an
	 * array of connected curves, but retains the API of a curve.
	 *
	 * @augments Curve
	 */
	class CurvePath extends Curve {

		/**
		 * Constructs a new curve path.
		 */
		constructor() {

			super();

			this.type = 'CurvePath';

			/**
			 * An array of curves defining the
			 * path.
			 *
			 * @type {Array<Curve>}
			 */
			this.curves = [];

			/**
			 * Whether the path should automatically be closed
			 * by a line curve.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.autoClose = false;

		}

		/**
		 * Adds a curve to this curve path.
		 *
		 * @param {Curve} curve - The curve to add.
		 */
		add( curve ) {

			this.curves.push( curve );

		}

		/**
		 * Adds a line curve to close the path.
		 *
		 * @return {CurvePath} A reference to this curve path.
		 */
		closePath() {

			// Add a line curve if start and end of lines are not connected
			const startPoint = this.curves[ 0 ].getPoint( 0 );
			const endPoint = this.curves[ this.curves.length - 1 ].getPoint( 1 );

			if ( ! startPoint.equals( endPoint ) ) {

				const lineType = ( startPoint.isVector2 === true ) ? 'LineCurve' : 'LineCurve3';
				this.curves.push( new Curves[ lineType ]( endPoint, startPoint ) );

			}

			return this;

		}

		/**
		 * This method returns a vector in 2D or 3D space (depending on the curve definitions)
		 * for the given interpolation factor.
		 *
		 * @param {number} t - A interpolation factor representing a position on the curve. Must be in the range `[0,1]`.
		 * @param {(Vector2|Vector3)} [optionalTarget] - The optional target vector the result is written to.
		 * @return {?(Vector2|Vector3)} The position on the curve. It can be a 2D or 3D vector depending on the curve definition.
		 */
		getPoint( t, optionalTarget ) {

			// To get accurate point with reference to
			// entire path distance at time t,
			// following has to be done:

			// 1. Length of each sub path have to be known
			// 2. Locate and identify type of curve
			// 3. Get t for the curve
			// 4. Return curve.getPointAt(t')

			const d = t * this.getLength();
			const curveLengths = this.getCurveLengths();
			let i = 0;

			// To think about boundaries points.

			while ( i < curveLengths.length ) {

				if ( curveLengths[ i ] >= d ) {

					const diff = curveLengths[ i ] - d;
					const curve = this.curves[ i ];

					const segmentLength = curve.getLength();
					const u = segmentLength === 0 ? 0 : 1 - diff / segmentLength;

					return curve.getPointAt( u, optionalTarget );

				}

				i ++;

			}

			return null;

			// loop where sum != 0, sum > d , sum+1 <d

		}

		getLength() {

			// We cannot use the default THREE.Curve getPoint() with getLength() because in
			// THREE.Curve, getLength() depends on getPoint() but in THREE.CurvePath
			// getPoint() depends on getLength

			const lens = this.getCurveLengths();
			return lens[ lens.length - 1 ];

		}

		updateArcLengths() {

			// cacheLengths must be recalculated.

			this.needsUpdate = true;
			this.cacheLengths = null;
			this.getCurveLengths();

		}

		/**
		 * Returns list of cumulative curve lengths of the defined curves.
		 *
		 * @return {Array<number>} The curve lengths.
		 */
		getCurveLengths() {

			// Compute lengths and cache them
			// We cannot overwrite getLengths() because UtoT mapping uses it.
			// We use cache values if curves and cache array are same length

			if ( this.cacheLengths && this.cacheLengths.length === this.curves.length ) {

				return this.cacheLengths;

			}

			// Get length of sub-curve
			// Push sums into cached array

			const lengths = [];
			let sums = 0;

			for ( let i = 0, l = this.curves.length; i < l; i ++ ) {

				sums += this.curves[ i ].getLength();
				lengths.push( sums );

			}

			this.cacheLengths = lengths;

			return lengths;

		}

		getSpacedPoints( divisions = 40 ) {

			const points = [];

			for ( let i = 0; i <= divisions; i ++ ) {

				points.push( this.getPoint( i / divisions ) );

			}

			if ( this.autoClose ) {

				points.push( points[ 0 ] );

			}

			return points;

		}

		getPoints( divisions = 12 ) {

			const points = [];
			let last;

			for ( let i = 0, curves = this.curves; i < curves.length; i ++ ) {

				const curve = curves[ i ];
				const resolution = curve.isEllipseCurve ? divisions * 2
					: ( curve.isLineCurve || curve.isLineCurve3 ) ? 1
						: curve.isSplineCurve ? divisions * curve.points.length
							: divisions;

				const pts = curve.getPoints( resolution );

				for ( let j = 0; j < pts.length; j ++ ) {

					const point = pts[ j ];

					if ( last && last.equals( point ) ) continue; // ensures no consecutive points are duplicates

					points.push( point );
					last = point;

				}

			}

			if ( this.autoClose && points.length > 1 && ! points[ points.length - 1 ].equals( points[ 0 ] ) ) {

				points.push( points[ 0 ] );

			}

			return points;

		}

		copy( source ) {

			super.copy( source );

			this.curves = [];

			for ( let i = 0, l = source.curves.length; i < l; i ++ ) {

				const curve = source.curves[ i ];

				this.curves.push( curve.clone() );

			}

			this.autoClose = source.autoClose;

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.autoClose = this.autoClose;
			data.curves = [];

			for ( let i = 0, l = this.curves.length; i < l; i ++ ) {

				const curve = this.curves[ i ];
				data.curves.push( curve.toJSON() );

			}

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.autoClose = json.autoClose;
			this.curves = [];

			for ( let i = 0, l = json.curves.length; i < l; i ++ ) {

				const curve = json.curves[ i ];
				this.curves.push( new Curves[ curve.type ]().fromJSON( curve ) );

			}

			return this;

		}

	}

	/**
	 * A 2D path representation. The class provides methods for creating paths
	 * and contours of 2D shapes similar to the 2D Canvas API.
	 *
	 * ```js
	 * const path = new THREE.Path();
	 *
	 * path.lineTo( 0, 0.8 );
	 * path.quadraticCurveTo( 0, 1, 0.2, 1 );
	 * path.lineTo( 1, 1 );
	 *
	 * const points = path.getPoints();
	 *
	 * const geometry = new THREE.BufferGeometry().setFromPoints( points );
	 * const material = new THREE.LineBasicMaterial( { color: 0xffffff } );
	 *
	 * const line = new THREE.Line( geometry, material );
	 * scene.add( line );
	 * ```
	 *
	 * @augments CurvePath
	 */
	class Path extends CurvePath {

		/**
		 * Constructs a new path.
		 *
		 * @param {Array<Vector2>} [points] - An array of 2D points defining the path.
		 */
		constructor( points ) {

			super();

			this.type = 'Path';

			/**
			 * The current offset of the path. Any new curve added will start here.
			 *
			 * @type {Vector2}
			 */
			this.currentPoint = new Vector2();

			if ( points ) {

				this.setFromPoints( points );

			}

		}

		/**
		 * Creates a path from the given list of points. The points are added
		 * to the path as instances of {@link LineCurve}.
		 *
		 * @param {Array<Vector2>} points - An array of 2D points.
		 * @return {Path} A reference to this path.
		 */
		setFromPoints( points ) {

			this.moveTo( points[ 0 ].x, points[ 0 ].y );

			for ( let i = 1, l = points.length; i < l; i ++ ) {

				this.lineTo( points[ i ].x, points[ i ].y );

			}

			return this;

		}

		/**
		 * Moves {@link Path#currentPoint} to the given point.
		 *
		 * @param {number} x - The x coordinate.
		 * @param {number} y - The y coordinate.
		 * @return {Path} A reference to this path.
		 */
		moveTo( x, y ) {

			this.currentPoint.set( x, y ); // TODO consider referencing vectors instead of copying?

			return this;

		}

		/**
		 * Adds an instance of {@link LineCurve} to the path by connecting
		 * the current point with the given one.
		 *
		 * @param {number} x - The x coordinate of the end point.
		 * @param {number} y - The y coordinate of the end point.
		 * @return {Path} A reference to this path.
		 */
		lineTo( x, y ) {

			const curve = new LineCurve( this.currentPoint.clone(), new Vector2( x, y ) );
			this.curves.push( curve );

			this.currentPoint.set( x, y );

			return this;

		}

		/**
		 * Adds an instance of {@link QuadraticBezierCurve} to the path by connecting
		 * the current point with the given one.
		 *
		 * @param {number} aCPx - The x coordinate of the control point.
		 * @param {number} aCPy - The y coordinate of the control point.
		 * @param {number} aX - The x coordinate of the end point.
		 * @param {number} aY - The y coordinate of the end point.
		 * @return {Path} A reference to this path.
		 */
		quadraticCurveTo( aCPx, aCPy, aX, aY ) {

			const curve = new QuadraticBezierCurve(
				this.currentPoint.clone(),
				new Vector2( aCPx, aCPy ),
				new Vector2( aX, aY )
			);

			this.curves.push( curve );

			this.currentPoint.set( aX, aY );

			return this;

		}

		/**
		 * Adds an instance of {@link CubicBezierCurve} to the path by connecting
		 * the current point with the given one.
		 *
		 * @param {number} aCP1x - The x coordinate of the first control point.
		 * @param {number} aCP1y - The y coordinate of the first control point.
		 * @param {number} aCP2x - The x coordinate of the second control point.
		 * @param {number} aCP2y - The y coordinate of the second control point.
		 * @param {number} aX - The x coordinate of the end point.
		 * @param {number} aY - The y coordinate of the end point.
		 * @return {Path} A reference to this path.
		 */
		bezierCurveTo( aCP1x, aCP1y, aCP2x, aCP2y, aX, aY ) {

			const curve = new CubicBezierCurve(
				this.currentPoint.clone(),
				new Vector2( aCP1x, aCP1y ),
				new Vector2( aCP2x, aCP2y ),
				new Vector2( aX, aY )
			);

			this.curves.push( curve );

			this.currentPoint.set( aX, aY );

			return this;

		}

		/**
		 * Adds an instance of {@link SplineCurve} to the path by connecting
		 * the current point with the given list of points.
		 *
		 * @param {Array<Vector2>} pts - An array of points in 2D space.
		 * @return {Path} A reference to this path.
		 */
		splineThru( pts ) {

			const npts = [ this.currentPoint.clone() ].concat( pts );

			const curve = new SplineCurve( npts );
			this.curves.push( curve );

			this.currentPoint.copy( pts[ pts.length - 1 ] );

			return this;

		}

		/**
		 * Adds an arc as an instance of {@link EllipseCurve} to the path, positioned relative
		 * to the current point.
		 *
		 * @param {number} aX - The x coordinate of the center of the arc offsetted from the previous curve.
		 * @param {number} aY - The y coordinate of the center of the arc offsetted from the previous curve.
		 * @param {number} aRadius - The radius of the arc.
		 * @param {number} aStartAngle - The start angle in radians.
		 * @param {number} aEndAngle - The end angle in radians.
		 * @param {boolean} [aClockwise=false] - Whether to sweep the arc clockwise or not.
		 * @return {Path} A reference to this path.
		 */
		arc( aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise ) {

			const x0 = this.currentPoint.x;
			const y0 = this.currentPoint.y;

			this.absarc( aX + x0, aY + y0, aRadius,
				aStartAngle, aEndAngle, aClockwise );

			return this;

		}

		/**
		 * Adds an absolutely positioned arc as an instance of {@link EllipseCurve} to the path.
		 *
		 * @param {number} aX - The x coordinate of the center of the arc.
		 * @param {number} aY - The y coordinate of the center of the arc.
		 * @param {number} aRadius - The radius of the arc.
		 * @param {number} aStartAngle - The start angle in radians.
		 * @param {number} aEndAngle - The end angle in radians.
		 * @param {boolean} [aClockwise=false] - Whether to sweep the arc clockwise or not.
		 * @return {Path} A reference to this path.
		 */
		absarc( aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise ) {

			this.absellipse( aX, aY, aRadius, aRadius, aStartAngle, aEndAngle, aClockwise );

			return this;

		}

		/**
		 * Adds an ellipse as an instance of {@link EllipseCurve} to the path, positioned relative
		 * to the current point
		 *
		 * @param {number} aX - The x coordinate of the center of the ellipse offsetted from the previous curve.
		 * @param {number} aY - The y coordinate of the center of the ellipse offsetted from the previous curve.
		 * @param {number} xRadius - The radius of the ellipse in the x axis.
		 * @param {number} yRadius - The radius of the ellipse in the y axis.
		 * @param {number} aStartAngle - The start angle in radians.
		 * @param {number} aEndAngle - The end angle in radians.
		 * @param {boolean} [aClockwise=false] - Whether to sweep the ellipse clockwise or not.
		 * @param {number} [aRotation=0] - The rotation angle of the ellipse in radians, counterclockwise from the positive X axis.
		 * @return {Path} A reference to this path.
		 */
		ellipse( aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation ) {

			const x0 = this.currentPoint.x;
			const y0 = this.currentPoint.y;

			this.absellipse( aX + x0, aY + y0, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation );

			return this;

		}

		/**
		 * Adds an absolutely positioned ellipse as an instance of {@link EllipseCurve} to the path.
		 *
		 * @param {number} aX - The x coordinate of the absolute center of the ellipse.
		 * @param {number} aY - The y coordinate of the absolute center of the ellipse.
		 * @param {number} xRadius - The radius of the ellipse in the x axis.
		 * @param {number} yRadius - The radius of the ellipse in the y axis.
		 * @param {number} aStartAngle - The start angle in radians.
		 * @param {number} aEndAngle - The end angle in radians.
		 * @param {boolean} [aClockwise=false] - Whether to sweep the ellipse clockwise or not.
		 * @param {number} [aRotation=0] - The rotation angle of the ellipse in radians, counterclockwise from the positive X axis.
		 * @return {Path} A reference to this path.
		 */
		absellipse( aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation ) {

			const curve = new EllipseCurve( aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation );

			if ( this.curves.length > 0 ) {

				// if a previous curve is present, attempt to join
				const firstPoint = curve.getPoint( 0 );

				if ( ! firstPoint.equals( this.currentPoint ) ) {

					this.lineTo( firstPoint.x, firstPoint.y );

				}

			}

			this.curves.push( curve );

			const lastPoint = curve.getPoint( 1 );
			this.currentPoint.copy( lastPoint );

			return this;

		}

		copy( source ) {

			super.copy( source );

			this.currentPoint.copy( source.currentPoint );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.currentPoint = this.currentPoint.toArray();

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.currentPoint.fromArray( json.currentPoint );

			return this;

		}

	}

	/**
	 * Defines an arbitrary 2d shape plane using paths with optional holes. It
	 * can be used with {@link ExtrudeGeometry}, {@link ShapeGeometry}, to get
	 * points, or to get triangulated faces.
	 *
	 * ```js
	 * const heartShape = new THREE.Shape();
	 *
	 * heartShape.moveTo( 25, 25 );
	 * heartShape.bezierCurveTo( 25, 25, 20, 0, 0, 0 );
	 * heartShape.bezierCurveTo( - 30, 0, - 30, 35, - 30, 35 );
	 * heartShape.bezierCurveTo( - 30, 55, - 10, 77, 25, 95 );
	 * heartShape.bezierCurveTo( 60, 77, 80, 55, 80, 35 );
	 * heartShape.bezierCurveTo( 80, 35, 80, 0, 50, 0 );
	 * heartShape.bezierCurveTo( 35, 0, 25, 25, 25, 25 );
	 *
	 * const extrudeSettings = {
	 * 	depth: 8,
	 * 	bevelEnabled: true,
	 * 	bevelSegments: 2,
	 * 	steps: 2,
	 * 	bevelSize: 1,
	 * 	bevelThickness: 1
	 * };
	 *
	 * const geometry = new THREE.ExtrudeGeometry( heartShape, extrudeSettings );
	 * const mesh = new THREE.Mesh( geometry, new THREE.MeshBasicMaterial() );
	 * ```
	 *
	 * @augments Path
	 */
	class Shape extends Path {

		/**
		 * Constructs a new shape.
		 *
		 * @param {Array<Vector2>} [points] - An array of 2D points defining the shape.
		 */
		constructor( points ) {

			super( points );

			/**
			 * The UUID of the shape.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.uuid = generateUUID();

			this.type = 'Shape';

			/**
			 * Defines the holes in the shape. Hole definitions must use the
			 * opposite winding order (CW/CCW) than the outer shape.
			 *
			 * @type {Array<Path>}
			 * @readonly
			 */
			this.holes = [];

		}

		/**
		 * Returns an array representing each contour of the holes
		 * as a list of 2D points.
		 *
		 * @param {number} divisions - The fineness of the result.
		 * @return {Array<Array<Vector2>>} The holes as a series of 2D points.
		 */
		getPointsHoles( divisions ) {

			const holesPts = [];

			for ( let i = 0, l = this.holes.length; i < l; i ++ ) {

				holesPts[ i ] = this.holes[ i ].getPoints( divisions );

			}

			return holesPts;

		}

		// get points of shape and holes (keypoints based on segments parameter)

		/**
		 * Returns an object that holds contour data for the shape and its holes as
		 * arrays of 2D points.
		 *
		 * @param {number} divisions - The fineness of the result.
		 * @return {{shape:Array<Vector2>,holes:Array<Array<Vector2>>}} An object with contour data.
		 */
		extractPoints( divisions ) {

			return {

				shape: this.getPoints( divisions ),
				holes: this.getPointsHoles( divisions )

			};

		}

		copy( source ) {

			super.copy( source );

			this.holes = [];

			for ( let i = 0, l = source.holes.length; i < l; i ++ ) {

				const hole = source.holes[ i ];

				this.holes.push( hole.clone() );

			}

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.uuid = this.uuid;
			data.holes = [];

			for ( let i = 0, l = this.holes.length; i < l; i ++ ) {

				const hole = this.holes[ i ];
				data.holes.push( hole.toJSON() );

			}

			return data;

		}

		fromJSON( json ) {

			super.fromJSON( json );

			this.uuid = json.uuid;
			this.holes = [];

			for ( let i = 0, l = json.holes.length; i < l; i ++ ) {

				const hole = json.holes[ i ];
				this.holes.push( new Path().fromJSON( hole ) );

			}

			return this;

		}

	}

	/* eslint-disable */
	// copy of mapbox/earcut version 3.0.1
	// https://github.com/mapbox/earcut/tree/v3.0.1

	function earcut(data, holeIndices, dim = 2) {

	    const hasHoles = holeIndices && holeIndices.length;
	    const outerLen = hasHoles ? holeIndices[0] * dim : data.length;
	    let outerNode = linkedList(data, 0, outerLen, dim, true);
	    const triangles = [];

	    if (!outerNode || outerNode.next === outerNode.prev) return triangles;

	    let minX, minY, invSize;

	    if (hasHoles) outerNode = eliminateHoles(data, holeIndices, outerNode, dim);

	    // if the shape is not too simple, we'll use z-order curve hash later; calculate polygon bbox
	    if (data.length > 80 * dim) {
	        minX = Infinity;
	        minY = Infinity;
	        let maxX = -Infinity;
	        let maxY = -Infinity;

	        for (let i = dim; i < outerLen; i += dim) {
	            const x = data[i];
	            const y = data[i + 1];
	            if (x < minX) minX = x;
	            if (y < minY) minY = y;
	            if (x > maxX) maxX = x;
	            if (y > maxY) maxY = y;
	        }

	        // minX, minY and invSize are later used to transform coords into integers for z-order calculation
	        invSize = Math.max(maxX - minX, maxY - minY);
	        invSize = invSize !== 0 ? 32767 / invSize : 0;
	    }

	    earcutLinked(outerNode, triangles, dim, minX, minY, invSize, 0);

	    return triangles;
	}

	// create a circular doubly linked list from polygon points in the specified winding order
	function linkedList(data, start, end, dim, clockwise) {
	    let last;

	    if (clockwise === (signedArea(data, start, end, dim) > 0)) {
	        for (let i = start; i < end; i += dim) last = insertNode(i / dim | 0, data[i], data[i + 1], last);
	    } else {
	        for (let i = end - dim; i >= start; i -= dim) last = insertNode(i / dim | 0, data[i], data[i + 1], last);
	    }

	    if (last && equals(last, last.next)) {
	        removeNode(last);
	        last = last.next;
	    }

	    return last;
	}

	// eliminate colinear or duplicate points
	function filterPoints(start, end) {
	    if (!start) return start;
	    if (!end) end = start;

	    let p = start,
	        again;
	    do {
	        again = false;

	        if (!p.steiner && (equals(p, p.next) || area(p.prev, p, p.next) === 0)) {
	            removeNode(p);
	            p = end = p.prev;
	            if (p === p.next) break;
	            again = true;

	        } else {
	            p = p.next;
	        }
	    } while (again || p !== end);

	    return end;
	}

	// main ear slicing loop which triangulates a polygon (given as a linked list)
	function earcutLinked(ear, triangles, dim, minX, minY, invSize, pass) {
	    if (!ear) return;

	    // interlink polygon nodes in z-order
	    if (!pass && invSize) indexCurve(ear, minX, minY, invSize);

	    let stop = ear;

	    // iterate through ears, slicing them one by one
	    while (ear.prev !== ear.next) {
	        const prev = ear.prev;
	        const next = ear.next;

	        if (invSize ? isEarHashed(ear, minX, minY, invSize) : isEar(ear)) {
	            triangles.push(prev.i, ear.i, next.i); // cut off the triangle

	            removeNode(ear);

	            // skipping the next vertex leads to less sliver triangles
	            ear = next.next;
	            stop = next.next;

	            continue;
	        }

	        ear = next;

	        // if we looped through the whole remaining polygon and can't find any more ears
	        if (ear === stop) {
	            // try filtering points and slicing again
	            if (!pass) {
	                earcutLinked(filterPoints(ear), triangles, dim, minX, minY, invSize, 1);

	            // if this didn't work, try curing all small self-intersections locally
	            } else if (pass === 1) {
	                ear = cureLocalIntersections(filterPoints(ear), triangles);
	                earcutLinked(ear, triangles, dim, minX, minY, invSize, 2);

	            // as a last resort, try splitting the remaining polygon into two
	            } else if (pass === 2) {
	                splitEarcut(ear, triangles, dim, minX, minY, invSize);
	            }

	            break;
	        }
	    }
	}

	// check whether a polygon node forms a valid ear with adjacent nodes
	function isEar(ear) {
	    const a = ear.prev,
	        b = ear,
	        c = ear.next;

	    if (area(a, b, c) >= 0) return false; // reflex, can't be an ear

	    // now make sure we don't have other points inside the potential ear
	    const ax = a.x, bx = b.x, cx = c.x, ay = a.y, by = b.y, cy = c.y;

	    // triangle bbox
	    const x0 = Math.min(ax, bx, cx),
	        y0 = Math.min(ay, by, cy),
	        x1 = Math.max(ax, bx, cx),
	        y1 = Math.max(ay, by, cy);

	    let p = c.next;
	    while (p !== a) {
	        if (p.x >= x0 && p.x <= x1 && p.y >= y0 && p.y <= y1 &&
	            pointInTriangleExceptFirst(ax, ay, bx, by, cx, cy, p.x, p.y) &&
	            area(p.prev, p, p.next) >= 0) return false;
	        p = p.next;
	    }

	    return true;
	}

	function isEarHashed(ear, minX, minY, invSize) {
	    const a = ear.prev,
	        b = ear,
	        c = ear.next;

	    if (area(a, b, c) >= 0) return false; // reflex, can't be an ear

	    const ax = a.x, bx = b.x, cx = c.x, ay = a.y, by = b.y, cy = c.y;

	    // triangle bbox
	    const x0 = Math.min(ax, bx, cx),
	        y0 = Math.min(ay, by, cy),
	        x1 = Math.max(ax, bx, cx),
	        y1 = Math.max(ay, by, cy);

	    // z-order range for the current triangle bbox;
	    const minZ = zOrder(x0, y0, minX, minY, invSize),
	        maxZ = zOrder(x1, y1, minX, minY, invSize);

	    let p = ear.prevZ,
	        n = ear.nextZ;

	    // look for points inside the triangle in both directions
	    while (p && p.z >= minZ && n && n.z <= maxZ) {
	        if (p.x >= x0 && p.x <= x1 && p.y >= y0 && p.y <= y1 && p !== a && p !== c &&
	            pointInTriangleExceptFirst(ax, ay, bx, by, cx, cy, p.x, p.y) && area(p.prev, p, p.next) >= 0) return false;
	        p = p.prevZ;

	        if (n.x >= x0 && n.x <= x1 && n.y >= y0 && n.y <= y1 && n !== a && n !== c &&
	            pointInTriangleExceptFirst(ax, ay, bx, by, cx, cy, n.x, n.y) && area(n.prev, n, n.next) >= 0) return false;
	        n = n.nextZ;
	    }

	    // look for remaining points in decreasing z-order
	    while (p && p.z >= minZ) {
	        if (p.x >= x0 && p.x <= x1 && p.y >= y0 && p.y <= y1 && p !== a && p !== c &&
	            pointInTriangleExceptFirst(ax, ay, bx, by, cx, cy, p.x, p.y) && area(p.prev, p, p.next) >= 0) return false;
	        p = p.prevZ;
	    }

	    // look for remaining points in increasing z-order
	    while (n && n.z <= maxZ) {
	        if (n.x >= x0 && n.x <= x1 && n.y >= y0 && n.y <= y1 && n !== a && n !== c &&
	            pointInTriangleExceptFirst(ax, ay, bx, by, cx, cy, n.x, n.y) && area(n.prev, n, n.next) >= 0) return false;
	        n = n.nextZ;
	    }

	    return true;
	}

	// go through all polygon nodes and cure small local self-intersections
	function cureLocalIntersections(start, triangles) {
	    let p = start;
	    do {
	        const a = p.prev,
	            b = p.next.next;

	        if (!equals(a, b) && intersects(a, p, p.next, b) && locallyInside(a, b) && locallyInside(b, a)) {

	            triangles.push(a.i, p.i, b.i);

	            // remove two nodes involved
	            removeNode(p);
	            removeNode(p.next);

	            p = start = b;
	        }
	        p = p.next;
	    } while (p !== start);

	    return filterPoints(p);
	}

	// try splitting polygon into two and triangulate them independently
	function splitEarcut(start, triangles, dim, minX, minY, invSize) {
	    // look for a valid diagonal that divides the polygon into two
	    let a = start;
	    do {
	        let b = a.next.next;
	        while (b !== a.prev) {
	            if (a.i !== b.i && isValidDiagonal(a, b)) {
	                // split the polygon in two by the diagonal
	                let c = splitPolygon(a, b);

	                // filter colinear points around the cuts
	                a = filterPoints(a, a.next);
	                c = filterPoints(c, c.next);

	                // run earcut on each half
	                earcutLinked(a, triangles, dim, minX, minY, invSize, 0);
	                earcutLinked(c, triangles, dim, minX, minY, invSize, 0);
	                return;
	            }
	            b = b.next;
	        }
	        a = a.next;
	    } while (a !== start);
	}

	// link every hole into the outer loop, producing a single-ring polygon without holes
	function eliminateHoles(data, holeIndices, outerNode, dim) {
	    const queue = [];

	    for (let i = 0, len = holeIndices.length; i < len; i++) {
	        const start = holeIndices[i] * dim;
	        const end = i < len - 1 ? holeIndices[i + 1] * dim : data.length;
	        const list = linkedList(data, start, end, dim, false);
	        if (list === list.next) list.steiner = true;
	        queue.push(getLeftmost(list));
	    }

	    queue.sort(compareXYSlope);

	    // process holes from left to right
	    for (let i = 0; i < queue.length; i++) {
	        outerNode = eliminateHole(queue[i], outerNode);
	    }

	    return outerNode;
	}

	function compareXYSlope(a, b) {
	    let result = a.x - b.x;
	    // when the left-most point of 2 holes meet at a vertex, sort the holes counterclockwise so that when we find
	    // the bridge to the outer shell is always the point that they meet at.
	    if (result === 0) {
	        result = a.y - b.y;
	        if (result === 0) {
	            const aSlope = (a.next.y - a.y) / (a.next.x - a.x);
	            const bSlope = (b.next.y - b.y) / (b.next.x - b.x);
	            result = aSlope - bSlope;
	        }
	    }
	    return result;
	}

	// find a bridge between vertices that connects hole with an outer ring and and link it
	function eliminateHole(hole, outerNode) {
	    const bridge = findHoleBridge(hole, outerNode);
	    if (!bridge) {
	        return outerNode;
	    }

	    const bridgeReverse = splitPolygon(bridge, hole);

	    // filter collinear points around the cuts
	    filterPoints(bridgeReverse, bridgeReverse.next);
	    return filterPoints(bridge, bridge.next);
	}

	// David Eberly's algorithm for finding a bridge between hole and outer polygon
	function findHoleBridge(hole, outerNode) {
	    let p = outerNode;
	    const hx = hole.x;
	    const hy = hole.y;
	    let qx = -Infinity;
	    let m;

	    // find a segment intersected by a ray from the hole's leftmost point to the left;
	    // segment's endpoint with lesser x will be potential connection point
	    // unless they intersect at a vertex, then choose the vertex
	    if (equals(hole, p)) return p;
	    do {
	        if (equals(hole, p.next)) return p.next;
	        else if (hy <= p.y && hy >= p.next.y && p.next.y !== p.y) {
	            const x = p.x + (hy - p.y) * (p.next.x - p.x) / (p.next.y - p.y);
	            if (x <= hx && x > qx) {
	                qx = x;
	                m = p.x < p.next.x ? p : p.next;
	                if (x === hx) return m; // hole touches outer segment; pick leftmost endpoint
	            }
	        }
	        p = p.next;
	    } while (p !== outerNode);

	    if (!m) return null;

	    // look for points inside the triangle of hole point, segment intersection and endpoint;
	    // if there are no points found, we have a valid connection;
	    // otherwise choose the point of the minimum angle with the ray as connection point

	    const stop = m;
	    const mx = m.x;
	    const my = m.y;
	    let tanMin = Infinity;

	    p = m;

	    do {
	        if (hx >= p.x && p.x >= mx && hx !== p.x &&
	                pointInTriangle(hy < my ? hx : qx, hy, mx, my, hy < my ? qx : hx, hy, p.x, p.y)) {

	            const tan = Math.abs(hy - p.y) / (hx - p.x); // tangential

	            if (locallyInside(p, hole) &&
	                (tan < tanMin || (tan === tanMin && (p.x > m.x || (p.x === m.x && sectorContainsSector(m, p)))))) {
	                m = p;
	                tanMin = tan;
	            }
	        }

	        p = p.next;
	    } while (p !== stop);

	    return m;
	}

	// whether sector in vertex m contains sector in vertex p in the same coordinates
	function sectorContainsSector(m, p) {
	    return area(m.prev, m, p.prev) < 0 && area(p.next, m, m.next) < 0;
	}

	// interlink polygon nodes in z-order
	function indexCurve(start, minX, minY, invSize) {
	    let p = start;
	    do {
	        if (p.z === 0) p.z = zOrder(p.x, p.y, minX, minY, invSize);
	        p.prevZ = p.prev;
	        p.nextZ = p.next;
	        p = p.next;
	    } while (p !== start);

	    p.prevZ.nextZ = null;
	    p.prevZ = null;

	    sortLinked(p);
	}

	// Simon Tatham's linked list merge sort algorithm
	// http://www.chiark.greenend.org.uk/~sgtatham/algorithms/listsort.html
	function sortLinked(list) {
	    let numMerges;
	    let inSize = 1;

	    do {
	        let p = list;
	        let e;
	        list = null;
	        let tail = null;
	        numMerges = 0;

	        while (p) {
	            numMerges++;
	            let q = p;
	            let pSize = 0;
	            for (let i = 0; i < inSize; i++) {
	                pSize++;
	                q = q.nextZ;
	                if (!q) break;
	            }
	            let qSize = inSize;

	            while (pSize > 0 || (qSize > 0 && q)) {

	                if (pSize !== 0 && (qSize === 0 || !q || p.z <= q.z)) {
	                    e = p;
	                    p = p.nextZ;
	                    pSize--;
	                } else {
	                    e = q;
	                    q = q.nextZ;
	                    qSize--;
	                }

	                if (tail) tail.nextZ = e;
	                else list = e;

	                e.prevZ = tail;
	                tail = e;
	            }

	            p = q;
	        }

	        tail.nextZ = null;
	        inSize *= 2;

	    } while (numMerges > 1);

	    return list;
	}

	// z-order of a point given coords and inverse of the longer side of data bbox
	function zOrder(x, y, minX, minY, invSize) {
	    // coords are transformed into non-negative 15-bit integer range
	    x = (x - minX) * invSize | 0;
	    y = (y - minY) * invSize | 0;

	    x = (x | (x << 8)) & 0x00FF00FF;
	    x = (x | (x << 4)) & 0x0F0F0F0F;
	    x = (x | (x << 2)) & 0x33333333;
	    x = (x | (x << 1)) & 0x55555555;

	    y = (y | (y << 8)) & 0x00FF00FF;
	    y = (y | (y << 4)) & 0x0F0F0F0F;
	    y = (y | (y << 2)) & 0x33333333;
	    y = (y | (y << 1)) & 0x55555555;

	    return x | (y << 1);
	}

	// find the leftmost node of a polygon ring
	function getLeftmost(start) {
	    let p = start,
	        leftmost = start;
	    do {
	        if (p.x < leftmost.x || (p.x === leftmost.x && p.y < leftmost.y)) leftmost = p;
	        p = p.next;
	    } while (p !== start);

	    return leftmost;
	}

	// check if a point lies within a convex triangle
	function pointInTriangle(ax, ay, bx, by, cx, cy, px, py) {
	    return (cx - px) * (ay - py) >= (ax - px) * (cy - py) &&
	           (ax - px) * (by - py) >= (bx - px) * (ay - py) &&
	           (bx - px) * (cy - py) >= (cx - px) * (by - py);
	}

	// check if a point lies within a convex triangle but false if its equal to the first point of the triangle
	function pointInTriangleExceptFirst(ax, ay, bx, by, cx, cy, px, py) {
	    return !(ax === px && ay === py) && pointInTriangle(ax, ay, bx, by, cx, cy, px, py);
	}

	// check if a diagonal between two polygon nodes is valid (lies in polygon interior)
	function isValidDiagonal(a, b) {
	    return a.next.i !== b.i && a.prev.i !== b.i && !intersectsPolygon(a, b) && // dones't intersect other edges
	           (locallyInside(a, b) && locallyInside(b, a) && middleInside(a, b) && // locally visible
	            (area(a.prev, a, b.prev) || area(a, b.prev, b)) || // does not create opposite-facing sectors
	            equals(a, b) && area(a.prev, a, a.next) > 0 && area(b.prev, b, b.next) > 0); // special zero-length case
	}

	// signed area of a triangle
	function area(p, q, r) {
	    return (q.y - p.y) * (r.x - q.x) - (q.x - p.x) * (r.y - q.y);
	}

	// check if two points are equal
	function equals(p1, p2) {
	    return p1.x === p2.x && p1.y === p2.y;
	}

	// check if two segments intersect
	function intersects(p1, q1, p2, q2) {
	    const o1 = sign(area(p1, q1, p2));
	    const o2 = sign(area(p1, q1, q2));
	    const o3 = sign(area(p2, q2, p1));
	    const o4 = sign(area(p2, q2, q1));

	    if (o1 !== o2 && o3 !== o4) return true; // general case

	    if (o1 === 0 && onSegment(p1, p2, q1)) return true; // p1, q1 and p2 are collinear and p2 lies on p1q1
	    if (o2 === 0 && onSegment(p1, q2, q1)) return true; // p1, q1 and q2 are collinear and q2 lies on p1q1
	    if (o3 === 0 && onSegment(p2, p1, q2)) return true; // p2, q2 and p1 are collinear and p1 lies on p2q2
	    if (o4 === 0 && onSegment(p2, q1, q2)) return true; // p2, q2 and q1 are collinear and q1 lies on p2q2

	    return false;
	}

	// for collinear points p, q, r, check if point q lies on segment pr
	function onSegment(p, q, r) {
	    return q.x <= Math.max(p.x, r.x) && q.x >= Math.min(p.x, r.x) && q.y <= Math.max(p.y, r.y) && q.y >= Math.min(p.y, r.y);
	}

	function sign(num) {
	    return num > 0 ? 1 : num < 0 ? -1 : 0;
	}

	// check if a polygon diagonal intersects any polygon segments
	function intersectsPolygon(a, b) {
	    let p = a;
	    do {
	        if (p.i !== a.i && p.next.i !== a.i && p.i !== b.i && p.next.i !== b.i &&
	                intersects(p, p.next, a, b)) return true;
	        p = p.next;
	    } while (p !== a);

	    return false;
	}

	// check if a polygon diagonal is locally inside the polygon
	function locallyInside(a, b) {
	    return area(a.prev, a, a.next) < 0 ?
	        area(a, b, a.next) >= 0 && area(a, a.prev, b) >= 0 :
	        area(a, b, a.prev) < 0 || area(a, a.next, b) < 0;
	}

	// check if the middle point of a polygon diagonal is inside the polygon
	function middleInside(a, b) {
	    let p = a;
	    let inside = false;
	    const px = (a.x + b.x) / 2;
	    const py = (a.y + b.y) / 2;
	    do {
	        if (((p.y > py) !== (p.next.y > py)) && p.next.y !== p.y &&
	                (px < (p.next.x - p.x) * (py - p.y) / (p.next.y - p.y) + p.x))
	            inside = !inside;
	        p = p.next;
	    } while (p !== a);

	    return inside;
	}

	// link two polygon vertices with a bridge; if the vertices belong to the same ring, it splits polygon into two;
	// if one belongs to the outer ring and another to a hole, it merges it into a single ring
	function splitPolygon(a, b) {
	    const a2 = createNode(a.i, a.x, a.y),
	        b2 = createNode(b.i, b.x, b.y),
	        an = a.next,
	        bp = b.prev;

	    a.next = b;
	    b.prev = a;

	    a2.next = an;
	    an.prev = a2;

	    b2.next = a2;
	    a2.prev = b2;

	    bp.next = b2;
	    b2.prev = bp;

	    return b2;
	}

	// create a node and optionally link it with previous one (in a circular doubly linked list)
	function insertNode(i, x, y, last) {
	    const p = createNode(i, x, y);

	    if (!last) {
	        p.prev = p;
	        p.next = p;

	    } else {
	        p.next = last.next;
	        p.prev = last;
	        last.next.prev = p;
	        last.next = p;
	    }
	    return p;
	}

	function removeNode(p) {
	    p.next.prev = p.prev;
	    p.prev.next = p.next;

	    if (p.prevZ) p.prevZ.nextZ = p.nextZ;
	    if (p.nextZ) p.nextZ.prevZ = p.prevZ;
	}

	function createNode(i, x, y) {
	    return {
	        i, // vertex index in coordinates array
	        x, y, // vertex coordinates
	        prev: null, // previous and next vertex nodes in a polygon ring
	        next: null,
	        z: 0, // z-order curve value
	        prevZ: null, // previous and next nodes in z-order
	        nextZ: null,
	        steiner: false // indicates whether this is a steiner point
	    };
	}

	function signedArea(data, start, end, dim) {
	    let sum = 0;
	    for (let i = start, j = end - dim; i < end; i += dim) {
	        sum += (data[j] - data[i]) * (data[i + 1] + data[j + 1]);
	        j = i;
	    }
	    return sum;
	}

	class Earcut {

		/**
		 * Triangulates the given shape definition by returning an array of triangles.
		 *
		 * @param {Array<number>} data - An array with 2D points.
		 * @param {Array<number>} holeIndices - An array with indices defining holes.
		 * @param {number} [dim=2] - The number of coordinates per vertex in the input array.
		 * @return {Array<number>} An array representing the triangulated faces. Each face is defined by three consecutive numbers
		 * representing vertex indices.
		 */
		static triangulate( data, holeIndices, dim = 2 ) {

			return earcut( data, holeIndices, dim );

		}

	}

	/**
	 * A class containing utility functions for shapes.
	 *
	 * @hideconstructor
	 */
	class ShapeUtils {

		/**
		 * Calculate area of a ( 2D ) contour polygon.
		 *
		 * @param {Array<Vector2>} contour - An array of 2D points.
		 * @return {number} The area.
		 */
		static area( contour ) {

			const n = contour.length;
			let a = 0.0;

			for ( let p = n - 1, q = 0; q < n; p = q ++ ) {

				a += contour[ p ].x * contour[ q ].y - contour[ q ].x * contour[ p ].y;

			}

			return a * 0.5;

		}

		/**
		 * Returns `true` if the given contour uses a clockwise winding order.
		 *
		 * @param {Array<Vector2>} pts - An array of 2D points defining a polygon.
		 * @return {boolean} Whether the given contour uses a clockwise winding order or not.
		 */
		static isClockWise( pts ) {

			return ShapeUtils.area( pts ) < 0;

		}

		/**
		 * Triangulates the given shape definition.
		 *
		 * @param {Array<Vector2>} contour - An array of 2D points defining the contour.
		 * @param {Array<Array<Vector2>>} holes - An array that holds arrays of 2D points defining the holes.
		 * @return {Array<Array<number>>} An array that holds for each face definition an array with three indices.
		 */
		static triangulateShape( contour, holes ) {

			const vertices = []; // flat array of vertices like [ x0,y0, x1,y1, x2,y2, ... ]
			const holeIndices = []; // array of hole indices
			const faces = []; // final array of vertex indices like [ [ a,b,d ], [ b,c,d ] ]

			removeDupEndPts( contour );
			addContour( vertices, contour );

			//

			let holeIndex = contour.length;

			holes.forEach( removeDupEndPts );

			for ( let i = 0; i < holes.length; i ++ ) {

				holeIndices.push( holeIndex );
				holeIndex += holes[ i ].length;
				addContour( vertices, holes[ i ] );

			}

			//

			const triangles = Earcut.triangulate( vertices, holeIndices );

			//

			for ( let i = 0; i < triangles.length; i += 3 ) {

				faces.push( triangles.slice( i, i + 3 ) );

			}

			return faces;

		}

	}

	function removeDupEndPts( points ) {

		const l = points.length;

		if ( l > 2 && points[ l - 1 ].equals( points[ 0 ] ) ) {

			points.pop();

		}

	}

	function addContour( vertices, contour ) {

		for ( let i = 0; i < contour.length; i ++ ) {

			vertices.push( contour[ i ].x );
			vertices.push( contour[ i ].y );

		}

	}

	/**
	 * Creates extruded geometry from a path shape.
	 *
	 * ```js
	 * const length = 12, width = 8;
	 *
	 * const shape = new THREE.Shape();
	 * shape.moveTo( 0,0 );
	 * shape.lineTo( 0, width );
	 * shape.lineTo( length, width );
	 * shape.lineTo( length, 0 );
	 * shape.lineTo( 0, 0 );
	 *
	 * const geometry = new THREE.ExtrudeGeometry( shape );
	 * const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );
	 * const mesh = new THREE.Mesh( geometry, material ) ;
	 * scene.add( mesh );
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class ExtrudeGeometry extends BufferGeometry {

		/**
		 * Constructs a new extrude geometry.
		 *
		 * @param {Shape|Array<Shape>} [shapes] - A shape or an array of shapes.
		 * @param {ExtrudeGeometry~Options} [options] - The extrude settings.
		 */
		constructor( shapes = new Shape( [ new Vector2( 0.5, 0.5 ), new Vector2( -0.5, 0.5 ), new Vector2( -0.5, -0.5 ), new Vector2( 0.5, -0.5 ) ] ), options = {} ) {

			super();

			this.type = 'ExtrudeGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				shapes: shapes,
				options: options
			};

			shapes = Array.isArray( shapes ) ? shapes : [ shapes ];

			const scope = this;

			const verticesArray = [];
			const uvArray = [];

			for ( let i = 0, l = shapes.length; i < l; i ++ ) {

				const shape = shapes[ i ];
				addShape( shape );

			}

			// build geometry

			this.setAttribute( 'position', new Float32BufferAttribute( verticesArray, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvArray, 2 ) );

			this.computeVertexNormals();

			// functions

			function addShape( shape ) {

				const placeholder = [];

				// options

				const curveSegments = options.curveSegments !== undefined ? options.curveSegments : 12;
				const steps = options.steps !== undefined ? options.steps : 1;
				const depth = options.depth !== undefined ? options.depth : 1;

				let bevelEnabled = options.bevelEnabled !== undefined ? options.bevelEnabled : true;
				let bevelThickness = options.bevelThickness !== undefined ? options.bevelThickness : 0.2;
				let bevelSize = options.bevelSize !== undefined ? options.bevelSize : bevelThickness - 0.1;
				let bevelOffset = options.bevelOffset !== undefined ? options.bevelOffset : 0;
				let bevelSegments = options.bevelSegments !== undefined ? options.bevelSegments : 3;

				const extrudePath = options.extrudePath;

				const uvgen = options.UVGenerator !== undefined ? options.UVGenerator : WorldUVGenerator;

				//

				let extrudePts, extrudeByPath = false;
				let splineTube, binormal, normal, position2;

				if ( extrudePath ) {

					extrudePts = extrudePath.getSpacedPoints( steps );

					extrudeByPath = true;
					bevelEnabled = false; // bevels not supported for path extrusion

					// SETUP TNB variables

					// TODO1 - have a .isClosed in spline?

					splineTube = extrudePath.computeFrenetFrames( steps, false );

					// console.log(splineTube, 'splineTube', splineTube.normals.length, 'steps', steps, 'extrudePts', extrudePts.length);

					binormal = new Vector3();
					normal = new Vector3();
					position2 = new Vector3();

				}

				// Safeguards if bevels are not enabled

				if ( ! bevelEnabled ) {

					bevelSegments = 0;
					bevelThickness = 0;
					bevelSize = 0;
					bevelOffset = 0;

				}

				// Variables initialization

				const shapePoints = shape.extractPoints( curveSegments );

				let vertices = shapePoints.shape;
				const holes = shapePoints.holes;

				const reverse = ! ShapeUtils.isClockWise( vertices );

				if ( reverse ) {

					vertices = vertices.reverse();

					// Maybe we should also check if holes are in the opposite direction, just to be safe ...

					for ( let h = 0, hl = holes.length; h < hl; h ++ ) {

						const ahole = holes[ h ];

						if ( ShapeUtils.isClockWise( ahole ) ) {

							holes[ h ] = ahole.reverse();

						}

					}

				}

				/**Merges index-adjacent points that are within a threshold distance of each other. Array is modified in-place. Threshold distance is empirical, and scaled based on the magnitude of point coordinates.
				 * @param {Array<Vector2>} points
				*/
				function mergeOverlappingPoints( points ) {

					const THRESHOLD = 1e-10;
					const THRESHOLD_SQ = THRESHOLD * THRESHOLD;
					let prevPos = points[ 0 ];
					for ( let i = 1; i <= points.length; i ++ ) {

						const currentIndex = i % points.length;
						const currentPos = points[ currentIndex ];
						const dx = currentPos.x - prevPos.x;
						const dy = currentPos.y - prevPos.y;
						const distSq = dx * dx + dy * dy;

						const scalingFactorSqrt = Math.max(
							Math.abs( currentPos.x ),
							Math.abs( currentPos.y ),
							Math.abs( prevPos.x ),
							Math.abs( prevPos.y )
						);
						const thresholdSqScaled = THRESHOLD_SQ * scalingFactorSqrt * scalingFactorSqrt;
						if ( distSq <= thresholdSqScaled ) {

							points.splice( currentIndex, 1 );
							i --;
							continue;

						}

						prevPos = currentPos;

					}

				}

				mergeOverlappingPoints( vertices );
				holes.forEach( mergeOverlappingPoints );

				const numHoles = holes.length;

				/* Vertices */

				const contour = vertices; // vertices has all points but contour has only points of circumference

				for ( let h = 0; h < numHoles; h ++ ) {

					const ahole = holes[ h ];

					vertices = vertices.concat( ahole );

				}


				function scalePt2( pt, vec, size ) {

					if ( ! vec ) console.error( 'THREE.ExtrudeGeometry: vec does not exist' );

					return pt.clone().addScaledVector( vec, size );

				}

				const vlen = vertices.length;


				// Find directions for point movement


				function getBevelVec( inPt, inPrev, inNext ) {

					// computes for inPt the corresponding point inPt' on a new contour
					//   shifted by 1 unit (length of normalized vector) to the left
					// if we walk along contour clockwise, this new contour is outside the old one
					//
					// inPt' is the intersection of the two lines parallel to the two
					//  adjacent edges of inPt at a distance of 1 unit on the left side.

					let v_trans_x, v_trans_y, shrink_by; // resulting translation vector for inPt

					// good reading for geometry algorithms (here: line-line intersection)
					// http://geomalgorithms.com/a05-_intersect-1.html

					const v_prev_x = inPt.x - inPrev.x,
						v_prev_y = inPt.y - inPrev.y;
					const v_next_x = inNext.x - inPt.x,
						v_next_y = inNext.y - inPt.y;

					const v_prev_lensq = ( v_prev_x * v_prev_x + v_prev_y * v_prev_y );

					// check for collinear edges
					const collinear0 = ( v_prev_x * v_next_y - v_prev_y * v_next_x );

					if ( Math.abs( collinear0 ) > Number.EPSILON ) {

						// not collinear

						// length of vectors for normalizing

						const v_prev_len = Math.sqrt( v_prev_lensq );
						const v_next_len = Math.sqrt( v_next_x * v_next_x + v_next_y * v_next_y );

						// shift adjacent points by unit vectors to the left

						const ptPrevShift_x = ( inPrev.x - v_prev_y / v_prev_len );
						const ptPrevShift_y = ( inPrev.y + v_prev_x / v_prev_len );

						const ptNextShift_x = ( inNext.x - v_next_y / v_next_len );
						const ptNextShift_y = ( inNext.y + v_next_x / v_next_len );

						// scaling factor for v_prev to intersection point

						const sf = ( ( ptNextShift_x - ptPrevShift_x ) * v_next_y -
								( ptNextShift_y - ptPrevShift_y ) * v_next_x ) /
							( v_prev_x * v_next_y - v_prev_y * v_next_x );

						// vector from inPt to intersection point

						v_trans_x = ( ptPrevShift_x + v_prev_x * sf - inPt.x );
						v_trans_y = ( ptPrevShift_y + v_prev_y * sf - inPt.y );

						// Don't normalize!, otherwise sharp corners become ugly
						//  but prevent crazy spikes
						const v_trans_lensq = ( v_trans_x * v_trans_x + v_trans_y * v_trans_y );
						if ( v_trans_lensq <= 2 ) {

							return new Vector2( v_trans_x, v_trans_y );

						} else {

							shrink_by = Math.sqrt( v_trans_lensq / 2 );

						}

					} else {

						// handle special case of collinear edges

						let direction_eq = false; // assumes: opposite

						if ( v_prev_x > Number.EPSILON ) {

							if ( v_next_x > Number.EPSILON ) {

								direction_eq = true;

							}

						} else {

							if ( v_prev_x < - Number.EPSILON ) {

								if ( v_next_x < - Number.EPSILON ) {

									direction_eq = true;

								}

							} else {

								if ( Math.sign( v_prev_y ) === Math.sign( v_next_y ) ) {

									direction_eq = true;

								}

							}

						}

						if ( direction_eq ) {

							// console.log("Warning: lines are a straight sequence");
							v_trans_x = - v_prev_y;
							v_trans_y = v_prev_x;
							shrink_by = Math.sqrt( v_prev_lensq );

						} else {

							// console.log("Warning: lines are a straight spike");
							v_trans_x = v_prev_x;
							v_trans_y = v_prev_y;
							shrink_by = Math.sqrt( v_prev_lensq / 2 );

						}

					}

					return new Vector2( v_trans_x / shrink_by, v_trans_y / shrink_by );

				}


				const contourMovements = [];

				for ( let i = 0, il = contour.length, j = il - 1, k = i + 1; i < il; i ++, j ++, k ++ ) {

					if ( j === il ) j = 0;
					if ( k === il ) k = 0;

					//  (j)---(i)---(k)
					// console.log('i,j,k', i, j , k)

					contourMovements[ i ] = getBevelVec( contour[ i ], contour[ j ], contour[ k ] );

				}

				const holesMovements = [];
				let oneHoleMovements, verticesMovements = contourMovements.concat();

				for ( let h = 0, hl = numHoles; h < hl; h ++ ) {

					const ahole = holes[ h ];

					oneHoleMovements = [];

					for ( let i = 0, il = ahole.length, j = il - 1, k = i + 1; i < il; i ++, j ++, k ++ ) {

						if ( j === il ) j = 0;
						if ( k === il ) k = 0;

						//  (j)---(i)---(k)
						oneHoleMovements[ i ] = getBevelVec( ahole[ i ], ahole[ j ], ahole[ k ] );

					}

					holesMovements.push( oneHoleMovements );
					verticesMovements = verticesMovements.concat( oneHoleMovements );

				}

				let faces;

				if ( bevelSegments === 0 ) {

					faces = ShapeUtils.triangulateShape( contour, holes );

				} else {

					const contractedContourVertices = [];
					const expandedHoleVertices = [];

					// Loop bevelSegments, 1 for the front, 1 for the back

					for ( let b = 0; b < bevelSegments; b ++ ) {

						//for ( b = bevelSegments; b > 0; b -- ) {

						const t = b / bevelSegments;
						const z = bevelThickness * Math.cos( t * Math.PI / 2 );
						const bs = bevelSize * Math.sin( t * Math.PI / 2 ) + bevelOffset;

						// contract shape

						for ( let i = 0, il = contour.length; i < il; i ++ ) {

							const vert = scalePt2( contour[ i ], contourMovements[ i ], bs );

							v( vert.x, vert.y, - z );
							if ( t === 0 ) contractedContourVertices.push( vert );

						}

						// expand holes

						for ( let h = 0, hl = numHoles; h < hl; h ++ ) {

							const ahole = holes[ h ];
							oneHoleMovements = holesMovements[ h ];
							const oneHoleVertices = [];
							for ( let i = 0, il = ahole.length; i < il; i ++ ) {

								const vert = scalePt2( ahole[ i ], oneHoleMovements[ i ], bs );

								v( vert.x, vert.y, - z );
								if ( t === 0 ) oneHoleVertices.push( vert );

							}

							if ( t === 0 ) expandedHoleVertices.push( oneHoleVertices );

						}

					}

					faces = ShapeUtils.triangulateShape( contractedContourVertices, expandedHoleVertices );

				}

				const flen = faces.length;

				const bs = bevelSize + bevelOffset;

				// Back facing vertices

				for ( let i = 0; i < vlen; i ++ ) {

					const vert = bevelEnabled ? scalePt2( vertices[ i ], verticesMovements[ i ], bs ) : vertices[ i ];

					if ( ! extrudeByPath ) {

						v( vert.x, vert.y, 0 );

					} else {

						// v( vert.x, vert.y + extrudePts[ 0 ].y, extrudePts[ 0 ].x );

						normal.copy( splineTube.normals[ 0 ] ).multiplyScalar( vert.x );
						binormal.copy( splineTube.binormals[ 0 ] ).multiplyScalar( vert.y );

						position2.copy( extrudePts[ 0 ] ).add( normal ).add( binormal );

						v( position2.x, position2.y, position2.z );

					}

				}

				// Add stepped vertices...
				// Including front facing vertices

				for ( let s = 1; s <= steps; s ++ ) {

					for ( let i = 0; i < vlen; i ++ ) {

						const vert = bevelEnabled ? scalePt2( vertices[ i ], verticesMovements[ i ], bs ) : vertices[ i ];

						if ( ! extrudeByPath ) {

							v( vert.x, vert.y, depth / steps * s );

						} else {

							// v( vert.x, vert.y + extrudePts[ s - 1 ].y, extrudePts[ s - 1 ].x );

							normal.copy( splineTube.normals[ s ] ).multiplyScalar( vert.x );
							binormal.copy( splineTube.binormals[ s ] ).multiplyScalar( vert.y );

							position2.copy( extrudePts[ s ] ).add( normal ).add( binormal );

							v( position2.x, position2.y, position2.z );

						}

					}

				}


				// Add bevel segments planes

				//for ( b = 1; b <= bevelSegments; b ++ ) {
				for ( let b = bevelSegments - 1; b >= 0; b -- ) {

					const t = b / bevelSegments;
					const z = bevelThickness * Math.cos( t * Math.PI / 2 );
					const bs = bevelSize * Math.sin( t * Math.PI / 2 ) + bevelOffset;

					// contract shape

					for ( let i = 0, il = contour.length; i < il; i ++ ) {

						const vert = scalePt2( contour[ i ], contourMovements[ i ], bs );
						v( vert.x, vert.y, depth + z );

					}

					// expand holes

					for ( let h = 0, hl = holes.length; h < hl; h ++ ) {

						const ahole = holes[ h ];
						oneHoleMovements = holesMovements[ h ];

						for ( let i = 0, il = ahole.length; i < il; i ++ ) {

							const vert = scalePt2( ahole[ i ], oneHoleMovements[ i ], bs );

							if ( ! extrudeByPath ) {

								v( vert.x, vert.y, depth + z );

							} else {

								v( vert.x, vert.y + extrudePts[ steps - 1 ].y, extrudePts[ steps - 1 ].x + z );

							}

						}

					}

				}

				/* Faces */

				// Top and bottom faces

				buildLidFaces();

				// Sides faces

				buildSideFaces();


				/////  Internal functions

				function buildLidFaces() {

					const start = verticesArray.length / 3;

					if ( bevelEnabled ) {

						let layer = 0; // steps + 1
						let offset = vlen * layer;

						// Bottom faces

						for ( let i = 0; i < flen; i ++ ) {

							const face = faces[ i ];
							f3( face[ 2 ] + offset, face[ 1 ] + offset, face[ 0 ] + offset );

						}

						layer = steps + bevelSegments * 2;
						offset = vlen * layer;

						// Top faces

						for ( let i = 0; i < flen; i ++ ) {

							const face = faces[ i ];
							f3( face[ 0 ] + offset, face[ 1 ] + offset, face[ 2 ] + offset );

						}

					} else {

						// Bottom faces

						for ( let i = 0; i < flen; i ++ ) {

							const face = faces[ i ];
							f3( face[ 2 ], face[ 1 ], face[ 0 ] );

						}

						// Top faces

						for ( let i = 0; i < flen; i ++ ) {

							const face = faces[ i ];
							f3( face[ 0 ] + vlen * steps, face[ 1 ] + vlen * steps, face[ 2 ] + vlen * steps );

						}

					}

					scope.addGroup( start, verticesArray.length / 3 - start, 0 );

				}

				// Create faces for the z-sides of the shape

				function buildSideFaces() {

					const start = verticesArray.length / 3;
					let layeroffset = 0;
					sidewalls( contour, layeroffset );
					layeroffset += contour.length;

					for ( let h = 0, hl = holes.length; h < hl; h ++ ) {

						const ahole = holes[ h ];
						sidewalls( ahole, layeroffset );

						//, true
						layeroffset += ahole.length;

					}


					scope.addGroup( start, verticesArray.length / 3 - start, 1 );


				}

				function sidewalls( contour, layeroffset ) {

					let i = contour.length;

					while ( -- i >= 0 ) {

						const j = i;
						let k = i - 1;
						if ( k < 0 ) k = contour.length - 1;

						//console.log('b', i,j, i-1, k,vertices.length);

						for ( let s = 0, sl = ( steps + bevelSegments * 2 ); s < sl; s ++ ) {

							const slen1 = vlen * s;
							const slen2 = vlen * ( s + 1 );

							const a = layeroffset + j + slen1,
								b = layeroffset + k + slen1,
								c = layeroffset + k + slen2,
								d = layeroffset + j + slen2;

							f4( a, b, c, d );

						}

					}

				}

				function v( x, y, z ) {

					placeholder.push( x );
					placeholder.push( y );
					placeholder.push( z );

				}


				function f3( a, b, c ) {

					addVertex( a );
					addVertex( b );
					addVertex( c );

					const nextIndex = verticesArray.length / 3;
					const uvs = uvgen.generateTopUV( scope, verticesArray, nextIndex - 3, nextIndex - 2, nextIndex - 1 );

					addUV( uvs[ 0 ] );
					addUV( uvs[ 1 ] );
					addUV( uvs[ 2 ] );

				}

				function f4( a, b, c, d ) {

					addVertex( a );
					addVertex( b );
					addVertex( d );

					addVertex( b );
					addVertex( c );
					addVertex( d );


					const nextIndex = verticesArray.length / 3;
					const uvs = uvgen.generateSideWallUV( scope, verticesArray, nextIndex - 6, nextIndex - 3, nextIndex - 2, nextIndex - 1 );

					addUV( uvs[ 0 ] );
					addUV( uvs[ 1 ] );
					addUV( uvs[ 3 ] );

					addUV( uvs[ 1 ] );
					addUV( uvs[ 2 ] );
					addUV( uvs[ 3 ] );

				}

				function addVertex( index ) {

					verticesArray.push( placeholder[ index * 3 + 0 ] );
					verticesArray.push( placeholder[ index * 3 + 1 ] );
					verticesArray.push( placeholder[ index * 3 + 2 ] );

				}


				function addUV( vector2 ) {

					uvArray.push( vector2.x );
					uvArray.push( vector2.y );

				}

			}

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			const shapes = this.parameters.shapes;
			const options = this.parameters.options;

			return toJSON$1( shapes, options, data );

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @param {Array<Shape>} shapes - An array of shapes.
		 * @return {ExtrudeGeometry} A new instance.
		 */
		static fromJSON( data, shapes ) {

			const geometryShapes = [];

			for ( let j = 0, jl = data.shapes.length; j < jl; j ++ ) {

				const shape = shapes[ data.shapes[ j ] ];

				geometryShapes.push( shape );

			}

			const extrudePath = data.options.extrudePath;

			if ( extrudePath !== undefined ) {

				data.options.extrudePath = new Curves[ extrudePath.type ]().fromJSON( extrudePath );

			}

			return new ExtrudeGeometry( geometryShapes, data.options );

		}

	}

	const WorldUVGenerator = {

		generateTopUV: function ( geometry, vertices, indexA, indexB, indexC ) {

			const a_x = vertices[ indexA * 3 ];
			const a_y = vertices[ indexA * 3 + 1 ];
			const b_x = vertices[ indexB * 3 ];
			const b_y = vertices[ indexB * 3 + 1 ];
			const c_x = vertices[ indexC * 3 ];
			const c_y = vertices[ indexC * 3 + 1 ];

			return [
				new Vector2( a_x, a_y ),
				new Vector2( b_x, b_y ),
				new Vector2( c_x, c_y )
			];

		},

		generateSideWallUV: function ( geometry, vertices, indexA, indexB, indexC, indexD ) {

			const a_x = vertices[ indexA * 3 ];
			const a_y = vertices[ indexA * 3 + 1 ];
			const a_z = vertices[ indexA * 3 + 2 ];
			const b_x = vertices[ indexB * 3 ];
			const b_y = vertices[ indexB * 3 + 1 ];
			const b_z = vertices[ indexB * 3 + 2 ];
			const c_x = vertices[ indexC * 3 ];
			const c_y = vertices[ indexC * 3 + 1 ];
			const c_z = vertices[ indexC * 3 + 2 ];
			const d_x = vertices[ indexD * 3 ];
			const d_y = vertices[ indexD * 3 + 1 ];
			const d_z = vertices[ indexD * 3 + 2 ];

			if ( Math.abs( a_y - b_y ) < Math.abs( a_x - b_x ) ) {

				return [
					new Vector2( a_x, 1 - a_z ),
					new Vector2( b_x, 1 - b_z ),
					new Vector2( c_x, 1 - c_z ),
					new Vector2( d_x, 1 - d_z )
				];

			} else {

				return [
					new Vector2( a_y, 1 - a_z ),
					new Vector2( b_y, 1 - b_z ),
					new Vector2( c_y, 1 - c_z ),
					new Vector2( d_y, 1 - d_z )
				];

			}

		}

	};

	function toJSON$1( shapes, options, data ) {

		data.shapes = [];

		if ( Array.isArray( shapes ) ) {

			for ( let i = 0, l = shapes.length; i < l; i ++ ) {

				const shape = shapes[ i ];

				data.shapes.push( shape.uuid );

			}

		} else {

			data.shapes.push( shapes.uuid );

		}

		data.options = Object.assign( {}, options );

		if ( options.extrudePath !== undefined ) data.options.extrudePath = options.extrudePath.toJSON();

		return data;

	}

	/**
	 * A geometry class for representing an icosahedron.
	 *
	 * ```js
	 * const geometry = new THREE.IcosahedronGeometry();
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffff00 } );
	 * const icosahedron = new THREE.Mesh( geometry, material );
	 * scene.add( icosahedron );
	 * ```
	 *
	 * @augments PolyhedronGeometry
	 */
	class IcosahedronGeometry extends PolyhedronGeometry {

		/**
		 * Constructs a new icosahedron geometry.
		 *
		 * @param {number} [radius=1] - Radius of the icosahedron.
		 * @param {number} [detail=0] - Setting this to a value greater than `0` adds vertices making it no longer a icosahedron.
		 */
		constructor( radius = 1, detail = 0 ) {

			const t = ( 1 + Math.sqrt( 5 ) ) / 2;

			const vertices = [
				-1, t, 0, 	1, t, 0, 	-1, - t, 0, 	1, - t, 0,
				0, -1, t, 	0, 1, t,	0, -1, - t, 	0, 1, - t,
				t, 0, -1, 	t, 0, 1, 	- t, 0, -1, 	- t, 0, 1
			];

			const indices = [
				0, 11, 5, 	0, 5, 1, 	0, 1, 7, 	0, 7, 10, 	0, 10, 11,
				1, 5, 9, 	5, 11, 4,	11, 10, 2,	10, 7, 6,	7, 1, 8,
				3, 9, 4, 	3, 4, 2,	3, 2, 6,	3, 6, 8,	3, 8, 9,
				4, 9, 5, 	2, 4, 11,	6, 2, 10,	8, 6, 7,	9, 8, 1
			];

			super( vertices, indices, radius, detail );

			this.type = 'IcosahedronGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				radius: radius,
				detail: detail
			};

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {IcosahedronGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new IcosahedronGeometry( data.radius, data.detail );

		}

	}

	/**
	 * A geometry class for representing an octahedron.
	 *
	 * ```js
	 * const geometry = new THREE.OctahedronGeometry();
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffff00 } );
	 * const octahedron = new THREE.Mesh( geometry, material );
	 * scene.add( octahedron );
	 * ```
	 *
	 * @augments PolyhedronGeometry
	 */
	class OctahedronGeometry extends PolyhedronGeometry {

		/**
		 * Constructs a new octahedron geometry.
		 *
		 * @param {number} [radius=1] - Radius of the octahedron.
		 * @param {number} [detail=0] - Setting this to a value greater than `0` adds vertices making it no longer a octahedron.
		 */
		constructor( radius = 1, detail = 0 ) {

			const vertices = [
				1, 0, 0, 	-1, 0, 0,	0, 1, 0,
				0, -1, 0, 	0, 0, 1,	0, 0, -1
			];

			const indices = [
				0, 2, 4,	0, 4, 3,	0, 3, 5,
				0, 5, 2,	1, 2, 5,	1, 5, 3,
				1, 3, 4,	1, 4, 2
			];

			super( vertices, indices, radius, detail );

			this.type = 'OctahedronGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				radius: radius,
				detail: detail
			};

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {OctahedronGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new OctahedronGeometry( data.radius, data.detail );

		}

	}

	/**
	 * A geometry class for representing a plane.
	 *
	 * ```js
	 * const geometry = new THREE.PlaneGeometry( 1, 1 );
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffff00, side: THREE.DoubleSide } );
	 * const plane = new THREE.Mesh( geometry, material );
	 * scene.add( plane );
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class PlaneGeometry extends BufferGeometry {

		/**
		 * Constructs a new plane geometry.
		 *
		 * @param {number} [width=1] - The width along the X axis.
		 * @param {number} [height=1] - The height along the Y axis
		 * @param {number} [widthSegments=1] - The number of segments along the X axis.
		 * @param {number} [heightSegments=1] - The number of segments along the Y axis.
		 */
		constructor( width = 1, height = 1, widthSegments = 1, heightSegments = 1 ) {

			super();

			this.type = 'PlaneGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				width: width,
				height: height,
				widthSegments: widthSegments,
				heightSegments: heightSegments
			};

			const width_half = width / 2;
			const height_half = height / 2;

			const gridX = Math.floor( widthSegments );
			const gridY = Math.floor( heightSegments );

			const gridX1 = gridX + 1;
			const gridY1 = gridY + 1;

			const segment_width = width / gridX;
			const segment_height = height / gridY;

			//

			const indices = [];
			const vertices = [];
			const normals = [];
			const uvs = [];

			for ( let iy = 0; iy < gridY1; iy ++ ) {

				const y = iy * segment_height - height_half;

				for ( let ix = 0; ix < gridX1; ix ++ ) {

					const x = ix * segment_width - width_half;

					vertices.push( x, - y, 0 );

					normals.push( 0, 0, 1 );

					uvs.push( ix / gridX );
					uvs.push( 1 - ( iy / gridY ) );

				}

			}

			for ( let iy = 0; iy < gridY; iy ++ ) {

				for ( let ix = 0; ix < gridX; ix ++ ) {

					const a = ix + gridX1 * iy;
					const b = ix + gridX1 * ( iy + 1 );
					const c = ( ix + 1 ) + gridX1 * ( iy + 1 );
					const d = ( ix + 1 ) + gridX1 * iy;

					indices.push( a, b, d );
					indices.push( b, c, d );

				}

			}

			this.setIndex( indices );
			this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {PlaneGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new PlaneGeometry( data.width, data.height, data.widthSegments, data.heightSegments );

		}

	}

	/**
	 * Creates an one-sided polygonal geometry from one or more path shapes.
	 *
	 * ```js
	 * const arcShape = new THREE.Shape()
	 *	.moveTo( 5, 1 )
	 *	.absarc( 1, 1, 4, 0, Math.PI * 2, false );
	 *
	 * const geometry = new THREE.ShapeGeometry( arcShape );
	 * const material = new THREE.MeshBasicMaterial( { color: 0x00ff00, side: THREE.DoubleSide } );
	 * const mesh = new THREE.Mesh( geometry, material ) ;
	 * scene.add( mesh );
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class ShapeGeometry extends BufferGeometry {

		/**
		 * Constructs a new shape geometry.
		 *
		 * @param {Shape|Array<Shape>} [shapes] - A shape or an array of shapes.
		 * @param {number} [curveSegments=12] - Number of segments per shape.
		 */
		constructor( shapes = new Shape( [ new Vector2( 0, 0.5 ), new Vector2( -0.5, -0.5 ), new Vector2( 0.5, -0.5 ) ] ), curveSegments = 12 ) {

			super();

			this.type = 'ShapeGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				shapes: shapes,
				curveSegments: curveSegments
			};

			// buffers

			const indices = [];
			const vertices = [];
			const normals = [];
			const uvs = [];

			// helper variables

			let groupStart = 0;
			let groupCount = 0;

			// allow single and array values for "shapes" parameter

			if ( Array.isArray( shapes ) === false ) {

				addShape( shapes );

			} else {

				for ( let i = 0; i < shapes.length; i ++ ) {

					addShape( shapes[ i ] );

					this.addGroup( groupStart, groupCount, i ); // enables MultiMaterial support

					groupStart += groupCount;
					groupCount = 0;

				}

			}

			// build geometry

			this.setIndex( indices );
			this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );


			// helper functions

			function addShape( shape ) {

				const indexOffset = vertices.length / 3;
				const points = shape.extractPoints( curveSegments );

				let shapeVertices = points.shape;
				const shapeHoles = points.holes;

				// check direction of vertices

				if ( ShapeUtils.isClockWise( shapeVertices ) === false ) {

					shapeVertices = shapeVertices.reverse();

				}

				for ( let i = 0, l = shapeHoles.length; i < l; i ++ ) {

					const shapeHole = shapeHoles[ i ];

					if ( ShapeUtils.isClockWise( shapeHole ) === true ) {

						shapeHoles[ i ] = shapeHole.reverse();

					}

				}

				const faces = ShapeUtils.triangulateShape( shapeVertices, shapeHoles );

				// join vertices of inner and outer paths to a single array

				for ( let i = 0, l = shapeHoles.length; i < l; i ++ ) {

					const shapeHole = shapeHoles[ i ];
					shapeVertices = shapeVertices.concat( shapeHole );

				}

				// vertices, normals, uvs

				for ( let i = 0, l = shapeVertices.length; i < l; i ++ ) {

					const vertex = shapeVertices[ i ];

					vertices.push( vertex.x, vertex.y, 0 );
					normals.push( 0, 0, 1 );
					uvs.push( vertex.x, vertex.y ); // world uvs

				}

				// indices

				for ( let i = 0, l = faces.length; i < l; i ++ ) {

					const face = faces[ i ];

					const a = face[ 0 ] + indexOffset;
					const b = face[ 1 ] + indexOffset;
					const c = face[ 2 ] + indexOffset;

					indices.push( a, b, c );
					groupCount += 3;

				}

			}

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			const shapes = this.parameters.shapes;

			return toJSON( shapes, data );

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @param {Array<Shape>} shapes - An array of shapes.
		 * @return {ShapeGeometry} A new instance.
		 */
		static fromJSON( data, shapes ) {

			const geometryShapes = [];

			for ( let j = 0, jl = data.shapes.length; j < jl; j ++ ) {

				const shape = shapes[ data.shapes[ j ] ];

				geometryShapes.push( shape );

			}

			return new ShapeGeometry( geometryShapes, data.curveSegments );

		}

	}

	function toJSON( shapes, data ) {

		data.shapes = [];

		if ( Array.isArray( shapes ) ) {

			for ( let i = 0, l = shapes.length; i < l; i ++ ) {

				const shape = shapes[ i ];

				data.shapes.push( shape.uuid );

			}

		} else {

			data.shapes.push( shapes.uuid );

		}

		return data;

	}

	/**
	 * A class for generating a sphere geometry.
	 *
	 * ```js
	 * const geometry = new THREE.SphereGeometry( 15, 32, 16 );
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffff00 } );
	 * const sphere = new THREE.Mesh( geometry, material );
	 * scene.add( sphere );
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class SphereGeometry extends BufferGeometry {

		/**
		 * Constructs a new sphere geometry.
		 *
		 * @param {number} [radius=1] - The sphere radius.
		 * @param {number} [widthSegments=32] - The number of horizontal segments. Minimum value is `3`.
		 * @param {number} [heightSegments=16] - The number of vertical segments. Minimum value is `2`.
		 * @param {number} [phiStart=0] - The horizontal starting angle in radians.
		 * @param {number} [phiLength=Math.PI*2] - The horizontal sweep angle size.
		 * @param {number} [thetaStart=0] - The vertical starting angle in radians.
		 * @param {number} [thetaLength=Math.PI] - The vertical sweep angle size.
		 */
		constructor( radius = 1, widthSegments = 32, heightSegments = 16, phiStart = 0, phiLength = Math.PI * 2, thetaStart = 0, thetaLength = Math.PI ) {

			super();

			this.type = 'SphereGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				radius: radius,
				widthSegments: widthSegments,
				heightSegments: heightSegments,
				phiStart: phiStart,
				phiLength: phiLength,
				thetaStart: thetaStart,
				thetaLength: thetaLength
			};

			widthSegments = Math.max( 3, Math.floor( widthSegments ) );
			heightSegments = Math.max( 2, Math.floor( heightSegments ) );

			const thetaEnd = Math.min( thetaStart + thetaLength, Math.PI );

			let index = 0;
			const grid = [];

			const vertex = new Vector3();
			const normal = new Vector3();

			// buffers

			const indices = [];
			const vertices = [];
			const normals = [];
			const uvs = [];

			// generate vertices, normals and uvs

			for ( let iy = 0; iy <= heightSegments; iy ++ ) {

				const verticesRow = [];

				const v = iy / heightSegments;

				// special case for the poles

				let uOffset = 0;

				if ( iy === 0 && thetaStart === 0 ) {

					uOffset = 0.5 / widthSegments;

				} else if ( iy === heightSegments && thetaEnd === Math.PI ) {

					uOffset = -0.5 / widthSegments;

				}

				for ( let ix = 0; ix <= widthSegments; ix ++ ) {

					const u = ix / widthSegments;

					// vertex

					vertex.x = - radius * Math.cos( phiStart + u * phiLength ) * Math.sin( thetaStart + v * thetaLength );
					vertex.y = radius * Math.cos( thetaStart + v * thetaLength );
					vertex.z = radius * Math.sin( phiStart + u * phiLength ) * Math.sin( thetaStart + v * thetaLength );

					vertices.push( vertex.x, vertex.y, vertex.z );

					// normal

					normal.copy( vertex ).normalize();
					normals.push( normal.x, normal.y, normal.z );

					// uv

					uvs.push( u + uOffset, 1 - v );

					verticesRow.push( index ++ );

				}

				grid.push( verticesRow );

			}

			// indices

			for ( let iy = 0; iy < heightSegments; iy ++ ) {

				for ( let ix = 0; ix < widthSegments; ix ++ ) {

					const a = grid[ iy ][ ix + 1 ];
					const b = grid[ iy ][ ix ];
					const c = grid[ iy + 1 ][ ix ];
					const d = grid[ iy + 1 ][ ix + 1 ];

					if ( iy !== 0 || thetaStart > 0 ) indices.push( a, b, d );
					if ( iy !== heightSegments - 1 || thetaEnd < Math.PI ) indices.push( b, c, d );

				}

			}

			// build geometry

			this.setIndex( indices );
			this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {SphereGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new SphereGeometry( data.radius, data.widthSegments, data.heightSegments, data.phiStart, data.phiLength, data.thetaStart, data.thetaLength );

		}

	}

	/**
	 * A geometry class for representing an torus.
	 *
	 * ```js
	 * const geometry = new THREE.TorusGeometry( 10, 3, 16, 100 );
	 * const material = new THREE.MeshBasicMaterial( { color: 0xffff00 } );
	 * const torus = new THREE.Mesh( geometry, material );
	 * scene.add( torus );
	 * ```
	 *
	 * @augments BufferGeometry
	 */
	class TorusGeometry extends BufferGeometry {

		/**
		 * Constructs a new torus geometry.
		 *
		 * @param {number} [radius=1] - Radius of the torus, from the center of the torus to the center of the tube.
		 * @param {number} [tube=0.4] - Radius of the tube. Must be smaller than `radius`.
		 * @param {number} [radialSegments=12] - The number of radial segments.
		 * @param {number} [tubularSegments=48] - The number of tubular segments.
		 * @param {number} [arc=Math.PI*2] - Central angle in radians.
		 */
		constructor( radius = 1, tube = 0.4, radialSegments = 12, tubularSegments = 48, arc = Math.PI * 2 ) {

			super();

			this.type = 'TorusGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				radius: radius,
				tube: tube,
				radialSegments: radialSegments,
				tubularSegments: tubularSegments,
				arc: arc
			};

			radialSegments = Math.floor( radialSegments );
			tubularSegments = Math.floor( tubularSegments );

			// buffers

			const indices = [];
			const vertices = [];
			const normals = [];
			const uvs = [];

			// helper variables

			const center = new Vector3();
			const vertex = new Vector3();
			const normal = new Vector3();

			// generate vertices, normals and uvs

			for ( let j = 0; j <= radialSegments; j ++ ) {

				for ( let i = 0; i <= tubularSegments; i ++ ) {

					const u = i / tubularSegments * arc;
					const v = j / radialSegments * Math.PI * 2;

					// vertex

					vertex.x = ( radius + tube * Math.cos( v ) ) * Math.cos( u );
					vertex.y = ( radius + tube * Math.cos( v ) ) * Math.sin( u );
					vertex.z = tube * Math.sin( v );

					vertices.push( vertex.x, vertex.y, vertex.z );

					// normal

					center.x = radius * Math.cos( u );
					center.y = radius * Math.sin( u );
					normal.subVectors( vertex, center ).normalize();

					normals.push( normal.x, normal.y, normal.z );

					// uv

					uvs.push( i / tubularSegments );
					uvs.push( j / radialSegments );

				}

			}

			// generate indices

			for ( let j = 1; j <= radialSegments; j ++ ) {

				for ( let i = 1; i <= tubularSegments; i ++ ) {

					// indices

					const a = ( tubularSegments + 1 ) * j + i - 1;
					const b = ( tubularSegments + 1 ) * ( j - 1 ) + i - 1;
					const c = ( tubularSegments + 1 ) * ( j - 1 ) + i;
					const d = ( tubularSegments + 1 ) * j + i;

					// faces

					indices.push( a, b, d );
					indices.push( b, c, d );

				}

			}

			// build geometry

			this.setIndex( indices );
			this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );
			this.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

		/**
		 * Factory method for creating an instance of this class from the given
		 * JSON object.
		 *
		 * @param {Object} data - A JSON object representing the serialized geometry.
		 * @return {TorusGeometry} A new instance.
		 */
		static fromJSON( data ) {

			return new TorusGeometry( data.radius, data.tube, data.radialSegments, data.tubularSegments, data.arc );

		}

	}

	/**
	 * Can be used as a helper object to visualize a geometry as a wireframe.
	 *
	 * ```js
	 * const geometry = new THREE.SphereGeometry();
	 *
	 * const wireframe = new THREE.WireframeGeometry( geometry );
	 *
	 * const line = new THREE.LineSegments( wireframe );
	 * line.material.depthWrite = false;
	 * line.material.opacity = 0.25;
	 * line.material.transparent = true;
	 *
	 * scene.add( line );
	 * ```
	 *
	 * Note: It is not yet possible to serialize/deserialize instances of this class.
	 *
	 * @augments BufferGeometry
	 */
	class WireframeGeometry extends BufferGeometry {

		/**
		 * Constructs a new wireframe geometry.
		 *
		 * @param {?BufferGeometry} [geometry=null] - The geometry.
		 */
		constructor( geometry = null ) {

			super();

			this.type = 'WireframeGeometry';

			/**
			 * Holds the constructor parameters that have been
			 * used to generate the geometry. Any modification
			 * after instantiation does not change the geometry.
			 *
			 * @type {Object}
			 */
			this.parameters = {
				geometry: geometry
			};

			if ( geometry !== null ) {

				// buffer

				const vertices = [];
				const edges = new Set();

				// helper variables

				const start = new Vector3();
				const end = new Vector3();

				if ( geometry.index !== null ) {

					// indexed BufferGeometry

					const position = geometry.attributes.position;
					const indices = geometry.index;
					let groups = geometry.groups;

					if ( groups.length === 0 ) {

						groups = [ { start: 0, count: indices.count, materialIndex: 0 } ];

					}

					// create a data structure that contains all edges without duplicates

					for ( let o = 0, ol = groups.length; o < ol; ++ o ) {

						const group = groups[ o ];

						const groupStart = group.start;
						const groupCount = group.count;

						for ( let i = groupStart, l = ( groupStart + groupCount ); i < l; i += 3 ) {

							for ( let j = 0; j < 3; j ++ ) {

								const index1 = indices.getX( i + j );
								const index2 = indices.getX( i + ( j + 1 ) % 3 );

								start.fromBufferAttribute( position, index1 );
								end.fromBufferAttribute( position, index2 );

								if ( isUniqueEdge( start, end, edges ) === true ) {

									vertices.push( start.x, start.y, start.z );
									vertices.push( end.x, end.y, end.z );

								}

							}

						}

					}

				} else {

					// non-indexed BufferGeometry

					const position = geometry.attributes.position;

					for ( let i = 0, l = ( position.count / 3 ); i < l; i ++ ) {

						for ( let j = 0; j < 3; j ++ ) {

							// three edges per triangle, an edge is represented as (index1, index2)
							// e.g. the first triangle has the following edges: (0,1),(1,2),(2,0)

							const index1 = 3 * i + j;
							const index2 = 3 * i + ( ( j + 1 ) % 3 );

							start.fromBufferAttribute( position, index1 );
							end.fromBufferAttribute( position, index2 );

							if ( isUniqueEdge( start, end, edges ) === true ) {

								vertices.push( start.x, start.y, start.z );
								vertices.push( end.x, end.y, end.z );

							}

						}

					}

				}

				// build geometry

				this.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );

			}

		}

		copy( source ) {

			super.copy( source );

			this.parameters = Object.assign( {}, source.parameters );

			return this;

		}

	}

	function isUniqueEdge( start, end, edges ) {

		const hash1 = `${start.x},${start.y},${start.z}-${end.x},${end.y},${end.z}`;
		const hash2 = `${end.x},${end.y},${end.z}-${start.x},${start.y},${start.z}`; // coincident edge

		if ( edges.has( hash1 ) === true || edges.has( hash2 ) === true ) {

			return false;

		} else {

			edges.add( hash1 );
			edges.add( hash2 );
			return true;

		}

	}

	/**
	 * A standard physically based material, using Metallic-Roughness workflow.
	 *
	 * Physically based rendering (PBR) has recently become the standard in many
	 * 3D applications, such as [Unity]{@link https://blogs.unity3d.com/2014/10/29/physically-based-shading-in-unity-5-a-primer/},
	 * [Unreal]{@link https://docs.unrealengine.com/latest/INT/Engine/Rendering/Materials/PhysicallyBased/} and
	 * [3D Studio Max]{@link http://area.autodesk.com/blogs/the-3ds-max-blog/what039s-new-for-rendering-in-3ds-max-2017}.
	 *
	 * This approach differs from older approaches in that instead of using
	 * approximations for the way in which light interacts with a surface, a
	 * physically correct model is used. The idea is that, instead of tweaking
	 * materials to look good under specific lighting, a material can be created
	 * that will react 'correctly' under all lighting scenarios.
	 *
	 * In practice this gives a more accurate and realistic looking result than
	 * the {@link MeshLambertMaterial} or {@link MeshPhongMaterial}, at the cost of
	 * being somewhat more computationally expensive. `MeshStandardMaterial` uses per-fragment
	 * shading.
	 *
	 * Note that for best results you should always specify an environment map when using this material.
	 *
	 * For a non-technical introduction to the concept of PBR and how to set up a
	 * PBR material, check out these articles by the people at [marmoset]{@link https://www.marmoset.co}:
	 *
	 * - [Basic Theory of Physically Based Rendering]{@link https://www.marmoset.co/posts/basic-theory-of-physically-based-rendering/}
	 * - [Physically Based Rendering and You Can Too]{@link https://www.marmoset.co/posts/physically-based-rendering-and-you-can-too/}
	 *
	 * Technical details of the approach used in three.js (and most other PBR systems) can be found is this
	 * [paper from Disney]{@link https://media.disneyanimation.com/uploads/production/publication_asset/48/asset/s2012_pbs_disney_brdf_notes_v3.pdf}
	 * (pdf), by Brent Burley.
	 *
	 * @augments Material
	 */
	class MeshStandardMaterial extends Material {

		/**
		 * Constructs a new mesh standard material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isMeshStandardMaterial = true;

			this.type = 'MeshStandardMaterial';

			this.defines = { 'STANDARD': '' };

			/**
			 * Color of the material.
			 *
			 * @type {Color}
			 * @default (1,1,1)
			 */
			this.color = new Color( 0xffffff ); // diffuse

			/**
			 * How rough the material appears. `0.0` means a smooth mirror reflection, `1.0`
			 * means fully diffuse. If `roughnessMap` is also provided,
			 * both values are multiplied.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.roughness = 1.0;

			/**
			 * How much the material is like a metal. Non-metallic materials such as wood
			 * or stone use `0.0`, metallic use `1.0`, with nothing (usually) in between.
			 * A value between `0.0` and `1.0` could be used for a rusty metal look.
			 * If `metalnessMap` is also provided, both values are multiplied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.metalness = 0.0;

			/**
			 * The color map. May optionally include an alpha channel, typically combined
			 * with {@link Material#transparent} or {@link Material#alphaTest}. The texture map
			 * color is modulated by the diffuse `color`.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.map = null;

			/**
			 * The light map. Requires a second set of UVs.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.lightMap = null;

			/**
			 * Intensity of the baked light.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.lightMapIntensity = 1.0;

			/**
			 * The red channel of this texture is used as the ambient occlusion map.
			 * Requires a second set of UVs.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.aoMap = null;

			/**
			 * Intensity of the ambient occlusion effect. Range is `[0,1]`, where `0`
			 * disables ambient occlusion. Where intensity is `1` and the AO map's
			 * red channel is also `1`, ambient light is fully occluded on a surface.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.aoMapIntensity = 1.0;

			/**
			 * Emissive (light) color of the material, essentially a solid color
			 * unaffected by other lighting.
			 *
			 * @type {Color}
			 * @default (0,0,0)
			 */
			this.emissive = new Color( 0x000000 );

			/**
			 * Intensity of the emissive light. Modulates the emissive color.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.emissiveIntensity = 1.0;

			/**
			 * Set emissive (glow) map. The emissive map color is modulated by the
			 * emissive color and the emissive intensity. If you have an emissive map,
			 * be sure to set the emissive color to something other than black.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.emissiveMap = null;

			/**
			 * The texture to create a bump map. The black and white values map to the
			 * perceived depth in relation to the lights. Bump doesn't actually affect
			 * the geometry of the object, only the lighting. If a normal map is defined
			 * this will be ignored.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.bumpMap = null;

			/**
			 * How much the bump map affects the material. Typical range is `[0,1]`.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.bumpScale = 1;

			/**
			 * The texture to create a normal map. The RGB values affect the surface
			 * normal for each pixel fragment and change the way the color is lit. Normal
			 * maps do not change the actual shape of the surface, only the lighting. In
			 * case the material has a normal map authored using the left handed
			 * convention, the `y` component of `normalScale` should be negated to compensate
			 * for the different handedness.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.normalMap = null;

			/**
			 * The type of normal map.
			 *
			 * @type {(TangentSpaceNormalMap|ObjectSpaceNormalMap)}
			 * @default TangentSpaceNormalMap
			 */
			this.normalMapType = TangentSpaceNormalMap;

			/**
			 * How much the normal map affects the material. Typical value range is `[0,1]`.
			 *
			 * @type {Vector2}
			 * @default (1,1)
			 */
			this.normalScale = new Vector2( 1, 1 );

			/**
			 * The displacement map affects the position of the mesh's vertices. Unlike
			 * other maps which only affect the light and shade of the material the
			 * displaced vertices can cast shadows, block other objects, and otherwise
			 * act as real geometry. The displacement texture is an image where the value
			 * of each pixel (white being the highest) is mapped against, and
			 * repositions, the vertices of the mesh.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.displacementMap = null;

			/**
			 * How much the displacement map affects the mesh (where black is no
			 * displacement, and white is maximum displacement). Without a displacement
			 * map set, this value is not applied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.displacementScale = 1;

			/**
			 * The offset of the displacement map's values on the mesh's vertices.
			 * The bias is added to the scaled sample of the displacement map.
			 * Without a displacement map set, this value is not applied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.displacementBias = 0;

			/**
			 * The green channel of this texture is used to alter the roughness of the
			 * material.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.roughnessMap = null;

			/**
			 * The blue channel of this texture is used to alter the metalness of the
			 * material.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.metalnessMap = null;

			/**
			 * The alpha map is a grayscale texture that controls the opacity across the
			 * surface (black: fully transparent; white: fully opaque).
			 *
			 * Only the color of the texture is used, ignoring the alpha channel if one
			 * exists. For RGB and RGBA textures, the renderer will use the green channel
			 * when sampling this texture due to the extra bit of precision provided for
			 * green in DXT-compressed and uncompressed RGB 565 formats. Luminance-only and
			 * luminance/alpha textures will also still work as expected.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.alphaMap = null;

			/**
			 * The environment map. To ensure a physically correct rendering, environment maps
			 * are internally pre-processed with {@link PMREMGenerator}.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.envMap = null;

			/**
			 * The rotation of the environment map in radians.
			 *
			 * @type {Euler}
			 * @default (0,0,0)
			 */
			this.envMapRotation = new Euler();

			/**
			 * Scales the effect of the environment map by multiplying its color.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.envMapIntensity = 1.0;

			/**
			 * Renders the geometry as a wireframe.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.wireframe = false;

			/**
			 * Controls the thickness of the wireframe.
			 *
			 * Can only be used with {@link SVGRenderer}.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.wireframeLinewidth = 1;

			/**
			 * Defines appearance of wireframe ends.
			 *
			 * Can only be used with {@link SVGRenderer}.
			 *
			 * @type {('round'|'bevel'|'miter')}
			 * @default 'round'
			 */
			this.wireframeLinecap = 'round';

			/**
			 * Defines appearance of wireframe joints.
			 *
			 * Can only be used with {@link SVGRenderer}.
			 *
			 * @type {('round'|'bevel'|'miter')}
			 * @default 'round'
			 */
			this.wireframeLinejoin = 'round';

			/**
			 * Whether the material is rendered with flat shading or not.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.flatShading = false;

			/**
			 * Whether the material is affected by fog or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.fog = true;

			this.setValues( parameters );

		}

		copy( source ) {

			super.copy( source );

			this.defines = { 'STANDARD': '' };

			this.color.copy( source.color );
			this.roughness = source.roughness;
			this.metalness = source.metalness;

			this.map = source.map;

			this.lightMap = source.lightMap;
			this.lightMapIntensity = source.lightMapIntensity;

			this.aoMap = source.aoMap;
			this.aoMapIntensity = source.aoMapIntensity;

			this.emissive.copy( source.emissive );
			this.emissiveMap = source.emissiveMap;
			this.emissiveIntensity = source.emissiveIntensity;

			this.bumpMap = source.bumpMap;
			this.bumpScale = source.bumpScale;

			this.normalMap = source.normalMap;
			this.normalMapType = source.normalMapType;
			this.normalScale.copy( source.normalScale );

			this.displacementMap = source.displacementMap;
			this.displacementScale = source.displacementScale;
			this.displacementBias = source.displacementBias;

			this.roughnessMap = source.roughnessMap;

			this.metalnessMap = source.metalnessMap;

			this.alphaMap = source.alphaMap;

			this.envMap = source.envMap;
			this.envMapRotation.copy( source.envMapRotation );
			this.envMapIntensity = source.envMapIntensity;

			this.wireframe = source.wireframe;
			this.wireframeLinewidth = source.wireframeLinewidth;
			this.wireframeLinecap = source.wireframeLinecap;
			this.wireframeLinejoin = source.wireframeLinejoin;

			this.flatShading = source.flatShading;

			this.fog = source.fog;

			return this;

		}

	}

	/**
	 * An extension of the {@link MeshStandardMaterial}, providing more advanced
	 * physically-based rendering properties:
	 *
	 * - Anisotropy: Ability to represent the anisotropic property of materials
	 * as observable with brushed metals.
	 * - Clearcoat: Some materials — like car paints, carbon fiber, and wet surfaces — require
	 * a clear, reflective layer on top of another layer that may be irregular or rough.
	 * Clearcoat approximates this effect, without the need for a separate transparent surface.
	 * - Iridescence: Allows to render the effect where hue varies  depending on the viewing
	 * angle and illumination angle. This can be seen on soap bubbles, oil films, or on the
	 * wings of many insects.
	 * - Physically-based transparency: One limitation of {@link Material#opacity} is that highly
	 * transparent materials are less reflective. Physically-based transmission provides a more
	 * realistic option for thin, transparent surfaces like glass.
	 * - Advanced reflectivity: More flexible reflectivity for non-metallic materials.
	 * - Sheen: Can be used for representing cloth and fabric materials.
	 *
	 * As a result of these complex shading features, `MeshPhysicalMaterial` has a
	 * higher performance cost, per pixel, than other three.js materials. Most
	 * effects are disabled by default, and add cost as they are enabled. For
	 * best results, always specify an environment map when using this material.
	 *
	 * @augments MeshStandardMaterial
	 */
	class MeshPhysicalMaterial extends MeshStandardMaterial {

		/**
		 * Constructs a new mesh physical material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isMeshPhysicalMaterial = true;

			this.defines = {

				'STANDARD': '',
				'PHYSICAL': ''

			};

			this.type = 'MeshPhysicalMaterial';

			/**
			 * The rotation of the anisotropy in tangent, bitangent space, measured in radians
			 * counter-clockwise from the tangent. When `anisotropyMap` is present, this
			 * property provides additional rotation to the vectors in the texture.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.anisotropyRotation = 0;

			/**
			 * Red and green channels represent the anisotropy direction in `[-1, 1]` tangent,
			 * bitangent space, to be rotated by `anisotropyRotation`. The blue channel
			 * contains strength as `[0, 1]` to be multiplied by `anisotropy`.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.anisotropyMap = null;

			/**
			 * The red channel of this texture is multiplied against `clearcoat`,
			 * for per-pixel control over a coating's intensity.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.clearcoatMap = null;

			/**
			 * Roughness of the clear coat layer, from `0.0` to `1.0`.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.clearcoatRoughness = 0.0;

			/**
			 * The green channel of this texture is multiplied against
			 * `clearcoatRoughness`, for per-pixel control over a coating's roughness.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.clearcoatRoughnessMap = null;

			/**
			 * How much `clearcoatNormalMap` affects the clear coat layer, from
			 * `(0,0)` to `(1,1)`.
			 *
			 * @type {Vector2}
			 * @default (1,1)
			 */
			this.clearcoatNormalScale = new Vector2( 1, 1 );

			/**
			 * Can be used to enable independent normals for the clear coat layer.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.clearcoatNormalMap = null;

			/**
			 * Index-of-refraction for non-metallic materials, from `1.0` to `2.333`.
			 *
			 * @type {number}
			 * @default 1.5
			 */
			this.ior = 1.5;

			/**
			 * Degree of reflectivity, from `0.0` to `1.0`. Default is `0.5`, which
			 * corresponds to an index-of-refraction of `1.5`.
			 *
			 * This models the reflectivity of non-metallic materials. It has no effect
			 * when `metalness` is `1.0`
			 *
			 * @name MeshPhysicalMaterial#reflectivity
			 * @type {number}
			 * @default 0.5
			 */
			Object.defineProperty( this, 'reflectivity', {
				get: function () {

					return ( clamp( 2.5 * ( this.ior - 1 ) / ( this.ior + 1 ), 0, 1 ) );

				},
				set: function ( reflectivity ) {

					this.ior = ( 1 + 0.4 * reflectivity ) / ( 1 - 0.4 * reflectivity );

				}
			} );

			/**
			 * The red channel of this texture is multiplied against `iridescence`, for per-pixel
			 * control over iridescence.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.iridescenceMap = null;

			/**
			 * Strength of the iridescence RGB color shift effect, represented by an index-of-refraction.
			 * Between `1.0` to `2.333`.
			 *
			 * @type {number}
			 * @default 1.3
			 */
			this.iridescenceIOR = 1.3;

			/**
			 *Array of exactly 2 elements, specifying minimum and maximum thickness of the iridescence layer.
			 Thickness of iridescence layer has an equivalent effect of the one `thickness` has on `ior`.
			 *
			 * @type {Array<number,number>}
			 * @default [100,400]
			 */
			this.iridescenceThicknessRange = [ 100, 400 ];

			/**
			 * A texture that defines the thickness of the iridescence layer, stored in the green channel.
			 * Minimum and maximum values of thickness are defined by `iridescenceThicknessRange` array:
			 * - `0.0` in the green channel will result in thickness equal to first element of the array.
			 * - `1.0` in the green channel will result in thickness equal to second element of the array.
			 * - Values in-between will linearly interpolate between the elements of the array.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.iridescenceThicknessMap = null;

			/**
			 * The sheen tint.
			 *
			 * @type {Color}
			 * @default (0,0,0)
			 */
			this.sheenColor = new Color( 0x000000 );

			/**
			 * The RGB channels of this texture are multiplied against  `sheenColor`, for per-pixel control
			 * over sheen tint.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.sheenColorMap = null;

			/**
			 * Roughness of the sheen layer, from `0.0` to `1.0`.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.sheenRoughness = 1.0;

			/**
			 * The alpha channel of this texture is multiplied against `sheenRoughness`, for per-pixel control
			 * over sheen roughness.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.sheenRoughnessMap = null;

			/**
			 * The red channel of this texture is multiplied against `transmission`, for per-pixel control over
			 * optical transparency.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.transmissionMap = null;

			/**
			 * The thickness of the volume beneath the surface. The value is given in the
			 * coordinate space of the mesh. If the value is `0` the material is
			 * thin-walled. Otherwise the material is a volume boundary.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.thickness = 0;

			/**
			 * A texture that defines the thickness, stored in the green channel. This will
			 * be multiplied by `thickness`.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.thicknessMap = null;

			/**
			 * Density of the medium given as the average distance that light travels in
			 * the medium before interacting with a particle. The value is given in world
			 * space units, and must be greater than zero.
			 *
			 * @type {number}
			 * @default Infinity
			 */
			this.attenuationDistance = Infinity;

			/**
			 * The color that white light turns into due to absorption when reaching the
			 * attenuation distance.
			 *
			 * @type {Color}
			 * @default (1,1,1)
			 */
			this.attenuationColor = new Color( 1, 1, 1 );

			/**
			 * A float that scales the amount of specular reflection for non-metals only.
			 * When set to zero, the model is effectively Lambertian. From `0.0` to `1.0`.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.specularIntensity = 1.0;

			/**
			 * The alpha channel of this texture is multiplied against `specularIntensity`,
			 * for per-pixel control over specular intensity.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.specularIntensityMap = null;

			/**
			 * Tints the specular reflection at normal incidence for non-metals only.
			 *
			 * @type {Color}
			 * @default (1,1,1)
			 */
			this.specularColor = new Color( 1, 1, 1 );

			/**
			 * The RGB channels of this texture are multiplied against `specularColor`,
			 * for per-pixel control over specular color.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.specularColorMap = null;

			this._anisotropy = 0;
			this._clearcoat = 0;
			this._dispersion = 0;
			this._iridescence = 0;
			this._sheen = 0.0;
			this._transmission = 0;

			this.setValues( parameters );

		}

		/**
		 * The anisotropy strength.
		 *
		 * @type {number}
		 * @default 0
		 */
		get anisotropy() {

			return this._anisotropy;

		}

		set anisotropy( value ) {

			if ( this._anisotropy > 0 !== value > 0 ) {

				this.version ++;

			}

			this._anisotropy = value;

		}

		/**
		 * Represents the intensity of the clear coat layer, from `0.0` to `1.0`. Use
		 * clear coat related properties to enable multilayer materials that have a
		 * thin translucent layer over the base layer.
		 *
		 * @type {number}
		 * @default 0
		 */
		get clearcoat() {

			return this._clearcoat;

		}

		set clearcoat( value ) {

			if ( this._clearcoat > 0 !== value > 0 ) {

				this.version ++;

			}

			this._clearcoat = value;

		}
		/**
		 * The intensity of the iridescence layer, simulating RGB color shift based on the angle between
		 * the surface and the viewer, from `0.0` to `1.0`.
		 *
		 * @type {number}
		 * @default 0
		 */
		get iridescence() {

			return this._iridescence;

		}

		set iridescence( value ) {

			if ( this._iridescence > 0 !== value > 0 ) {

				this.version ++;

			}

			this._iridescence = value;

		}

		/**
		 * Defines the strength of the angular separation of colors (chromatic aberration) transmitting
		 * through a relatively clear volume. Any value zero or larger is valid, the typical range of
		 * realistic values is `[0, 1]`. This property can be only be used with transmissive objects.
		 *
		 * @type {number}
		 * @default 0
		 */
		get dispersion() {

			return this._dispersion;

		}

		set dispersion( value ) {

			if ( this._dispersion > 0 !== value > 0 ) {

				this.version ++;

			}

			this._dispersion = value;

		}

		/**
		 * The intensity of the sheen layer, from `0.0` to `1.0`.
		 *
		 * @type {number}
		 * @default 0
		 */
		get sheen() {

			return this._sheen;

		}

		set sheen( value ) {

			if ( this._sheen > 0 !== value > 0 ) {

				this.version ++;

			}

			this._sheen = value;

		}

		/**
		 * Degree of transmission (or optical transparency), from `0.0` to `1.0`.
		 *
		 * Thin, transparent or semitransparent, plastic or glass materials remain
		 * largely reflective even if they are fully transmissive. The transmission
		 * property can be used to model these materials.
		 *
		 * When transmission is non-zero, `opacity` should be  set to `1`.
		 *
		 * @type {number}
		 * @default 0
		 */
		get transmission() {

			return this._transmission;

		}

		set transmission( value ) {

			if ( this._transmission > 0 !== value > 0 ) {

				this.version ++;

			}

			this._transmission = value;

		}

		copy( source ) {

			super.copy( source );

			this.defines = {

				'STANDARD': '',
				'PHYSICAL': ''

			};

			this.anisotropy = source.anisotropy;
			this.anisotropyRotation = source.anisotropyRotation;
			this.anisotropyMap = source.anisotropyMap;

			this.clearcoat = source.clearcoat;
			this.clearcoatMap = source.clearcoatMap;
			this.clearcoatRoughness = source.clearcoatRoughness;
			this.clearcoatRoughnessMap = source.clearcoatRoughnessMap;
			this.clearcoatNormalMap = source.clearcoatNormalMap;
			this.clearcoatNormalScale.copy( source.clearcoatNormalScale );

			this.dispersion = source.dispersion;
			this.ior = source.ior;

			this.iridescence = source.iridescence;
			this.iridescenceMap = source.iridescenceMap;
			this.iridescenceIOR = source.iridescenceIOR;
			this.iridescenceThicknessRange = [ ...source.iridescenceThicknessRange ];
			this.iridescenceThicknessMap = source.iridescenceThicknessMap;

			this.sheen = source.sheen;
			this.sheenColor.copy( source.sheenColor );
			this.sheenColorMap = source.sheenColorMap;
			this.sheenRoughness = source.sheenRoughness;
			this.sheenRoughnessMap = source.sheenRoughnessMap;

			this.transmission = source.transmission;
			this.transmissionMap = source.transmissionMap;

			this.thickness = source.thickness;
			this.thicknessMap = source.thicknessMap;
			this.attenuationDistance = source.attenuationDistance;
			this.attenuationColor.copy( source.attenuationColor );

			this.specularIntensity = source.specularIntensity;
			this.specularIntensityMap = source.specularIntensityMap;
			this.specularColor.copy( source.specularColor );
			this.specularColorMap = source.specularColorMap;

			return this;

		}

	}

	/**
	 * A material that maps the normal vectors to RGB colors.
	 *
	 * @augments Material
	 */
	class MeshNormalMaterial extends Material {

		/**
		 * Constructs a new mesh normal material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isMeshNormalMaterial = true;

			this.type = 'MeshNormalMaterial';

			/**
			 * The texture to create a bump map. The black and white values map to the
			 * perceived depth in relation to the lights. Bump doesn't actually affect
			 * the geometry of the object, only the lighting. If a normal map is defined
			 * this will be ignored.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.bumpMap = null;

			/**
			 * How much the bump map affects the material. Typical range is `[0,1]`.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.bumpScale = 1;

			/**
			 * The texture to create a normal map. The RGB values affect the surface
			 * normal for each pixel fragment and change the way the color is lit. Normal
			 * maps do not change the actual shape of the surface, only the lighting. In
			 * case the material has a normal map authored using the left handed
			 * convention, the `y` component of `normalScale` should be negated to compensate
			 * for the different handedness.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.normalMap = null;

			/**
			 * The type of normal map.
			 *
			 * @type {(TangentSpaceNormalMap|ObjectSpaceNormalMap)}
			 * @default TangentSpaceNormalMap
			 */
			this.normalMapType = TangentSpaceNormalMap;

			/**
			 * How much the normal map affects the material. Typical value range is `[0,1]`.
			 *
			 * @type {Vector2}
			 * @default (1,1)
			 */
			this.normalScale = new Vector2( 1, 1 );

			/**
			 * The displacement map affects the position of the mesh's vertices. Unlike
			 * other maps which only affect the light and shade of the material the
			 * displaced vertices can cast shadows, block other objects, and otherwise
			 * act as real geometry. The displacement texture is an image where the value
			 * of each pixel (white being the highest) is mapped against, and
			 * repositions, the vertices of the mesh.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.displacementMap = null;

			/**
			 * How much the displacement map affects the mesh (where black is no
			 * displacement, and white is maximum displacement). Without a displacement
			 * map set, this value is not applied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.displacementScale = 1;

			/**
			 * The offset of the displacement map's values on the mesh's vertices.
			 * The bias is added to the scaled sample of the displacement map.
			 * Without a displacement map set, this value is not applied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.displacementBias = 0;

			/**
			 * Renders the geometry as a wireframe.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.wireframe = false;

			/**
			 * Controls the thickness of the wireframe.
			 *
			 * WebGL and WebGPU ignore this property and always render
			 * 1 pixel wide lines.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.wireframeLinewidth = 1;

			/**
			 * Whether the material is rendered with flat shading or not.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.flatShading = false;

			this.setValues( parameters );

		}

		copy( source ) {

			super.copy( source );

			this.bumpMap = source.bumpMap;
			this.bumpScale = source.bumpScale;

			this.normalMap = source.normalMap;
			this.normalMapType = source.normalMapType;
			this.normalScale.copy( source.normalScale );

			this.displacementMap = source.displacementMap;
			this.displacementScale = source.displacementScale;
			this.displacementBias = source.displacementBias;

			this.wireframe = source.wireframe;
			this.wireframeLinewidth = source.wireframeLinewidth;

			this.flatShading = source.flatShading;

			return this;

		}

	}

	/**
	 * A material for drawing geometry by depth. Depth is based off of the camera
	 * near and far plane. White is nearest, black is farthest.
	 *
	 * @augments Material
	 */
	class MeshDepthMaterial extends Material {

		/**
		 * Constructs a new mesh depth material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isMeshDepthMaterial = true;

			this.type = 'MeshDepthMaterial';

			/**
			 * Type for depth packing.
			 *
			 * @type {(BasicDepthPacking|RGBADepthPacking|RGBDepthPacking|RGDepthPacking)}
			 * @default BasicDepthPacking
			 */
			this.depthPacking = BasicDepthPacking;

			/**
			 * The color map. May optionally include an alpha channel, typically combined
			 * with {@link Material#transparent} or {@link Material#alphaTest}.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.map = null;

			/**
			 * The alpha map is a grayscale texture that controls the opacity across the
			 * surface (black: fully transparent; white: fully opaque).
			 *
			 * Only the color of the texture is used, ignoring the alpha channel if one
			 * exists. For RGB and RGBA textures, the renderer will use the green channel
			 * when sampling this texture due to the extra bit of precision provided for
			 * green in DXT-compressed and uncompressed RGB 565 formats. Luminance-only and
			 * luminance/alpha textures will also still work as expected.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.alphaMap = null;

			/**
			 * The displacement map affects the position of the mesh's vertices. Unlike
			 * other maps which only affect the light and shade of the material the
			 * displaced vertices can cast shadows, block other objects, and otherwise
			 * act as real geometry. The displacement texture is an image where the value
			 * of each pixel (white being the highest) is mapped against, and
			 * repositions, the vertices of the mesh.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.displacementMap = null;

			/**
			 * How much the displacement map affects the mesh (where black is no
			 * displacement, and white is maximum displacement). Without a displacement
			 * map set, this value is not applied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.displacementScale = 1;

			/**
			 * The offset of the displacement map's values on the mesh's vertices.
			 * The bias is added to the scaled sample of the displacement map.
			 * Without a displacement map set, this value is not applied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.displacementBias = 0;

			/**
			 * Renders the geometry as a wireframe.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.wireframe = false;

			/**
			 * Controls the thickness of the wireframe.
			 *
			 * WebGL and WebGPU ignore this property and always render
			 * 1 pixel wide lines.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.wireframeLinewidth = 1;

			this.setValues( parameters );

		}

		copy( source ) {

			super.copy( source );

			this.depthPacking = source.depthPacking;

			this.map = source.map;

			this.alphaMap = source.alphaMap;

			this.displacementMap = source.displacementMap;
			this.displacementScale = source.displacementScale;
			this.displacementBias = source.displacementBias;

			this.wireframe = source.wireframe;
			this.wireframeLinewidth = source.wireframeLinewidth;

			return this;

		}

	}

	/**
	 * A material used internally for implementing shadow mapping with
	 * point lights.
	 *
	 * Can also be used to customize the shadow casting of an object by assigning
	 * an instance of `MeshDistanceMaterial` to {@link Object3D#customDistanceMaterial}.
	 * The following examples demonstrates this approach in order to ensure
	 * transparent parts of objects do no cast shadows.
	 *
	 * @augments Material
	 */
	class MeshDistanceMaterial extends Material {

		/**
		 * Constructs a new mesh distance material.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isMeshDistanceMaterial = true;

			this.type = 'MeshDistanceMaterial';

			/**
			 * The color map. May optionally include an alpha channel, typically combined
			 * with {@link Material#transparent} or {@link Material#alphaTest}.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.map = null;

			/**
			 * The alpha map is a grayscale texture that controls the opacity across the
			 * surface (black: fully transparent; white: fully opaque).
			 *
			 * Only the color of the texture is used, ignoring the alpha channel if one
			 * exists. For RGB and RGBA textures, the renderer will use the green channel
			 * when sampling this texture due to the extra bit of precision provided for
			 * green in DXT-compressed and uncompressed RGB 565 formats. Luminance-only and
			 * luminance/alpha textures will also still work as expected.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.alphaMap = null;

			/**
			 * The displacement map affects the position of the mesh's vertices. Unlike
			 * other maps which only affect the light and shade of the material the
			 * displaced vertices can cast shadows, block other objects, and otherwise
			 * act as real geometry. The displacement texture is an image where the value
			 * of each pixel (white being the highest) is mapped against, and
			 * repositions, the vertices of the mesh.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.displacementMap = null;

			/**
			 * How much the displacement map affects the mesh (where black is no
			 * displacement, and white is maximum displacement). Without a displacement
			 * map set, this value is not applied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.displacementScale = 1;

			/**
			 * The offset of the displacement map's values on the mesh's vertices.
			 * The bias is added to the scaled sample of the displacement map.
			 * Without a displacement map set, this value is not applied.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.displacementBias = 0;

			this.setValues( parameters );

		}

		copy( source ) {

			super.copy( source );

			this.map = source.map;

			this.alphaMap = source.alphaMap;

			this.displacementMap = source.displacementMap;
			this.displacementScale = source.displacementScale;
			this.displacementBias = source.displacementBias;

			return this;

		}

	}

	/**
	 * Converts an array to a specific type.
	 *
	 * @param {TypedArray|Array} array - The array to convert.
	 * @param {TypedArray.constructor} type - The constructor of a typed array that defines the new type.
	 * @return {TypedArray} The converted array.
	 */
	function convertArray( array, type ) {

		if ( ! array || array.constructor === type ) return array;

		if ( typeof type.BYTES_PER_ELEMENT === 'number' ) {

			return new type( array ); // create typed array

		}

		return Array.prototype.slice.call( array ); // create Array

	}

	/**
	 * Returns `true` if the given object is a typed array.
	 *
	 * @param {any} object - The object to check.
	 * @return {boolean} Whether the given object is a typed array.
	 */
	function isTypedArray( object ) {

		return ArrayBuffer.isView( object ) && ! ( object instanceof DataView );

	}

	/**
	 * Returns an array by which times and values can be sorted.
	 *
	 * @param {Array<number>} times - The keyframe time values.
	 * @return {Array<number>} The array.
	 */
	function getKeyframeOrder( times ) {

		function compareTime( i, j ) {

			return times[ i ] - times[ j ];

		}

		const n = times.length;
		const result = new Array( n );
		for ( let i = 0; i !== n; ++ i ) result[ i ] = i;

		result.sort( compareTime );

		return result;

	}

	/**
	 * Sorts the given array by the previously computed order via `getKeyframeOrder()`.
	 *
	 * @param {Array<number>} values - The values to sort.
	 * @param {number} stride - The stride.
	 * @param {Array<number>} order - The sort order.
	 * @return {Array<number>} The sorted values.
	 */
	function sortedArray( values, stride, order ) {

		const nValues = values.length;
		const result = new values.constructor( nValues );

		for ( let i = 0, dstOffset = 0; dstOffset !== nValues; ++ i ) {

			const srcOffset = order[ i ] * stride;

			for ( let j = 0; j !== stride; ++ j ) {

				result[ dstOffset ++ ] = values[ srcOffset + j ];

			}

		}

		return result;

	}

	/**
	 * Used for parsing AOS keyframe formats.
	 *
	 * @param {Array<number>} jsonKeys - A list of JSON keyframes.
	 * @param {Array<number>} times - This array will be filled with keyframe times by this function.
	 * @param {Array<number>} values - This array will be filled with keyframe values by this function.
	 * @param {string} valuePropertyName - The name of the property to use.
	 */
	function flattenJSON( jsonKeys, times, values, valuePropertyName ) {

		let i = 1, key = jsonKeys[ 0 ];

		while ( key !== undefined && key[ valuePropertyName ] === undefined ) {

			key = jsonKeys[ i ++ ];

		}

		if ( key === undefined ) return; // no data

		let value = key[ valuePropertyName ];
		if ( value === undefined ) return; // no data

		if ( Array.isArray( value ) ) {

			do {

				value = key[ valuePropertyName ];

				if ( value !== undefined ) {

					times.push( key.time );
					values.push( ...value ); // push all elements

				}

				key = jsonKeys[ i ++ ];

			} while ( key !== undefined );

		} else if ( value.toArray !== undefined ) {

			// ...assume THREE.Math-ish

			do {

				value = key[ valuePropertyName ];

				if ( value !== undefined ) {

					times.push( key.time );
					value.toArray( values, values.length );

				}

				key = jsonKeys[ i ++ ];

			} while ( key !== undefined );

		} else {

			// otherwise push as-is

			do {

				value = key[ valuePropertyName ];

				if ( value !== undefined ) {

					times.push( key.time );
					values.push( value );

				}

				key = jsonKeys[ i ++ ];

			} while ( key !== undefined );

		}

	}

	/**
	 * Abstract base class of interpolants over parametric samples.
	 *
	 * The parameter domain is one dimensional, typically the time or a path
	 * along a curve defined by the data.
	 *
	 * The sample values can have any dimensionality and derived classes may
	 * apply special interpretations to the data.
	 *
	 * This class provides the interval seek in a Template Method, deferring
	 * the actual interpolation to derived classes.
	 *
	 * Time complexity is O(1) for linear access crossing at most two points
	 * and O(log N) for random access, where N is the number of positions.
	 *
	 * References: {@link http://www.oodesign.com/template-method-pattern.html}
	 *
	 * @abstract
	 */
	class Interpolant {

		/**
		 * Constructs a new interpolant.
		 *
		 * @param {TypedArray} parameterPositions - The parameter positions hold the interpolation factors.
		 * @param {TypedArray} sampleValues - The sample values.
		 * @param {number} sampleSize - The sample size
		 * @param {TypedArray} [resultBuffer] - The result buffer.
		 */
		constructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {

			/**
			 * The parameter positions.
			 *
			 * @type {TypedArray}
			 */
			this.parameterPositions = parameterPositions;

			/**
			 * A cache index.
			 *
			 * @private
			 * @type {number}
			 * @default 0
			 */
			this._cachedIndex = 0;

			/**
			 * The result buffer.
			 *
			 * @type {TypedArray}
			 */
			this.resultBuffer = resultBuffer !== undefined ? resultBuffer : new sampleValues.constructor( sampleSize );

			/**
			 * The sample values.
			 *
			 * @type {TypedArray}
			 */
			this.sampleValues = sampleValues;

			/**
			 * The value size.
			 *
			 * @type {TypedArray}
			 */
			this.valueSize = sampleSize;

			/**
			 * The interpolation settings.
			 *
			 * @type {?Object}
			 * @default null
			 */
			this.settings = null;

			/**
			 * The default settings object.
			 *
			 * @type {Object}
			 */
			this.DefaultSettings_ = {};

		}

		/**
		 * Evaluate the interpolant at position `t`.
		 *
		 * @param {number} t - The interpolation factor.
		 * @return {TypedArray} The result buffer.
		 */
		evaluate( t ) {

			const pp = this.parameterPositions;
			let i1 = this._cachedIndex,
				t1 = pp[ i1 ],
				t0 = pp[ i1 - 1 ];

			validate_interval: {

				seek: {

					let right;

					linear_scan: {

						//- See http://jsperf.com/comparison-to-undefined/3
						//- slower code:
						//-
						//- 				if ( t >= t1 || t1 === undefined ) {
						forward_scan: if ( ! ( t < t1 ) ) {

							for ( let giveUpAt = i1 + 2; ; ) {

								if ( t1 === undefined ) {

									if ( t < t0 ) break forward_scan;

									// after end

									i1 = pp.length;
									this._cachedIndex = i1;
									return this.copySampleValue_( i1 - 1 );

								}

								if ( i1 === giveUpAt ) break; // this loop

								t0 = t1;
								t1 = pp[ ++ i1 ];

								if ( t < t1 ) {

									// we have arrived at the sought interval
									break seek;

								}

							}

							// prepare binary search on the right side of the index
							right = pp.length;
							break linear_scan;

						}

						//- slower code:
						//-					if ( t < t0 || t0 === undefined ) {
						if ( ! ( t >= t0 ) ) {

							// looping?

							const t1global = pp[ 1 ];

							if ( t < t1global ) {

								i1 = 2; // + 1, using the scan for the details
								t0 = t1global;

							}

							// linear reverse scan

							for ( let giveUpAt = i1 - 2; ; ) {

								if ( t0 === undefined ) {

									// before start

									this._cachedIndex = 0;
									return this.copySampleValue_( 0 );

								}

								if ( i1 === giveUpAt ) break; // this loop

								t1 = t0;
								t0 = pp[ -- i1 - 1 ];

								if ( t >= t0 ) {

									// we have arrived at the sought interval
									break seek;

								}

							}

							// prepare binary search on the left side of the index
							right = i1;
							i1 = 0;
							break linear_scan;

						}

						// the interval is valid

						break validate_interval;

					} // linear scan

					// binary search

					while ( i1 < right ) {

						const mid = ( i1 + right ) >>> 1;

						if ( t < pp[ mid ] ) {

							right = mid;

						} else {

							i1 = mid + 1;

						}

					}

					t1 = pp[ i1 ];
					t0 = pp[ i1 - 1 ];

					// check boundary cases, again

					if ( t0 === undefined ) {

						this._cachedIndex = 0;
						return this.copySampleValue_( 0 );

					}

					if ( t1 === undefined ) {

						i1 = pp.length;
						this._cachedIndex = i1;
						return this.copySampleValue_( i1 - 1 );

					}

				} // seek

				this._cachedIndex = i1;

				this.intervalChanged_( i1, t0, t1 );

			} // validate_interval

			return this.interpolate_( i1, t0, t, t1 );

		}

		/**
		 * Returns the interpolation settings.
		 *
		 * @return {Object} The interpolation settings.
		 */
		getSettings_() {

			return this.settings || this.DefaultSettings_;

		}

		/**
		 * Copies a sample value to the result buffer.
		 *
		 * @param {number} index - An index into the sample value buffer.
		 * @return {TypedArray} The result buffer.
		 */
		copySampleValue_( index ) {

			// copies a sample value to the result buffer

			const result = this.resultBuffer,
				values = this.sampleValues,
				stride = this.valueSize,
				offset = index * stride;

			for ( let i = 0; i !== stride; ++ i ) {

				result[ i ] = values[ offset + i ];

			}

			return result;

		}

		/**
		 * Copies a sample value to the result buffer.
		 *
		 * @abstract
		 * @param {number} i1 - An index into the sample value buffer.
		 * @param {number} t0 - The previous interpolation factor.
		 * @param {number} t - The current interpolation factor.
		 * @param {number} t1 - The next interpolation factor.
		 * @return {TypedArray} The result buffer.
		 */
		interpolate_( /* i1, t0, t, t1 */ ) {

			throw new Error( 'call to abstract method' );
			// implementations shall return this.resultBuffer

		}

		/**
		 * Optional method that is executed when the interval has changed.
		 *
		 * @param {number} i1 - An index into the sample value buffer.
		 * @param {number} t0 - The previous interpolation factor.
		 * @param {number} t - The current interpolation factor.
		 */
		intervalChanged_( /* i1, t0, t1 */ ) {

			// empty

		}

	}

	/**
	 * Fast and simple cubic spline interpolant.
	 *
	 * It was derived from a Hermitian construction setting the first derivative
	 * at each sample position to the linear slope between neighboring positions
	 * over their parameter interval.
	 *
	 * @augments Interpolant
	 */
	class CubicInterpolant extends Interpolant {

		/**
		 * Constructs a new cubic interpolant.
		 *
		 * @param {TypedArray} parameterPositions - The parameter positions hold the interpolation factors.
		 * @param {TypedArray} sampleValues - The sample values.
		 * @param {number} sampleSize - The sample size
		 * @param {TypedArray} [resultBuffer] - The result buffer.
		 */
		constructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {

			super( parameterPositions, sampleValues, sampleSize, resultBuffer );

			this._weightPrev = -0;
			this._offsetPrev = -0;
			this._weightNext = -0;
			this._offsetNext = -0;

			this.DefaultSettings_ = {

				endingStart: ZeroCurvatureEnding,
				endingEnd: ZeroCurvatureEnding

			};

		}

		intervalChanged_( i1, t0, t1 ) {

			const pp = this.parameterPositions;
			let iPrev = i1 - 2,
				iNext = i1 + 1,

				tPrev = pp[ iPrev ],
				tNext = pp[ iNext ];

			if ( tPrev === undefined ) {

				switch ( this.getSettings_().endingStart ) {

					case ZeroSlopeEnding:

						// f'(t0) = 0
						iPrev = i1;
						tPrev = 2 * t0 - t1;

						break;

					case WrapAroundEnding:

						// use the other end of the curve
						iPrev = pp.length - 2;
						tPrev = t0 + pp[ iPrev ] - pp[ iPrev + 1 ];

						break;

					default: // ZeroCurvatureEnding

						// f''(t0) = 0 a.k.a. Natural Spline
						iPrev = i1;
						tPrev = t1;

				}

			}

			if ( tNext === undefined ) {

				switch ( this.getSettings_().endingEnd ) {

					case ZeroSlopeEnding:

						// f'(tN) = 0
						iNext = i1;
						tNext = 2 * t1 - t0;

						break;

					case WrapAroundEnding:

						// use the other end of the curve
						iNext = 1;
						tNext = t1 + pp[ 1 ] - pp[ 0 ];

						break;

					default: // ZeroCurvatureEnding

						// f''(tN) = 0, a.k.a. Natural Spline
						iNext = i1 - 1;
						tNext = t0;

				}

			}

			const halfDt = ( t1 - t0 ) * 0.5,
				stride = this.valueSize;

			this._weightPrev = halfDt / ( t0 - tPrev );
			this._weightNext = halfDt / ( tNext - t1 );
			this._offsetPrev = iPrev * stride;
			this._offsetNext = iNext * stride;

		}

		interpolate_( i1, t0, t, t1 ) {

			const result = this.resultBuffer,
				values = this.sampleValues,
				stride = this.valueSize,

				o1 = i1 * stride,		o0 = o1 - stride,
				oP = this._offsetPrev, 	oN = this._offsetNext,
				wP = this._weightPrev,	wN = this._weightNext,

				p = ( t - t0 ) / ( t1 - t0 ),
				pp = p * p,
				ppp = pp * p;

			// evaluate polynomials

			const sP = - wP * ppp + 2 * wP * pp - wP * p;
			const s0 = ( 1 + wP ) * ppp + ( -1.5 - 2 * wP ) * pp + ( -0.5 + wP ) * p + 1;
			const s1 = ( -1 - wN ) * ppp + ( 1.5 + wN ) * pp + 0.5 * p;
			const sN = wN * ppp - wN * pp;

			// combine data linearly

			for ( let i = 0; i !== stride; ++ i ) {

				result[ i ] =
						sP * values[ oP + i ] +
						s0 * values[ o0 + i ] +
						s1 * values[ o1 + i ] +
						sN * values[ oN + i ];

			}

			return result;

		}

	}

	/**
	 * A basic linear interpolant.
	 *
	 * @augments Interpolant
	 */
	class LinearInterpolant extends Interpolant {

		/**
		 * Constructs a new linear interpolant.
		 *
		 * @param {TypedArray} parameterPositions - The parameter positions hold the interpolation factors.
		 * @param {TypedArray} sampleValues - The sample values.
		 * @param {number} sampleSize - The sample size
		 * @param {TypedArray} [resultBuffer] - The result buffer.
		 */
		constructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {

			super( parameterPositions, sampleValues, sampleSize, resultBuffer );

		}

		interpolate_( i1, t0, t, t1 ) {

			const result = this.resultBuffer,
				values = this.sampleValues,
				stride = this.valueSize,

				offset1 = i1 * stride,
				offset0 = offset1 - stride,

				weight1 = ( t - t0 ) / ( t1 - t0 ),
				weight0 = 1 - weight1;

			for ( let i = 0; i !== stride; ++ i ) {

				result[ i ] =
						values[ offset0 + i ] * weight0 +
						values[ offset1 + i ] * weight1;

			}

			return result;

		}

	}

	/**
	 * Interpolant that evaluates to the sample value at the position preceding
	 * the parameter.
	 *
	 * @augments Interpolant
	 */
	class DiscreteInterpolant extends Interpolant {

		/**
		 * Constructs a new discrete interpolant.
		 *
		 * @param {TypedArray} parameterPositions - The parameter positions hold the interpolation factors.
		 * @param {TypedArray} sampleValues - The sample values.
		 * @param {number} sampleSize - The sample size
		 * @param {TypedArray} [resultBuffer] - The result buffer.
		 */
		constructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {

			super( parameterPositions, sampleValues, sampleSize, resultBuffer );

		}

		interpolate_( i1 /*, t0, t, t1 */ ) {

			return this.copySampleValue_( i1 - 1 );

		}

	}

	/**
	 * Represents s a timed sequence of keyframes, which are composed of lists of
	 * times and related values, and which are used to animate a specific property
	 * of an object.
	 */
	class KeyframeTrack {

		/**
		 * Constructs a new keyframe track.
		 *
		 * @param {string} name - The keyframe track's name.
		 * @param {Array<number>} times - A list of keyframe times.
		 * @param {Array<number>} values - A list of keyframe values.
		 * @param {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)} [interpolation] - The interpolation type.
		 */
		constructor( name, times, values, interpolation ) {

			if ( name === undefined ) throw new Error( 'THREE.KeyframeTrack: track name is undefined' );
			if ( times === undefined || times.length === 0 ) throw new Error( 'THREE.KeyframeTrack: no keyframes in track named ' + name );

			/**
			 * The track's name can refer to morph targets or bones or
			 * possibly other values within an animated object. See {@link PropertyBinding#parseTrackName}
			 * for the forms of strings that can be parsed for property binding.
			 *
			 * @type {string}
			 */
			this.name = name;

			/**
			 * The keyframe times.
			 *
			 * @type {Float32Array}
			 */
			this.times = convertArray( times, this.TimeBufferType );

			/**
			 * The keyframe values.
			 *
			 * @type {Float32Array}
			 */
			this.values = convertArray( values, this.ValueBufferType );

			this.setInterpolation( interpolation || this.DefaultInterpolation );

		}

		/**
		 * Converts the keyframe track to JSON.
		 *
		 * @static
		 * @param {KeyframeTrack} track - The keyframe track to serialize.
		 * @return {Object} The serialized keyframe track as JSON.
		 */
		static toJSON( track ) {

			const trackType = track.constructor;

			let json;

			// derived classes can define a static toJSON method
			if ( trackType.toJSON !== this.toJSON ) {

				json = trackType.toJSON( track );

			} else {

				// by default, we assume the data can be serialized as-is
				json = {

					'name': track.name,
					'times': convertArray( track.times, Array ),
					'values': convertArray( track.values, Array )

				};

				const interpolation = track.getInterpolation();

				if ( interpolation !== track.DefaultInterpolation ) {

					json.interpolation = interpolation;

				}

			}

			json.type = track.ValueTypeName; // mandatory

			return json;

		}

		/**
		 * Factory method for creating a new discrete interpolant.
		 *
		 * @static
		 * @param {TypedArray} [result] - The result buffer.
		 * @return {DiscreteInterpolant} The new interpolant.
		 */
		InterpolantFactoryMethodDiscrete( result ) {

			return new DiscreteInterpolant( this.times, this.values, this.getValueSize(), result );

		}

		/**
		 * Factory method for creating a new linear interpolant.
		 *
		 * @static
		 * @param {TypedArray} [result] - The result buffer.
		 * @return {LinearInterpolant} The new interpolant.
		 */
		InterpolantFactoryMethodLinear( result ) {

			return new LinearInterpolant( this.times, this.values, this.getValueSize(), result );

		}

		/**
		 * Factory method for creating a new smooth interpolant.
		 *
		 * @static
		 * @param {TypedArray} [result] - The result buffer.
		 * @return {CubicInterpolant} The new interpolant.
		 */
		InterpolantFactoryMethodSmooth( result ) {

			return new CubicInterpolant( this.times, this.values, this.getValueSize(), result );

		}

		/**
		 * Defines the interpolation factor method for this keyframe track.
		 *
		 * @param {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)} interpolation - The interpolation type.
		 * @return {KeyframeTrack} A reference to this keyframe track.
		 */
		setInterpolation( interpolation ) {

			let factoryMethod;

			switch ( interpolation ) {

				case InterpolateDiscrete:

					factoryMethod = this.InterpolantFactoryMethodDiscrete;

					break;

				case InterpolateLinear:

					factoryMethod = this.InterpolantFactoryMethodLinear;

					break;

				case InterpolateSmooth:

					factoryMethod = this.InterpolantFactoryMethodSmooth;

					break;

			}

			if ( factoryMethod === undefined ) {

				const message = 'unsupported interpolation for ' +
					this.ValueTypeName + ' keyframe track named ' + this.name;

				if ( this.createInterpolant === undefined ) {

					// fall back to default, unless the default itself is messed up
					if ( interpolation !== this.DefaultInterpolation ) {

						this.setInterpolation( this.DefaultInterpolation );

					} else {

						throw new Error( message ); // fatal, in this case

					}

				}

				console.warn( 'THREE.KeyframeTrack:', message );
				return this;

			}

			this.createInterpolant = factoryMethod;

			return this;

		}

		/**
		 * Returns the current interpolation type.
		 *
		 * @return {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)} The interpolation type.
		 */
		getInterpolation() {

			switch ( this.createInterpolant ) {

				case this.InterpolantFactoryMethodDiscrete:

					return InterpolateDiscrete;

				case this.InterpolantFactoryMethodLinear:

					return InterpolateLinear;

				case this.InterpolantFactoryMethodSmooth:

					return InterpolateSmooth;

			}

		}

		/**
		 * Returns the value size.
		 *
		 * @return {number} The value size.
		 */
		getValueSize() {

			return this.values.length / this.times.length;

		}

		/**
		 * Moves all keyframes either forward or backward in time.
		 *
		 * @param {number} timeOffset - The offset to move the time values.
		 * @return {KeyframeTrack} A reference to this keyframe track.
		 */
		shift( timeOffset ) {

			if ( timeOffset !== 0.0 ) {

				const times = this.times;

				for ( let i = 0, n = times.length; i !== n; ++ i ) {

					times[ i ] += timeOffset;

				}

			}

			return this;

		}

		/**
		 * Scale all keyframe times by a factor (useful for frame - seconds conversions).
		 *
		 * @param {number} timeScale - The time scale.
		 * @return {KeyframeTrack} A reference to this keyframe track.
		 */
		scale( timeScale ) {

			if ( timeScale !== 1.0 ) {

				const times = this.times;

				for ( let i = 0, n = times.length; i !== n; ++ i ) {

					times[ i ] *= timeScale;

				}

			}

			return this;

		}

		/**
		 * Removes keyframes before and after animation without changing any values within the defined time range.
		 *
		 * Note: The method does not shift around keys to the start of the track time, because for interpolated
		 * keys this will change their values
		 *
		 * @param {number} startTime - The start time.
		 * @param {number} endTime - The end time.
		 * @return {KeyframeTrack} A reference to this keyframe track.
		 */
		trim( startTime, endTime ) {

			const times = this.times,
				nKeys = times.length;

			let from = 0,
				to = nKeys - 1;

			while ( from !== nKeys && times[ from ] < startTime ) {

				++ from;

			}

			while ( to !== -1 && times[ to ] > endTime ) {

				-- to;

			}

			++ to; // inclusive -> exclusive bound

			if ( from !== 0 || to !== nKeys ) {

				// empty tracks are forbidden, so keep at least one keyframe
				if ( from >= to ) {

					to = Math.max( to, 1 );
					from = to - 1;

				}

				const stride = this.getValueSize();
				this.times = times.slice( from, to );
				this.values = this.values.slice( from * stride, to * stride );

			}

			return this;

		}

		/**
		 * Performs minimal validation on the keyframe track. Returns `true` if the values
		 * are valid.
		 *
		 * @return {boolean} Whether the keyframes are valid or not.
		 */
		validate() {

			let valid = true;

			const valueSize = this.getValueSize();
			if ( valueSize - Math.floor( valueSize ) !== 0 ) {

				console.error( 'THREE.KeyframeTrack: Invalid value size in track.', this );
				valid = false;

			}

			const times = this.times,
				values = this.values,

				nKeys = times.length;

			if ( nKeys === 0 ) {

				console.error( 'THREE.KeyframeTrack: Track is empty.', this );
				valid = false;

			}

			let prevTime = null;

			for ( let i = 0; i !== nKeys; i ++ ) {

				const currTime = times[ i ];

				if ( typeof currTime === 'number' && isNaN( currTime ) ) {

					console.error( 'THREE.KeyframeTrack: Time is not a valid number.', this, i, currTime );
					valid = false;
					break;

				}

				if ( prevTime !== null && prevTime > currTime ) {

					console.error( 'THREE.KeyframeTrack: Out of order keys.', this, i, currTime, prevTime );
					valid = false;
					break;

				}

				prevTime = currTime;

			}

			if ( values !== undefined ) {

				if ( isTypedArray( values ) ) {

					for ( let i = 0, n = values.length; i !== n; ++ i ) {

						const value = values[ i ];

						if ( isNaN( value ) ) {

							console.error( 'THREE.KeyframeTrack: Value is not a valid number.', this, i, value );
							valid = false;
							break;

						}

					}

				}

			}

			return valid;

		}

		/**
		 * Optimizes this keyframe track by removing equivalent sequential keys (which are
		 * common in morph target sequences).
		 *
		 * @return {AnimationClip} A reference to this animation clip.
		 */
		optimize() {

			// (0,0,0,0,1,1,1,0,0,0,0,0,0,0) --> (0,0,1,1,0,0)

			// times or values may be shared with other tracks, so overwriting is unsafe
			const times = this.times.slice(),
				values = this.values.slice(),
				stride = this.getValueSize(),

				smoothInterpolation = this.getInterpolation() === InterpolateSmooth,

				lastIndex = times.length - 1;

			let writeIndex = 1;

			for ( let i = 1; i < lastIndex; ++ i ) {

				let keep = false;

				const time = times[ i ];
				const timeNext = times[ i + 1 ];

				// remove adjacent keyframes scheduled at the same time

				if ( time !== timeNext && ( i !== 1 || time !== times[ 0 ] ) ) {

					if ( ! smoothInterpolation ) {

						// remove unnecessary keyframes same as their neighbors

						const offset = i * stride,
							offsetP = offset - stride,
							offsetN = offset + stride;

						for ( let j = 0; j !== stride; ++ j ) {

							const value = values[ offset + j ];

							if ( value !== values[ offsetP + j ] ||
								value !== values[ offsetN + j ] ) {

								keep = true;
								break;

							}

						}

					} else {

						keep = true;

					}

				}

				// in-place compaction

				if ( keep ) {

					if ( i !== writeIndex ) {

						times[ writeIndex ] = times[ i ];

						const readOffset = i * stride,
							writeOffset = writeIndex * stride;

						for ( let j = 0; j !== stride; ++ j ) {

							values[ writeOffset + j ] = values[ readOffset + j ];

						}

					}

					++ writeIndex;

				}

			}

			// flush last keyframe (compaction looks ahead)

			if ( lastIndex > 0 ) {

				times[ writeIndex ] = times[ lastIndex ];

				for ( let readOffset = lastIndex * stride, writeOffset = writeIndex * stride, j = 0; j !== stride; ++ j ) {

					values[ writeOffset + j ] = values[ readOffset + j ];

				}

				++ writeIndex;

			}

			if ( writeIndex !== times.length ) {

				this.times = times.slice( 0, writeIndex );
				this.values = values.slice( 0, writeIndex * stride );

			} else {

				this.times = times;
				this.values = values;

			}

			return this;

		}

		/**
		 * Returns a new keyframe track with copied values from this instance.
		 *
		 * @return {KeyframeTrack} A clone of this instance.
		 */
		clone() {

			const times = this.times.slice();
			const values = this.values.slice();

			const TypedKeyframeTrack = this.constructor;
			const track = new TypedKeyframeTrack( this.name, times, values );

			// Interpolant argument to constructor is not saved, so copy the factory method directly.
			track.createInterpolant = this.createInterpolant;

			return track;

		}

	}

	/**
	 * The value type name.
	 *
	 * @type {String}
	 * @default ''
	 */
	KeyframeTrack.prototype.ValueTypeName = '';

	/**
	 * The time buffer type of this keyframe track.
	 *
	 * @type {TypedArray|Array}
	 * @default Float32Array.constructor
	 */
	KeyframeTrack.prototype.TimeBufferType = Float32Array;

	/**
	 * The value buffer type of this keyframe track.
	 *
	 * @type {TypedArray|Array}
	 * @default Float32Array.constructor
	 */
	KeyframeTrack.prototype.ValueBufferType = Float32Array;

	/**
	 * The default interpolation type of this keyframe track.
	 *
	 * @type {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)}
	 * @default InterpolateLinear
	 */
	KeyframeTrack.prototype.DefaultInterpolation = InterpolateLinear;

	/**
	 * A track for boolean keyframe values.
	 *
	 * @augments KeyframeTrack
	 */
	class BooleanKeyframeTrack extends KeyframeTrack {

		/**
		 * Constructs a new boolean keyframe track.
		 *
		 * This keyframe track type has no `interpolation` parameter because the
		 * interpolation is always discrete.
		 *
		 * @param {string} name - The keyframe track's name.
		 * @param {Array<number>} times - A list of keyframe times.
		 * @param {Array<number>} values - A list of keyframe values.
		 */
		constructor( name, times, values ) {

			super( name, times, values );

		}

	}

	/**
	 * The value type name.
	 *
	 * @type {String}
	 * @default 'bool'
	 */
	BooleanKeyframeTrack.prototype.ValueTypeName = 'bool';

	/**
	 * The value buffer type of this keyframe track.
	 *
	 * @type {TypedArray|Array}
	 * @default Array.constructor
	 */
	BooleanKeyframeTrack.prototype.ValueBufferType = Array;

	/**
	 * The default interpolation type of this keyframe track.
	 *
	 * @type {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)}
	 * @default InterpolateDiscrete
	 */
	BooleanKeyframeTrack.prototype.DefaultInterpolation = InterpolateDiscrete;
	BooleanKeyframeTrack.prototype.InterpolantFactoryMethodLinear = undefined;
	BooleanKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;

	/**
	 * A track for color keyframe values.
	 *
	 * @augments KeyframeTrack
	 */
	class ColorKeyframeTrack extends KeyframeTrack {

		/**
		 * Constructs a new color keyframe track.
		 *
		 * @param {string} name - The keyframe track's name.
		 * @param {Array<number>} times - A list of keyframe times.
		 * @param {Array<number>} values - A list of keyframe values.
		 * @param {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)} [interpolation] - The interpolation type.
		 */
		constructor( name, times, values, interpolation ) {

			super( name, times, values, interpolation );

		}

	}

	/**
	 * The value type name.
	 *
	 * @type {String}
	 * @default 'color'
	 */
	ColorKeyframeTrack.prototype.ValueTypeName = 'color';

	/**
	 * A track for numeric keyframe values.
	 *
	 * @augments KeyframeTrack
	 */
	class NumberKeyframeTrack extends KeyframeTrack {

		/**
		 * Constructs a new number keyframe track.
		 *
		 * @param {string} name - The keyframe track's name.
		 * @param {Array<number>} times - A list of keyframe times.
		 * @param {Array<number>} values - A list of keyframe values.
		 * @param {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)} [interpolation] - The interpolation type.
		 */
		constructor( name, times, values, interpolation ) {

			super( name, times, values, interpolation );

		}

	}

	/**
	 * The value type name.
	 *
	 * @type {String}
	 * @default 'number'
	 */
	NumberKeyframeTrack.prototype.ValueTypeName = 'number';

	/**
	 * Spherical linear unit quaternion interpolant.
	 *
	 * @augments Interpolant
	 */
	class QuaternionLinearInterpolant extends Interpolant {

		/**
		 * Constructs a new SLERP interpolant.
		 *
		 * @param {TypedArray} parameterPositions - The parameter positions hold the interpolation factors.
		 * @param {TypedArray} sampleValues - The sample values.
		 * @param {number} sampleSize - The sample size
		 * @param {TypedArray} [resultBuffer] - The result buffer.
		 */
		constructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {

			super( parameterPositions, sampleValues, sampleSize, resultBuffer );

		}

		interpolate_( i1, t0, t, t1 ) {

			const result = this.resultBuffer,
				values = this.sampleValues,
				stride = this.valueSize,

				alpha = ( t - t0 ) / ( t1 - t0 );

			let offset = i1 * stride;

			for ( let end = offset + stride; offset !== end; offset += 4 ) {

				Quaternion.slerpFlat( result, 0, values, offset - stride, values, offset, alpha );

			}

			return result;

		}

	}

	/**
	 * A track for Quaternion keyframe values.
	 *
	 * @augments KeyframeTrack
	 */
	class QuaternionKeyframeTrack extends KeyframeTrack {

		/**
		 * Constructs a new Quaternion keyframe track.
		 *
		 * @param {string} name - The keyframe track's name.
		 * @param {Array<number>} times - A list of keyframe times.
		 * @param {Array<number>} values - A list of keyframe values.
		 * @param {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)} [interpolation] - The interpolation type.
		 */
		constructor( name, times, values, interpolation ) {

			super( name, times, values, interpolation );

		}

		/**
		 * Overwritten so the method returns Quaternion based interpolant.
		 *
		 * @static
		 * @param {TypedArray} [result] - The result buffer.
		 * @return {QuaternionLinearInterpolant} The new interpolant.
		 */
		InterpolantFactoryMethodLinear( result ) {

			return new QuaternionLinearInterpolant( this.times, this.values, this.getValueSize(), result );

		}

	}

	/**
	 * The value type name.
	 *
	 * @type {String}
	 * @default 'quaternion'
	 */
	QuaternionKeyframeTrack.prototype.ValueTypeName = 'quaternion';
	// ValueBufferType is inherited
	// DefaultInterpolation is inherited;
	QuaternionKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;

	/**
	 * A track for string keyframe values.
	 *
	 * @augments KeyframeTrack
	 */
	class StringKeyframeTrack extends KeyframeTrack {

		/**
		 * Constructs a new string keyframe track.
		 *
		 * This keyframe track type has no `interpolation` parameter because the
		 * interpolation is always discrete.
		 *
		 * @param {string} name - The keyframe track's name.
		 * @param {Array<number>} times - A list of keyframe times.
		 * @param {Array<number>} values - A list of keyframe values.
		 */
		constructor( name, times, values ) {

			super( name, times, values );

		}

	}

	/**
	 * The value type name.
	 *
	 * @type {String}
	 * @default 'string'
	 */
	StringKeyframeTrack.prototype.ValueTypeName = 'string';

	/**
	 * The value buffer type of this keyframe track.
	 *
	 * @type {TypedArray|Array}
	 * @default Array.constructor
	 */
	StringKeyframeTrack.prototype.ValueBufferType = Array;

	/**
	 * The default interpolation type of this keyframe track.
	 *
	 * @type {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)}
	 * @default InterpolateDiscrete
	 */
	StringKeyframeTrack.prototype.DefaultInterpolation = InterpolateDiscrete;
	StringKeyframeTrack.prototype.InterpolantFactoryMethodLinear = undefined;
	StringKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;

	/**
	 * A track for vector keyframe values.
	 *
	 * @augments KeyframeTrack
	 */
	class VectorKeyframeTrack extends KeyframeTrack {

		/**
		 * Constructs a new vector keyframe track.
		 *
		 * @param {string} name - The keyframe track's name.
		 * @param {Array<number>} times - A list of keyframe times.
		 * @param {Array<number>} values - A list of keyframe values.
		 * @param {(InterpolateLinear|InterpolateDiscrete|InterpolateSmooth)} [interpolation] - The interpolation type.
		 */
		constructor( name, times, values, interpolation ) {

			super( name, times, values, interpolation );

		}

	}

	/**
	 * The value type name.
	 *
	 * @type {String}
	 * @default 'vector'
	 */
	VectorKeyframeTrack.prototype.ValueTypeName = 'vector';

	/**
	 * A reusable set of keyframe tracks which represent an animation.
	 */
	class AnimationClip {

		/**
		 * Constructs a new animation clip.
		 *
		 * Note: Instead of instantiating an AnimationClip directly with the constructor, you can
		 * use the static interface of this class for creating clips. In most cases though, animation clips
		 * will automatically be created by loaders when importing animated 3D assets.
		 *
		 * @param {string} [name=''] - The clip's name.
		 * @param {number} [duration=-1] - The clip's duration in seconds. If a negative value is passed,
		 * the duration will be calculated from the passed keyframes.
		 * @param {Array<KeyframeTrack>} tracks - An array of keyframe tracks.
		 * @param {(NormalAnimationBlendMode|AdditiveAnimationBlendMode)} [blendMode=NormalAnimationBlendMode] - Defines how the animation
		 * is blended/combined when two or more animations are simultaneously played.
		 */
		constructor( name = '', duration = -1, tracks = [], blendMode = NormalAnimationBlendMode ) {

			/**
			 * The clip's name.
			 *
			 * @type {string}
			 */
			this.name = name;

			/**
			 *  An array of keyframe tracks.
			 *
			 * @type {Array<KeyframeTrack>}
			 */
			this.tracks = tracks;

			/**
			 * The clip's duration in seconds.
			 *
			 * @type {number}
			 */
			this.duration = duration;

			/**
			 * Defines how the animation is blended/combined when two or more animations
			 * are simultaneously played.
			 *
			 * @type {(NormalAnimationBlendMode|AdditiveAnimationBlendMode)}
			 */
			this.blendMode = blendMode;

			/**
			 * The UUID of the animation clip.
			 *
			 * @type {string}
			 * @readonly
			 */
			this.uuid = generateUUID();

			// this means it should figure out its duration by scanning the tracks
			if ( this.duration < 0 ) {

				this.resetDuration();

			}

		}

		/**
		 * Factory method for creating an animation clip from the given JSON.
		 *
		 * @static
		 * @param {Object} json - The serialized animation clip.
		 * @return {AnimationClip} The new animation clip.
		 */
		static parse( json ) {

			const tracks = [],
				jsonTracks = json.tracks,
				frameTime = 1.0 / ( json.fps || 1.0 );

			for ( let i = 0, n = jsonTracks.length; i !== n; ++ i ) {

				tracks.push( parseKeyframeTrack( jsonTracks[ i ] ).scale( frameTime ) );

			}

			const clip = new this( json.name, json.duration, tracks, json.blendMode );
			clip.uuid = json.uuid;

			return clip;

		}

		/**
		 * Serializes the given animation clip into JSON.
		 *
		 * @static
		 * @param {AnimationClip} clip - The animation clip to serialize.
		 * @return {Object} The JSON object.
		 */
		static toJSON( clip ) {

			const tracks = [],
				clipTracks = clip.tracks;

			const json = {

				'name': clip.name,
				'duration': clip.duration,
				'tracks': tracks,
				'uuid': clip.uuid,
				'blendMode': clip.blendMode

			};

			for ( let i = 0, n = clipTracks.length; i !== n; ++ i ) {

				tracks.push( KeyframeTrack.toJSON( clipTracks[ i ] ) );

			}

			return json;

		}

		/**
		 * Returns a new animation clip from the passed morph targets array of a
		 * geometry, taking a name and the number of frames per second.
		 *
		 * Note: The fps parameter is required, but the animation speed can be
		 * overridden via {@link AnimationAction#setDuration}.
		 *
		 * @static
		 * @param {string} name - The name of the animation clip.
		 * @param {Array<Object>} morphTargetSequence - A sequence of morph targets.
		 * @param {number} fps - The Frames-Per-Second value.
		 * @param {boolean} noLoop - Whether the clip should be no loop or not.
		 * @return {AnimationClip} The new animation clip.
		 */
		static CreateFromMorphTargetSequence( name, morphTargetSequence, fps, noLoop ) {

			const numMorphTargets = morphTargetSequence.length;
			const tracks = [];

			for ( let i = 0; i < numMorphTargets; i ++ ) {

				let times = [];
				let values = [];

				times.push(
					( i + numMorphTargets - 1 ) % numMorphTargets,
					i,
					( i + 1 ) % numMorphTargets );

				values.push( 0, 1, 0 );

				const order = getKeyframeOrder( times );
				times = sortedArray( times, 1, order );
				values = sortedArray( values, 1, order );

				// if there is a key at the first frame, duplicate it as the
				// last frame as well for perfect loop.
				if ( ! noLoop && times[ 0 ] === 0 ) {

					times.push( numMorphTargets );
					values.push( values[ 0 ] );

				}

				tracks.push(
					new NumberKeyframeTrack(
						'.morphTargetInfluences[' + morphTargetSequence[ i ].name + ']',
						times, values
					).scale( 1.0 / fps ) );

			}

			return new this( name, -1, tracks );

		}

		/**
		 * Searches for an animation clip by name, taking as its first parameter
		 * either an array of clips, or a mesh or geometry that contains an
		 * array named "animations" property.
		 *
		 * @static
		 * @param {(Array<AnimationClip>|Object3D)} objectOrClipArray - The array or object to search through.
		 * @param {string} name - The name to search for.
		 * @return {?AnimationClip} The found animation clip. Returns `null` if no clip has been found.
		 */
		static findByName( objectOrClipArray, name ) {

			let clipArray = objectOrClipArray;

			if ( ! Array.isArray( objectOrClipArray ) ) {

				const o = objectOrClipArray;
				clipArray = o.geometry && o.geometry.animations || o.animations;

			}

			for ( let i = 0; i < clipArray.length; i ++ ) {

				if ( clipArray[ i ].name === name ) {

					return clipArray[ i ];

				}

			}

			return null;

		}

		/**
		 * Returns an array of new AnimationClips created from the morph target
		 * sequences of a geometry, trying to sort morph target names into
		 * animation-group-based patterns like "Walk_001, Walk_002, Run_001, Run_002...".
		 *
		 * See {@link MD2Loader#parse} as an example for how the method should be used.
		 *
		 * @static
		 * @param {Array<Object>} morphTargets - A sequence of morph targets.
		 * @param {number} fps - The Frames-Per-Second value.
		 * @param {boolean} noLoop - Whether the clip should be no loop or not.
		 * @return {Array<AnimationClip>} An array of new animation clips.
		 */
		static CreateClipsFromMorphTargetSequences( morphTargets, fps, noLoop ) {

			const animationToMorphTargets = {};

			// tested with https://regex101.com/ on trick sequences
			// such flamingo_flyA_003, flamingo_run1_003, crdeath0059
			const pattern = /^([\w-]*?)([\d]+)$/;

			// sort morph target names into animation groups based
			// patterns like Walk_001, Walk_002, Run_001, Run_002
			for ( let i = 0, il = morphTargets.length; i < il; i ++ ) {

				const morphTarget = morphTargets[ i ];
				const parts = morphTarget.name.match( pattern );

				if ( parts && parts.length > 1 ) {

					const name = parts[ 1 ];

					let animationMorphTargets = animationToMorphTargets[ name ];

					if ( ! animationMorphTargets ) {

						animationToMorphTargets[ name ] = animationMorphTargets = [];

					}

					animationMorphTargets.push( morphTarget );

				}

			}

			const clips = [];

			for ( const name in animationToMorphTargets ) {

				clips.push( this.CreateFromMorphTargetSequence( name, animationToMorphTargets[ name ], fps, noLoop ) );

			}

			return clips;

		}

		/**
		 * Parses the `animation.hierarchy` format and returns a new animation clip.
		 *
		 * @static
		 * @deprecated since r175.
		 * @param {Object} animation - A serialized animation clip as JSON.
		 * @param {Array<Bones>} bones - An array of bones.
		 * @return {?AnimationClip} The new animation clip.
		 */
		static parseAnimation( animation, bones ) {

			console.warn( 'THREE.AnimationClip: parseAnimation() is deprecated and will be removed with r185' );

			if ( ! animation ) {

				console.error( 'THREE.AnimationClip: No animation in JSONLoader data.' );
				return null;

			}

			const addNonemptyTrack = function ( trackType, trackName, animationKeys, propertyName, destTracks ) {

				// only return track if there are actually keys.
				if ( animationKeys.length !== 0 ) {

					const times = [];
					const values = [];

					flattenJSON( animationKeys, times, values, propertyName );

					// empty keys are filtered out, so check again
					if ( times.length !== 0 ) {

						destTracks.push( new trackType( trackName, times, values ) );

					}

				}

			};

			const tracks = [];

			const clipName = animation.name || 'default';
			const fps = animation.fps || 30;
			const blendMode = animation.blendMode;

			// automatic length determination in AnimationClip.
			let duration = animation.length || -1;

			const hierarchyTracks = animation.hierarchy || [];

			for ( let h = 0; h < hierarchyTracks.length; h ++ ) {

				const animationKeys = hierarchyTracks[ h ].keys;

				// skip empty tracks
				if ( ! animationKeys || animationKeys.length === 0 ) continue;

				// process morph targets
				if ( animationKeys[ 0 ].morphTargets ) {

					// figure out all morph targets used in this track
					const morphTargetNames = {};

					let k;

					for ( k = 0; k < animationKeys.length; k ++ ) {

						if ( animationKeys[ k ].morphTargets ) {

							for ( let m = 0; m < animationKeys[ k ].morphTargets.length; m ++ ) {

								morphTargetNames[ animationKeys[ k ].morphTargets[ m ] ] = -1;

							}

						}

					}

					// create a track for each morph target with all zero
					// morphTargetInfluences except for the keys in which
					// the morphTarget is named.
					for ( const morphTargetName in morphTargetNames ) {

						const times = [];
						const values = [];

						for ( let m = 0; m !== animationKeys[ k ].morphTargets.length; ++ m ) {

							const animationKey = animationKeys[ k ];

							times.push( animationKey.time );
							values.push( ( animationKey.morphTarget === morphTargetName ) ? 1 : 0 );

						}

						tracks.push( new NumberKeyframeTrack( '.morphTargetInfluence[' + morphTargetName + ']', times, values ) );

					}

					duration = morphTargetNames.length * fps;

				} else {

					// ...assume skeletal animation

					const boneName = '.bones[' + bones[ h ].name + ']';

					addNonemptyTrack(
						VectorKeyframeTrack, boneName + '.position',
						animationKeys, 'pos', tracks );

					addNonemptyTrack(
						QuaternionKeyframeTrack, boneName + '.quaternion',
						animationKeys, 'rot', tracks );

					addNonemptyTrack(
						VectorKeyframeTrack, boneName + '.scale',
						animationKeys, 'scl', tracks );

				}

			}

			if ( tracks.length === 0 ) {

				return null;

			}

			const clip = new this( clipName, duration, tracks, blendMode );

			return clip;

		}

		/**
		 * Sets the duration of this clip to the duration of its longest keyframe track.
		 *
		 * @return {AnimationClip} A reference to this animation clip.
		 */
		resetDuration() {

			const tracks = this.tracks;
			let duration = 0;

			for ( let i = 0, n = tracks.length; i !== n; ++ i ) {

				const track = this.tracks[ i ];

				duration = Math.max( duration, track.times[ track.times.length - 1 ] );

			}

			this.duration = duration;

			return this;

		}

		/**
		 * Trims all tracks to the clip's duration.
		 *
		 * @return {AnimationClip} A reference to this animation clip.
		 */
		trim() {

			for ( let i = 0; i < this.tracks.length; i ++ ) {

				this.tracks[ i ].trim( 0, this.duration );

			}

			return this;

		}

		/**
		 * Performs minimal validation on each track in the clip. Returns `true` if all
		 * tracks are valid.
		 *
		 * @return {boolean} Whether the clip's keyframes are valid or not.
		 */
		validate() {

			let valid = true;

			for ( let i = 0; i < this.tracks.length; i ++ ) {

				valid = valid && this.tracks[ i ].validate();

			}

			return valid;

		}

		/**
		 * Optimizes each track by removing equivalent sequential keys (which are
		 * common in morph target sequences).
		 *
		 * @return {AnimationClip} A reference to this animation clip.
		 */
		optimize() {

			for ( let i = 0; i < this.tracks.length; i ++ ) {

				this.tracks[ i ].optimize();

			}

			return this;

		}

		/**
		 * Returns a new animation clip with copied values from this instance.
		 *
		 * @return {AnimationClip} A clone of this instance.
		 */
		clone() {

			const tracks = [];

			for ( let i = 0; i < this.tracks.length; i ++ ) {

				tracks.push( this.tracks[ i ].clone() );

			}

			return new this.constructor( this.name, this.duration, tracks, this.blendMode );

		}

		/**
		 * Serializes this animation clip into JSON.
		 *
		 * @return {Object} The JSON object.
		 */
		toJSON() {

			return this.constructor.toJSON( this );

		}

	}

	function getTrackTypeForValueTypeName( typeName ) {

		switch ( typeName.toLowerCase() ) {

			case 'scalar':
			case 'double':
			case 'float':
			case 'number':
			case 'integer':

				return NumberKeyframeTrack;

			case 'vector':
			case 'vector2':
			case 'vector3':
			case 'vector4':

				return VectorKeyframeTrack;

			case 'color':

				return ColorKeyframeTrack;

			case 'quaternion':

				return QuaternionKeyframeTrack;

			case 'bool':
			case 'boolean':

				return BooleanKeyframeTrack;

			case 'string':

				return StringKeyframeTrack;

		}

		throw new Error( 'THREE.KeyframeTrack: Unsupported typeName: ' + typeName );

	}

	function parseKeyframeTrack( json ) {

		if ( json.type === undefined ) {

			throw new Error( 'THREE.KeyframeTrack: track type undefined, can not parse' );

		}

		const trackType = getTrackTypeForValueTypeName( json.type );

		if ( json.times === undefined ) {

			const times = [], values = [];

			flattenJSON( json.keys, times, values, 'value' );

			json.times = times;
			json.values = values;

		}

		// derived classes can define a static parse method
		if ( trackType.parse !== undefined ) {

			return trackType.parse( json );

		} else {

			// by default, we assume a constructor compatible with the base
			return new trackType( json.name, json.times, json.values, json.interpolation );

		}

	}

	/**
	 * @class
	 * @classdesc A simple caching system, used internally by {@link FileLoader}.
	 * To enable caching across all loaders that use {@link FileLoader}, add `THREE.Cache.enabled = true.` once in your app.
	 * @hideconstructor
	 */
	const Cache = {

		/**
		 * Whether caching is enabled or not.
		 *
		 * @static
		 * @type {boolean}
		 * @default false
		 */
		enabled: false,

		/**
		 * A dictionary that holds cached files.
		 *
		 * @static
		 * @type {Object<string,Object>}
		 */
		files: {},

		/**
		 * Adds a cache entry with a key to reference the file. If this key already
		 * holds a file, it is overwritten.
		 *
		 * @static
		 * @param {string} key - The key to reference the cached file.
		 * @param {Object} file -  The file to be cached.
		 */
		add: function ( key, file ) {

			if ( this.enabled === false ) return;

			// console.log( 'THREE.Cache', 'Adding key:', key );

			this.files[ key ] = file;

		},

		/**
		 * Gets the cached value for the given key.
		 *
		 * @static
		 * @param {string} key - The key to reference the cached file.
		 * @return {Object|undefined} The cached file. If the key does not exist `undefined` is returned.
		 */
		get: function ( key ) {

			if ( this.enabled === false ) return;

			// console.log( 'THREE.Cache', 'Checking key:', key );

			return this.files[ key ];

		},

		/**
		 * Removes the cached file associated with the given key.
		 *
		 * @static
		 * @param {string} key - The key to reference the cached file.
		 */
		remove: function ( key ) {

			delete this.files[ key ];

		},

		/**
		 * Remove all values from the cache.
		 *
		 * @static
		 */
		clear: function () {

			this.files = {};

		}

	};

	/**
	 * Handles and keeps track of loaded and pending data. A default global
	 * instance of this class is created and used by loaders if not supplied
	 * manually.
	 *
	 * In general that should be sufficient, however there are times when it can
	 * be useful to have separate loaders - for example if you want to show
	 * separate loading bars for objects and textures.
	 *
	 * ```js
	 * const manager = new THREE.LoadingManager();
	 * manager.onLoad = () => console.log( 'Loading complete!' );
	 *
	 * const loader1 = new OBJLoader( manager );
	 * const loader2 = new ColladaLoader( manager );
	 * ```
	 */
	class LoadingManager {

		/**
		 * Constructs a new loading manager.
		 *
		 * @param {Function} [onLoad] - Executes when all items have been loaded.
		 * @param {Function} [onProgress] - Executes when single items have been loaded.
		 * @param {Function} [onError] - Executes when an error occurs.
		 */
		constructor( onLoad, onProgress, onError ) {

			const scope = this;

			let isLoading = false;
			let itemsLoaded = 0;
			let itemsTotal = 0;
			let urlModifier = undefined;
			const handlers = [];

			// Refer to #5689 for the reason why we don't set .onStart
			// in the constructor

			/**
			 * Executes when an item starts loading.
			 *
			 * @type {Function|undefined}
			 * @default undefined
			 */
			this.onStart = undefined;

			/**
			 * Executes when all items have been loaded.
			 *
			 * @type {Function|undefined}
			 * @default undefined
			 */
			this.onLoad = onLoad;

			/**
			 * Executes when single items have been loaded.
			 *
			 * @type {Function|undefined}
			 * @default undefined
			 */
			this.onProgress = onProgress;

			/**
			 * Executes when an error occurs.
			 *
			 * @type {Function|undefined}
			 * @default undefined
			 */
			this.onError = onError;

			/**
			 * This should be called by any loader using the manager when the loader
			 * starts loading an item.
			 *
			 * @param {string} url - The URL to load.
			 */
			this.itemStart = function ( url ) {

				itemsTotal ++;

				if ( isLoading === false ) {

					if ( scope.onStart !== undefined ) {

						scope.onStart( url, itemsLoaded, itemsTotal );

					}

				}

				isLoading = true;

			};

			/**
			 * This should be called by any loader using the manager when the loader
			 * ended loading an item.
			 *
			 * @param {string} url - The URL of the loaded item.
			 */
			this.itemEnd = function ( url ) {

				itemsLoaded ++;

				if ( scope.onProgress !== undefined ) {

					scope.onProgress( url, itemsLoaded, itemsTotal );

				}

				if ( itemsLoaded === itemsTotal ) {

					isLoading = false;

					if ( scope.onLoad !== undefined ) {

						scope.onLoad();

					}

				}

			};

			/**
			 * This should be called by any loader using the manager when the loader
			 * encounters an error when loading an item.
			 *
			 * @param {string} url - The URL of the item that produces an error.
			 */
			this.itemError = function ( url ) {

				if ( scope.onError !== undefined ) {

					scope.onError( url );

				}

			};

			/**
			 * Given a URL, uses the URL modifier callback (if any) and returns a
			 * resolved URL. If no URL modifier is set, returns the original URL.
			 *
			 * @param {string} url - The URL to load.
			 * @return {string} The resolved URL.
			 */
			this.resolveURL = function ( url ) {

				if ( urlModifier ) {

					return urlModifier( url );

				}

				return url;

			};

			/**
			 * If provided, the callback will be passed each resource URL before a
			 * request is sent. The callback may return the original URL, or a new URL to
			 * override loading behavior. This behavior can be used to load assets from
			 * .ZIP files, drag-and-drop APIs, and Data URIs.
			 *
			 * ```js
			 * const blobs = {'fish.gltf': blob1, 'diffuse.png': blob2, 'normal.png': blob3};
			 *
			 * const manager = new THREE.LoadingManager();
			 *
			 * // Initialize loading manager with URL callback.
			 * const objectURLs = [];
			 * manager.setURLModifier( ( url ) => {
			 *
			 * 	url = URL.createObjectURL( blobs[ url ] );
			 * 	objectURLs.push( url );
			 * 	return url;
			 *
			 * } );
			 *
			 * // Load as usual, then revoke the blob URLs.
			 * const loader = new GLTFLoader( manager );
			 * loader.load( 'fish.gltf', (gltf) => {
			 *
			 * 	scene.add( gltf.scene );
			 * 	objectURLs.forEach( ( url ) => URL.revokeObjectURL( url ) );
			 *
			 * } );
			 * ```
			 *
			 * @param {function(string):string} transform - URL modifier callback. Called with an URL and must return a resolved URL.
			 * @return {LoadingManager} A reference to this loading manager.
			 */
			this.setURLModifier = function ( transform ) {

				urlModifier = transform;

				return this;

			};

			/**
			 * Registers a loader with the given regular expression. Can be used to
			 * define what loader should be used in order to load specific files. A
			 * typical use case is to overwrite the default loader for textures.
			 *
			 * ```js
			 * // add handler for TGA textures
			 * manager.addHandler( /\.tga$/i, new TGALoader() );
			 * ```
			 *
			 * @param {string} regex - A regular expression.
			 * @param {Loader} loader - A loader that should handle matched cases.
			 * @return {LoadingManager} A reference to this loading manager.
			 */
			this.addHandler = function ( regex, loader ) {

				handlers.push( regex, loader );

				return this;

			};

			/**
			 * Removes the loader for the given regular expression.
			 *
			 * @param {string} regex - A regular expression.
			 * @return {LoadingManager} A reference to this loading manager.
			 */
			this.removeHandler = function ( regex ) {

				const index = handlers.indexOf( regex );

				if ( index !== -1 ) {

					handlers.splice( index, 2 );

				}

				return this;

			};

			/**
			 * Can be used to retrieve the registered loader for the given file path.
			 *
			 * @param {string} file - The file path.
			 * @return {?Loader} The registered loader. Returns `null` if no loader was found.
			 */
			this.getHandler = function ( file ) {

				for ( let i = 0, l = handlers.length; i < l; i += 2 ) {

					const regex = handlers[ i ];
					const loader = handlers[ i + 1 ];

					if ( regex.global ) regex.lastIndex = 0; // see #17920

					if ( regex.test( file ) ) {

						return loader;

					}

				}

				return null;

			};

		}

	}

	/**
	 * The global default loading manager.
	 *
	 * @constant
	 * @type {LoadingManager}
	 */
	const DefaultLoadingManager = /*@__PURE__*/ new LoadingManager();

	/**
	 * Abstract base class for loaders.
	 *
	 * @abstract
	 */
	class Loader {

		/**
		 * Constructs a new loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			/**
			 * The loading manager.
			 *
			 * @type {LoadingManager}
			 * @default DefaultLoadingManager
			 */
			this.manager = ( manager !== undefined ) ? manager : DefaultLoadingManager;

			/**
			 * The crossOrigin string to implement CORS for loading the url from a
			 * different domain that allows CORS.
			 *
			 * @type {string}
			 * @default 'anonymous'
			 */
			this.crossOrigin = 'anonymous';

			/**
			 * Whether the XMLHttpRequest uses credentials.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.withCredentials = false;

			/**
			 * The base path from which the asset will be loaded.
			 *
			 * @type {string}
			 */
			this.path = '';

			/**
			 * The base path from which additional resources like textures will be loaded.
			 *
			 * @type {string}
			 */
			this.resourcePath = '';

			/**
			 * The [request header]{@link https://developer.mozilla.org/en-US/docs/Glossary/Request_header}
			 * used in HTTP request.
			 *
			 * @type {Object<string, any>}
			 */
			this.requestHeader = {};

		}

		/**
		 * This method needs to be implemented by all concrete loaders. It holds the
		 * logic for loading assets from the backend.
		 *
		 * @param {string} url - The path/URL of the file to be loaded.
		 * @param {Function} onLoad - Executed when the loading process has been finished.
		 * @param {onProgressCallback} [onProgress] - Executed while the loading is in progress.
		 * @param {onErrorCallback} [onError] - Executed when errors occur.
		 */
		load( /* url, onLoad, onProgress, onError */ ) {}

		/**
		 * A async version of {@link Loader#load}.
		 *
		 * @param {string} url - The path/URL of the file to be loaded.
		 * @param {onProgressCallback} [onProgress] - Executed while the loading is in progress.
		 * @return {Promise} A Promise that resolves when the asset has been loaded.
		 */
		loadAsync( url, onProgress ) {

			const scope = this;

			return new Promise( function ( resolve, reject ) {

				scope.load( url, resolve, onProgress, reject );

			} );

		}

		/**
		 * This method needs to be implemented by all concrete loaders. It holds the
		 * logic for parsing the asset into three.js entities.
		 *
		 * @param {any} data - The data to parse.
		 */
		parse( /* data */ ) {}

		/**
		 * Sets the `crossOrigin` String to implement CORS for loading the URL
		 * from a different domain that allows CORS.
		 *
		 * @param {string} crossOrigin - The `crossOrigin` value.
		 * @return {Loader} A reference to this instance.
		 */
		setCrossOrigin( crossOrigin ) {

			this.crossOrigin = crossOrigin;
			return this;

		}

		/**
		 * Whether the XMLHttpRequest uses credentials such as cookies, authorization
		 * headers or TLS client certificates, see [XMLHttpRequest.withCredentials]{@link https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/withCredentials}.
		 *
		 * Note: This setting has no effect if you are loading files locally or from the same domain.
		 *
		 * @param {boolean} value - The `withCredentials` value.
		 * @return {Loader} A reference to this instance.
		 */
		setWithCredentials( value ) {

			this.withCredentials = value;
			return this;

		}

		/**
		 * Sets the base path for the asset.
		 *
		 * @param {string} path - The base path.
		 * @return {Loader} A reference to this instance.
		 */
		setPath( path ) {

			this.path = path;
			return this;

		}

		/**
		 * Sets the base path for dependent resources like textures.
		 *
		 * @param {string} resourcePath - The resource path.
		 * @return {Loader} A reference to this instance.
		 */
		setResourcePath( resourcePath ) {

			this.resourcePath = resourcePath;
			return this;

		}

		/**
		 * Sets the given request header.
		 *
		 * @param {Object} requestHeader - A [request header]{@link https://developer.mozilla.org/en-US/docs/Glossary/Request_header}
		 * for configuring the HTTP request.
		 * @return {Loader} A reference to this instance.
		 */
		setRequestHeader( requestHeader ) {

			this.requestHeader = requestHeader;
			return this;

		}

	}

	/**
	 * Callback for onProgress in loaders.
	 *
	 * @callback onProgressCallback
	 * @param {ProgressEvent} event - An instance of `ProgressEvent` that represents the current loading status.
	 */

	/**
	 * Callback for onError in loaders.
	 *
	 * @callback onErrorCallback
	 * @param {Error} error - The error which occurred during the loading process.
	 */

	/**
	 * The default material name that is used by loaders
	 * when creating materials for loaded 3D objects.
	 *
	 * Note: Not all loaders might honor this setting.
	 *
	 * @static
	 * @type {string}
	 * @default '__DEFAULT'
	 */
	Loader.DEFAULT_MATERIAL_NAME = '__DEFAULT';

	const loading = {};

	class HttpError extends Error {

		constructor( message, response ) {

			super( message );
			this.response = response;

		}

	}

	/**
	 * A low level class for loading resources with the Fetch API, used internally by
	 * most loaders. It can also be used directly to load any file type that does
	 * not have a loader.
	 *
	 * This loader supports caching. If you want to use it, add `THREE.Cache.enabled = true;`
	 * once to your application.
	 *
	 * ```js
	 * const loader = new THREE.FileLoader();
	 * const data = await loader.loadAsync( 'example.txt' );
	 * ```
	 *
	 * @augments Loader
	 */
	class FileLoader extends Loader {

		/**
		 * Constructs a new file loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			super( manager );

			/**
			 * The expected mime type.
			 *
			 * @type {string}
			 */
			this.mimeType = '';

			/**
			 * The expected response type.
			 *
			 * @type {('arraybuffer'|'blob'|'document'|'json'|'')}
			 * @default ''
			 */
			this.responseType = '';

		}

		/**
		 * Starts loading from the given URL and pass the loaded response to the `onLoad()` callback.
		 *
		 * @param {string} url - The path/URL of the file to be loaded. This can also be a data URI.
		 * @param {function(any)} onLoad - Executed when the loading process has been finished.
		 * @param {onProgressCallback} [onProgress] - Executed while the loading is in progress.
		 * @param {onErrorCallback} [onError] - Executed when errors occur.
		 * @return {any|undefined} The cached resource if available.
		 */
		load( url, onLoad, onProgress, onError ) {

			if ( url === undefined ) url = '';

			if ( this.path !== undefined ) url = this.path + url;

			url = this.manager.resolveURL( url );

			const cached = Cache.get( url );

			if ( cached !== undefined ) {

				this.manager.itemStart( url );

				setTimeout( () => {

					if ( onLoad ) onLoad( cached );

					this.manager.itemEnd( url );

				}, 0 );

				return cached;

			}

			// Check if request is duplicate

			if ( loading[ url ] !== undefined ) {

				loading[ url ].push( {

					onLoad: onLoad,
					onProgress: onProgress,
					onError: onError

				} );

				return;

			}

			// Initialise array for duplicate requests
			loading[ url ] = [];

			loading[ url ].push( {
				onLoad: onLoad,
				onProgress: onProgress,
				onError: onError,
			} );

			// create request
			const req = new Request( url, {
				headers: new Headers( this.requestHeader ),
				credentials: this.withCredentials ? 'include' : 'same-origin',
				// An abort controller could be added within a future PR
			} );

			// record states ( avoid data race )
			const mimeType = this.mimeType;
			const responseType = this.responseType;

			// start the fetch
			fetch( req )
				.then( response => {

					if ( response.status === 200 || response.status === 0 ) {

						// Some browsers return HTTP Status 0 when using non-http protocol
						// e.g. 'file://' or 'data://'. Handle as success.

						if ( response.status === 0 ) {

							console.warn( 'THREE.FileLoader: HTTP Status 0 received.' );

						}

						// Workaround: Checking if response.body === undefined for Alipay browser #23548

						if ( typeof ReadableStream === 'undefined' || response.body === undefined || response.body.getReader === undefined ) {

							return response;

						}

						const callbacks = loading[ url ];
						const reader = response.body.getReader();

						// Nginx needs X-File-Size check
						// https://serverfault.com/questions/482875/why-does-nginx-remove-content-length-header-for-chunked-content
						const contentLength = response.headers.get( 'X-File-Size' ) || response.headers.get( 'Content-Length' );
						const total = contentLength ? parseInt( contentLength ) : 0;
						const lengthComputable = total !== 0;
						let loaded = 0;

						// periodically read data into the new stream tracking while download progress
						const stream = new ReadableStream( {
							start( controller ) {

								readData();

								function readData() {

									reader.read().then( ( { done, value } ) => {

										if ( done ) {

											controller.close();

										} else {

											loaded += value.byteLength;

											const event = new ProgressEvent( 'progress', { lengthComputable, loaded, total } );
											for ( let i = 0, il = callbacks.length; i < il; i ++ ) {

												const callback = callbacks[ i ];
												if ( callback.onProgress ) callback.onProgress( event );

											}

											controller.enqueue( value );
											readData();

										}

									}, ( e ) => {

										controller.error( e );

									} );

								}

							}

						} );

						return new Response( stream );

					} else {

						throw new HttpError( `fetch for "${response.url}" responded with ${response.status}: ${response.statusText}`, response );

					}

				} )
				.then( response => {

					switch ( responseType ) {

						case 'arraybuffer':

							return response.arrayBuffer();

						case 'blob':

							return response.blob();

						case 'document':

							return response.text()
								.then( text => {

									const parser = new DOMParser();
									return parser.parseFromString( text, mimeType );

								} );

						case 'json':

							return response.json();

						default:

							if ( mimeType === '' ) {

								return response.text();

							} else {

								// sniff encoding
								const re = /charset="?([^;"\s]*)"?/i;
								const exec = re.exec( mimeType );
								const label = exec && exec[ 1 ] ? exec[ 1 ].toLowerCase() : undefined;
								const decoder = new TextDecoder( label );
								return response.arrayBuffer().then( ab => decoder.decode( ab ) );

							}

					}

				} )
				.then( data => {

					// Add to cache only on HTTP success, so that we do not cache
					// error response bodies as proper responses to requests.
					Cache.add( url, data );

					const callbacks = loading[ url ];
					delete loading[ url ];

					for ( let i = 0, il = callbacks.length; i < il; i ++ ) {

						const callback = callbacks[ i ];
						if ( callback.onLoad ) callback.onLoad( data );

					}

				} )
				.catch( err => {

					// Abort errors and other errors are handled the same

					const callbacks = loading[ url ];

					if ( callbacks === undefined ) {

						// When onLoad was called and url was deleted in `loading`
						this.manager.itemError( url );
						throw err;

					}

					delete loading[ url ];

					for ( let i = 0, il = callbacks.length; i < il; i ++ ) {

						const callback = callbacks[ i ];
						if ( callback.onError ) callback.onError( err );

					}

					this.manager.itemError( url );

				} )
				.finally( () => {

					this.manager.itemEnd( url );

				} );

			this.manager.itemStart( url );

		}

		/**
		 * Sets the expected response type.
		 *
		 * @param {('arraybuffer'|'blob'|'document'|'json'|'')} value - The response type.
		 * @return {FileLoader} A reference to this file loader.
		 */
		setResponseType( value ) {

			this.responseType = value;
			return this;

		}

		/**
		 * Sets the expected mime type of the loaded file.
		 *
		 * @param {string} value - The mime type.
		 * @return {FileLoader} A reference to this file loader.
		 */
		setMimeType( value ) {

			this.mimeType = value;
			return this;

		}

	}

	/**
	 * A loader for loading images. The class loads images with the HTML `Image` API.
	 *
	 * ```js
	 * const loader = new THREE.ImageLoader();
	 * const image = await loader.loadAsync( 'image.png' );
	 * ```
	 * Please note that `ImageLoader` has dropped support for progress
	 * events in `r84`. For an `ImageLoader` that supports progress events, see
	 * [this thread]{@link https://github.com/mrdoob/three.js/issues/10439#issuecomment-275785639}.
	 *
	 * @augments Loader
	 */
	class ImageLoader extends Loader {

		/**
		 * Constructs a new image loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			super( manager );

		}

		/**
		 * Starts loading from the given URL and passes the loaded image
		 * to the `onLoad()` callback. The method also returns a new `Image` object which can
		 * directly be used for texture creation. If you do it this way, the texture
		 * may pop up in your scene once the respective loading process is finished.
		 *
		 * @param {string} url - The path/URL of the file to be loaded. This can also be a data URI.
		 * @param {function(Image)} onLoad - Executed when the loading process has been finished.
		 * @param {onProgressCallback} onProgress - Unsupported in this loader.
		 * @param {onErrorCallback} onError - Executed when errors occur.
		 * @return {Image} The image.
		 */
		load( url, onLoad, onProgress, onError ) {

			if ( this.path !== undefined ) url = this.path + url;

			url = this.manager.resolveURL( url );

			const scope = this;

			const cached = Cache.get( url );

			if ( cached !== undefined ) {

				scope.manager.itemStart( url );

				setTimeout( function () {

					if ( onLoad ) onLoad( cached );

					scope.manager.itemEnd( url );

				}, 0 );

				return cached;

			}

			const image = createElementNS( 'img' );

			function onImageLoad() {

				removeEventListeners();

				Cache.add( url, this );

				if ( onLoad ) onLoad( this );

				scope.manager.itemEnd( url );

			}

			function onImageError( event ) {

				removeEventListeners();

				if ( onError ) onError( event );

				scope.manager.itemError( url );
				scope.manager.itemEnd( url );

			}

			function removeEventListeners() {

				image.removeEventListener( 'load', onImageLoad, false );
				image.removeEventListener( 'error', onImageError, false );

			}

			image.addEventListener( 'load', onImageLoad, false );
			image.addEventListener( 'error', onImageError, false );

			if ( url.slice( 0, 5 ) !== 'data:' ) {

				if ( this.crossOrigin !== undefined ) image.crossOrigin = this.crossOrigin;

			}

			scope.manager.itemStart( url );

			image.src = url;

			return image;

		}

	}

	/**
	 * Abstract base class for loading binary texture formats RGBE, EXR or TGA.
	 * Textures are internally loaded via {@link FileLoader}.
	 *
	 * Derived classes have to implement the `parse()` method which holds the parsing
	 * for the respective format.
	 *
	 * @abstract
	 * @augments Loader
	 */
	class DataTextureLoader extends Loader {

		/**
		 * Constructs a new data texture loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			super( manager );

		}

		/**
		 * Starts loading from the given URL and passes the loaded data texture
		 * to the `onLoad()` callback. The method also returns a new texture object which can
		 * directly be used for material creation. If you do it this way, the texture
		 * may pop up in your scene once the respective loading process is finished.
		 *
		 * @param {string} url - The path/URL of the file to be loaded. This can also be a data URI.
		 * @param {function(DataTexture)} onLoad - Executed when the loading process has been finished.
		 * @param {onProgressCallback} onProgress - Executed while the loading is in progress.
		 * @param {onErrorCallback} onError - Executed when errors occur.
		 * @return {DataTexture} The data texture.
		 */
		load( url, onLoad, onProgress, onError ) {

			const scope = this;

			const texture = new DataTexture();

			const loader = new FileLoader( this.manager );
			loader.setResponseType( 'arraybuffer' );
			loader.setRequestHeader( this.requestHeader );
			loader.setPath( this.path );
			loader.setWithCredentials( scope.withCredentials );
			loader.load( url, function ( buffer ) {

				let texData;

				try {

					texData = scope.parse( buffer );

				} catch ( error ) {

					if ( onError !== undefined ) {

						onError( error );

					} else {

						console.error( error );
						return;

					}

				}

				if ( texData.image !== undefined ) {

					texture.image = texData.image;

				} else if ( texData.data !== undefined ) {

					texture.image.width = texData.width;
					texture.image.height = texData.height;
					texture.image.data = texData.data;

				}

				texture.wrapS = texData.wrapS !== undefined ? texData.wrapS : ClampToEdgeWrapping;
				texture.wrapT = texData.wrapT !== undefined ? texData.wrapT : ClampToEdgeWrapping;

				texture.magFilter = texData.magFilter !== undefined ? texData.magFilter : LinearFilter;
				texture.minFilter = texData.minFilter !== undefined ? texData.minFilter : LinearFilter;

				texture.anisotropy = texData.anisotropy !== undefined ? texData.anisotropy : 1;

				if ( texData.colorSpace !== undefined ) {

					texture.colorSpace = texData.colorSpace;

				}

				if ( texData.flipY !== undefined ) {

					texture.flipY = texData.flipY;

				}

				if ( texData.format !== undefined ) {

					texture.format = texData.format;

				}

				if ( texData.type !== undefined ) {

					texture.type = texData.type;

				}

				if ( texData.mipmaps !== undefined ) {

					texture.mipmaps = texData.mipmaps;
					texture.minFilter = LinearMipmapLinearFilter; // presumably...

				}

				if ( texData.mipmapCount === 1 ) {

					texture.minFilter = LinearFilter;

				}

				if ( texData.generateMipmaps !== undefined ) {

					texture.generateMipmaps = texData.generateMipmaps;

				}

				texture.needsUpdate = true;

				if ( onLoad ) onLoad( texture, texData );

			}, onProgress, onError );


			return texture;

		}

	}

	/**
	 * Class for loading textures. Images are internally
	 * loaded via {@link ImageLoader}.
	 *
	 * ```js
	 * const loader = new THREE.TextureLoader();
	 * const texture = await loader.loadAsync( 'textures/land_ocean_ice_cloud_2048.jpg' );
	 *
	 * const material = new THREE.MeshBasicMaterial( { map:texture } );
	 * ```
	 * Please note that `TextureLoader` has dropped support for progress
	 * events in `r84`. For a `TextureLoader` that supports progress events, see
	 * [this thread]{@link https://github.com/mrdoob/three.js/issues/10439#issuecomment-293260145}.
	 *
	 * @augments Loader
	 */
	class TextureLoader extends Loader {

		/**
		 * Constructs a new texture loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			super( manager );

		}

		/**
		 * Starts loading from the given URL and pass the fully loaded texture
		 * to the `onLoad()` callback. The method also returns a new texture object which can
		 * directly be used for material creation. If you do it this way, the texture
		 * may pop up in your scene once the respective loading process is finished.
		 *
		 * @param {string} url - The path/URL of the file to be loaded. This can also be a data URI.
		 * @param {function(Texture)} onLoad - Executed when the loading process has been finished.
		 * @param {onProgressCallback} onProgress - Unsupported in this loader.
		 * @param {onErrorCallback} onError - Executed when errors occur.
		 * @return {Texture} The texture.
		 */
		load( url, onLoad, onProgress, onError ) {

			const texture = new Texture();

			const loader = new ImageLoader( this.manager );
			loader.setCrossOrigin( this.crossOrigin );
			loader.setPath( this.path );

			loader.load( url, function ( image ) {

				texture.image = image;
				texture.needsUpdate = true;

				if ( onLoad !== undefined ) {

					onLoad( texture );

				}

			}, onProgress, onError );

			return texture;

		}

	}

	/**
	 * Abstract base class for lights - all other light types inherit the
	 * properties and methods described here.
	 *
	 * @abstract
	 * @augments Object3D
	 */
	class Light extends Object3D {

		/**
		 * Constructs a new light.
		 *
		 * @param {(number|Color|string)} [color=0xffffff] - The light's color.
		 * @param {number} [intensity=1] - The light's strength/intensity.
		 */
		constructor( color, intensity = 1 ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLight = true;

			this.type = 'Light';

			/**
			 * The light's color.
			 *
			 * @type {Color}
			 */
			this.color = new Color( color );

			/**
			 * The light's intensity.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.intensity = intensity;

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 */
		dispose() {

			// Empty here in base class; some subclasses override.

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.color.copy( source.color );
			this.intensity = source.intensity;

			return this;

		}

		toJSON( meta ) {

			const data = super.toJSON( meta );

			data.object.color = this.color.getHex();
			data.object.intensity = this.intensity;

			if ( this.groundColor !== undefined ) data.object.groundColor = this.groundColor.getHex();

			if ( this.distance !== undefined ) data.object.distance = this.distance;
			if ( this.angle !== undefined ) data.object.angle = this.angle;
			if ( this.decay !== undefined ) data.object.decay = this.decay;
			if ( this.penumbra !== undefined ) data.object.penumbra = this.penumbra;

			if ( this.shadow !== undefined ) data.object.shadow = this.shadow.toJSON();
			if ( this.target !== undefined ) data.object.target = this.target.uuid;

			return data;

		}

	}

	/**
	 * A light source positioned directly above the scene, with color fading from
	 * the sky color to the ground color.
	 *
	 * This light cannot be used to cast shadows.
	 *
	 * ```js
	 * const light = new THREE.HemisphereLight( 0xffffbb, 0x080820, 1 );
	 * scene.add( light );
	 * ```
	 *
	 * @augments Light
	 */
	class HemisphereLight extends Light {

		/**
		 * Constructs a new hemisphere light.
		 *
		 * @param {(number|Color|string)} [skyColor=0xffffff] - The light's sky color.
		 * @param {(number|Color|string)} [groundColor=0xffffff] - The light's ground color.
		 * @param {number} [intensity=1] - The light's strength/intensity.
		 */
		constructor( skyColor, groundColor, intensity ) {

			super( skyColor, intensity );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isHemisphereLight = true;

			this.type = 'HemisphereLight';

			this.position.copy( Object3D.DEFAULT_UP );
			this.updateMatrix();

			/**
			 * The light's ground color.
			 *
			 * @type {Color}
			 */
			this.groundColor = new Color( groundColor );

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.groundColor.copy( source.groundColor );

			return this;

		}

	}

	const _projScreenMatrix$1 = /*@__PURE__*/ new Matrix4();
	const _lightPositionWorld$1 = /*@__PURE__*/ new Vector3();
	const _lookTarget$1 = /*@__PURE__*/ new Vector3();

	/**
	 * Abstract base class for light shadow classes. These classes
	 * represent the shadow configuration for different light types.
	 *
	 * @abstract
	 */
	class LightShadow {

		/**
		 * Constructs a new light shadow.
		 *
		 * @param {Camera} camera - The light's view of the world.
		 */
		constructor( camera ) {

			/**
			 * The light's view of the world.
			 *
			 * @type {Camera}
			 */
			this.camera = camera;

			/**
			 * The intensity of the shadow. The default is `1`.
			 * Valid values are in the range `[0, 1]`.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.intensity = 1;

			/**
			 * Shadow map bias, how much to add or subtract from the normalized depth
			 * when deciding whether a surface is in shadow.
			 *
			 * The default is `0`. Very tiny adjustments here (in the order of `0.0001`)
			 * may help reduce artifacts in shadows.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.bias = 0;

			/**
			 * Defines how much the position used to query the shadow map is offset along
			 * the object normal. The default is `0`. Increasing this value can be used to
			 * reduce shadow acne especially in large scenes where light shines onto
			 * geometry at a shallow angle. The cost is that shadows may appear distorted.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.normalBias = 0;

			/**
			 * Setting this to values greater than 1 will blur the edges of the shadow.
			 * High values will cause unwanted banding effects in the shadows - a greater
			 * map size will allow for a higher value to be used here before these effects
			 * become visible.
			 *
			 * The property has no effect when the shadow map type is `PCFSoftShadowMap` and
			 * and it is recommended to increase softness by decreasing the shadow map size instead.
			 *
			 * The property has no effect when the shadow map type is `BasicShadowMap`.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.radius = 1;

			/**
			 * The amount of samples to use when blurring a VSM shadow map.
			 *
			 * @type {number}
			 * @default 8
			 */
			this.blurSamples = 8;

			/**
			 * Defines the width and height of the shadow map. Higher values give better quality
			 * shadows at the cost of computation time. Values must be powers of two.
			 *
			 * @type {Vector2}
			 * @default (512,512)
			 */
			this.mapSize = new Vector2( 512, 512 );

			/**
			 * The type of shadow texture. The default is `UnsignedByteType`.
			 *
			 * @type {number}
			 * @default UnsignedByteType
			 */
			this.mapType = UnsignedByteType;

			/**
			 * The depth map generated using the internal camera; a location beyond a
			 * pixel's depth is in shadow. Computed internally during rendering.
			 *
			 * @type {?RenderTarget}
			 * @default null
			 */
			this.map = null;

			/**
			 * The distribution map generated using the internal camera; an occlusion is
			 * calculated based on the distribution of depths. Computed internally during
			 * rendering.
			 *
			 * @type {?RenderTarget}
			 * @default null
			 */
			this.mapPass = null;

			/**
			 * Model to shadow camera space, to compute location and depth in shadow map.
			 * This is computed internally during rendering.
			 *
			 * @type {Matrix4}
			 */
			this.matrix = new Matrix4();

			/**
			 * Enables automatic updates of the light's shadow. If you do not require dynamic
			 * lighting / shadows, you may set this to `false`.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.autoUpdate = true;

			/**
			 * When set to `true`, shadow maps will be updated in the next `render` call.
			 * If you have set {@link LightShadow#autoUpdate} to `false`, you will need to
			 * set this property to `true` and then make a render call to update the light's shadow.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.needsUpdate = false;

			this._frustum = new Frustum();
			this._frameExtents = new Vector2( 1, 1 );

			this._viewportCount = 1;

			this._viewports = [

				new Vector4( 0, 0, 1, 1 )

			];

		}

		/**
		 * Used internally by the renderer to get the number of viewports that need
		 * to be rendered for this shadow.
		 *
		 * @return {number} The viewport count.
		 */
		getViewportCount() {

			return this._viewportCount;

		}

		/**
		 * Gets the shadow cameras frustum. Used internally by the renderer to cull objects.
		 *
		 * @return {Frustum} The shadow camera frustum.
		 */
		getFrustum() {

			return this._frustum;

		}

		/**
		 * Update the matrices for the camera and shadow, used internally by the renderer.
		 *
		 * @param {Light} light - The light for which the shadow is being rendered.
		 */
		updateMatrices( light ) {

			const shadowCamera = this.camera;
			const shadowMatrix = this.matrix;

			_lightPositionWorld$1.setFromMatrixPosition( light.matrixWorld );
			shadowCamera.position.copy( _lightPositionWorld$1 );

			_lookTarget$1.setFromMatrixPosition( light.target.matrixWorld );
			shadowCamera.lookAt( _lookTarget$1 );
			shadowCamera.updateMatrixWorld();

			_projScreenMatrix$1.multiplyMatrices( shadowCamera.projectionMatrix, shadowCamera.matrixWorldInverse );
			this._frustum.setFromProjectionMatrix( _projScreenMatrix$1 );

			shadowMatrix.set(
				0.5, 0.0, 0.0, 0.5,
				0.0, 0.5, 0.0, 0.5,
				0.0, 0.0, 0.5, 0.5,
				0.0, 0.0, 0.0, 1.0
			);

			shadowMatrix.multiply( _projScreenMatrix$1 );

		}

		/**
		 * Returns a viewport definition for the given viewport index.
		 *
		 * @param {number} viewportIndex - The viewport index.
		 * @return {Vector4} The viewport.
		 */
		getViewport( viewportIndex ) {

			return this._viewports[ viewportIndex ];

		}

		/**
		 * Returns the frame extends.
		 *
		 * @return {Vector2} The frame extends.
		 */
		getFrameExtents() {

			return this._frameExtents;

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 */
		dispose() {

			if ( this.map ) {

				this.map.dispose();

			}

			if ( this.mapPass ) {

				this.mapPass.dispose();

			}

		}

		/**
		 * Copies the values of the given light shadow instance to this instance.
		 *
		 * @param {LightShadow} source - The light shadow to copy.
		 * @return {LightShadow} A reference to this light shadow instance.
		 */
		copy( source ) {

			this.camera = source.camera.clone();

			this.intensity = source.intensity;

			this.bias = source.bias;
			this.radius = source.radius;

			this.autoUpdate = source.autoUpdate;
			this.needsUpdate = source.needsUpdate;
			this.normalBias = source.normalBias;
			this.blurSamples = source.blurSamples;

			this.mapSize.copy( source.mapSize );

			return this;

		}

		/**
		 * Returns a new light shadow instance with copied values from this instance.
		 *
		 * @return {LightShadow} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

		/**
		 * Serializes the light shadow into JSON.
		 *
		 * @return {Object} A JSON object representing the serialized light shadow.
		 * @see {@link ObjectLoader#parse}
		 */
		toJSON() {

			const object = {};

			if ( this.intensity !== 1 ) object.intensity = this.intensity;
			if ( this.bias !== 0 ) object.bias = this.bias;
			if ( this.normalBias !== 0 ) object.normalBias = this.normalBias;
			if ( this.radius !== 1 ) object.radius = this.radius;
			if ( this.mapSize.x !== 512 || this.mapSize.y !== 512 ) object.mapSize = this.mapSize.toArray();

			object.camera = this.camera.toJSON( false ).object;
			delete object.camera.matrix;

			return object;

		}

	}

	/**
	 * Represents the shadow configuration of directional lights.
	 *
	 * @augments LightShadow
	 */
	class SpotLightShadow extends LightShadow {

		/**
		 * Constructs a new spot light shadow.
		 */
		constructor() {

			super( new PerspectiveCamera( 50, 1, 0.5, 500 ) );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isSpotLightShadow = true;

			/**
			 * Used to focus the shadow camera. The camera's field of view is set as a
			 * percentage of the spotlight's field-of-view. Range is `[0, 1]`.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.focus = 1;

			/**
			 * Texture aspect ratio.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.aspect = 1;

		}

		updateMatrices( light ) {

			const camera = this.camera;

			const fov = RAD2DEG * 2 * light.angle * this.focus;
			const aspect = ( this.mapSize.width / this.mapSize.height ) * this.aspect;
			const far = light.distance || camera.far;

			if ( fov !== camera.fov || aspect !== camera.aspect || far !== camera.far ) {

				camera.fov = fov;
				camera.aspect = aspect;
				camera.far = far;
				camera.updateProjectionMatrix();

			}

			super.updateMatrices( light );

		}

		copy( source ) {

			super.copy( source );

			this.focus = source.focus;

			return this;

		}

	}

	/**
	 * This light gets emitted from a single point in one direction, along a cone
	 * that increases in size the further from the light it gets.
	 *
	 * This light can cast shadows - see the {@link SpotLightShadow} for details.
	 *
	 * ```js
	 * // white spotlight shining from the side, modulated by a texture
	 * const spotLight = new THREE.SpotLight( 0xffffff );
	 * spotLight.position.set( 100, 1000, 100 );
	 * spotLight.map = new THREE.TextureLoader().load( url );
	 *
	 * spotLight.castShadow = true;
	 * spotLight.shadow.mapSize.width = 1024;
	 * spotLight.shadow.mapSize.height = 1024;
	 * spotLight.shadow.camera.near = 500;
	 * spotLight.shadow.camera.far = 4000;
	 * spotLight.shadow.camera.fov = 30;s
	 * ```
	 *
	 * @augments Light
	 */
	class SpotLight extends Light {

		/**
		 * Constructs a new spot light.
		 *
		 * @param {(number|Color|string)} [color=0xffffff] - The light's color.
		 * @param {number} [intensity=1] - The light's strength/intensity measured in candela (cd).
		 * @param {number} [distance=0] - Maximum range of the light. `0` means no limit.
		 * @param {number} [angle=Math.PI/3] - Maximum angle of light dispersion from its direction whose upper bound is `Math.PI/2`.
		 * @param {number} [penumbra=0] - Percent of the spotlight cone that is attenuated due to penumbra. Value range is `[0,1]`.
		 * @param {number} [decay=2] - The amount the light dims along the distance of the light.
		 */
		constructor( color, intensity, distance = 0, angle = Math.PI / 3, penumbra = 0, decay = 2 ) {

			super( color, intensity );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isSpotLight = true;

			this.type = 'SpotLight';

			this.position.copy( Object3D.DEFAULT_UP );
			this.updateMatrix();

			/**
			 * The spot light points from its position to the
			 * target's position.
			 *
			 * For the target's position to be changed to anything other
			 * than the default, it must be added to the scene.
			 *
			 * It is also possible to set the target to be another 3D object
			 * in the scene. The light will now track the target object.
			 *
			 * @type {Object3D}
			 */
			this.target = new Object3D();

			/**
			 * Maximum range of the light. `0` means no limit.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.distance = distance;

			/**
			 * Maximum angle of light dispersion from its direction whose upper bound is `Math.PI/2`.
			 *
			 * @type {number}
			 * @default Math.PI/3
			 */
			this.angle = angle;

			/**
			 * Percent of the spotlight cone that is attenuated due to penumbra.
			 * Value range is `[0,1]`.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.penumbra = penumbra;

			/**
			 * The amount the light dims along the distance of the light. In context of
			 * physically-correct rendering the default value should not be changed.
			 *
			 * @type {number}
			 * @default 2
			 */
			this.decay = decay;

			/**
			 * A texture used to modulate the color of the light. The spot light
			 * color is mixed with the RGB value of this texture, with a ratio
			 * corresponding to its alpha value. The cookie-like masking effect is
			 * reproduced using pixel values (0, 0, 0, 1-cookie_value).
			 *
			 * *Warning*: This property is disabled if {@link Object3D#castShadow} is set to `false`.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.map = null;

			/**
			 * This property holds the light's shadow configuration.
			 *
			 * @type {SpotLightShadow}
			 */
			this.shadow = new SpotLightShadow();

		}

		/**
		 * The light's power. Power is the luminous power of the light measured in lumens (lm).
		 *  Changing the power will also change the light's intensity.
		 *
		 * @type {number}
		 */
		get power() {

			// compute the light's luminous power (in lumens) from its intensity (in candela)
			// by convention for a spotlight, luminous power (lm) = π * luminous intensity (cd)
			return this.intensity * Math.PI;

		}

		set power( power ) {

			// set the light's intensity (in candela) from the desired luminous power (in lumens)
			this.intensity = power / Math.PI;

		}

		dispose() {

			this.shadow.dispose();

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.distance = source.distance;
			this.angle = source.angle;
			this.penumbra = source.penumbra;
			this.decay = source.decay;

			this.target = source.target.clone();

			this.shadow = source.shadow.clone();

			return this;

		}

	}

	const _projScreenMatrix = /*@__PURE__*/ new Matrix4();
	const _lightPositionWorld = /*@__PURE__*/ new Vector3();
	const _lookTarget = /*@__PURE__*/ new Vector3();

	/**
	 * Represents the shadow configuration of point lights.
	 *
	 * @augments LightShadow
	 */
	class PointLightShadow extends LightShadow {

		/**
		 * Constructs a new point light shadow.
		 */
		constructor() {

			super( new PerspectiveCamera( 90, 1, 0.5, 500 ) );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isPointLightShadow = true;

			this._frameExtents = new Vector2( 4, 2 );

			this._viewportCount = 6;

			this._viewports = [
				// These viewports map a cube-map onto a 2D texture with the
				// following orientation:
				//
				//  xzXZ
				//   y Y
				//
				// X - Positive x direction
				// x - Negative x direction
				// Y - Positive y direction
				// y - Negative y direction
				// Z - Positive z direction
				// z - Negative z direction

				// positive X
				new Vector4( 2, 1, 1, 1 ),
				// negative X
				new Vector4( 0, 1, 1, 1 ),
				// positive Z
				new Vector4( 3, 1, 1, 1 ),
				// negative Z
				new Vector4( 1, 1, 1, 1 ),
				// positive Y
				new Vector4( 3, 0, 1, 1 ),
				// negative Y
				new Vector4( 1, 0, 1, 1 )
			];

			this._cubeDirections = [
				new Vector3( 1, 0, 0 ), new Vector3( -1, 0, 0 ), new Vector3( 0, 0, 1 ),
				new Vector3( 0, 0, -1 ), new Vector3( 0, 1, 0 ), new Vector3( 0, -1, 0 )
			];

			this._cubeUps = [
				new Vector3( 0, 1, 0 ), new Vector3( 0, 1, 0 ), new Vector3( 0, 1, 0 ),
				new Vector3( 0, 1, 0 ), new Vector3( 0, 0, 1 ),	new Vector3( 0, 0, -1 )
			];

		}

		/**
		 * Update the matrices for the camera and shadow, used internally by the renderer.
		 *
		 * @param {Light} light - The light for which the shadow is being rendered.
		 * @param {number} [viewportIndex=0] - The viewport index.
		 */
		updateMatrices( light, viewportIndex = 0 ) {

			const camera = this.camera;
			const shadowMatrix = this.matrix;

			const far = light.distance || camera.far;

			if ( far !== camera.far ) {

				camera.far = far;
				camera.updateProjectionMatrix();

			}

			_lightPositionWorld.setFromMatrixPosition( light.matrixWorld );
			camera.position.copy( _lightPositionWorld );

			_lookTarget.copy( camera.position );
			_lookTarget.add( this._cubeDirections[ viewportIndex ] );
			camera.up.copy( this._cubeUps[ viewportIndex ] );
			camera.lookAt( _lookTarget );
			camera.updateMatrixWorld();

			shadowMatrix.makeTranslation( - _lightPositionWorld.x, - _lightPositionWorld.y, - _lightPositionWorld.z );

			_projScreenMatrix.multiplyMatrices( camera.projectionMatrix, camera.matrixWorldInverse );
			this._frustum.setFromProjectionMatrix( _projScreenMatrix );

		}

	}

	/**
	 * A light that gets emitted from a single point in all directions. A common
	 * use case for this is to replicate the light emitted from a bare
	 * lightbulb.
	 *
	 * This light can cast shadows - see the {@link PointLightShadow} for details.
	 *
	 * ```js
	 * const light = new THREE.PointLight( 0xff0000, 1, 100 );
	 * light.position.set( 50, 50, 50 );
	 * scene.add( light );
	 * ```
	 *
	 * @augments Light
	 */
	class PointLight extends Light {

		/**
		 * Constructs a new point light.
		 *
		 * @param {(number|Color|string)} [color=0xffffff] - The light's color.
		 * @param {number} [intensity=1] - The light's strength/intensity measured in candela (cd).
		 * @param {number} [distance=0] - Maximum range of the light. `0` means no limit.
		 * @param {number} [decay=2] - The amount the light dims along the distance of the light.
		 */
		constructor( color, intensity, distance = 0, decay = 2 ) {

			super( color, intensity );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isPointLight = true;

			this.type = 'PointLight';

			/**
			 * When distance is zero, light will attenuate according to inverse-square
			 * law to infinite distance. When distance is non-zero, light will attenuate
			 * according to inverse-square law until near the distance cutoff, where it
			 * will then attenuate quickly and smoothly to 0. Inherently, cutoffs are not
			 * physically correct.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.distance = distance;

			/**
			 * The amount the light dims along the distance of the light. In context of
			 * physically-correct rendering the default value should not be changed.
			 *
			 * @type {number}
			 * @default 2
			 */
			this.decay = decay;

			/**
			 * This property holds the light's shadow configuration.
			 *
			 * @type {PointLightShadow}
			 */
			this.shadow = new PointLightShadow();

		}

		/**
		 * The light's power. Power is the luminous power of the light measured in lumens (lm).
		 * Changing the power will also change the light's intensity.
		 *
		 * @type {number}
		 */
		get power() {

			// compute the light's luminous power (in lumens) from its intensity (in candela)
			// for an isotropic light source, luminous power (lm) = 4 π luminous intensity (cd)
			return this.intensity * 4 * Math.PI;

		}

		set power( power ) {

			// set the light's intensity (in candela) from the desired luminous power (in lumens)
			this.intensity = power / ( 4 * Math.PI );

		}

		dispose() {

			this.shadow.dispose();

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.distance = source.distance;
			this.decay = source.decay;

			this.shadow = source.shadow.clone();

			return this;

		}

	}

	/**
	 * Camera that uses [orthographic projection]{@link https://en.wikipedia.org/wiki/Orthographic_projection}.
	 *
	 * In this projection mode, an object's size in the rendered image stays
	 * constant regardless of its distance from the camera. This can be useful
	 * for rendering 2D scenes and UI elements, amongst other things.
	 *
	 * ```js
	 * const camera = new THREE.OrthographicCamera( width / - 2, width / 2, height / 2, height / - 2, 1, 1000 );
	 * scene.add( camera );
	 * ```
	 *
	 * @augments Camera
	 */
	class OrthographicCamera extends Camera {

		/**
		 * Constructs a new orthographic camera.
		 *
		 * @param {number} [left=-1] - The left plane of the camera's frustum.
		 * @param {number} [right=1] - The right plane of the camera's frustum.
		 * @param {number} [top=1] - The top plane of the camera's frustum.
		 * @param {number} [bottom=-1] - The bottom plane of the camera's frustum.
		 * @param {number} [near=0.1] - The camera's near plane.
		 * @param {number} [far=2000] - The camera's far plane.
		 */
		constructor( left = -1, right = 1, top = 1, bottom = -1, near = 0.1, far = 2000 ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isOrthographicCamera = true;

			this.type = 'OrthographicCamera';

			/**
			 * The zoom factor of the camera.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.zoom = 1;

			/**
			 * Represents the frustum window specification. This property should not be edited
			 * directly but via {@link PerspectiveCamera#setViewOffset} and {@link PerspectiveCamera#clearViewOffset}.
			 *
			 * @type {?Object}
			 * @default null
			 */
			this.view = null;

			/**
			 * The left plane of the camera's frustum.
			 *
			 * @type {number}
			 * @default -1
			 */
			this.left = left;

			/**
			 * The right plane of the camera's frustum.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.right = right;

			/**
			 * The top plane of the camera's frustum.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.top = top;

			/**
			 * The bottom plane of the camera's frustum.
			 *
			 * @type {number}
			 * @default -1
			 */
			this.bottom = bottom;

			/**
			 * The camera's near plane. The valid range is greater than `0`
			 * and less than the current value of {@link OrthographicCamera#far}.
			 *
			 * Note that, unlike for the {@link PerspectiveCamera}, `0` is a
			 * valid value for an orthographic camera's near plane.
			 *
			 * @type {number}
			 * @default 0.1
			 */
			this.near = near;

			/**
			 * The camera's far plane. Must be greater than the
			 * current value of {@link OrthographicCamera#near}.
			 *
			 * @type {number}
			 * @default 2000
			 */
			this.far = far;

			this.updateProjectionMatrix();

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.left = source.left;
			this.right = source.right;
			this.top = source.top;
			this.bottom = source.bottom;
			this.near = source.near;
			this.far = source.far;

			this.zoom = source.zoom;
			this.view = source.view === null ? null : Object.assign( {}, source.view );

			return this;

		}

		/**
		 * Sets an offset in a larger frustum. This is useful for multi-window or
		 * multi-monitor/multi-machine setups.
		 *
		 * @param {number} fullWidth - The full width of multiview setup.
		 * @param {number} fullHeight - The full height of multiview setup.
		 * @param {number} x - The horizontal offset of the subcamera.
		 * @param {number} y - The vertical offset of the subcamera.
		 * @param {number} width - The width of subcamera.
		 * @param {number} height - The height of subcamera.
		 * @see {@link PerspectiveCamera#setViewOffset}
		 */
		setViewOffset( fullWidth, fullHeight, x, y, width, height ) {

			if ( this.view === null ) {

				this.view = {
					enabled: true,
					fullWidth: 1,
					fullHeight: 1,
					offsetX: 0,
					offsetY: 0,
					width: 1,
					height: 1
				};

			}

			this.view.enabled = true;
			this.view.fullWidth = fullWidth;
			this.view.fullHeight = fullHeight;
			this.view.offsetX = x;
			this.view.offsetY = y;
			this.view.width = width;
			this.view.height = height;

			this.updateProjectionMatrix();

		}

		/**
		 * Removes the view offset from the projection matrix.
		 */
		clearViewOffset() {

			if ( this.view !== null ) {

				this.view.enabled = false;

			}

			this.updateProjectionMatrix();

		}

		/**
		 * Updates the camera's projection matrix. Must be called after any change of
		 * camera properties.
		 */
		updateProjectionMatrix() {

			const dx = ( this.right - this.left ) / ( 2 * this.zoom );
			const dy = ( this.top - this.bottom ) / ( 2 * this.zoom );
			const cx = ( this.right + this.left ) / 2;
			const cy = ( this.top + this.bottom ) / 2;

			let left = cx - dx;
			let right = cx + dx;
			let top = cy + dy;
			let bottom = cy - dy;

			if ( this.view !== null && this.view.enabled ) {

				const scaleW = ( this.right - this.left ) / this.view.fullWidth / this.zoom;
				const scaleH = ( this.top - this.bottom ) / this.view.fullHeight / this.zoom;

				left += scaleW * this.view.offsetX;
				right = left + scaleW * this.view.width;
				top -= scaleH * this.view.offsetY;
				bottom = top - scaleH * this.view.height;

			}

			this.projectionMatrix.makeOrthographic( left, right, top, bottom, this.near, this.far, this.coordinateSystem );

			this.projectionMatrixInverse.copy( this.projectionMatrix ).invert();

		}

		toJSON( meta ) {

			const data = super.toJSON( meta );

			data.object.zoom = this.zoom;
			data.object.left = this.left;
			data.object.right = this.right;
			data.object.top = this.top;
			data.object.bottom = this.bottom;
			data.object.near = this.near;
			data.object.far = this.far;

			if ( this.view !== null ) data.object.view = Object.assign( {}, this.view );

			return data;

		}

	}

	/**
	 * Represents the shadow configuration of directional lights.
	 *
	 * @augments LightShadow
	 */
	class DirectionalLightShadow extends LightShadow {

		/**
		 * Constructs a new directional light shadow.
		 */
		constructor() {

			super( new OrthographicCamera( -5, 5, 5, -5, 0.5, 500 ) );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isDirectionalLightShadow = true;

		}

	}

	/**
	 * A light that gets emitted in a specific direction. This light will behave
	 * as though it is infinitely far away and the rays produced from it are all
	 * parallel. The common use case for this is to simulate daylight; the sun is
	 * far enough away that its position can be considered to be infinite, and
	 * all light rays coming from it are parallel.
	 *
	 * A common point of confusion for directional lights is that setting the
	 * rotation has no effect. This is because three.js's DirectionalLight is the
	 * equivalent to what is often called a 'Target Direct Light' in other
	 * applications.
	 *
	 * This means that its direction is calculated as pointing from the light's
	 * {@link Object3D#position} to the {@link DirectionalLight#target} position
	 * (as opposed to a 'Free Direct Light' that just has a rotation
	 * component).
	 *
	 * This light can cast shadows - see the {@link DirectionalLightShadow} for details.
	 *
	 * ```js
	 * // White directional light at half intensity shining from the top.
	 * const directionalLight = new THREE.DirectionalLight( 0xffffff, 0.5 );
	 * scene.add( directionalLight );
	 * ```
	 *
	 * @augments Light
	 */
	class DirectionalLight extends Light {

		/**
		 * Constructs a new directional light.
		 *
		 * @param {(number|Color|string)} [color=0xffffff] - The light's color.
		 * @param {number} [intensity=1] - The light's strength/intensity.
		 */
		constructor( color, intensity ) {

			super( color, intensity );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isDirectionalLight = true;

			this.type = 'DirectionalLight';

			this.position.copy( Object3D.DEFAULT_UP );
			this.updateMatrix();

			/**
			 * The directional light points from its position to the
			 * target's position.
			 *
			 * For the target's position to be changed to anything other
			 * than the default, it must be added to the scene.
			 *
			 * It is also possible to set the target to be another 3D object
			 * in the scene. The light will now track the target object.
			 *
			 * @type {Object3D}
			 */
			this.target = new Object3D();

			/**
			 * This property holds the light's shadow configuration.
			 *
			 * @type {DirectionalLightShadow}
			 */
			this.shadow = new DirectionalLightShadow();

		}

		dispose() {

			this.shadow.dispose();

		}

		copy( source ) {

			super.copy( source );

			this.target = source.target.clone();
			this.shadow = source.shadow.clone();

			return this;

		}

	}

	/**
	 * This light globally illuminates all objects in the scene equally.
	 *
	 * It cannot be used to cast shadows as it does not have a direction.
	 *
	 * ```js
	 * const light = new THREE.AmbientLight( 0x404040 ); // soft white light
	 * scene.add( light );
	 * ```
	 *
	 * @augments Light
	 */
	class AmbientLight extends Light {

		/**
		 * Constructs a new ambient light.
		 *
		 * @param {(number|Color|string)} [color=0xffffff] - The light's color.
		 * @param {number} [intensity=1] - The light's strength/intensity.
		 */
		constructor( color, intensity ) {

			super( color, intensity );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isAmbientLight = true;

			this.type = 'AmbientLight';

		}

	}

	/**
	 * A class with loader utility functions.
	 */
	class LoaderUtils {

		/**
		 * Extracts the base URL from the given URL.
		 *
		 * @param {string} url -The URL to extract the base URL from.
		 * @return {string} The extracted base URL.
		 */
		static extractUrlBase( url ) {

			const index = url.lastIndexOf( '/' );

			if ( index === -1 ) return './';

			return url.slice( 0, index + 1 );

		}

		/**
		 * Resolves relative URLs against the given path. Absolute paths, data urls,
		 * and blob URLs will be returned as is. Invalid URLs will return an empty
		 * string.
		 *
		 * @param {string} url -The URL to resolve.
		 * @param {string} path - The base path for relative URLs to be resolved against.
		 * @return {string} The resolved URL.
		 */
		static resolveURL( url, path ) {

			// Invalid URL
			if ( typeof url !== 'string' || url === '' ) return '';

			// Host Relative URL
			if ( /^https?:\/\//i.test( path ) && /^\//.test( url ) ) {

				path = path.replace( /(^https?:\/\/[^\/]+).*/i, '$1' );

			}

			// Absolute URL http://,https://,//
			if ( /^(https?:)?\/\//i.test( url ) ) return url;

			// Data URI
			if ( /^data:.*,.*$/i.test( url ) ) return url;

			// Blob URL
			if ( /^blob:.*$/i.test( url ) ) return url;

			// Relative URL
			return path + url;

		}

	}

	/**
	 * An instanced version of a geometry.
	 */
	class InstancedBufferGeometry extends BufferGeometry {

		/**
		 * Constructs a new instanced buffer geometry.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isInstancedBufferGeometry = true;

			this.type = 'InstancedBufferGeometry';

			/**
			 * The instance count.
			 *
			 * @type {number}
			 * @default Infinity
			 */
			this.instanceCount = Infinity;

		}

		copy( source ) {

			super.copy( source );

			this.instanceCount = source.instanceCount;

			return this;

		}

		toJSON() {

			const data = super.toJSON();

			data.instanceCount = this.instanceCount;

			data.isInstancedBufferGeometry = true;

			return data;

		}

	}

	const _errorMap = new WeakMap();

	/**
	 * A loader for loading images as an [ImageBitmap]{@link https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap}.
	 * An `ImageBitmap` provides an asynchronous and resource efficient pathway to prepare
	 * textures for rendering.
	 *
	 * Note that {@link Texture#flipY} and {@link Texture#premultiplyAlpha} are ignored with image bitmaps.
	 * They needs these configuration on bitmap creation unlike regular images need them on uploading to GPU.
	 *
	 * You need to set the equivalent options via {@link ImageBitmapLoader#setOptions} instead.
	 *
	 * Also note that unlike {@link FileLoader}, this loader avoids multiple concurrent requests to the same URL only if `Cache` is enabled.
	 *
	 * ```js
	 * const loader = new THREE.ImageBitmapLoader();
	 * loader.setOptions( { imageOrientation: 'flipY' } ); // set options if needed
	 * const imageBitmap = await loader.loadAsync( 'image.png' );
	 *
	 * const texture = new THREE.Texture( imageBitmap );
	 * texture.needsUpdate = true;
	 * ```
	 *
	 * @augments Loader
	 */
	class ImageBitmapLoader extends Loader {

		/**
		 * Constructs a new image bitmap loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			super( manager );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isImageBitmapLoader = true;

			if ( typeof createImageBitmap === 'undefined' ) {

				console.warn( 'THREE.ImageBitmapLoader: createImageBitmap() not supported.' );

			}

			if ( typeof fetch === 'undefined' ) {

				console.warn( 'THREE.ImageBitmapLoader: fetch() not supported.' );

			}

			/**
			 * Represents the loader options.
			 *
			 * @type {Object}
			 * @default {premultiplyAlpha:'none'}
			 */
			this.options = { premultiplyAlpha: 'none' };

		}

		/**
		 * Sets the given loader options. The structure of the object must match the `options` parameter of
		 * [createImageBitmap]{@link https://developer.mozilla.org/en-US/docs/Web/API/Window/createImageBitmap}.
		 *
		 * @param {Object} options - The loader options to set.
		 * @return {ImageBitmapLoader} A reference to this image bitmap loader.
		 */
		setOptions( options ) {

			this.options = options;

			return this;

		}

		/**
		 * Starts loading from the given URL and pass the loaded image bitmap to the `onLoad()` callback.
		 *
		 * @param {string} url - The path/URL of the file to be loaded. This can also be a data URI.
		 * @param {function(ImageBitmap)} onLoad - Executed when the loading process has been finished.
		 * @param {onProgressCallback} onProgress - Unsupported in this loader.
		 * @param {onErrorCallback} onError - Executed when errors occur.
		 * @return {ImageBitmap|undefined} The image bitmap.
		 */
		load( url, onLoad, onProgress, onError ) {

			if ( url === undefined ) url = '';

			if ( this.path !== undefined ) url = this.path + url;

			url = this.manager.resolveURL( url );

			const scope = this;

			const cached = Cache.get( url );

			if ( cached !== undefined ) {

				scope.manager.itemStart( url );

				// If cached is a promise, wait for it to resolve
				if ( cached.then ) {

					cached.then( imageBitmap => {

						// check if there is an error for the cached promise

						if ( _errorMap.has( cached ) === true ) {

							if ( onError ) onError( _errorMap.get( cached ) );

							scope.manager.itemError( url );
							scope.manager.itemEnd( url );

						} else {

							if ( onLoad ) onLoad( imageBitmap );

							scope.manager.itemEnd( url );

							return imageBitmap;

						}

					} );

					return;

				}

				// If cached is not a promise (i.e., it's already an imageBitmap)
				setTimeout( function () {

					if ( onLoad ) onLoad( cached );

					scope.manager.itemEnd( url );

				}, 0 );

				return cached;

			}

			const fetchOptions = {};
			fetchOptions.credentials = ( this.crossOrigin === 'anonymous' ) ? 'same-origin' : 'include';
			fetchOptions.headers = this.requestHeader;

			const promise = fetch( url, fetchOptions ).then( function ( res ) {

				return res.blob();

			} ).then( function ( blob ) {

				return createImageBitmap( blob, Object.assign( scope.options, { colorSpaceConversion: 'none' } ) );

			} ).then( function ( imageBitmap ) {

				Cache.add( url, imageBitmap );

				if ( onLoad ) onLoad( imageBitmap );

				scope.manager.itemEnd( url );

				return imageBitmap;

			} ).catch( function ( e ) {

				if ( onError ) onError( e );

				_errorMap.set( promise, e );

				Cache.remove( url );

				scope.manager.itemError( url );
				scope.manager.itemEnd( url );

			} );

			Cache.add( url, promise );
			scope.manager.itemStart( url );

		}

	}

	/**
	 * This type of camera can be used in order to efficiently render a scene with a
	 * predefined set of cameras. This is an important performance aspect for
	 * rendering VR scenes.
	 *
	 * An instance of `ArrayCamera` always has an array of sub cameras. It's mandatory
	 * to define for each sub camera the `viewport` property which determines the
	 * part of the viewport that is rendered with this camera.
	 *
	 * @augments PerspectiveCamera
	 */
	class ArrayCamera extends PerspectiveCamera {

		/**
		 * Constructs a new array camera.
		 *
		 * @param {Array<PerspectiveCamera>} [array=[]] - An array of perspective sub cameras.
		 */
		constructor( array = [] ) {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isArrayCamera = true;

			/**
			 * Whether this camera is used with multiview rendering or not.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default false
			 */
			this.isMultiViewCamera = false;

			/**
			 * An array of perspective sub cameras.
			 *
			 * @type {Array<PerspectiveCamera>}
			 */
			this.cameras = array;

		}

	}

	/**
	 * Class for keeping track of time.
	 */
	class Clock {

		/**
		 * Constructs a new clock.
		 *
		 * @param {boolean} [autoStart=true] - Whether to automatically start the clock when
		 * `getDelta()` is called for the first time.
		 */
		constructor( autoStart = true ) {

			/**
			 * If set to `true`, the clock starts automatically when `getDelta()` is called
			 * for the first time.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.autoStart = autoStart;

			/**
			 * Holds the time at which the clock's `start()` method was last called.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.startTime = 0;

			/**
			 * Holds the time at which the clock's `start()`, `getElapsedTime()` or
			 * `getDelta()` methods were last called.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.oldTime = 0;

			/**
			 * Keeps track of the total time that the clock has been running.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.elapsedTime = 0;

			/**
			 * Whether the clock is running or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.running = false;

		}

		/**
		 * Starts the clock. When `autoStart` is set to `true`, the method is automatically
		 * called by the class.
		 */
		start() {

			this.startTime = now();

			this.oldTime = this.startTime;
			this.elapsedTime = 0;
			this.running = true;

		}

		/**
		 * Stops the clock.
		 */
		stop() {

			this.getElapsedTime();
			this.running = false;
			this.autoStart = false;

		}

		/**
		 * Returns the elapsed time in seconds.
		 *
		 * @return {number} The elapsed time.
		 */
		getElapsedTime() {

			this.getDelta();
			return this.elapsedTime;

		}

		/**
		 * Returns the delta time in seconds.
		 *
		 * @return {number} The delta time.
		 */
		getDelta() {

			let diff = 0;

			if ( this.autoStart && ! this.running ) {

				this.start();
				return 0;

			}

			if ( this.running ) {

				const newTime = now();

				diff = ( newTime - this.oldTime ) / 1000;
				this.oldTime = newTime;

				this.elapsedTime += diff;

			}

			return diff;

		}

	}

	function now() {

		return performance.now();

	}

	// Characters [].:/ are reserved for track binding syntax.
	const _RESERVED_CHARS_RE = '\\[\\]\\.:\\/';
	const _reservedRe = new RegExp( '[' + _RESERVED_CHARS_RE + ']', 'g' );

	// Attempts to allow node names from any language. ES5's `\w` regexp matches
	// only latin characters, and the unicode \p{L} is not yet supported. So
	// instead, we exclude reserved characters and match everything else.
	const _wordChar = '[^' + _RESERVED_CHARS_RE + ']';
	const _wordCharOrDot = '[^' + _RESERVED_CHARS_RE.replace( '\\.', '' ) + ']';

	// Parent directories, delimited by '/' or ':'. Currently unused, but must
	// be matched to parse the rest of the track name.
	const _directoryRe = /*@__PURE__*/ /((?:WC+[\/:])*)/.source.replace( 'WC', _wordChar );

	// Target node. May contain word characters (a-zA-Z0-9_) and '.' or '-'.
	const _nodeRe = /*@__PURE__*/ /(WCOD+)?/.source.replace( 'WCOD', _wordCharOrDot );

	// Object on target node, and accessor. May not contain reserved
	// characters. Accessor may contain any character except closing bracket.
	const _objectRe = /*@__PURE__*/ /(?:\.(WC+)(?:\[(.+)\])?)?/.source.replace( 'WC', _wordChar );

	// Property and accessor. May not contain reserved characters. Accessor may
	// contain any non-bracket characters.
	const _propertyRe = /*@__PURE__*/ /\.(WC+)(?:\[(.+)\])?/.source.replace( 'WC', _wordChar );

	const _trackRe = new RegExp( ''
		+ '^'
		+ _directoryRe
		+ _nodeRe
		+ _objectRe
		+ _propertyRe
		+ '$'
	);

	const _supportedObjectNames = [ 'material', 'materials', 'bones', 'map' ];

	class Composite {

		constructor( targetGroup, path, optionalParsedPath ) {

			const parsedPath = optionalParsedPath || PropertyBinding.parseTrackName( path );

			this._targetGroup = targetGroup;
			this._bindings = targetGroup.subscribe_( path, parsedPath );

		}

		getValue( array, offset ) {

			this.bind(); // bind all binding

			const firstValidIndex = this._targetGroup.nCachedObjects_,
				binding = this._bindings[ firstValidIndex ];

			// and only call .getValue on the first
			if ( binding !== undefined ) binding.getValue( array, offset );

		}

		setValue( array, offset ) {

			const bindings = this._bindings;

			for ( let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++ i ) {

				bindings[ i ].setValue( array, offset );

			}

		}

		bind() {

			const bindings = this._bindings;

			for ( let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++ i ) {

				bindings[ i ].bind();

			}

		}

		unbind() {

			const bindings = this._bindings;

			for ( let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++ i ) {

				bindings[ i ].unbind();

			}

		}

	}

	// Note: This class uses a State pattern on a per-method basis:
	// 'bind' sets 'this.getValue' / 'setValue' and shadows the
	// prototype version of these methods with one that represents
	// the bound state. When the property is not found, the methods
	// become no-ops.


	/**
	 * This holds a reference to a real property in the scene graph; used internally.
	 */
	class PropertyBinding {

		/**
		 * Constructs a new property binding.
		 *
		 * @param {Object} rootNode - The root node.
		 * @param {string} path - The path.
		 * @param {?Object} [parsedPath] - The parsed path.
		 */
		constructor( rootNode, path, parsedPath ) {

			/**
			 * The object path to the animated property.
			 *
			 * @type {string}
			 */
			this.path = path;

			/**
			 * An object holding information about the path.
			 *
			 * @type {Object}
			 */
			this.parsedPath = parsedPath || PropertyBinding.parseTrackName( path );

			/**
			 * The object owns the animated property.
			 *
			 * @type {?Object}
			 */
			this.node = PropertyBinding.findNode( rootNode, this.parsedPath.nodeName );

			/**
			 * The root node.
			 *
			 * @type {Object3D|Skeleton}
			 */
			this.rootNode = rootNode;

			// initial state of these methods that calls 'bind'
			this.getValue = this._getValue_unbound;
			this.setValue = this._setValue_unbound;

		}


		/**
		 * Factory method for creating a property binding from the given parameters.
		 *
		 * @static
		 * @param {Object} root - The root node.
		 * @param {string} path - The path.
		 * @param {?Object} [parsedPath] - The parsed path.
		 * @return {PropertyBinding|Composite} The created property binding or composite.
		 */
		static create( root, path, parsedPath ) {

			if ( ! ( root && root.isAnimationObjectGroup ) ) {

				return new PropertyBinding( root, path, parsedPath );

			} else {

				return new PropertyBinding.Composite( root, path, parsedPath );

			}

		}

		/**
		 * Replaces spaces with underscores and removes unsupported characters from
		 * node names, to ensure compatibility with parseTrackName().
		 *
		 * @param {string} name - Node name to be sanitized.
		 * @return {string} The sanitized node name.
		 */
		static sanitizeNodeName( name ) {

			return name.replace( /\s/g, '_' ).replace( _reservedRe, '' );

		}

		/**
		 * Parses the given track name (an object path to an animated property) and
		 * returns an object with information about the path. Matches strings in the following forms:
		 *
		 * - nodeName.property
		 * - nodeName.property[accessor]
		 * - nodeName.material.property[accessor]
		 * - uuid.property[accessor]
		 * - uuid.objectName[objectIndex].propertyName[propertyIndex]
		 * - parentName/nodeName.property
		 * - parentName/parentName/nodeName.property[index]
		 * - .bone[Armature.DEF_cog].position
		 * - scene:helium_balloon_model:helium_balloon_model.position
		 *
		 * @static
		 * @param {string} trackName - The track name to parse.
		 * @return {Object} The parsed track name as an object.
		 */
		static parseTrackName( trackName ) {

			const matches = _trackRe.exec( trackName );

			if ( matches === null ) {

				throw new Error( 'PropertyBinding: Cannot parse trackName: ' + trackName );

			}

			const results = {
				// directoryName: matches[ 1 ], // (tschw) currently unused
				nodeName: matches[ 2 ],
				objectName: matches[ 3 ],
				objectIndex: matches[ 4 ],
				propertyName: matches[ 5 ], // required
				propertyIndex: matches[ 6 ]
			};

			const lastDot = results.nodeName && results.nodeName.lastIndexOf( '.' );

			if ( lastDot !== undefined && lastDot !== -1 ) {

				const objectName = results.nodeName.substring( lastDot + 1 );

				// Object names must be checked against an allowlist. Otherwise, there
				// is no way to parse 'foo.bar.baz': 'baz' must be a property, but
				// 'bar' could be the objectName, or part of a nodeName (which can
				// include '.' characters).
				if ( _supportedObjectNames.indexOf( objectName ) !== -1 ) {

					results.nodeName = results.nodeName.substring( 0, lastDot );
					results.objectName = objectName;

				}

			}

			if ( results.propertyName === null || results.propertyName.length === 0 ) {

				throw new Error( 'PropertyBinding: can not parse propertyName from trackName: ' + trackName );

			}

			return results;

		}

		/**
		 * Searches for a node in the hierarchy of the given root object by the given
		 * node name.
		 *
		 * @static
		 * @param {Object} root - The root object.
		 * @param {string|number} nodeName - The name of the node.
		 * @return {?Object} The found node. Returns `null` if no object was found.
		 */
		static findNode( root, nodeName ) {

			if ( nodeName === undefined || nodeName === '' || nodeName === '.' || nodeName === -1 || nodeName === root.name || nodeName === root.uuid ) {

				return root;

			}

			// search into skeleton bones.
			if ( root.skeleton ) {

				const bone = root.skeleton.getBoneByName( nodeName );

				if ( bone !== undefined ) {

					return bone;

				}

			}

			// search into node subtree.
			if ( root.children ) {

				const searchNodeSubtree = function ( children ) {

					for ( let i = 0; i < children.length; i ++ ) {

						const childNode = children[ i ];

						if ( childNode.name === nodeName || childNode.uuid === nodeName ) {

							return childNode;

						}

						const result = searchNodeSubtree( childNode.children );

						if ( result ) return result;

					}

					return null;

				};

				const subTreeNode = searchNodeSubtree( root.children );

				if ( subTreeNode ) {

					return subTreeNode;

				}

			}

			return null;

		}

		// these are used to "bind" a nonexistent property
		_getValue_unavailable() {}
		_setValue_unavailable() {}

		// Getters

		_getValue_direct( buffer, offset ) {

			buffer[ offset ] = this.targetObject[ this.propertyName ];

		}

		_getValue_array( buffer, offset ) {

			const source = this.resolvedProperty;

			for ( let i = 0, n = source.length; i !== n; ++ i ) {

				buffer[ offset ++ ] = source[ i ];

			}

		}

		_getValue_arrayElement( buffer, offset ) {

			buffer[ offset ] = this.resolvedProperty[ this.propertyIndex ];

		}

		_getValue_toArray( buffer, offset ) {

			this.resolvedProperty.toArray( buffer, offset );

		}

		// Direct

		_setValue_direct( buffer, offset ) {

			this.targetObject[ this.propertyName ] = buffer[ offset ];

		}

		_setValue_direct_setNeedsUpdate( buffer, offset ) {

			this.targetObject[ this.propertyName ] = buffer[ offset ];
			this.targetObject.needsUpdate = true;

		}

		_setValue_direct_setMatrixWorldNeedsUpdate( buffer, offset ) {

			this.targetObject[ this.propertyName ] = buffer[ offset ];
			this.targetObject.matrixWorldNeedsUpdate = true;

		}

		// EntireArray

		_setValue_array( buffer, offset ) {

			const dest = this.resolvedProperty;

			for ( let i = 0, n = dest.length; i !== n; ++ i ) {

				dest[ i ] = buffer[ offset ++ ];

			}

		}

		_setValue_array_setNeedsUpdate( buffer, offset ) {

			const dest = this.resolvedProperty;

			for ( let i = 0, n = dest.length; i !== n; ++ i ) {

				dest[ i ] = buffer[ offset ++ ];

			}

			this.targetObject.needsUpdate = true;

		}

		_setValue_array_setMatrixWorldNeedsUpdate( buffer, offset ) {

			const dest = this.resolvedProperty;

			for ( let i = 0, n = dest.length; i !== n; ++ i ) {

				dest[ i ] = buffer[ offset ++ ];

			}

			this.targetObject.matrixWorldNeedsUpdate = true;

		}

		// ArrayElement

		_setValue_arrayElement( buffer, offset ) {

			this.resolvedProperty[ this.propertyIndex ] = buffer[ offset ];

		}

		_setValue_arrayElement_setNeedsUpdate( buffer, offset ) {

			this.resolvedProperty[ this.propertyIndex ] = buffer[ offset ];
			this.targetObject.needsUpdate = true;

		}

		_setValue_arrayElement_setMatrixWorldNeedsUpdate( buffer, offset ) {

			this.resolvedProperty[ this.propertyIndex ] = buffer[ offset ];
			this.targetObject.matrixWorldNeedsUpdate = true;

		}

		// HasToFromArray

		_setValue_fromArray( buffer, offset ) {

			this.resolvedProperty.fromArray( buffer, offset );

		}

		_setValue_fromArray_setNeedsUpdate( buffer, offset ) {

			this.resolvedProperty.fromArray( buffer, offset );
			this.targetObject.needsUpdate = true;

		}

		_setValue_fromArray_setMatrixWorldNeedsUpdate( buffer, offset ) {

			this.resolvedProperty.fromArray( buffer, offset );
			this.targetObject.matrixWorldNeedsUpdate = true;

		}

		_getValue_unbound( targetArray, offset ) {

			this.bind();
			this.getValue( targetArray, offset );

		}

		_setValue_unbound( sourceArray, offset ) {

			this.bind();
			this.setValue( sourceArray, offset );

		}

		/**
		 * Creates a getter / setter pair for the property tracked by this binding.
		 */
		bind() {

			let targetObject = this.node;
			const parsedPath = this.parsedPath;

			const objectName = parsedPath.objectName;
			const propertyName = parsedPath.propertyName;
			let propertyIndex = parsedPath.propertyIndex;

			if ( ! targetObject ) {

				targetObject = PropertyBinding.findNode( this.rootNode, parsedPath.nodeName );

				this.node = targetObject;

			}

			// set fail state so we can just 'return' on error
			this.getValue = this._getValue_unavailable;
			this.setValue = this._setValue_unavailable;

			// ensure there is a value node
			if ( ! targetObject ) {

				console.warn( 'THREE.PropertyBinding: No target node found for track: ' + this.path + '.' );
				return;

			}

			if ( objectName ) {

				let objectIndex = parsedPath.objectIndex;

				// special cases were we need to reach deeper into the hierarchy to get the face materials....
				switch ( objectName ) {

					case 'materials':

						if ( ! targetObject.material ) {

							console.error( 'THREE.PropertyBinding: Can not bind to material as node does not have a material.', this );
							return;

						}

						if ( ! targetObject.material.materials ) {

							console.error( 'THREE.PropertyBinding: Can not bind to material.materials as node.material does not have a materials array.', this );
							return;

						}

						targetObject = targetObject.material.materials;

						break;

					case 'bones':

						if ( ! targetObject.skeleton ) {

							console.error( 'THREE.PropertyBinding: Can not bind to bones as node does not have a skeleton.', this );
							return;

						}

						// potential future optimization: skip this if propertyIndex is already an integer
						// and convert the integer string to a true integer.

						targetObject = targetObject.skeleton.bones;

						// support resolving morphTarget names into indices.
						for ( let i = 0; i < targetObject.length; i ++ ) {

							if ( targetObject[ i ].name === objectIndex ) {

								objectIndex = i;
								break;

							}

						}

						break;

					case 'map':

						if ( 'map' in targetObject ) {

							targetObject = targetObject.map;
							break;

						}

						if ( ! targetObject.material ) {

							console.error( 'THREE.PropertyBinding: Can not bind to material as node does not have a material.', this );
							return;

						}

						if ( ! targetObject.material.map ) {

							console.error( 'THREE.PropertyBinding: Can not bind to material.map as node.material does not have a map.', this );
							return;

						}

						targetObject = targetObject.material.map;
						break;

					default:

						if ( targetObject[ objectName ] === undefined ) {

							console.error( 'THREE.PropertyBinding: Can not bind to objectName of node undefined.', this );
							return;

						}

						targetObject = targetObject[ objectName ];

				}


				if ( objectIndex !== undefined ) {

					if ( targetObject[ objectIndex ] === undefined ) {

						console.error( 'THREE.PropertyBinding: Trying to bind to objectIndex of objectName, but is undefined.', this, targetObject );
						return;

					}

					targetObject = targetObject[ objectIndex ];

				}

			}

			// resolve property
			const nodeProperty = targetObject[ propertyName ];

			if ( nodeProperty === undefined ) {

				const nodeName = parsedPath.nodeName;

				console.error( 'THREE.PropertyBinding: Trying to update property for track: ' + nodeName +
					'.' + propertyName + ' but it wasn\'t found.', targetObject );
				return;

			}

			// determine versioning scheme
			let versioning = this.Versioning.None;

			this.targetObject = targetObject;

			if ( targetObject.isMaterial === true ) {

				versioning = this.Versioning.NeedsUpdate;

			} else if ( targetObject.isObject3D === true ) {

				versioning = this.Versioning.MatrixWorldNeedsUpdate;

			}

			// determine how the property gets bound
			let bindingType = this.BindingType.Direct;

			if ( propertyIndex !== undefined ) {

				// access a sub element of the property array (only primitives are supported right now)

				if ( propertyName === 'morphTargetInfluences' ) {

					// potential optimization, skip this if propertyIndex is already an integer, and convert the integer string to a true integer.

					// support resolving morphTarget names into indices.
					if ( ! targetObject.geometry ) {

						console.error( 'THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.', this );
						return;

					}

					if ( ! targetObject.geometry.morphAttributes ) {

						console.error( 'THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.morphAttributes.', this );
						return;

					}

					if ( targetObject.morphTargetDictionary[ propertyIndex ] !== undefined ) {

						propertyIndex = targetObject.morphTargetDictionary[ propertyIndex ];

					}

				}

				bindingType = this.BindingType.ArrayElement;

				this.resolvedProperty = nodeProperty;
				this.propertyIndex = propertyIndex;

			} else if ( nodeProperty.fromArray !== undefined && nodeProperty.toArray !== undefined ) {

				// must use copy for Object3D.Euler/Quaternion

				bindingType = this.BindingType.HasFromToArray;

				this.resolvedProperty = nodeProperty;

			} else if ( Array.isArray( nodeProperty ) ) {

				bindingType = this.BindingType.EntireArray;

				this.resolvedProperty = nodeProperty;

			} else {

				this.propertyName = propertyName;

			}

			// select getter / setter
			this.getValue = this.GetterByBindingType[ bindingType ];
			this.setValue = this.SetterByBindingTypeAndVersioning[ bindingType ][ versioning ];

		}

		/**
		 * Unbinds the property.
		 */
		unbind() {

			this.node = null;

			// back to the prototype version of getValue / setValue
			// note: avoiding to mutate the shape of 'this' via 'delete'
			this.getValue = this._getValue_unbound;
			this.setValue = this._setValue_unbound;

		}

	}

	PropertyBinding.Composite = Composite;

	PropertyBinding.prototype.BindingType = {
		Direct: 0,
		EntireArray: 1,
		ArrayElement: 2,
		HasFromToArray: 3
	};

	PropertyBinding.prototype.Versioning = {
		None: 0,
		NeedsUpdate: 1,
		MatrixWorldNeedsUpdate: 2
	};

	PropertyBinding.prototype.GetterByBindingType = [

		PropertyBinding.prototype._getValue_direct,
		PropertyBinding.prototype._getValue_array,
		PropertyBinding.prototype._getValue_arrayElement,
		PropertyBinding.prototype._getValue_toArray,

	];

	PropertyBinding.prototype.SetterByBindingTypeAndVersioning = [

		[
			// Direct
			PropertyBinding.prototype._setValue_direct,
			PropertyBinding.prototype._setValue_direct_setNeedsUpdate,
			PropertyBinding.prototype._setValue_direct_setMatrixWorldNeedsUpdate,

		], [

			// EntireArray

			PropertyBinding.prototype._setValue_array,
			PropertyBinding.prototype._setValue_array_setNeedsUpdate,
			PropertyBinding.prototype._setValue_array_setMatrixWorldNeedsUpdate,

		], [

			// ArrayElement
			PropertyBinding.prototype._setValue_arrayElement,
			PropertyBinding.prototype._setValue_arrayElement_setNeedsUpdate,
			PropertyBinding.prototype._setValue_arrayElement_setMatrixWorldNeedsUpdate,

		], [

			// HasToFromArray
			PropertyBinding.prototype._setValue_fromArray,
			PropertyBinding.prototype._setValue_fromArray_setNeedsUpdate,
			PropertyBinding.prototype._setValue_fromArray_setMatrixWorldNeedsUpdate,

		]

	];

	/**
	 * Represents a uniform which is a global shader variable. They are passed to shader programs.
	 *
	 * When declaring a uniform of a {@link ShaderMaterial}, it is declared by value or by object.
	 * ```js
	 * uniforms: {
	 * 	time: { value: 1.0 },
	 * 	resolution: new Uniform( new Vector2() )
	 * };
	 * ```
	 * Since this class can only be used in context of {@link ShaderMaterial}, it is only supported
	 * in {@link WebGLRenderer}.
	 */
	class Uniform {

		/**
		 * Constructs a new uniform.
		 *
		 * @param {any} value - The uniform value.
		 */
		constructor( value ) {

			/**
			 * The uniform value.
			 *
			 * @type {any}
			 */
			this.value = value;

		}

		/**
		 * Returns a new uniform with copied values from this instance.
		 * If the value has a `clone()` method, the value is cloned as well.
		 *
		 * @return {Uniform} A clone of this instance.
		 */
		clone() {

			return new Uniform( this.value.clone === undefined ? this.value : this.value.clone() );

		}

	}

	/**
	 * An instanced version of an interleaved buffer.
	 *
	 * @augments InterleavedBuffer
	 */
	class InstancedInterleavedBuffer extends InterleavedBuffer {

		/**
		 * Constructs a new instanced interleaved buffer.
		 *
		 * @param {TypedArray} array - A typed array with a shared buffer storing attribute data.
		 * @param {number} stride - The number of typed-array elements per vertex.
		 * @param {number} [meshPerAttribute=1] - Defines how often a value of this interleaved buffer should be repeated.
		 */
		constructor( array, stride, meshPerAttribute = 1 ) {

			super( array, stride );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isInstancedInterleavedBuffer = true;

			/**
			 * Defines how often a value of this buffer attribute should be repeated,
			 * see {@link InstancedBufferAttribute#meshPerAttribute}.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.meshPerAttribute = meshPerAttribute;

		}

		copy( source ) {

			super.copy( source );

			this.meshPerAttribute = source.meshPerAttribute;

			return this;

		}

		clone( data ) {

			const ib = super.clone( data );

			ib.meshPerAttribute = this.meshPerAttribute;

			return ib;

		}

		toJSON( data ) {

			const json = super.toJSON( data );

			json.isInstancedInterleavedBuffer = true;
			json.meshPerAttribute = this.meshPerAttribute;

			return json;

		}

	}

	const _matrix = /*@__PURE__*/ new Matrix4();

	/**
	 * This class is designed to assist with raycasting. Raycasting is used for
	 * mouse picking (working out what objects in the 3d space the mouse is over)
	 * amongst other things.
	 */
	class Raycaster {

		/**
		 * Constructs a new raycaster.
		 *
		 * @param {Vector3} origin - The origin vector where the ray casts from.
		 * @param {Vector3} direction - The (normalized) direction vector that gives direction to the ray.
		 * @param {number} [near=0] - All results returned are further away than near. Near can't be negative.
		 * @param {number} [far=Infinity] - All results returned are closer than far. Far can't be lower than near.
		 */
		constructor( origin, direction, near = 0, far = Infinity ) {

			/**
			 * The ray used for raycasting.
			 *
			 * @type {Ray}
			 */
			this.ray = new Ray( origin, direction );

			/**
			 * All results returned are further away than near. Near can't be negative.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.near = near;

			/**
			 * All results returned are further away than near. Near can't be negative.
			 *
			 * @type {number}
			 * @default Infinity
			 */
			this.far = far;

			/**
			 * The camera to use when raycasting against view-dependent objects such as
			 * billboarded objects like sprites. This field can be set manually or
			 * is set when calling `setFromCamera()`.
			 *
			 * @type {?Camera}
			 * @default null
			 */
			this.camera = null;

			/**
			 * Allows to selectively ignore 3D objects when performing intersection tests.
			 * The following code example ensures that only 3D objects on layer `1` will be
			 * honored by raycaster.
			 * ```js
			 * raycaster.layers.set( 1 );
			 * object.layers.enable( 1 );
			 * ```
			 *
			 * @type {Layers}
			 */
			this.layers = new Layers();


			/**
			 * A parameter object that configures the raycasting. It has the structure:
			 *
			 * ```
			 * {
			 * 	Mesh: {},
			 * 	Line: { threshold: 1 },
			 * 	LOD: {},
			 * 	Points: { threshold: 1 },
			 * 	Sprite: {}
			 * }
			 * ```
			 * Where `threshold` is the precision of the raycaster when intersecting objects, in world units.
			 *
			 * @type {Object}
			 */
			this.params = {
				Mesh: {},
				Line: { threshold: 1 },
				LOD: {},
				Points: { threshold: 1 },
				Sprite: {}
			};

		}

		/**
		 * Updates the ray with a new origin and direction by copying the values from the arguments.
		 *
		 * @param {Vector3} origin - The origin vector where the ray casts from.
		 * @param {Vector3} direction - The (normalized) direction vector that gives direction to the ray.
		 */
		set( origin, direction ) {

			// direction is assumed to be normalized (for accurate distance calculations)

			this.ray.set( origin, direction );

		}

		/**
		 * Uses the given coordinates and camera to compute a new origin and direction for the internal ray.
		 *
		 * @param {Vector2} coords - 2D coordinates of the mouse, in normalized device coordinates (NDC).
		 * X and Y components should be between `-1` and `1`.
		 * @param {Camera} camera - The camera from which the ray should originate.
		 */
		setFromCamera( coords, camera ) {

			if ( camera.isPerspectiveCamera ) {

				this.ray.origin.setFromMatrixPosition( camera.matrixWorld );
				this.ray.direction.set( coords.x, coords.y, 0.5 ).unproject( camera ).sub( this.ray.origin ).normalize();
				this.camera = camera;

			} else if ( camera.isOrthographicCamera ) {

				this.ray.origin.set( coords.x, coords.y, ( camera.near + camera.far ) / ( camera.near - camera.far ) ).unproject( camera ); // set origin in plane of camera
				this.ray.direction.set( 0, 0, -1 ).transformDirection( camera.matrixWorld );
				this.camera = camera;

			} else {

				console.error( 'THREE.Raycaster: Unsupported camera type: ' + camera.type );

			}

		}

		/**
		 * Uses the given WebXR controller to compute a new origin and direction for the internal ray.
		 *
		 * @param {WebXRController} controller - The controller to copy the position and direction from.
		 * @return {Raycaster} A reference to this raycaster.
		 */
		setFromXRController( controller ) {

			_matrix.identity().extractRotation( controller.matrixWorld );

			this.ray.origin.setFromMatrixPosition( controller.matrixWorld );
			this.ray.direction.set( 0, 0, -1 ).applyMatrix4( _matrix );

			return this;

		}

		/**
		 * The intersection point of a raycaster intersection test.
		 * @typedef {Object} Raycaster~Intersection
		 * @property {number} distance - The distance from the ray's origin to the intersection point.
		 * @property {number} distanceToRay -  Some 3D objects e.g. {@link Points} provide the distance of the
		 * intersection to the nearest point on the ray. For other objects it will be `undefined`.
		 * @property {Vector3} point - The intersection point, in world coordinates.
		 * @property {Object} face - The face that has been intersected.
		 * @property {number} faceIndex - The face index.
		 * @property {Object3D} object - The 3D object that has been intersected.
		 * @property {Vector2} uv - U,V coordinates at point of intersection.
		 * @property {Vector2} uv1 - Second set of U,V coordinates at point of intersection.
		 * @property {Vector3} uv1 - Interpolated normal vector at point of intersection.
		 * @property {number} instanceId - The index number of the instance where the ray
		 * intersects the {@link InstancedMesh}.
		 */

		/**
		 * Checks all intersection between the ray and the object with or without the
		 * descendants. Intersections are returned sorted by distance, closest first.
		 *
		 * `Raycaster` delegates to the `raycast()` method of the passed 3D object, when
		 * evaluating whether the ray intersects the object or not. This allows meshes to respond
		 * differently to ray casting than lines or points.
		 *
		 * Note that for meshes, faces must be pointed towards the origin of the ray in order
		 * to be detected; intersections of the ray passing through the back of a face will not
		 * be detected. To raycast against both faces of an object, you'll want to set  {@link Material#side}
		 * to `THREE.DoubleSide`.
		 *
		 * @param {Object3D} object - The 3D object to check for intersection with the ray.
		 * @param {boolean} [recursive=true] - If set to `true`, it also checks all descendants.
		 * Otherwise it only checks intersection with the object.
		 * @param {Array<Raycaster~Intersection>} [intersects=[]] The target array that holds the result of the method.
		 * @return {Array<Raycaster~Intersection>} An array holding the intersection points.
		 */
		intersectObject( object, recursive = true, intersects = [] ) {

			intersect( object, this, intersects, recursive );

			intersects.sort( ascSort );

			return intersects;

		}

		/**
		 * Checks all intersection between the ray and the objects with or without
		 * the descendants. Intersections are returned sorted by distance, closest first.
		 *
		 * @param {Array<Object3D>} objects - The 3D objects to check for intersection with the ray.
		 * @param {boolean} [recursive=true] - If set to `true`, it also checks all descendants.
		 * Otherwise it only checks intersection with the object.
		 * @param {Array<Raycaster~Intersection>} [intersects=[]] The target array that holds the result of the method.
		 * @return {Array<Raycaster~Intersection>} An array holding the intersection points.
		 */
		intersectObjects( objects, recursive = true, intersects = [] ) {

			for ( let i = 0, l = objects.length; i < l; i ++ ) {

				intersect( objects[ i ], this, intersects, recursive );

			}

			intersects.sort( ascSort );

			return intersects;

		}

	}

	function ascSort( a, b ) {

		return a.distance - b.distance;

	}

	function intersect( object, raycaster, intersects, recursive ) {

		let propagate = true;

		if ( object.layers.test( raycaster.layers ) ) {

			const result = object.raycast( raycaster, intersects );

			if ( result === false ) propagate = false;

		}

		if ( propagate === true && recursive === true ) {

			const children = object.children;

			for ( let i = 0, l = children.length; i < l; i ++ ) {

				intersect( children[ i ], raycaster, intersects, true );

			}

		}

	}

	/**
	 * This class can be used to represent points in 3D space as
	 * [Spherical coordinates]{@link https://en.wikipedia.org/wiki/Spherical_coordinate_system}.
	 */
	class Spherical {

		/**
		 * Constructs a new spherical.
		 *
		 * @param {number} [radius=1] - The radius, or the Euclidean distance (straight-line distance) from the point to the origin.
		 * @param {number} [phi=0] - The polar angle in radians from the y (up) axis.
		 * @param {number} [theta=0] - The equator/azimuthal angle in radians around the y (up) axis.
		 */
		constructor( radius = 1, phi = 0, theta = 0 ) {

			/**
			 * The radius, or the Euclidean distance (straight-line distance) from the point to the origin.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.radius = radius;

			/**
			 * The polar angle in radians from the y (up) axis.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.phi = phi;

			/**
			 * The equator/azimuthal angle in radians around the y (up) axis.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.theta = theta;

		}

		/**
		 * Sets the spherical components by copying the given values.
		 *
		 * @param {number} radius - The radius.
		 * @param {number} phi - The polar angle.
		 * @param {number} theta - The azimuthal angle.
		 * @return {Spherical} A reference to this spherical.
		 */
		set( radius, phi, theta ) {

			this.radius = radius;
			this.phi = phi;
			this.theta = theta;

			return this;

		}

		/**
		 * Copies the values of the given spherical to this instance.
		 *
		 * @param {Spherical} other - The spherical to copy.
		 * @return {Spherical} A reference to this spherical.
		 */
		copy( other ) {

			this.radius = other.radius;
			this.phi = other.phi;
			this.theta = other.theta;

			return this;

		}

		/**
		 * Restricts the polar angle [page:.phi phi] to be between `0.000001` and pi -
		 * `0.000001`.
		 *
		 * @return {Spherical} A reference to this spherical.
		 */
		makeSafe() {

			const EPS = 0.000001;
			this.phi = clamp( this.phi, EPS, Math.PI - EPS );

			return this;

		}

		/**
		 * Sets the spherical components from the given vector which is assumed to hold
		 * Cartesian coordinates.
		 *
		 * @param {Vector3} v - The vector to set.
		 * @return {Spherical} A reference to this spherical.
		 */
		setFromVector3( v ) {

			return this.setFromCartesianCoords( v.x, v.y, v.z );

		}

		/**
		 * Sets the spherical components from the given Cartesian coordinates.
		 *
		 * @param {number} x - The x value.
		 * @param {number} y - The x value.
		 * @param {number} z - The x value.
		 * @return {Spherical} A reference to this spherical.
		 */
		setFromCartesianCoords( x, y, z ) {

			this.radius = Math.sqrt( x * x + y * y + z * z );

			if ( this.radius === 0 ) {

				this.theta = 0;
				this.phi = 0;

			} else {

				this.theta = Math.atan2( x, z );
				this.phi = Math.acos( clamp( y / this.radius, -1, 1 ) );

			}

			return this;

		}

		/**
		 * Returns a new spherical with copied values from this instance.
		 *
		 * @return {Spherical} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

	}

	const _startP = /*@__PURE__*/ new Vector3();
	const _startEnd = /*@__PURE__*/ new Vector3();

	/**
	 * An analytical line segment in 3D space represented by a start and end point.
	 */
	class Line3 {

		/**
		 * Constructs a new line segment.
		 *
		 * @param {Vector3} [start=(0,0,0)] - Start of the line segment.
		 * @param {Vector3} [end=(0,0,0)] - End of the line segment.
		 */
		constructor( start = new Vector3(), end = new Vector3() ) {

			/**
			 * Start of the line segment.
			 *
			 * @type {Vector3}
			 */
			this.start = start;

			/**
			 * End of the line segment.
			 *
			 * @type {Vector3}
			 */
			this.end = end;

		}

		/**
		 * Sets the start and end values by copying the given vectors.
		 *
		 * @param {Vector3} start - The start point.
		 * @param {Vector3} end - The end point.
		 * @return {Line3} A reference to this line segment.
		 */
		set( start, end ) {

			this.start.copy( start );
			this.end.copy( end );

			return this;

		}

		/**
		 * Copies the values of the given line segment to this instance.
		 *
		 * @param {Line3} line - The line segment to copy.
		 * @return {Line3} A reference to this line segment.
		 */
		copy( line ) {

			this.start.copy( line.start );
			this.end.copy( line.end );

			return this;

		}

		/**
		 * Returns the center of the line segment.
		 *
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The center point.
		 */
		getCenter( target ) {

			return target.addVectors( this.start, this.end ).multiplyScalar( 0.5 );

		}

		/**
		 * Returns the delta vector of the line segment's start and end point.
		 *
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The delta vector.
		 */
		delta( target ) {

			return target.subVectors( this.end, this.start );

		}

		/**
		 * Returns the squared Euclidean distance between the line' start and end point.
		 *
		 * @return {number} The squared Euclidean distance.
		 */
		distanceSq() {

			return this.start.distanceToSquared( this.end );

		}

		/**
		 * Returns the Euclidean distance between the line' start and end point.
		 *
		 * @return {number} The Euclidean distance.
		 */
		distance() {

			return this.start.distanceTo( this.end );

		}

		/**
		 * Returns a vector at a certain position along the line segment.
		 *
		 * @param {number} t - A value between `[0,1]` to represent a position along the line segment.
		 * @param {Vector3} target - The target vector that is used to store the method's result.
		 * @return {Vector3} The delta vector.
		 */
		at( t, target ) {

			return this.delta( target ).multiplyScalar( t ).add( this.start );

		}

		/**
		 * Returns a point parameter based on the closest point as projected on the line segment.
		 *
		 * @param {Vector3} point - The point for which to return a point parameter.
		 * @param {boolean} clampToLine - Whether to clamp the result to the range `[0,1]` or not.
		 * @return {number} The point parameter.
		 */
		closestPointToPointParameter( point, clampToLine ) {

			_startP.subVectors( point, this.start );
			_startEnd.subVectors( this.end, this.start );

			const startEnd2 = _startEnd.dot( _startEnd );
			const startEnd_startP = _startEnd.dot( _startP );

			let t = startEnd_startP / startEnd2;

			if ( clampToLine ) {

				t = clamp( t, 0, 1 );

			}

			return t;

		}

		/**
		 * Returns the closets point on the line for a given point.
		 *
		 * @param {Vector3} point - The point to compute the closest point on the line for.
		 * @param {boolean} clampToLine - Whether to clamp the result to the range `[0,1]` or not.
		 * @param {Vector3} target -  The target vector that is used to store the method's result.
		 * @return {Vector3} The closest point on the line.
		 */
		closestPointToPoint( point, clampToLine, target ) {

			const t = this.closestPointToPointParameter( point, clampToLine );

			return this.delta( target ).multiplyScalar( t ).add( this.start );

		}

		/**
		 * Applies a 4x4 transformation matrix to this line segment.
		 *
		 * @param {Matrix4} matrix - The transformation matrix.
		 * @return {Line3} A reference to this line segment.
		 */
		applyMatrix4( matrix ) {

			this.start.applyMatrix4( matrix );
			this.end.applyMatrix4( matrix );

			return this;

		}

		/**
		 * Returns `true` if this line segment is equal with the given one.
		 *
		 * @param {Line3} line - The line segment to test for equality.
		 * @return {boolean} Whether this line segment is equal with the given one.
		 */
		equals( line ) {

			return line.start.equals( this.start ) && line.end.equals( this.end );

		}

		/**
		 * Returns a new line segment with copied values from this instance.
		 *
		 * @return {Line3} A clone of this instance.
		 */
		clone() {

			return new this.constructor().copy( this );

		}

	}

	const _box = /*@__PURE__*/ new Box3();

	/**
	 * Helper object to graphically show the world-axis-aligned bounding box
	 * around an object. The actual bounding box is handled with {@link Box3},
	 * this is just a visual helper for debugging. It can be automatically
	 * resized with {@link BoxHelper#update} when the object it's created from
	 * is transformed. Note that the object must have a geometry for this to work,
	 * so it won't work with sprites.
	 *
	 * ```js
	 * const sphere = new THREE.SphereGeometry();
	 * const object = new THREE.Mesh( sphere, new THREE.MeshBasicMaterial( 0xff0000 ) );
	 * const box = new THREE.BoxHelper( object, 0xffff00 );
	 * scene.add( box );
	 * ```
	 *
	 * @augments LineSegments
	 */
	class BoxHelper extends LineSegments {

		/**
		 * Constructs a new box helper.
		 *
		 * @param {Object3D} [object] - The 3D object to show the world-axis-aligned bounding box.
		 * @param {number|Color|string} [color=0xffff00] - The box's color.
		 */
		constructor( object, color = 0xffff00 ) {

			const indices = new Uint16Array( [ 0, 1, 1, 2, 2, 3, 3, 0, 4, 5, 5, 6, 6, 7, 7, 4, 0, 4, 1, 5, 2, 6, 3, 7 ] );
			const positions = new Float32Array( 8 * 3 );

			const geometry = new BufferGeometry();
			geometry.setIndex( new BufferAttribute( indices, 1 ) );
			geometry.setAttribute( 'position', new BufferAttribute( positions, 3 ) );

			super( geometry, new LineBasicMaterial( { color: color, toneMapped: false } ) );

			/**
			 * The 3D object being visualized.
			 *
			 * @type {Object3D}
			 */
			this.object = object;
			this.type = 'BoxHelper';

			this.matrixAutoUpdate = false;

			this.update();

		}

		/**
		 * Updates the helper's geometry to match the dimensions of the object,
		 * including any children.
		 */
		update() {

			if ( this.object !== undefined ) {

				_box.setFromObject( this.object );

			}

			if ( _box.isEmpty() ) return;

			const min = _box.min;
			const max = _box.max;

			/*
				5____4
			1/___0/|
			| 6__|_7
			2/___3/

			0: max.x, max.y, max.z
			1: min.x, max.y, max.z
			2: min.x, min.y, max.z
			3: max.x, min.y, max.z
			4: max.x, max.y, min.z
			5: min.x, max.y, min.z
			6: min.x, min.y, min.z
			7: max.x, min.y, min.z
			*/

			const position = this.geometry.attributes.position;
			const array = position.array;

			array[ 0 ] = max.x; array[ 1 ] = max.y; array[ 2 ] = max.z;
			array[ 3 ] = min.x; array[ 4 ] = max.y; array[ 5 ] = max.z;
			array[ 6 ] = min.x; array[ 7 ] = min.y; array[ 8 ] = max.z;
			array[ 9 ] = max.x; array[ 10 ] = min.y; array[ 11 ] = max.z;
			array[ 12 ] = max.x; array[ 13 ] = max.y; array[ 14 ] = min.z;
			array[ 15 ] = min.x; array[ 16 ] = max.y; array[ 17 ] = min.z;
			array[ 18 ] = min.x; array[ 19 ] = min.y; array[ 20 ] = min.z;
			array[ 21 ] = max.x; array[ 22 ] = min.y; array[ 23 ] = min.z;

			position.needsUpdate = true;

			this.geometry.computeBoundingSphere();

		}

		/**
		 * Updates the wireframe box for the passed object.
		 *
		 * @param {Object3D} object - The 3D object to create the helper for.
		 * @return {BoxHelper} A reference to this instance.
		 */
		setFromObject( object ) {

			this.object = object;
			this.update();

			return this;

		}

		copy( source, recursive ) {

			super.copy( source, recursive );

			this.object = source.object;

			return this;

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever this instance is no longer used in your app.
		 */
		dispose() {

			this.geometry.dispose();
			this.material.dispose();

		}

	}

	/**
	 * This class is used to convert a series of paths to an array of
	 * shapes. It is specifically used in context of fonts and SVG.
	 */
	class ShapePath {

		/**
		 * Constructs a new shape path.
		 */
		constructor() {

			this.type = 'ShapePath';

			/**
			 * The color of the shape.
			 *
			 * @type {Color}
			 */
			this.color = new Color();

			/**
			 * The paths that have been generated for this shape.
			 *
			 * @type {Array<Path>}
			 * @default null
			 */
			this.subPaths = [];

			/**
			 * The current path that is being generated.
			 *
			 * @type {?Path}
			 * @default null
			 */
			this.currentPath = null;

		}

		/**
		 * Creates a new path and moves it current point to the given one.
		 *
		 * @param {number} x - The x coordinate.
		 * @param {number} y - The y coordinate.
		 * @return {ShapePath} A reference to this shape path.
		 */
		moveTo( x, y ) {

			this.currentPath = new Path();
			this.subPaths.push( this.currentPath );
			this.currentPath.moveTo( x, y );

			return this;

		}

		/**
		 * Adds an instance of {@link LineCurve} to the path by connecting
		 * the current point with the given one.
		 *
		 * @param {number} x - The x coordinate of the end point.
		 * @param {number} y - The y coordinate of the end point.
		 * @return {ShapePath} A reference to this shape path.
		 */
		lineTo( x, y ) {

			this.currentPath.lineTo( x, y );

			return this;

		}

		/**
		 * Adds an instance of {@link QuadraticBezierCurve} to the path by connecting
		 * the current point with the given one.
		 *
		 * @param {number} aCPx - The x coordinate of the control point.
		 * @param {number} aCPy - The y coordinate of the control point.
		 * @param {number} aX - The x coordinate of the end point.
		 * @param {number} aY - The y coordinate of the end point.
		 * @return {ShapePath} A reference to this shape path.
		 */
		quadraticCurveTo( aCPx, aCPy, aX, aY ) {

			this.currentPath.quadraticCurveTo( aCPx, aCPy, aX, aY );

			return this;

		}

		/**
		 * Adds an instance of {@link CubicBezierCurve} to the path by connecting
		 * the current point with the given one.
		 *
		 * @param {number} aCP1x - The x coordinate of the first control point.
		 * @param {number} aCP1y - The y coordinate of the first control point.
		 * @param {number} aCP2x - The x coordinate of the second control point.
		 * @param {number} aCP2y - The y coordinate of the second control point.
		 * @param {number} aX - The x coordinate of the end point.
		 * @param {number} aY - The y coordinate of the end point.
		 * @return {ShapePath} A reference to this shape path.
		 */
		bezierCurveTo( aCP1x, aCP1y, aCP2x, aCP2y, aX, aY ) {

			this.currentPath.bezierCurveTo( aCP1x, aCP1y, aCP2x, aCP2y, aX, aY );

			return this;

		}

		/**
		 * Adds an instance of {@link SplineCurve} to the path by connecting
		 * the current point with the given list of points.
		 *
		 * @param {Array<Vector2>} pts - An array of points in 2D space.
		 * @return {ShapePath} A reference to this shape path.
		 */
		splineThru( pts ) {

			this.currentPath.splineThru( pts );

			return this;

		}

		/**
		 * Converts the paths into an array of shapes.
		 *
		 * @param {boolean} isCCW - By default solid shapes are  defined clockwise (CW) and holes are defined counterclockwise (CCW).
		 * If this flag is set to `true`, then those are flipped.
		 * @return {Array<Shape>} An array of shapes.
		 */
		toShapes( isCCW ) {

			function toShapesNoHoles( inSubpaths ) {

				const shapes = [];

				for ( let i = 0, l = inSubpaths.length; i < l; i ++ ) {

					const tmpPath = inSubpaths[ i ];

					const tmpShape = new Shape();
					tmpShape.curves = tmpPath.curves;

					shapes.push( tmpShape );

				}

				return shapes;

			}

			function isPointInsidePolygon( inPt, inPolygon ) {

				const polyLen = inPolygon.length;

				// inPt on polygon contour => immediate success    or
				// toggling of inside/outside at every single! intersection point of an edge
				//  with the horizontal line through inPt, left of inPt
				//  not counting lowerY endpoints of edges and whole edges on that line
				let inside = false;
				for ( let p = polyLen - 1, q = 0; q < polyLen; p = q ++ ) {

					let edgeLowPt = inPolygon[ p ];
					let edgeHighPt = inPolygon[ q ];

					let edgeDx = edgeHighPt.x - edgeLowPt.x;
					let edgeDy = edgeHighPt.y - edgeLowPt.y;

					if ( Math.abs( edgeDy ) > Number.EPSILON ) {

						// not parallel
						if ( edgeDy < 0 ) {

							edgeLowPt = inPolygon[ q ]; edgeDx = - edgeDx;
							edgeHighPt = inPolygon[ p ]; edgeDy = - edgeDy;

						}

						if ( ( inPt.y < edgeLowPt.y ) || ( inPt.y > edgeHighPt.y ) ) 		continue;

						if ( inPt.y === edgeLowPt.y ) {

							if ( inPt.x === edgeLowPt.x )		return	true;		// inPt is on contour ?
							// continue;				// no intersection or edgeLowPt => doesn't count !!!

						} else {

							const perpEdge = edgeDy * ( inPt.x - edgeLowPt.x ) - edgeDx * ( inPt.y - edgeLowPt.y );
							if ( perpEdge === 0 )				return	true;		// inPt is on contour ?
							if ( perpEdge < 0 ) 				continue;
							inside = ! inside;		// true intersection left of inPt

						}

					} else {

						// parallel or collinear
						if ( inPt.y !== edgeLowPt.y ) 		continue;			// parallel
						// edge lies on the same horizontal line as inPt
						if ( ( ( edgeHighPt.x <= inPt.x ) && ( inPt.x <= edgeLowPt.x ) ) ||
							 ( ( edgeLowPt.x <= inPt.x ) && ( inPt.x <= edgeHighPt.x ) ) )		return	true;	// inPt: Point on contour !
						// continue;

					}

				}

				return	inside;

			}

			const isClockWise = ShapeUtils.isClockWise;

			const subPaths = this.subPaths;
			if ( subPaths.length === 0 ) return [];

			let solid, tmpPath, tmpShape;
			const shapes = [];

			if ( subPaths.length === 1 ) {

				tmpPath = subPaths[ 0 ];
				tmpShape = new Shape();
				tmpShape.curves = tmpPath.curves;
				shapes.push( tmpShape );
				return shapes;

			}

			let holesFirst = ! isClockWise( subPaths[ 0 ].getPoints() );
			holesFirst = isCCW ? ! holesFirst : holesFirst;

			// console.log("Holes first", holesFirst);

			const betterShapeHoles = [];
			const newShapes = [];
			let newShapeHoles = [];
			let mainIdx = 0;
			let tmpPoints;

			newShapes[ mainIdx ] = undefined;
			newShapeHoles[ mainIdx ] = [];

			for ( let i = 0, l = subPaths.length; i < l; i ++ ) {

				tmpPath = subPaths[ i ];
				tmpPoints = tmpPath.getPoints();
				solid = isClockWise( tmpPoints );
				solid = isCCW ? ! solid : solid;

				if ( solid ) {

					if ( ( ! holesFirst ) && ( newShapes[ mainIdx ] ) )	mainIdx ++;

					newShapes[ mainIdx ] = { s: new Shape(), p: tmpPoints };
					newShapes[ mainIdx ].s.curves = tmpPath.curves;

					if ( holesFirst )	mainIdx ++;
					newShapeHoles[ mainIdx ] = [];

					//console.log('cw', i);

				} else {

					newShapeHoles[ mainIdx ].push( { h: tmpPath, p: tmpPoints[ 0 ] } );

					//console.log('ccw', i);

				}

			}

			// only Holes? -> probably all Shapes with wrong orientation
			if ( ! newShapes[ 0 ] )	return	toShapesNoHoles( subPaths );


			if ( newShapes.length > 1 ) {

				let ambiguous = false;
				let toChange = 0;

				for ( let sIdx = 0, sLen = newShapes.length; sIdx < sLen; sIdx ++ ) {

					betterShapeHoles[ sIdx ] = [];

				}

				for ( let sIdx = 0, sLen = newShapes.length; sIdx < sLen; sIdx ++ ) {

					const sho = newShapeHoles[ sIdx ];

					for ( let hIdx = 0; hIdx < sho.length; hIdx ++ ) {

						const ho = sho[ hIdx ];
						let hole_unassigned = true;

						for ( let s2Idx = 0; s2Idx < newShapes.length; s2Idx ++ ) {

							if ( isPointInsidePolygon( ho.p, newShapes[ s2Idx ].p ) ) {

								if ( sIdx !== s2Idx )	toChange ++;

								if ( hole_unassigned ) {

									hole_unassigned = false;
									betterShapeHoles[ s2Idx ].push( ho );

								} else {

									ambiguous = true;

								}

							}

						}

						if ( hole_unassigned ) {

							betterShapeHoles[ sIdx ].push( ho );

						}

					}

				}

				if ( toChange > 0 && ambiguous === false ) {

					newShapeHoles = betterShapeHoles;

				}

			}

			let tmpHoles;

			for ( let i = 0, il = newShapes.length; i < il; i ++ ) {

				tmpShape = newShapes[ i ].s;
				shapes.push( tmpShape );
				tmpHoles = newShapeHoles[ i ];

				for ( let j = 0, jl = tmpHoles.length; j < jl; j ++ ) {

					tmpShape.holes.push( tmpHoles[ j ].h );

				}

			}

			//console.log("shape", shapes);

			return shapes;

		}

	}

	/**
	 * Abstract base class for controls.
	 *
	 * @abstract
	 * @augments EventDispatcher
	 */
	class Controls extends EventDispatcher {

		/**
		 * Constructs a new controls instance.
		 *
		 * @param {Object3D} object - The object that is managed by the controls.
		 * @param {?HTMLDOMElement} domElement - The HTML element used for event listeners.
		 */
		constructor( object, domElement = null ) {

			super();

			/**
			 * The object that is managed by the controls.
			 *
			 * @type {Object3D}
			 */
			this.object = object;

			/**
			 * The HTML element used for event listeners.
			 *
			 * @type {?HTMLDOMElement}
			 * @default null
			 */
			this.domElement = domElement;

			/**
			 * Whether the controls responds to user input or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.enabled = true;

			/**
			 * The internal state of the controls.
			 *
			 * @type {number}
			 * @default -1
			 */
			this.state = -1;

			/**
			 * This object defines the keyboard input of the controls.
			 *
			 * @type {Object}
			 */
			this.keys = {};

			/**
			 * This object defines what type of actions are assigned to the available mouse buttons.
			 * It depends on the control implementation what kind of mouse buttons and actions are supported.
			 *
			 * @type {{LEFT: ?number, MIDDLE: ?number, RIGHT: ?number}}
			 */
			this.mouseButtons = { LEFT: null, MIDDLE: null, RIGHT: null };

			/**
			 * This object defines what type of actions are assigned to what kind of touch interaction.
			 * It depends on the control implementation what kind of touch interaction and actions are supported.
			 *
			 * @type {{ONE: ?number, TWO: ?number}}
			 */
			this.touches = { ONE: null, TWO: null };

		}

		/**
		 * Connects the controls to the DOM. This method has so called "side effects" since
		 * it adds the module's event listeners to the DOM.
		 *
		 * @param {HTMLDOMElement} element - The DOM element to connect to.
		 */
		connect( element ) {

			if ( element === undefined ) {

				console.warn( 'THREE.Controls: connect() now requires an element.' ); // @deprecated, the warning can be removed with r185
				return;

			}

			if ( this.domElement !== null ) this.disconnect();

			this.domElement = element;

		}

		/**
		 * Disconnects the controls from the DOM.
		 */
		disconnect() {}

		/**
		 * Call this method if you no longer want use to the controls. It frees all internal
		 * resources and removes all event listeners.
		 */
		dispose() {}

		/**
		 * Controls should implement this method if they have to update their internal state
		 * per simulation step.
		 *
		 * @param {number} [delta] - The time delta in seconds.
		 */
		update( /* delta */ ) {}

	}

	/**
	 * Determines how many bytes must be used to represent the texture.
	 *
	 * @param {number} width - The width of the texture.
	 * @param {number} height - The height of the texture.
	 * @param {number} format - The texture's format.
	 * @param {number} type - The texture's type.
	 * @return {number} The byte length.
	 */
	function getByteLength( width, height, format, type ) {

		const typeByteLength = getTextureTypeByteLength( type );

		switch ( format ) {

			// https://registry.khronos.org/OpenGL-Refpages/es3.0/html/glTexImage2D.xhtml
			case AlphaFormat:
				return width * height;
			case RedFormat:
				return ( ( width * height ) / typeByteLength.components ) * typeByteLength.byteLength;
			case RedIntegerFormat:
				return ( ( width * height ) / typeByteLength.components ) * typeByteLength.byteLength;
			case RGFormat:
				return ( ( width * height * 2 ) / typeByteLength.components ) * typeByteLength.byteLength;
			case RGIntegerFormat:
				return ( ( width * height * 2 ) / typeByteLength.components ) * typeByteLength.byteLength;
			case RGBFormat:
				return ( ( width * height * 3 ) / typeByteLength.components ) * typeByteLength.byteLength;
			case RGBAFormat:
				return ( ( width * height * 4 ) / typeByteLength.components ) * typeByteLength.byteLength;
			case RGBAIntegerFormat:
				return ( ( width * height * 4 ) / typeByteLength.components ) * typeByteLength.byteLength;

			// https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_s3tc_srgb/
			case RGB_S3TC_DXT1_Format:
			case RGBA_S3TC_DXT1_Format:
				return Math.floor( ( width + 3 ) / 4 ) * Math.floor( ( height + 3 ) / 4 ) * 8;
			case RGBA_S3TC_DXT3_Format:
			case RGBA_S3TC_DXT5_Format:
				return Math.floor( ( width + 3 ) / 4 ) * Math.floor( ( height + 3 ) / 4 ) * 16;

			// https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_pvrtc/
			case RGB_PVRTC_2BPPV1_Format:
			case RGBA_PVRTC_2BPPV1_Format:
				return ( Math.max( width, 16 ) * Math.max( height, 8 ) ) / 4;
			case RGB_PVRTC_4BPPV1_Format:
			case RGBA_PVRTC_4BPPV1_Format:
				return ( Math.max( width, 8 ) * Math.max( height, 8 ) ) / 2;

			// https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_etc/
			case RGB_ETC1_Format:
			case RGB_ETC2_Format:
				return Math.floor( ( width + 3 ) / 4 ) * Math.floor( ( height + 3 ) / 4 ) * 8;
			case RGBA_ETC2_EAC_Format:
				return Math.floor( ( width + 3 ) / 4 ) * Math.floor( ( height + 3 ) / 4 ) * 16;

			// https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_astc/
			case RGBA_ASTC_4x4_Format:
				return Math.floor( ( width + 3 ) / 4 ) * Math.floor( ( height + 3 ) / 4 ) * 16;
			case RGBA_ASTC_5x4_Format:
				return Math.floor( ( width + 4 ) / 5 ) * Math.floor( ( height + 3 ) / 4 ) * 16;
			case RGBA_ASTC_5x5_Format:
				return Math.floor( ( width + 4 ) / 5 ) * Math.floor( ( height + 4 ) / 5 ) * 16;
			case RGBA_ASTC_6x5_Format:
				return Math.floor( ( width + 5 ) / 6 ) * Math.floor( ( height + 4 ) / 5 ) * 16;
			case RGBA_ASTC_6x6_Format:
				return Math.floor( ( width + 5 ) / 6 ) * Math.floor( ( height + 5 ) / 6 ) * 16;
			case RGBA_ASTC_8x5_Format:
				return Math.floor( ( width + 7 ) / 8 ) * Math.floor( ( height + 4 ) / 5 ) * 16;
			case RGBA_ASTC_8x6_Format:
				return Math.floor( ( width + 7 ) / 8 ) * Math.floor( ( height + 5 ) / 6 ) * 16;
			case RGBA_ASTC_8x8_Format:
				return Math.floor( ( width + 7 ) / 8 ) * Math.floor( ( height + 7 ) / 8 ) * 16;
			case RGBA_ASTC_10x5_Format:
				return Math.floor( ( width + 9 ) / 10 ) * Math.floor( ( height + 4 ) / 5 ) * 16;
			case RGBA_ASTC_10x6_Format:
				return Math.floor( ( width + 9 ) / 10 ) * Math.floor( ( height + 5 ) / 6 ) * 16;
			case RGBA_ASTC_10x8_Format:
				return Math.floor( ( width + 9 ) / 10 ) * Math.floor( ( height + 7 ) / 8 ) * 16;
			case RGBA_ASTC_10x10_Format:
				return Math.floor( ( width + 9 ) / 10 ) * Math.floor( ( height + 9 ) / 10 ) * 16;
			case RGBA_ASTC_12x10_Format:
				return Math.floor( ( width + 11 ) / 12 ) * Math.floor( ( height + 9 ) / 10 ) * 16;
			case RGBA_ASTC_12x12_Format:
				return Math.floor( ( width + 11 ) / 12 ) * Math.floor( ( height + 11 ) / 12 ) * 16;

			// https://registry.khronos.org/webgl/extensions/EXT_texture_compression_bptc/
			case RGBA_BPTC_Format:
			case RGB_BPTC_SIGNED_Format:
			case RGB_BPTC_UNSIGNED_Format:
				return Math.ceil( width / 4 ) * Math.ceil( height / 4 ) * 16;

			// https://registry.khronos.org/webgl/extensions/EXT_texture_compression_rgtc/
			case RED_RGTC1_Format:
			case SIGNED_RED_RGTC1_Format:
				return Math.ceil( width / 4 ) * Math.ceil( height / 4 ) * 8;
			case RED_GREEN_RGTC2_Format:
			case SIGNED_RED_GREEN_RGTC2_Format:
				return Math.ceil( width / 4 ) * Math.ceil( height / 4 ) * 16;

		}

		throw new Error(
			`Unable to determine texture byte length for ${format} format.`,
		);

	}

	function getTextureTypeByteLength( type ) {

		switch ( type ) {

			case UnsignedByteType:
			case ByteType:
				return { byteLength: 1, components: 1 };
			case UnsignedShortType:
			case ShortType:
			case HalfFloatType:
				return { byteLength: 2, components: 1 };
			case UnsignedShort4444Type:
			case UnsignedShort5551Type:
				return { byteLength: 2, components: 4 };
			case UnsignedIntType:
			case IntType:
			case FloatType:
				return { byteLength: 4, components: 1 };
			case UnsignedInt5999Type:
				return { byteLength: 4, components: 3 };

		}

		throw new Error( `Unknown texture type ${type}.` );

	}

	if ( typeof __THREE_DEVTOOLS__ !== 'undefined' ) {

		__THREE_DEVTOOLS__.dispatchEvent( new CustomEvent( 'register', { detail: {
			revision: REVISION,
		} } ) );

	}

	if ( typeof window !== 'undefined' ) {

		if ( window.__THREE__ ) {

			console.warn( 'WARNING: Multiple instances of Three.js being imported.' );

		} else {

			window.__THREE__ = REVISION;

		}

	}

	/**
	 * @license
	 * Copyright 2010-2025 Three.js Authors
	 * SPDX-License-Identifier: MIT
	 */

	function WebGLAnimation() {

		let context = null;
		let isAnimating = false;
		let animationLoop = null;
		let requestId = null;

		function onAnimationFrame( time, frame ) {

			animationLoop( time, frame );

			requestId = context.requestAnimationFrame( onAnimationFrame );

		}

		return {

			start: function () {

				if ( isAnimating === true ) return;
				if ( animationLoop === null ) return;

				requestId = context.requestAnimationFrame( onAnimationFrame );

				isAnimating = true;

			},

			stop: function () {

				context.cancelAnimationFrame( requestId );

				isAnimating = false;

			},

			setAnimationLoop: function ( callback ) {

				animationLoop = callback;

			},

			setContext: function ( value ) {

				context = value;

			}

		};

	}

	function WebGLAttributes( gl ) {

		const buffers = new WeakMap();

		function createBuffer( attribute, bufferType ) {

			const array = attribute.array;
			const usage = attribute.usage;
			const size = array.byteLength;

			const buffer = gl.createBuffer();

			gl.bindBuffer( bufferType, buffer );
			gl.bufferData( bufferType, array, usage );

			attribute.onUploadCallback();

			let type;

			if ( array instanceof Float32Array ) {

				type = gl.FLOAT;

			} else if ( array instanceof Uint16Array ) {

				if ( attribute.isFloat16BufferAttribute ) {

					type = gl.HALF_FLOAT;

				} else {

					type = gl.UNSIGNED_SHORT;

				}

			} else if ( array instanceof Int16Array ) {

				type = gl.SHORT;

			} else if ( array instanceof Uint32Array ) {

				type = gl.UNSIGNED_INT;

			} else if ( array instanceof Int32Array ) {

				type = gl.INT;

			} else if ( array instanceof Int8Array ) {

				type = gl.BYTE;

			} else if ( array instanceof Uint8Array ) {

				type = gl.UNSIGNED_BYTE;

			} else if ( array instanceof Uint8ClampedArray ) {

				type = gl.UNSIGNED_BYTE;

			} else {

				throw new Error( 'THREE.WebGLAttributes: Unsupported buffer data format: ' + array );

			}

			return {
				buffer: buffer,
				type: type,
				bytesPerElement: array.BYTES_PER_ELEMENT,
				version: attribute.version,
				size: size
			};

		}

		function updateBuffer( buffer, attribute, bufferType ) {

			const array = attribute.array;
			const updateRanges = attribute.updateRanges;

			gl.bindBuffer( bufferType, buffer );

			if ( updateRanges.length === 0 ) {

				// Not using update ranges
				gl.bufferSubData( bufferType, 0, array );

			} else {

				// Before applying update ranges, we merge any adjacent / overlapping
				// ranges to reduce load on `gl.bufferSubData`. Empirically, this has led
				// to performance improvements for applications which make heavy use of
				// update ranges. Likely due to GPU command overhead.
				//
				// Note that to reduce garbage collection between frames, we merge the
				// update ranges in-place. This is safe because this method will clear the
				// update ranges once updated.

				updateRanges.sort( ( a, b ) => a.start - b.start );

				// To merge the update ranges in-place, we work from left to right in the
				// existing updateRanges array, merging ranges. This may result in a final
				// array which is smaller than the original. This index tracks the last
				// index representing a merged range, any data after this index can be
				// trimmed once the merge algorithm is completed.
				let mergeIndex = 0;

				for ( let i = 1; i < updateRanges.length; i ++ ) {

					const previousRange = updateRanges[ mergeIndex ];
					const range = updateRanges[ i ];

					// We add one here to merge adjacent ranges. This is safe because ranges
					// operate over positive integers.
					if ( range.start <= previousRange.start + previousRange.count + 1 ) {

						previousRange.count = Math.max(
							previousRange.count,
							range.start + range.count - previousRange.start
						);

					} else {

						++ mergeIndex;
						updateRanges[ mergeIndex ] = range;

					}

				}

				// Trim the array to only contain the merged ranges.
				updateRanges.length = mergeIndex + 1;

				for ( let i = 0, l = updateRanges.length; i < l; i ++ ) {

					const range = updateRanges[ i ];

					gl.bufferSubData( bufferType, range.start * array.BYTES_PER_ELEMENT,
						array, range.start, range.count );

				}

				attribute.clearUpdateRanges();

			}

			attribute.onUploadCallback();

		}

		//

		function get( attribute ) {

			if ( attribute.isInterleavedBufferAttribute ) attribute = attribute.data;

			return buffers.get( attribute );

		}

		function remove( attribute ) {

			if ( attribute.isInterleavedBufferAttribute ) attribute = attribute.data;

			const data = buffers.get( attribute );

			if ( data ) {

				gl.deleteBuffer( data.buffer );

				buffers.delete( attribute );

			}

		}

		function update( attribute, bufferType ) {

			if ( attribute.isInterleavedBufferAttribute ) attribute = attribute.data;

			if ( attribute.isGLBufferAttribute ) {

				const cached = buffers.get( attribute );

				if ( ! cached || cached.version < attribute.version ) {

					buffers.set( attribute, {
						buffer: attribute.buffer,
						type: attribute.type,
						bytesPerElement: attribute.elementSize,
						version: attribute.version
					} );

				}

				return;

			}

			const data = buffers.get( attribute );

			if ( data === undefined ) {

				buffers.set( attribute, createBuffer( attribute, bufferType ) );

			} else if ( data.version < attribute.version ) {

				if ( data.size !== attribute.array.byteLength ) {

					throw new Error( 'THREE.WebGLAttributes: The size of the buffer attribute\'s array buffer does not match the original size. Resizing buffer attributes is not supported.' );

				}

				updateBuffer( data.buffer, attribute, bufferType );

				data.version = attribute.version;

			}

		}

		return {

			get: get,
			remove: remove,
			update: update

		};

	}

	var alphahash_fragment = "#ifdef USE_ALPHAHASH\n\tif ( diffuseColor.a < getAlphaHashThreshold( vPosition ) ) discard;\n#endif";

	var alphahash_pars_fragment = "#ifdef USE_ALPHAHASH\n\tconst float ALPHA_HASH_SCALE = 0.05;\n\tfloat hash2D( vec2 value ) {\n\t\treturn fract( 1.0e4 * sin( 17.0 * value.x + 0.1 * value.y ) * ( 0.1 + abs( sin( 13.0 * value.y + value.x ) ) ) );\n\t}\n\tfloat hash3D( vec3 value ) {\n\t\treturn hash2D( vec2( hash2D( value.xy ), value.z ) );\n\t}\n\tfloat getAlphaHashThreshold( vec3 position ) {\n\t\tfloat maxDeriv = max(\n\t\t\tlength( dFdx( position.xyz ) ),\n\t\t\tlength( dFdy( position.xyz ) )\n\t\t);\n\t\tfloat pixScale = 1.0 / ( ALPHA_HASH_SCALE * maxDeriv );\n\t\tvec2 pixScales = vec2(\n\t\t\texp2( floor( log2( pixScale ) ) ),\n\t\t\texp2( ceil( log2( pixScale ) ) )\n\t\t);\n\t\tvec2 alpha = vec2(\n\t\t\thash3D( floor( pixScales.x * position.xyz ) ),\n\t\t\thash3D( floor( pixScales.y * position.xyz ) )\n\t\t);\n\t\tfloat lerpFactor = fract( log2( pixScale ) );\n\t\tfloat x = ( 1.0 - lerpFactor ) * alpha.x + lerpFactor * alpha.y;\n\t\tfloat a = min( lerpFactor, 1.0 - lerpFactor );\n\t\tvec3 cases = vec3(\n\t\t\tx * x / ( 2.0 * a * ( 1.0 - a ) ),\n\t\t\t( x - 0.5 * a ) / ( 1.0 - a ),\n\t\t\t1.0 - ( ( 1.0 - x ) * ( 1.0 - x ) / ( 2.0 * a * ( 1.0 - a ) ) )\n\t\t);\n\t\tfloat threshold = ( x < ( 1.0 - a ) )\n\t\t\t? ( ( x < a ) ? cases.x : cases.y )\n\t\t\t: cases.z;\n\t\treturn clamp( threshold , 1.0e-6, 1.0 );\n\t}\n#endif";

	var alphamap_fragment = "#ifdef USE_ALPHAMAP\n\tdiffuseColor.a *= texture2D( alphaMap, vAlphaMapUv ).g;\n#endif";

	var alphamap_pars_fragment = "#ifdef USE_ALPHAMAP\n\tuniform sampler2D alphaMap;\n#endif";

	var alphatest_fragment = "#ifdef USE_ALPHATEST\n\t#ifdef ALPHA_TO_COVERAGE\n\tdiffuseColor.a = smoothstep( alphaTest, alphaTest + fwidth( diffuseColor.a ), diffuseColor.a );\n\tif ( diffuseColor.a == 0.0 ) discard;\n\t#else\n\tif ( diffuseColor.a < alphaTest ) discard;\n\t#endif\n#endif";

	var alphatest_pars_fragment = "#ifdef USE_ALPHATEST\n\tuniform float alphaTest;\n#endif";

	var aomap_fragment = "#ifdef USE_AOMAP\n\tfloat ambientOcclusion = ( texture2D( aoMap, vAoMapUv ).r - 1.0 ) * aoMapIntensity + 1.0;\n\treflectedLight.indirectDiffuse *= ambientOcclusion;\n\t#if defined( USE_CLEARCOAT ) \n\t\tclearcoatSpecularIndirect *= ambientOcclusion;\n\t#endif\n\t#if defined( USE_SHEEN ) \n\t\tsheenSpecularIndirect *= ambientOcclusion;\n\t#endif\n\t#if defined( USE_ENVMAP ) && defined( STANDARD )\n\t\tfloat dotNV = saturate( dot( geometryNormal, geometryViewDir ) );\n\t\treflectedLight.indirectSpecular *= computeSpecularOcclusion( dotNV, ambientOcclusion, material.roughness );\n\t#endif\n#endif";

	var aomap_pars_fragment = "#ifdef USE_AOMAP\n\tuniform sampler2D aoMap;\n\tuniform float aoMapIntensity;\n#endif";

	var batching_pars_vertex = "#ifdef USE_BATCHING\n\t#if ! defined( GL_ANGLE_multi_draw )\n\t#define gl_DrawID _gl_DrawID\n\tuniform int _gl_DrawID;\n\t#endif\n\tuniform highp sampler2D batchingTexture;\n\tuniform highp usampler2D batchingIdTexture;\n\tmat4 getBatchingMatrix( const in float i ) {\n\t\tint size = textureSize( batchingTexture, 0 ).x;\n\t\tint j = int( i ) * 4;\n\t\tint x = j % size;\n\t\tint y = j / size;\n\t\tvec4 v1 = texelFetch( batchingTexture, ivec2( x, y ), 0 );\n\t\tvec4 v2 = texelFetch( batchingTexture, ivec2( x + 1, y ), 0 );\n\t\tvec4 v3 = texelFetch( batchingTexture, ivec2( x + 2, y ), 0 );\n\t\tvec4 v4 = texelFetch( batchingTexture, ivec2( x + 3, y ), 0 );\n\t\treturn mat4( v1, v2, v3, v4 );\n\t}\n\tfloat getIndirectIndex( const in int i ) {\n\t\tint size = textureSize( batchingIdTexture, 0 ).x;\n\t\tint x = i % size;\n\t\tint y = i / size;\n\t\treturn float( texelFetch( batchingIdTexture, ivec2( x, y ), 0 ).r );\n\t}\n#endif\n#ifdef USE_BATCHING_COLOR\n\tuniform sampler2D batchingColorTexture;\n\tvec3 getBatchingColor( const in float i ) {\n\t\tint size = textureSize( batchingColorTexture, 0 ).x;\n\t\tint j = int( i );\n\t\tint x = j % size;\n\t\tint y = j / size;\n\t\treturn texelFetch( batchingColorTexture, ivec2( x, y ), 0 ).rgb;\n\t}\n#endif";

	var batching_vertex = "#ifdef USE_BATCHING\n\tmat4 batchingMatrix = getBatchingMatrix( getIndirectIndex( gl_DrawID ) );\n#endif";

	var begin_vertex = "vec3 transformed = vec3( position );\n#ifdef USE_ALPHAHASH\n\tvPosition = vec3( position );\n#endif";

	var beginnormal_vertex = "vec3 objectNormal = vec3( normal );\n#ifdef USE_TANGENT\n\tvec3 objectTangent = vec3( tangent.xyz );\n#endif";

	var bsdfs = "float G_BlinnPhong_Implicit( ) {\n\treturn 0.25;\n}\nfloat D_BlinnPhong( const in float shininess, const in float dotNH ) {\n\treturn RECIPROCAL_PI * ( shininess * 0.5 + 1.0 ) * pow( dotNH, shininess );\n}\nvec3 BRDF_BlinnPhong( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in vec3 specularColor, const in float shininess ) {\n\tvec3 halfDir = normalize( lightDir + viewDir );\n\tfloat dotNH = saturate( dot( normal, halfDir ) );\n\tfloat dotVH = saturate( dot( viewDir, halfDir ) );\n\tvec3 F = F_Schlick( specularColor, 1.0, dotVH );\n\tfloat G = G_BlinnPhong_Implicit( );\n\tfloat D = D_BlinnPhong( shininess, dotNH );\n\treturn F * ( G * D );\n} // validated";

	var iridescence_fragment = "#ifdef USE_IRIDESCENCE\n\tconst mat3 XYZ_TO_REC709 = mat3(\n\t\t 3.2404542, -0.9692660,  0.0556434,\n\t\t-1.5371385,  1.8760108, -0.2040259,\n\t\t-0.4985314,  0.0415560,  1.0572252\n\t);\n\tvec3 Fresnel0ToIor( vec3 fresnel0 ) {\n\t\tvec3 sqrtF0 = sqrt( fresnel0 );\n\t\treturn ( vec3( 1.0 ) + sqrtF0 ) / ( vec3( 1.0 ) - sqrtF0 );\n\t}\n\tvec3 IorToFresnel0( vec3 transmittedIor, float incidentIor ) {\n\t\treturn pow2( ( transmittedIor - vec3( incidentIor ) ) / ( transmittedIor + vec3( incidentIor ) ) );\n\t}\n\tfloat IorToFresnel0( float transmittedIor, float incidentIor ) {\n\t\treturn pow2( ( transmittedIor - incidentIor ) / ( transmittedIor + incidentIor ));\n\t}\n\tvec3 evalSensitivity( float OPD, vec3 shift ) {\n\t\tfloat phase = 2.0 * PI * OPD * 1.0e-9;\n\t\tvec3 val = vec3( 5.4856e-13, 4.4201e-13, 5.2481e-13 );\n\t\tvec3 pos = vec3( 1.6810e+06, 1.7953e+06, 2.2084e+06 );\n\t\tvec3 var = vec3( 4.3278e+09, 9.3046e+09, 6.6121e+09 );\n\t\tvec3 xyz = val * sqrt( 2.0 * PI * var ) * cos( pos * phase + shift ) * exp( - pow2( phase ) * var );\n\t\txyz.x += 9.7470e-14 * sqrt( 2.0 * PI * 4.5282e+09 ) * cos( 2.2399e+06 * phase + shift[ 0 ] ) * exp( - 4.5282e+09 * pow2( phase ) );\n\t\txyz /= 1.0685e-7;\n\t\tvec3 rgb = XYZ_TO_REC709 * xyz;\n\t\treturn rgb;\n\t}\n\tvec3 evalIridescence( float outsideIOR, float eta2, float cosTheta1, float thinFilmThickness, vec3 baseF0 ) {\n\t\tvec3 I;\n\t\tfloat iridescenceIOR = mix( outsideIOR, eta2, smoothstep( 0.0, 0.03, thinFilmThickness ) );\n\t\tfloat sinTheta2Sq = pow2( outsideIOR / iridescenceIOR ) * ( 1.0 - pow2( cosTheta1 ) );\n\t\tfloat cosTheta2Sq = 1.0 - sinTheta2Sq;\n\t\tif ( cosTheta2Sq < 0.0 ) {\n\t\t\treturn vec3( 1.0 );\n\t\t}\n\t\tfloat cosTheta2 = sqrt( cosTheta2Sq );\n\t\tfloat R0 = IorToFresnel0( iridescenceIOR, outsideIOR );\n\t\tfloat R12 = F_Schlick( R0, 1.0, cosTheta1 );\n\t\tfloat T121 = 1.0 - R12;\n\t\tfloat phi12 = 0.0;\n\t\tif ( iridescenceIOR < outsideIOR ) phi12 = PI;\n\t\tfloat phi21 = PI - phi12;\n\t\tvec3 baseIOR = Fresnel0ToIor( clamp( baseF0, 0.0, 0.9999 ) );\t\tvec3 R1 = IorToFresnel0( baseIOR, iridescenceIOR );\n\t\tvec3 R23 = F_Schlick( R1, 1.0, cosTheta2 );\n\t\tvec3 phi23 = vec3( 0.0 );\n\t\tif ( baseIOR[ 0 ] < iridescenceIOR ) phi23[ 0 ] = PI;\n\t\tif ( baseIOR[ 1 ] < iridescenceIOR ) phi23[ 1 ] = PI;\n\t\tif ( baseIOR[ 2 ] < iridescenceIOR ) phi23[ 2 ] = PI;\n\t\tfloat OPD = 2.0 * iridescenceIOR * thinFilmThickness * cosTheta2;\n\t\tvec3 phi = vec3( phi21 ) + phi23;\n\t\tvec3 R123 = clamp( R12 * R23, 1e-5, 0.9999 );\n\t\tvec3 r123 = sqrt( R123 );\n\t\tvec3 Rs = pow2( T121 ) * R23 / ( vec3( 1.0 ) - R123 );\n\t\tvec3 C0 = R12 + Rs;\n\t\tI = C0;\n\t\tvec3 Cm = Rs - T121;\n\t\tfor ( int m = 1; m <= 2; ++ m ) {\n\t\t\tCm *= r123;\n\t\t\tvec3 Sm = 2.0 * evalSensitivity( float( m ) * OPD, float( m ) * phi );\n\t\t\tI += Cm * Sm;\n\t\t}\n\t\treturn max( I, vec3( 0.0 ) );\n\t}\n#endif";

	var bumpmap_pars_fragment = "#ifdef USE_BUMPMAP\n\tuniform sampler2D bumpMap;\n\tuniform float bumpScale;\n\tvec2 dHdxy_fwd() {\n\t\tvec2 dSTdx = dFdx( vBumpMapUv );\n\t\tvec2 dSTdy = dFdy( vBumpMapUv );\n\t\tfloat Hll = bumpScale * texture2D( bumpMap, vBumpMapUv ).x;\n\t\tfloat dBx = bumpScale * texture2D( bumpMap, vBumpMapUv + dSTdx ).x - Hll;\n\t\tfloat dBy = bumpScale * texture2D( bumpMap, vBumpMapUv + dSTdy ).x - Hll;\n\t\treturn vec2( dBx, dBy );\n\t}\n\tvec3 perturbNormalArb( vec3 surf_pos, vec3 surf_norm, vec2 dHdxy, float faceDirection ) {\n\t\tvec3 vSigmaX = normalize( dFdx( surf_pos.xyz ) );\n\t\tvec3 vSigmaY = normalize( dFdy( surf_pos.xyz ) );\n\t\tvec3 vN = surf_norm;\n\t\tvec3 R1 = cross( vSigmaY, vN );\n\t\tvec3 R2 = cross( vN, vSigmaX );\n\t\tfloat fDet = dot( vSigmaX, R1 ) * faceDirection;\n\t\tvec3 vGrad = sign( fDet ) * ( dHdxy.x * R1 + dHdxy.y * R2 );\n\t\treturn normalize( abs( fDet ) * surf_norm - vGrad );\n\t}\n#endif";

	var clipping_planes_fragment = "#if NUM_CLIPPING_PLANES > 0\n\tvec4 plane;\n\t#ifdef ALPHA_TO_COVERAGE\n\t\tfloat distanceToPlane, distanceGradient;\n\t\tfloat clipOpacity = 1.0;\n\t\t#pragma unroll_loop_start\n\t\tfor ( int i = 0; i < UNION_CLIPPING_PLANES; i ++ ) {\n\t\t\tplane = clippingPlanes[ i ];\n\t\t\tdistanceToPlane = - dot( vClipPosition, plane.xyz ) + plane.w;\n\t\t\tdistanceGradient = fwidth( distanceToPlane ) / 2.0;\n\t\t\tclipOpacity *= smoothstep( - distanceGradient, distanceGradient, distanceToPlane );\n\t\t\tif ( clipOpacity == 0.0 ) discard;\n\t\t}\n\t\t#pragma unroll_loop_end\n\t\t#if UNION_CLIPPING_PLANES < NUM_CLIPPING_PLANES\n\t\t\tfloat unionClipOpacity = 1.0;\n\t\t\t#pragma unroll_loop_start\n\t\t\tfor ( int i = UNION_CLIPPING_PLANES; i < NUM_CLIPPING_PLANES; i ++ ) {\n\t\t\t\tplane = clippingPlanes[ i ];\n\t\t\t\tdistanceToPlane = - dot( vClipPosition, plane.xyz ) + plane.w;\n\t\t\t\tdistanceGradient = fwidth( distanceToPlane ) / 2.0;\n\t\t\t\tunionClipOpacity *= 1.0 - smoothstep( - distanceGradient, distanceGradient, distanceToPlane );\n\t\t\t}\n\t\t\t#pragma unroll_loop_end\n\t\t\tclipOpacity *= 1.0 - unionClipOpacity;\n\t\t#endif\n\t\tdiffuseColor.a *= clipOpacity;\n\t\tif ( diffuseColor.a == 0.0 ) discard;\n\t#else\n\t\t#pragma unroll_loop_start\n\t\tfor ( int i = 0; i < UNION_CLIPPING_PLANES; i ++ ) {\n\t\t\tplane = clippingPlanes[ i ];\n\t\t\tif ( dot( vClipPosition, plane.xyz ) > plane.w ) discard;\n\t\t}\n\t\t#pragma unroll_loop_end\n\t\t#if UNION_CLIPPING_PLANES < NUM_CLIPPING_PLANES\n\t\t\tbool clipped = true;\n\t\t\t#pragma unroll_loop_start\n\t\t\tfor ( int i = UNION_CLIPPING_PLANES; i < NUM_CLIPPING_PLANES; i ++ ) {\n\t\t\t\tplane = clippingPlanes[ i ];\n\t\t\t\tclipped = ( dot( vClipPosition, plane.xyz ) > plane.w ) && clipped;\n\t\t\t}\n\t\t\t#pragma unroll_loop_end\n\t\t\tif ( clipped ) discard;\n\t\t#endif\n\t#endif\n#endif";

	var clipping_planes_pars_fragment = "#if NUM_CLIPPING_PLANES > 0\n\tvarying vec3 vClipPosition;\n\tuniform vec4 clippingPlanes[ NUM_CLIPPING_PLANES ];\n#endif";

	var clipping_planes_pars_vertex = "#if NUM_CLIPPING_PLANES > 0\n\tvarying vec3 vClipPosition;\n#endif";

	var clipping_planes_vertex = "#if NUM_CLIPPING_PLANES > 0\n\tvClipPosition = - mvPosition.xyz;\n#endif";

	var color_fragment = "#if defined( USE_COLOR_ALPHA )\n\tdiffuseColor *= vColor;\n#elif defined( USE_COLOR )\n\tdiffuseColor.rgb *= vColor;\n#endif";

	var color_pars_fragment = "#if defined( USE_COLOR_ALPHA )\n\tvarying vec4 vColor;\n#elif defined( USE_COLOR )\n\tvarying vec3 vColor;\n#endif";

	var color_pars_vertex = "#if defined( USE_COLOR_ALPHA )\n\tvarying vec4 vColor;\n#elif defined( USE_COLOR ) || defined( USE_INSTANCING_COLOR ) || defined( USE_BATCHING_COLOR )\n\tvarying vec3 vColor;\n#endif";

	var color_vertex = "#if defined( USE_COLOR_ALPHA )\n\tvColor = vec4( 1.0 );\n#elif defined( USE_COLOR ) || defined( USE_INSTANCING_COLOR ) || defined( USE_BATCHING_COLOR )\n\tvColor = vec3( 1.0 );\n#endif\n#ifdef USE_COLOR\n\tvColor *= color;\n#endif\n#ifdef USE_INSTANCING_COLOR\n\tvColor.xyz *= instanceColor.xyz;\n#endif\n#ifdef USE_BATCHING_COLOR\n\tvec3 batchingColor = getBatchingColor( getIndirectIndex( gl_DrawID ) );\n\tvColor.xyz *= batchingColor.xyz;\n#endif";

	var common = "#define PI 3.141592653589793\n#define PI2 6.283185307179586\n#define PI_HALF 1.5707963267948966\n#define RECIPROCAL_PI 0.3183098861837907\n#define RECIPROCAL_PI2 0.15915494309189535\n#define EPSILON 1e-6\n#ifndef saturate\n#define saturate( a ) clamp( a, 0.0, 1.0 )\n#endif\n#define whiteComplement( a ) ( 1.0 - saturate( a ) )\nfloat pow2( const in float x ) { return x*x; }\nvec3 pow2( const in vec3 x ) { return x*x; }\nfloat pow3( const in float x ) { return x*x*x; }\nfloat pow4( const in float x ) { float x2 = x*x; return x2*x2; }\nfloat max3( const in vec3 v ) { return max( max( v.x, v.y ), v.z ); }\nfloat average( const in vec3 v ) { return dot( v, vec3( 0.3333333 ) ); }\nhighp float rand( const in vec2 uv ) {\n\tconst highp float a = 12.9898, b = 78.233, c = 43758.5453;\n\thighp float dt = dot( uv.xy, vec2( a,b ) ), sn = mod( dt, PI );\n\treturn fract( sin( sn ) * c );\n}\n#ifdef HIGH_PRECISION\n\tfloat precisionSafeLength( vec3 v ) { return length( v ); }\n#else\n\tfloat precisionSafeLength( vec3 v ) {\n\t\tfloat maxComponent = max3( abs( v ) );\n\t\treturn length( v / maxComponent ) * maxComponent;\n\t}\n#endif\nstruct IncidentLight {\n\tvec3 color;\n\tvec3 direction;\n\tbool visible;\n};\nstruct ReflectedLight {\n\tvec3 directDiffuse;\n\tvec3 directSpecular;\n\tvec3 indirectDiffuse;\n\tvec3 indirectSpecular;\n};\n#ifdef USE_ALPHAHASH\n\tvarying vec3 vPosition;\n#endif\nvec3 transformDirection( in vec3 dir, in mat4 matrix ) {\n\treturn normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );\n}\nvec3 inverseTransformDirection( in vec3 dir, in mat4 matrix ) {\n\treturn normalize( ( vec4( dir, 0.0 ) * matrix ).xyz );\n}\nmat3 transposeMat3( const in mat3 m ) {\n\tmat3 tmp;\n\ttmp[ 0 ] = vec3( m[ 0 ].x, m[ 1 ].x, m[ 2 ].x );\n\ttmp[ 1 ] = vec3( m[ 0 ].y, m[ 1 ].y, m[ 2 ].y );\n\ttmp[ 2 ] = vec3( m[ 0 ].z, m[ 1 ].z, m[ 2 ].z );\n\treturn tmp;\n}\nbool isPerspectiveMatrix( mat4 m ) {\n\treturn m[ 2 ][ 3 ] == - 1.0;\n}\nvec2 equirectUv( in vec3 dir ) {\n\tfloat u = atan( dir.z, dir.x ) * RECIPROCAL_PI2 + 0.5;\n\tfloat v = asin( clamp( dir.y, - 1.0, 1.0 ) ) * RECIPROCAL_PI + 0.5;\n\treturn vec2( u, v );\n}\nvec3 BRDF_Lambert( const in vec3 diffuseColor ) {\n\treturn RECIPROCAL_PI * diffuseColor;\n}\nvec3 F_Schlick( const in vec3 f0, const in float f90, const in float dotVH ) {\n\tfloat fresnel = exp2( ( - 5.55473 * dotVH - 6.98316 ) * dotVH );\n\treturn f0 * ( 1.0 - fresnel ) + ( f90 * fresnel );\n}\nfloat F_Schlick( const in float f0, const in float f90, const in float dotVH ) {\n\tfloat fresnel = exp2( ( - 5.55473 * dotVH - 6.98316 ) * dotVH );\n\treturn f0 * ( 1.0 - fresnel ) + ( f90 * fresnel );\n} // validated";

	var cube_uv_reflection_fragment = "#ifdef ENVMAP_TYPE_CUBE_UV\n\t#define cubeUV_minMipLevel 4.0\n\t#define cubeUV_minTileSize 16.0\n\tfloat getFace( vec3 direction ) {\n\t\tvec3 absDirection = abs( direction );\n\t\tfloat face = - 1.0;\n\t\tif ( absDirection.x > absDirection.z ) {\n\t\t\tif ( absDirection.x > absDirection.y )\n\t\t\t\tface = direction.x > 0.0 ? 0.0 : 3.0;\n\t\t\telse\n\t\t\t\tface = direction.y > 0.0 ? 1.0 : 4.0;\n\t\t} else {\n\t\t\tif ( absDirection.z > absDirection.y )\n\t\t\t\tface = direction.z > 0.0 ? 2.0 : 5.0;\n\t\t\telse\n\t\t\t\tface = direction.y > 0.0 ? 1.0 : 4.0;\n\t\t}\n\t\treturn face;\n\t}\n\tvec2 getUV( vec3 direction, float face ) {\n\t\tvec2 uv;\n\t\tif ( face == 0.0 ) {\n\t\t\tuv = vec2( direction.z, direction.y ) / abs( direction.x );\n\t\t} else if ( face == 1.0 ) {\n\t\t\tuv = vec2( - direction.x, - direction.z ) / abs( direction.y );\n\t\t} else if ( face == 2.0 ) {\n\t\t\tuv = vec2( - direction.x, direction.y ) / abs( direction.z );\n\t\t} else if ( face == 3.0 ) {\n\t\t\tuv = vec2( - direction.z, direction.y ) / abs( direction.x );\n\t\t} else if ( face == 4.0 ) {\n\t\t\tuv = vec2( - direction.x, direction.z ) / abs( direction.y );\n\t\t} else {\n\t\t\tuv = vec2( direction.x, direction.y ) / abs( direction.z );\n\t\t}\n\t\treturn 0.5 * ( uv + 1.0 );\n\t}\n\tvec3 bilinearCubeUV( sampler2D envMap, vec3 direction, float mipInt ) {\n\t\tfloat face = getFace( direction );\n\t\tfloat filterInt = max( cubeUV_minMipLevel - mipInt, 0.0 );\n\t\tmipInt = max( mipInt, cubeUV_minMipLevel );\n\t\tfloat faceSize = exp2( mipInt );\n\t\thighp vec2 uv = getUV( direction, face ) * ( faceSize - 2.0 ) + 1.0;\n\t\tif ( face > 2.0 ) {\n\t\t\tuv.y += faceSize;\n\t\t\tface -= 3.0;\n\t\t}\n\t\tuv.x += face * faceSize;\n\t\tuv.x += filterInt * 3.0 * cubeUV_minTileSize;\n\t\tuv.y += 4.0 * ( exp2( CUBEUV_MAX_MIP ) - faceSize );\n\t\tuv.x *= CUBEUV_TEXEL_WIDTH;\n\t\tuv.y *= CUBEUV_TEXEL_HEIGHT;\n\t\t#ifdef texture2DGradEXT\n\t\t\treturn texture2DGradEXT( envMap, uv, vec2( 0.0 ), vec2( 0.0 ) ).rgb;\n\t\t#else\n\t\t\treturn texture2D( envMap, uv ).rgb;\n\t\t#endif\n\t}\n\t#define cubeUV_r0 1.0\n\t#define cubeUV_m0 - 2.0\n\t#define cubeUV_r1 0.8\n\t#define cubeUV_m1 - 1.0\n\t#define cubeUV_r4 0.4\n\t#define cubeUV_m4 2.0\n\t#define cubeUV_r5 0.305\n\t#define cubeUV_m5 3.0\n\t#define cubeUV_r6 0.21\n\t#define cubeUV_m6 4.0\n\tfloat roughnessToMip( float roughness ) {\n\t\tfloat mip = 0.0;\n\t\tif ( roughness >= cubeUV_r1 ) {\n\t\t\tmip = ( cubeUV_r0 - roughness ) * ( cubeUV_m1 - cubeUV_m0 ) / ( cubeUV_r0 - cubeUV_r1 ) + cubeUV_m0;\n\t\t} else if ( roughness >= cubeUV_r4 ) {\n\t\t\tmip = ( cubeUV_r1 - roughness ) * ( cubeUV_m4 - cubeUV_m1 ) / ( cubeUV_r1 - cubeUV_r4 ) + cubeUV_m1;\n\t\t} else if ( roughness >= cubeUV_r5 ) {\n\t\t\tmip = ( cubeUV_r4 - roughness ) * ( cubeUV_m5 - cubeUV_m4 ) / ( cubeUV_r4 - cubeUV_r5 ) + cubeUV_m4;\n\t\t} else if ( roughness >= cubeUV_r6 ) {\n\t\t\tmip = ( cubeUV_r5 - roughness ) * ( cubeUV_m6 - cubeUV_m5 ) / ( cubeUV_r5 - cubeUV_r6 ) + cubeUV_m5;\n\t\t} else {\n\t\t\tmip = - 2.0 * log2( 1.16 * roughness );\t\t}\n\t\treturn mip;\n\t}\n\tvec4 textureCubeUV( sampler2D envMap, vec3 sampleDir, float roughness ) {\n\t\tfloat mip = clamp( roughnessToMip( roughness ), cubeUV_m0, CUBEUV_MAX_MIP );\n\t\tfloat mipF = fract( mip );\n\t\tfloat mipInt = floor( mip );\n\t\tvec3 color0 = bilinearCubeUV( envMap, sampleDir, mipInt );\n\t\tif ( mipF == 0.0 ) {\n\t\t\treturn vec4( color0, 1.0 );\n\t\t} else {\n\t\t\tvec3 color1 = bilinearCubeUV( envMap, sampleDir, mipInt + 1.0 );\n\t\t\treturn vec4( mix( color0, color1, mipF ), 1.0 );\n\t\t}\n\t}\n#endif";

	var defaultnormal_vertex = "vec3 transformedNormal = objectNormal;\n#ifdef USE_TANGENT\n\tvec3 transformedTangent = objectTangent;\n#endif\n#ifdef USE_BATCHING\n\tmat3 bm = mat3( batchingMatrix );\n\ttransformedNormal /= vec3( dot( bm[ 0 ], bm[ 0 ] ), dot( bm[ 1 ], bm[ 1 ] ), dot( bm[ 2 ], bm[ 2 ] ) );\n\ttransformedNormal = bm * transformedNormal;\n\t#ifdef USE_TANGENT\n\t\ttransformedTangent = bm * transformedTangent;\n\t#endif\n#endif\n#ifdef USE_INSTANCING\n\tmat3 im = mat3( instanceMatrix );\n\ttransformedNormal /= vec3( dot( im[ 0 ], im[ 0 ] ), dot( im[ 1 ], im[ 1 ] ), dot( im[ 2 ], im[ 2 ] ) );\n\ttransformedNormal = im * transformedNormal;\n\t#ifdef USE_TANGENT\n\t\ttransformedTangent = im * transformedTangent;\n\t#endif\n#endif\ntransformedNormal = normalMatrix * transformedNormal;\n#ifdef FLIP_SIDED\n\ttransformedNormal = - transformedNormal;\n#endif\n#ifdef USE_TANGENT\n\ttransformedTangent = ( modelViewMatrix * vec4( transformedTangent, 0.0 ) ).xyz;\n\t#ifdef FLIP_SIDED\n\t\ttransformedTangent = - transformedTangent;\n\t#endif\n#endif";

	var displacementmap_pars_vertex = "#ifdef USE_DISPLACEMENTMAP\n\tuniform sampler2D displacementMap;\n\tuniform float displacementScale;\n\tuniform float displacementBias;\n#endif";

	var displacementmap_vertex = "#ifdef USE_DISPLACEMENTMAP\n\ttransformed += normalize( objectNormal ) * ( texture2D( displacementMap, vDisplacementMapUv ).x * displacementScale + displacementBias );\n#endif";

	var emissivemap_fragment = "#ifdef USE_EMISSIVEMAP\n\tvec4 emissiveColor = texture2D( emissiveMap, vEmissiveMapUv );\n\t#ifdef DECODE_VIDEO_TEXTURE_EMISSIVE\n\t\temissiveColor = sRGBTransferEOTF( emissiveColor );\n\t#endif\n\ttotalEmissiveRadiance *= emissiveColor.rgb;\n#endif";

	var emissivemap_pars_fragment = "#ifdef USE_EMISSIVEMAP\n\tuniform sampler2D emissiveMap;\n#endif";

	var colorspace_fragment = "gl_FragColor = linearToOutputTexel( gl_FragColor );";

	var colorspace_pars_fragment = "vec4 LinearTransferOETF( in vec4 value ) {\n\treturn value;\n}\nvec4 sRGBTransferEOTF( in vec4 value ) {\n\treturn vec4( mix( pow( value.rgb * 0.9478672986 + vec3( 0.0521327014 ), vec3( 2.4 ) ), value.rgb * 0.0773993808, vec3( lessThanEqual( value.rgb, vec3( 0.04045 ) ) ) ), value.a );\n}\nvec4 sRGBTransferOETF( in vec4 value ) {\n\treturn vec4( mix( pow( value.rgb, vec3( 0.41666 ) ) * 1.055 - vec3( 0.055 ), value.rgb * 12.92, vec3( lessThanEqual( value.rgb, vec3( 0.0031308 ) ) ) ), value.a );\n}";

	var envmap_fragment = "#ifdef USE_ENVMAP\n\t#ifdef ENV_WORLDPOS\n\t\tvec3 cameraToFrag;\n\t\tif ( isOrthographic ) {\n\t\t\tcameraToFrag = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\n\t\t} else {\n\t\t\tcameraToFrag = normalize( vWorldPosition - cameraPosition );\n\t\t}\n\t\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\n\t\t#ifdef ENVMAP_MODE_REFLECTION\n\t\t\tvec3 reflectVec = reflect( cameraToFrag, worldNormal );\n\t\t#else\n\t\t\tvec3 reflectVec = refract( cameraToFrag, worldNormal, refractionRatio );\n\t\t#endif\n\t#else\n\t\tvec3 reflectVec = vReflect;\n\t#endif\n\t#ifdef ENVMAP_TYPE_CUBE\n\t\tvec4 envColor = textureCube( envMap, envMapRotation * vec3( flipEnvMap * reflectVec.x, reflectVec.yz ) );\n\t#else\n\t\tvec4 envColor = vec4( 0.0 );\n\t#endif\n\t#ifdef ENVMAP_BLENDING_MULTIPLY\n\t\toutgoingLight = mix( outgoingLight, outgoingLight * envColor.xyz, specularStrength * reflectivity );\n\t#elif defined( ENVMAP_BLENDING_MIX )\n\t\toutgoingLight = mix( outgoingLight, envColor.xyz, specularStrength * reflectivity );\n\t#elif defined( ENVMAP_BLENDING_ADD )\n\t\toutgoingLight += envColor.xyz * specularStrength * reflectivity;\n\t#endif\n#endif";

	var envmap_common_pars_fragment = "#ifdef USE_ENVMAP\n\tuniform float envMapIntensity;\n\tuniform float flipEnvMap;\n\tuniform mat3 envMapRotation;\n\t#ifdef ENVMAP_TYPE_CUBE\n\t\tuniform samplerCube envMap;\n\t#else\n\t\tuniform sampler2D envMap;\n\t#endif\n\t\n#endif";

	var envmap_pars_fragment = "#ifdef USE_ENVMAP\n\tuniform float reflectivity;\n\t#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) || defined( PHONG ) || defined( LAMBERT )\n\t\t#define ENV_WORLDPOS\n\t#endif\n\t#ifdef ENV_WORLDPOS\n\t\tvarying vec3 vWorldPosition;\n\t\tuniform float refractionRatio;\n\t#else\n\t\tvarying vec3 vReflect;\n\t#endif\n#endif";

	var envmap_pars_vertex = "#ifdef USE_ENVMAP\n\t#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) || defined( PHONG ) || defined( LAMBERT )\n\t\t#define ENV_WORLDPOS\n\t#endif\n\t#ifdef ENV_WORLDPOS\n\t\t\n\t\tvarying vec3 vWorldPosition;\n\t#else\n\t\tvarying vec3 vReflect;\n\t\tuniform float refractionRatio;\n\t#endif\n#endif";

	var envmap_vertex = "#ifdef USE_ENVMAP\n\t#ifdef ENV_WORLDPOS\n\t\tvWorldPosition = worldPosition.xyz;\n\t#else\n\t\tvec3 cameraToVertex;\n\t\tif ( isOrthographic ) {\n\t\t\tcameraToVertex = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\n\t\t} else {\n\t\t\tcameraToVertex = normalize( worldPosition.xyz - cameraPosition );\n\t\t}\n\t\tvec3 worldNormal = inverseTransformDirection( transformedNormal, viewMatrix );\n\t\t#ifdef ENVMAP_MODE_REFLECTION\n\t\t\tvReflect = reflect( cameraToVertex, worldNormal );\n\t\t#else\n\t\t\tvReflect = refract( cameraToVertex, worldNormal, refractionRatio );\n\t\t#endif\n\t#endif\n#endif";

	var fog_vertex = "#ifdef USE_FOG\n\tvFogDepth = - mvPosition.z;\n#endif";

	var fog_pars_vertex = "#ifdef USE_FOG\n\tvarying float vFogDepth;\n#endif";

	var fog_fragment = "#ifdef USE_FOG\n\t#ifdef FOG_EXP2\n\t\tfloat fogFactor = 1.0 - exp( - fogDensity * fogDensity * vFogDepth * vFogDepth );\n\t#else\n\t\tfloat fogFactor = smoothstep( fogNear, fogFar, vFogDepth );\n\t#endif\n\tgl_FragColor.rgb = mix( gl_FragColor.rgb, fogColor, fogFactor );\n#endif";

	var fog_pars_fragment = "#ifdef USE_FOG\n\tuniform vec3 fogColor;\n\tvarying float vFogDepth;\n\t#ifdef FOG_EXP2\n\t\tuniform float fogDensity;\n\t#else\n\t\tuniform float fogNear;\n\t\tuniform float fogFar;\n\t#endif\n#endif";

	var gradientmap_pars_fragment = "#ifdef USE_GRADIENTMAP\n\tuniform sampler2D gradientMap;\n#endif\nvec3 getGradientIrradiance( vec3 normal, vec3 lightDirection ) {\n\tfloat dotNL = dot( normal, lightDirection );\n\tvec2 coord = vec2( dotNL * 0.5 + 0.5, 0.0 );\n\t#ifdef USE_GRADIENTMAP\n\t\treturn vec3( texture2D( gradientMap, coord ).r );\n\t#else\n\t\tvec2 fw = fwidth( coord ) * 0.5;\n\t\treturn mix( vec3( 0.7 ), vec3( 1.0 ), smoothstep( 0.7 - fw.x, 0.7 + fw.x, coord.x ) );\n\t#endif\n}";

	var lightmap_pars_fragment = "#ifdef USE_LIGHTMAP\n\tuniform sampler2D lightMap;\n\tuniform float lightMapIntensity;\n#endif";

	var lights_lambert_fragment = "LambertMaterial material;\nmaterial.diffuseColor = diffuseColor.rgb;\nmaterial.specularStrength = specularStrength;";

	var lights_lambert_pars_fragment = "varying vec3 vViewPosition;\nstruct LambertMaterial {\n\tvec3 diffuseColor;\n\tfloat specularStrength;\n};\nvoid RE_Direct_Lambert( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in LambertMaterial material, inout ReflectedLight reflectedLight ) {\n\tfloat dotNL = saturate( dot( geometryNormal, directLight.direction ) );\n\tvec3 irradiance = dotNL * directLight.color;\n\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\nvoid RE_IndirectDiffuse_Lambert( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in LambertMaterial material, inout ReflectedLight reflectedLight ) {\n\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\n#define RE_Direct\t\t\t\tRE_Direct_Lambert\n#define RE_IndirectDiffuse\t\tRE_IndirectDiffuse_Lambert";

	var lights_pars_begin = "uniform bool receiveShadow;\nuniform vec3 ambientLightColor;\n#if defined( USE_LIGHT_PROBES )\n\tuniform vec3 lightProbe[ 9 ];\n#endif\nvec3 shGetIrradianceAt( in vec3 normal, in vec3 shCoefficients[ 9 ] ) {\n\tfloat x = normal.x, y = normal.y, z = normal.z;\n\tvec3 result = shCoefficients[ 0 ] * 0.886227;\n\tresult += shCoefficients[ 1 ] * 2.0 * 0.511664 * y;\n\tresult += shCoefficients[ 2 ] * 2.0 * 0.511664 * z;\n\tresult += shCoefficients[ 3 ] * 2.0 * 0.511664 * x;\n\tresult += shCoefficients[ 4 ] * 2.0 * 0.429043 * x * y;\n\tresult += shCoefficients[ 5 ] * 2.0 * 0.429043 * y * z;\n\tresult += shCoefficients[ 6 ] * ( 0.743125 * z * z - 0.247708 );\n\tresult += shCoefficients[ 7 ] * 2.0 * 0.429043 * x * z;\n\tresult += shCoefficients[ 8 ] * 0.429043 * ( x * x - y * y );\n\treturn result;\n}\nvec3 getLightProbeIrradiance( const in vec3 lightProbe[ 9 ], const in vec3 normal ) {\n\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\n\tvec3 irradiance = shGetIrradianceAt( worldNormal, lightProbe );\n\treturn irradiance;\n}\nvec3 getAmbientLightIrradiance( const in vec3 ambientLightColor ) {\n\tvec3 irradiance = ambientLightColor;\n\treturn irradiance;\n}\nfloat getDistanceAttenuation( const in float lightDistance, const in float cutoffDistance, const in float decayExponent ) {\n\tfloat distanceFalloff = 1.0 / max( pow( lightDistance, decayExponent ), 0.01 );\n\tif ( cutoffDistance > 0.0 ) {\n\t\tdistanceFalloff *= pow2( saturate( 1.0 - pow4( lightDistance / cutoffDistance ) ) );\n\t}\n\treturn distanceFalloff;\n}\nfloat getSpotAttenuation( const in float coneCosine, const in float penumbraCosine, const in float angleCosine ) {\n\treturn smoothstep( coneCosine, penumbraCosine, angleCosine );\n}\n#if NUM_DIR_LIGHTS > 0\n\tstruct DirectionalLight {\n\t\tvec3 direction;\n\t\tvec3 color;\n\t};\n\tuniform DirectionalLight directionalLights[ NUM_DIR_LIGHTS ];\n\tvoid getDirectionalLightInfo( const in DirectionalLight directionalLight, out IncidentLight light ) {\n\t\tlight.color = directionalLight.color;\n\t\tlight.direction = directionalLight.direction;\n\t\tlight.visible = true;\n\t}\n#endif\n#if NUM_POINT_LIGHTS > 0\n\tstruct PointLight {\n\t\tvec3 position;\n\t\tvec3 color;\n\t\tfloat distance;\n\t\tfloat decay;\n\t};\n\tuniform PointLight pointLights[ NUM_POINT_LIGHTS ];\n\tvoid getPointLightInfo( const in PointLight pointLight, const in vec3 geometryPosition, out IncidentLight light ) {\n\t\tvec3 lVector = pointLight.position - geometryPosition;\n\t\tlight.direction = normalize( lVector );\n\t\tfloat lightDistance = length( lVector );\n\t\tlight.color = pointLight.color;\n\t\tlight.color *= getDistanceAttenuation( lightDistance, pointLight.distance, pointLight.decay );\n\t\tlight.visible = ( light.color != vec3( 0.0 ) );\n\t}\n#endif\n#if NUM_SPOT_LIGHTS > 0\n\tstruct SpotLight {\n\t\tvec3 position;\n\t\tvec3 direction;\n\t\tvec3 color;\n\t\tfloat distance;\n\t\tfloat decay;\n\t\tfloat coneCos;\n\t\tfloat penumbraCos;\n\t};\n\tuniform SpotLight spotLights[ NUM_SPOT_LIGHTS ];\n\tvoid getSpotLightInfo( const in SpotLight spotLight, const in vec3 geometryPosition, out IncidentLight light ) {\n\t\tvec3 lVector = spotLight.position - geometryPosition;\n\t\tlight.direction = normalize( lVector );\n\t\tfloat angleCos = dot( light.direction, spotLight.direction );\n\t\tfloat spotAttenuation = getSpotAttenuation( spotLight.coneCos, spotLight.penumbraCos, angleCos );\n\t\tif ( spotAttenuation > 0.0 ) {\n\t\t\tfloat lightDistance = length( lVector );\n\t\t\tlight.color = spotLight.color * spotAttenuation;\n\t\t\tlight.color *= getDistanceAttenuation( lightDistance, spotLight.distance, spotLight.decay );\n\t\t\tlight.visible = ( light.color != vec3( 0.0 ) );\n\t\t} else {\n\t\t\tlight.color = vec3( 0.0 );\n\t\t\tlight.visible = false;\n\t\t}\n\t}\n#endif\n#if NUM_RECT_AREA_LIGHTS > 0\n\tstruct RectAreaLight {\n\t\tvec3 color;\n\t\tvec3 position;\n\t\tvec3 halfWidth;\n\t\tvec3 halfHeight;\n\t};\n\tuniform sampler2D ltc_1;\tuniform sampler2D ltc_2;\n\tuniform RectAreaLight rectAreaLights[ NUM_RECT_AREA_LIGHTS ];\n#endif\n#if NUM_HEMI_LIGHTS > 0\n\tstruct HemisphereLight {\n\t\tvec3 direction;\n\t\tvec3 skyColor;\n\t\tvec3 groundColor;\n\t};\n\tuniform HemisphereLight hemisphereLights[ NUM_HEMI_LIGHTS ];\n\tvec3 getHemisphereLightIrradiance( const in HemisphereLight hemiLight, const in vec3 normal ) {\n\t\tfloat dotNL = dot( normal, hemiLight.direction );\n\t\tfloat hemiDiffuseWeight = 0.5 * dotNL + 0.5;\n\t\tvec3 irradiance = mix( hemiLight.groundColor, hemiLight.skyColor, hemiDiffuseWeight );\n\t\treturn irradiance;\n\t}\n#endif";

	var envmap_physical_pars_fragment = "#ifdef USE_ENVMAP\n\tvec3 getIBLIrradiance( const in vec3 normal ) {\n\t\t#ifdef ENVMAP_TYPE_CUBE_UV\n\t\t\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\n\t\t\tvec4 envMapColor = textureCubeUV( envMap, envMapRotation * worldNormal, 1.0 );\n\t\t\treturn PI * envMapColor.rgb * envMapIntensity;\n\t\t#else\n\t\t\treturn vec3( 0.0 );\n\t\t#endif\n\t}\n\tvec3 getIBLRadiance( const in vec3 viewDir, const in vec3 normal, const in float roughness ) {\n\t\t#ifdef ENVMAP_TYPE_CUBE_UV\n\t\t\tvec3 reflectVec = reflect( - viewDir, normal );\n\t\t\treflectVec = normalize( mix( reflectVec, normal, roughness * roughness) );\n\t\t\treflectVec = inverseTransformDirection( reflectVec, viewMatrix );\n\t\t\tvec4 envMapColor = textureCubeUV( envMap, envMapRotation * reflectVec, roughness );\n\t\t\treturn envMapColor.rgb * envMapIntensity;\n\t\t#else\n\t\t\treturn vec3( 0.0 );\n\t\t#endif\n\t}\n\t#ifdef USE_ANISOTROPY\n\t\tvec3 getIBLAnisotropyRadiance( const in vec3 viewDir, const in vec3 normal, const in float roughness, const in vec3 bitangent, const in float anisotropy ) {\n\t\t\t#ifdef ENVMAP_TYPE_CUBE_UV\n\t\t\t\tvec3 bentNormal = cross( bitangent, viewDir );\n\t\t\t\tbentNormal = normalize( cross( bentNormal, bitangent ) );\n\t\t\t\tbentNormal = normalize( mix( bentNormal, normal, pow2( pow2( 1.0 - anisotropy * ( 1.0 - roughness ) ) ) ) );\n\t\t\t\treturn getIBLRadiance( viewDir, bentNormal, roughness );\n\t\t\t#else\n\t\t\t\treturn vec3( 0.0 );\n\t\t\t#endif\n\t\t}\n\t#endif\n#endif";

	var lights_toon_fragment = "ToonMaterial material;\nmaterial.diffuseColor = diffuseColor.rgb;";

	var lights_toon_pars_fragment = "varying vec3 vViewPosition;\nstruct ToonMaterial {\n\tvec3 diffuseColor;\n};\nvoid RE_Direct_Toon( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {\n\tvec3 irradiance = getGradientIrradiance( geometryNormal, directLight.direction ) * directLight.color;\n\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\nvoid RE_IndirectDiffuse_Toon( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {\n\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\n#define RE_Direct\t\t\t\tRE_Direct_Toon\n#define RE_IndirectDiffuse\t\tRE_IndirectDiffuse_Toon";

	var lights_phong_fragment = "BlinnPhongMaterial material;\nmaterial.diffuseColor = diffuseColor.rgb;\nmaterial.specularColor = specular;\nmaterial.specularShininess = shininess;\nmaterial.specularStrength = specularStrength;";

	var lights_phong_pars_fragment = "varying vec3 vViewPosition;\nstruct BlinnPhongMaterial {\n\tvec3 diffuseColor;\n\tvec3 specularColor;\n\tfloat specularShininess;\n\tfloat specularStrength;\n};\nvoid RE_Direct_BlinnPhong( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {\n\tfloat dotNL = saturate( dot( geometryNormal, directLight.direction ) );\n\tvec3 irradiance = dotNL * directLight.color;\n\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n\treflectedLight.directSpecular += irradiance * BRDF_BlinnPhong( directLight.direction, geometryViewDir, geometryNormal, material.specularColor, material.specularShininess ) * material.specularStrength;\n}\nvoid RE_IndirectDiffuse_BlinnPhong( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {\n\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\n#define RE_Direct\t\t\t\tRE_Direct_BlinnPhong\n#define RE_IndirectDiffuse\t\tRE_IndirectDiffuse_BlinnPhong";

	var lights_physical_fragment = "PhysicalMaterial material;\nmaterial.diffuseColor = diffuseColor.rgb * ( 1.0 - metalnessFactor );\nvec3 dxy = max( abs( dFdx( nonPerturbedNormal ) ), abs( dFdy( nonPerturbedNormal ) ) );\nfloat geometryRoughness = max( max( dxy.x, dxy.y ), dxy.z );\nmaterial.roughness = max( roughnessFactor, 0.0525 );material.roughness += geometryRoughness;\nmaterial.roughness = min( material.roughness, 1.0 );\n#ifdef IOR\n\tmaterial.ior = ior;\n\t#ifdef USE_SPECULAR\n\t\tfloat specularIntensityFactor = specularIntensity;\n\t\tvec3 specularColorFactor = specularColor;\n\t\t#ifdef USE_SPECULAR_COLORMAP\n\t\t\tspecularColorFactor *= texture2D( specularColorMap, vSpecularColorMapUv ).rgb;\n\t\t#endif\n\t\t#ifdef USE_SPECULAR_INTENSITYMAP\n\t\t\tspecularIntensityFactor *= texture2D( specularIntensityMap, vSpecularIntensityMapUv ).a;\n\t\t#endif\n\t\tmaterial.specularF90 = mix( specularIntensityFactor, 1.0, metalnessFactor );\n\t#else\n\t\tfloat specularIntensityFactor = 1.0;\n\t\tvec3 specularColorFactor = vec3( 1.0 );\n\t\tmaterial.specularF90 = 1.0;\n\t#endif\n\tmaterial.specularColor = mix( min( pow2( ( material.ior - 1.0 ) / ( material.ior + 1.0 ) ) * specularColorFactor, vec3( 1.0 ) ) * specularIntensityFactor, diffuseColor.rgb, metalnessFactor );\n#else\n\tmaterial.specularColor = mix( vec3( 0.04 ), diffuseColor.rgb, metalnessFactor );\n\tmaterial.specularF90 = 1.0;\n#endif\n#ifdef USE_CLEARCOAT\n\tmaterial.clearcoat = clearcoat;\n\tmaterial.clearcoatRoughness = clearcoatRoughness;\n\tmaterial.clearcoatF0 = vec3( 0.04 );\n\tmaterial.clearcoatF90 = 1.0;\n\t#ifdef USE_CLEARCOATMAP\n\t\tmaterial.clearcoat *= texture2D( clearcoatMap, vClearcoatMapUv ).x;\n\t#endif\n\t#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n\t\tmaterial.clearcoatRoughness *= texture2D( clearcoatRoughnessMap, vClearcoatRoughnessMapUv ).y;\n\t#endif\n\tmaterial.clearcoat = saturate( material.clearcoat );\tmaterial.clearcoatRoughness = max( material.clearcoatRoughness, 0.0525 );\n\tmaterial.clearcoatRoughness += geometryRoughness;\n\tmaterial.clearcoatRoughness = min( material.clearcoatRoughness, 1.0 );\n#endif\n#ifdef USE_DISPERSION\n\tmaterial.dispersion = dispersion;\n#endif\n#ifdef USE_IRIDESCENCE\n\tmaterial.iridescence = iridescence;\n\tmaterial.iridescenceIOR = iridescenceIOR;\n\t#ifdef USE_IRIDESCENCEMAP\n\t\tmaterial.iridescence *= texture2D( iridescenceMap, vIridescenceMapUv ).r;\n\t#endif\n\t#ifdef USE_IRIDESCENCE_THICKNESSMAP\n\t\tmaterial.iridescenceThickness = (iridescenceThicknessMaximum - iridescenceThicknessMinimum) * texture2D( iridescenceThicknessMap, vIridescenceThicknessMapUv ).g + iridescenceThicknessMinimum;\n\t#else\n\t\tmaterial.iridescenceThickness = iridescenceThicknessMaximum;\n\t#endif\n#endif\n#ifdef USE_SHEEN\n\tmaterial.sheenColor = sheenColor;\n\t#ifdef USE_SHEEN_COLORMAP\n\t\tmaterial.sheenColor *= texture2D( sheenColorMap, vSheenColorMapUv ).rgb;\n\t#endif\n\tmaterial.sheenRoughness = clamp( sheenRoughness, 0.07, 1.0 );\n\t#ifdef USE_SHEEN_ROUGHNESSMAP\n\t\tmaterial.sheenRoughness *= texture2D( sheenRoughnessMap, vSheenRoughnessMapUv ).a;\n\t#endif\n#endif\n#ifdef USE_ANISOTROPY\n\t#ifdef USE_ANISOTROPYMAP\n\t\tmat2 anisotropyMat = mat2( anisotropyVector.x, anisotropyVector.y, - anisotropyVector.y, anisotropyVector.x );\n\t\tvec3 anisotropyPolar = texture2D( anisotropyMap, vAnisotropyMapUv ).rgb;\n\t\tvec2 anisotropyV = anisotropyMat * normalize( 2.0 * anisotropyPolar.rg - vec2( 1.0 ) ) * anisotropyPolar.b;\n\t#else\n\t\tvec2 anisotropyV = anisotropyVector;\n\t#endif\n\tmaterial.anisotropy = length( anisotropyV );\n\tif( material.anisotropy == 0.0 ) {\n\t\tanisotropyV = vec2( 1.0, 0.0 );\n\t} else {\n\t\tanisotropyV /= material.anisotropy;\n\t\tmaterial.anisotropy = saturate( material.anisotropy );\n\t}\n\tmaterial.alphaT = mix( pow2( material.roughness ), 1.0, pow2( material.anisotropy ) );\n\tmaterial.anisotropyT = tbn[ 0 ] * anisotropyV.x + tbn[ 1 ] * anisotropyV.y;\n\tmaterial.anisotropyB = tbn[ 1 ] * anisotropyV.x - tbn[ 0 ] * anisotropyV.y;\n#endif";

	var lights_physical_pars_fragment = "struct PhysicalMaterial {\n\tvec3 diffuseColor;\n\tfloat roughness;\n\tvec3 specularColor;\n\tfloat specularF90;\n\tfloat dispersion;\n\t#ifdef USE_CLEARCOAT\n\t\tfloat clearcoat;\n\t\tfloat clearcoatRoughness;\n\t\tvec3 clearcoatF0;\n\t\tfloat clearcoatF90;\n\t#endif\n\t#ifdef USE_IRIDESCENCE\n\t\tfloat iridescence;\n\t\tfloat iridescenceIOR;\n\t\tfloat iridescenceThickness;\n\t\tvec3 iridescenceFresnel;\n\t\tvec3 iridescenceF0;\n\t#endif\n\t#ifdef USE_SHEEN\n\t\tvec3 sheenColor;\n\t\tfloat sheenRoughness;\n\t#endif\n\t#ifdef IOR\n\t\tfloat ior;\n\t#endif\n\t#ifdef USE_TRANSMISSION\n\t\tfloat transmission;\n\t\tfloat transmissionAlpha;\n\t\tfloat thickness;\n\t\tfloat attenuationDistance;\n\t\tvec3 attenuationColor;\n\t#endif\n\t#ifdef USE_ANISOTROPY\n\t\tfloat anisotropy;\n\t\tfloat alphaT;\n\t\tvec3 anisotropyT;\n\t\tvec3 anisotropyB;\n\t#endif\n};\nvec3 clearcoatSpecularDirect = vec3( 0.0 );\nvec3 clearcoatSpecularIndirect = vec3( 0.0 );\nvec3 sheenSpecularDirect = vec3( 0.0 );\nvec3 sheenSpecularIndirect = vec3(0.0 );\nvec3 Schlick_to_F0( const in vec3 f, const in float f90, const in float dotVH ) {\n    float x = clamp( 1.0 - dotVH, 0.0, 1.0 );\n    float x2 = x * x;\n    float x5 = clamp( x * x2 * x2, 0.0, 0.9999 );\n    return ( f - vec3( f90 ) * x5 ) / ( 1.0 - x5 );\n}\nfloat V_GGX_SmithCorrelated( const in float alpha, const in float dotNL, const in float dotNV ) {\n\tfloat a2 = pow2( alpha );\n\tfloat gv = dotNL * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNV ) );\n\tfloat gl = dotNV * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNL ) );\n\treturn 0.5 / max( gv + gl, EPSILON );\n}\nfloat D_GGX( const in float alpha, const in float dotNH ) {\n\tfloat a2 = pow2( alpha );\n\tfloat denom = pow2( dotNH ) * ( a2 - 1.0 ) + 1.0;\n\treturn RECIPROCAL_PI * a2 / pow2( denom );\n}\n#ifdef USE_ANISOTROPY\n\tfloat V_GGX_SmithCorrelated_Anisotropic( const in float alphaT, const in float alphaB, const in float dotTV, const in float dotBV, const in float dotTL, const in float dotBL, const in float dotNV, const in float dotNL ) {\n\t\tfloat gv = dotNL * length( vec3( alphaT * dotTV, alphaB * dotBV, dotNV ) );\n\t\tfloat gl = dotNV * length( vec3( alphaT * dotTL, alphaB * dotBL, dotNL ) );\n\t\tfloat v = 0.5 / ( gv + gl );\n\t\treturn saturate(v);\n\t}\n\tfloat D_GGX_Anisotropic( const in float alphaT, const in float alphaB, const in float dotNH, const in float dotTH, const in float dotBH ) {\n\t\tfloat a2 = alphaT * alphaB;\n\t\thighp vec3 v = vec3( alphaB * dotTH, alphaT * dotBH, a2 * dotNH );\n\t\thighp float v2 = dot( v, v );\n\t\tfloat w2 = a2 / v2;\n\t\treturn RECIPROCAL_PI * a2 * pow2 ( w2 );\n\t}\n#endif\n#ifdef USE_CLEARCOAT\n\tvec3 BRDF_GGX_Clearcoat( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in PhysicalMaterial material) {\n\t\tvec3 f0 = material.clearcoatF0;\n\t\tfloat f90 = material.clearcoatF90;\n\t\tfloat roughness = material.clearcoatRoughness;\n\t\tfloat alpha = pow2( roughness );\n\t\tvec3 halfDir = normalize( lightDir + viewDir );\n\t\tfloat dotNL = saturate( dot( normal, lightDir ) );\n\t\tfloat dotNV = saturate( dot( normal, viewDir ) );\n\t\tfloat dotNH = saturate( dot( normal, halfDir ) );\n\t\tfloat dotVH = saturate( dot( viewDir, halfDir ) );\n\t\tvec3 F = F_Schlick( f0, f90, dotVH );\n\t\tfloat V = V_GGX_SmithCorrelated( alpha, dotNL, dotNV );\n\t\tfloat D = D_GGX( alpha, dotNH );\n\t\treturn F * ( V * D );\n\t}\n#endif\nvec3 BRDF_GGX( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in PhysicalMaterial material ) {\n\tvec3 f0 = material.specularColor;\n\tfloat f90 = material.specularF90;\n\tfloat roughness = material.roughness;\n\tfloat alpha = pow2( roughness );\n\tvec3 halfDir = normalize( lightDir + viewDir );\n\tfloat dotNL = saturate( dot( normal, lightDir ) );\n\tfloat dotNV = saturate( dot( normal, viewDir ) );\n\tfloat dotNH = saturate( dot( normal, halfDir ) );\n\tfloat dotVH = saturate( dot( viewDir, halfDir ) );\n\tvec3 F = F_Schlick( f0, f90, dotVH );\n\t#ifdef USE_IRIDESCENCE\n\t\tF = mix( F, material.iridescenceFresnel, material.iridescence );\n\t#endif\n\t#ifdef USE_ANISOTROPY\n\t\tfloat dotTL = dot( material.anisotropyT, lightDir );\n\t\tfloat dotTV = dot( material.anisotropyT, viewDir );\n\t\tfloat dotTH = dot( material.anisotropyT, halfDir );\n\t\tfloat dotBL = dot( material.anisotropyB, lightDir );\n\t\tfloat dotBV = dot( material.anisotropyB, viewDir );\n\t\tfloat dotBH = dot( material.anisotropyB, halfDir );\n\t\tfloat V = V_GGX_SmithCorrelated_Anisotropic( material.alphaT, alpha, dotTV, dotBV, dotTL, dotBL, dotNV, dotNL );\n\t\tfloat D = D_GGX_Anisotropic( material.alphaT, alpha, dotNH, dotTH, dotBH );\n\t#else\n\t\tfloat V = V_GGX_SmithCorrelated( alpha, dotNL, dotNV );\n\t\tfloat D = D_GGX( alpha, dotNH );\n\t#endif\n\treturn F * ( V * D );\n}\nvec2 LTC_Uv( const in vec3 N, const in vec3 V, const in float roughness ) {\n\tconst float LUT_SIZE = 64.0;\n\tconst float LUT_SCALE = ( LUT_SIZE - 1.0 ) / LUT_SIZE;\n\tconst float LUT_BIAS = 0.5 / LUT_SIZE;\n\tfloat dotNV = saturate( dot( N, V ) );\n\tvec2 uv = vec2( roughness, sqrt( 1.0 - dotNV ) );\n\tuv = uv * LUT_SCALE + LUT_BIAS;\n\treturn uv;\n}\nfloat LTC_ClippedSphereFormFactor( const in vec3 f ) {\n\tfloat l = length( f );\n\treturn max( ( l * l + f.z ) / ( l + 1.0 ), 0.0 );\n}\nvec3 LTC_EdgeVectorFormFactor( const in vec3 v1, const in vec3 v2 ) {\n\tfloat x = dot( v1, v2 );\n\tfloat y = abs( x );\n\tfloat a = 0.8543985 + ( 0.4965155 + 0.0145206 * y ) * y;\n\tfloat b = 3.4175940 + ( 4.1616724 + y ) * y;\n\tfloat v = a / b;\n\tfloat theta_sintheta = ( x > 0.0 ) ? v : 0.5 * inversesqrt( max( 1.0 - x * x, 1e-7 ) ) - v;\n\treturn cross( v1, v2 ) * theta_sintheta;\n}\nvec3 LTC_Evaluate( const in vec3 N, const in vec3 V, const in vec3 P, const in mat3 mInv, const in vec3 rectCoords[ 4 ] ) {\n\tvec3 v1 = rectCoords[ 1 ] - rectCoords[ 0 ];\n\tvec3 v2 = rectCoords[ 3 ] - rectCoords[ 0 ];\n\tvec3 lightNormal = cross( v1, v2 );\n\tif( dot( lightNormal, P - rectCoords[ 0 ] ) < 0.0 ) return vec3( 0.0 );\n\tvec3 T1, T2;\n\tT1 = normalize( V - N * dot( V, N ) );\n\tT2 = - cross( N, T1 );\n\tmat3 mat = mInv * transposeMat3( mat3( T1, T2, N ) );\n\tvec3 coords[ 4 ];\n\tcoords[ 0 ] = mat * ( rectCoords[ 0 ] - P );\n\tcoords[ 1 ] = mat * ( rectCoords[ 1 ] - P );\n\tcoords[ 2 ] = mat * ( rectCoords[ 2 ] - P );\n\tcoords[ 3 ] = mat * ( rectCoords[ 3 ] - P );\n\tcoords[ 0 ] = normalize( coords[ 0 ] );\n\tcoords[ 1 ] = normalize( coords[ 1 ] );\n\tcoords[ 2 ] = normalize( coords[ 2 ] );\n\tcoords[ 3 ] = normalize( coords[ 3 ] );\n\tvec3 vectorFormFactor = vec3( 0.0 );\n\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 0 ], coords[ 1 ] );\n\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 1 ], coords[ 2 ] );\n\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 2 ], coords[ 3 ] );\n\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 3 ], coords[ 0 ] );\n\tfloat result = LTC_ClippedSphereFormFactor( vectorFormFactor );\n\treturn vec3( result );\n}\n#if defined( USE_SHEEN )\nfloat D_Charlie( float roughness, float dotNH ) {\n\tfloat alpha = pow2( roughness );\n\tfloat invAlpha = 1.0 / alpha;\n\tfloat cos2h = dotNH * dotNH;\n\tfloat sin2h = max( 1.0 - cos2h, 0.0078125 );\n\treturn ( 2.0 + invAlpha ) * pow( sin2h, invAlpha * 0.5 ) / ( 2.0 * PI );\n}\nfloat V_Neubelt( float dotNV, float dotNL ) {\n\treturn saturate( 1.0 / ( 4.0 * ( dotNL + dotNV - dotNL * dotNV ) ) );\n}\nvec3 BRDF_Sheen( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, vec3 sheenColor, const in float sheenRoughness ) {\n\tvec3 halfDir = normalize( lightDir + viewDir );\n\tfloat dotNL = saturate( dot( normal, lightDir ) );\n\tfloat dotNV = saturate( dot( normal, viewDir ) );\n\tfloat dotNH = saturate( dot( normal, halfDir ) );\n\tfloat D = D_Charlie( sheenRoughness, dotNH );\n\tfloat V = V_Neubelt( dotNV, dotNL );\n\treturn sheenColor * ( D * V );\n}\n#endif\nfloat IBLSheenBRDF( const in vec3 normal, const in vec3 viewDir, const in float roughness ) {\n\tfloat dotNV = saturate( dot( normal, viewDir ) );\n\tfloat r2 = roughness * roughness;\n\tfloat a = roughness < 0.25 ? -339.2 * r2 + 161.4 * roughness - 25.9 : -8.48 * r2 + 14.3 * roughness - 9.95;\n\tfloat b = roughness < 0.25 ? 44.0 * r2 - 23.7 * roughness + 3.26 : 1.97 * r2 - 3.27 * roughness + 0.72;\n\tfloat DG = exp( a * dotNV + b ) + ( roughness < 0.25 ? 0.0 : 0.1 * ( roughness - 0.25 ) );\n\treturn saturate( DG * RECIPROCAL_PI );\n}\nvec2 DFGApprox( const in vec3 normal, const in vec3 viewDir, const in float roughness ) {\n\tfloat dotNV = saturate( dot( normal, viewDir ) );\n\tconst vec4 c0 = vec4( - 1, - 0.0275, - 0.572, 0.022 );\n\tconst vec4 c1 = vec4( 1, 0.0425, 1.04, - 0.04 );\n\tvec4 r = roughness * c0 + c1;\n\tfloat a004 = min( r.x * r.x, exp2( - 9.28 * dotNV ) ) * r.x + r.y;\n\tvec2 fab = vec2( - 1.04, 1.04 ) * a004 + r.zw;\n\treturn fab;\n}\nvec3 EnvironmentBRDF( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float roughness ) {\n\tvec2 fab = DFGApprox( normal, viewDir, roughness );\n\treturn specularColor * fab.x + specularF90 * fab.y;\n}\n#ifdef USE_IRIDESCENCE\nvoid computeMultiscatteringIridescence( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float iridescence, const in vec3 iridescenceF0, const in float roughness, inout vec3 singleScatter, inout vec3 multiScatter ) {\n#else\nvoid computeMultiscattering( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float roughness, inout vec3 singleScatter, inout vec3 multiScatter ) {\n#endif\n\tvec2 fab = DFGApprox( normal, viewDir, roughness );\n\t#ifdef USE_IRIDESCENCE\n\t\tvec3 Fr = mix( specularColor, iridescenceF0, iridescence );\n\t#else\n\t\tvec3 Fr = specularColor;\n\t#endif\n\tvec3 FssEss = Fr * fab.x + specularF90 * fab.y;\n\tfloat Ess = fab.x + fab.y;\n\tfloat Ems = 1.0 - Ess;\n\tvec3 Favg = Fr + ( 1.0 - Fr ) * 0.047619;\tvec3 Fms = FssEss * Favg / ( 1.0 - Ems * Favg );\n\tsingleScatter += FssEss;\n\tmultiScatter += Fms * Ems;\n}\n#if NUM_RECT_AREA_LIGHTS > 0\n\tvoid RE_Direct_RectArea_Physical( const in RectAreaLight rectAreaLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\n\t\tvec3 normal = geometryNormal;\n\t\tvec3 viewDir = geometryViewDir;\n\t\tvec3 position = geometryPosition;\n\t\tvec3 lightPos = rectAreaLight.position;\n\t\tvec3 halfWidth = rectAreaLight.halfWidth;\n\t\tvec3 halfHeight = rectAreaLight.halfHeight;\n\t\tvec3 lightColor = rectAreaLight.color;\n\t\tfloat roughness = material.roughness;\n\t\tvec3 rectCoords[ 4 ];\n\t\trectCoords[ 0 ] = lightPos + halfWidth - halfHeight;\t\trectCoords[ 1 ] = lightPos - halfWidth - halfHeight;\n\t\trectCoords[ 2 ] = lightPos - halfWidth + halfHeight;\n\t\trectCoords[ 3 ] = lightPos + halfWidth + halfHeight;\n\t\tvec2 uv = LTC_Uv( normal, viewDir, roughness );\n\t\tvec4 t1 = texture2D( ltc_1, uv );\n\t\tvec4 t2 = texture2D( ltc_2, uv );\n\t\tmat3 mInv = mat3(\n\t\t\tvec3( t1.x, 0, t1.y ),\n\t\t\tvec3(    0, 1,    0 ),\n\t\t\tvec3( t1.z, 0, t1.w )\n\t\t);\n\t\tvec3 fresnel = ( material.specularColor * t2.x + ( vec3( 1.0 ) - material.specularColor ) * t2.y );\n\t\treflectedLight.directSpecular += lightColor * fresnel * LTC_Evaluate( normal, viewDir, position, mInv, rectCoords );\n\t\treflectedLight.directDiffuse += lightColor * material.diffuseColor * LTC_Evaluate( normal, viewDir, position, mat3( 1.0 ), rectCoords );\n\t}\n#endif\nvoid RE_Direct_Physical( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\n\tfloat dotNL = saturate( dot( geometryNormal, directLight.direction ) );\n\tvec3 irradiance = dotNL * directLight.color;\n\t#ifdef USE_CLEARCOAT\n\t\tfloat dotNLcc = saturate( dot( geometryClearcoatNormal, directLight.direction ) );\n\t\tvec3 ccIrradiance = dotNLcc * directLight.color;\n\t\tclearcoatSpecularDirect += ccIrradiance * BRDF_GGX_Clearcoat( directLight.direction, geometryViewDir, geometryClearcoatNormal, material );\n\t#endif\n\t#ifdef USE_SHEEN\n\t\tsheenSpecularDirect += irradiance * BRDF_Sheen( directLight.direction, geometryViewDir, geometryNormal, material.sheenColor, material.sheenRoughness );\n\t#endif\n\treflectedLight.directSpecular += irradiance * BRDF_GGX( directLight.direction, geometryViewDir, geometryNormal, material );\n\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\nvoid RE_IndirectDiffuse_Physical( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\n\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\nvoid RE_IndirectSpecular_Physical( const in vec3 radiance, const in vec3 irradiance, const in vec3 clearcoatRadiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight) {\n\t#ifdef USE_CLEARCOAT\n\t\tclearcoatSpecularIndirect += clearcoatRadiance * EnvironmentBRDF( geometryClearcoatNormal, geometryViewDir, material.clearcoatF0, material.clearcoatF90, material.clearcoatRoughness );\n\t#endif\n\t#ifdef USE_SHEEN\n\t\tsheenSpecularIndirect += irradiance * material.sheenColor * IBLSheenBRDF( geometryNormal, geometryViewDir, material.sheenRoughness );\n\t#endif\n\tvec3 singleScattering = vec3( 0.0 );\n\tvec3 multiScattering = vec3( 0.0 );\n\tvec3 cosineWeightedIrradiance = irradiance * RECIPROCAL_PI;\n\t#ifdef USE_IRIDESCENCE\n\t\tcomputeMultiscatteringIridescence( geometryNormal, geometryViewDir, material.specularColor, material.specularF90, material.iridescence, material.iridescenceFresnel, material.roughness, singleScattering, multiScattering );\n\t#else\n\t\tcomputeMultiscattering( geometryNormal, geometryViewDir, material.specularColor, material.specularF90, material.roughness, singleScattering, multiScattering );\n\t#endif\n\tvec3 totalScattering = singleScattering + multiScattering;\n\tvec3 diffuse = material.diffuseColor * ( 1.0 - max( max( totalScattering.r, totalScattering.g ), totalScattering.b ) );\n\treflectedLight.indirectSpecular += radiance * singleScattering;\n\treflectedLight.indirectSpecular += multiScattering * cosineWeightedIrradiance;\n\treflectedLight.indirectDiffuse += diffuse * cosineWeightedIrradiance;\n}\n#define RE_Direct\t\t\t\tRE_Direct_Physical\n#define RE_Direct_RectArea\t\tRE_Direct_RectArea_Physical\n#define RE_IndirectDiffuse\t\tRE_IndirectDiffuse_Physical\n#define RE_IndirectSpecular\t\tRE_IndirectSpecular_Physical\nfloat computeSpecularOcclusion( const in float dotNV, const in float ambientOcclusion, const in float roughness ) {\n\treturn saturate( pow( dotNV + ambientOcclusion, exp2( - 16.0 * roughness - 1.0 ) ) - 1.0 + ambientOcclusion );\n}";

	var lights_fragment_begin = "\nvec3 geometryPosition = - vViewPosition;\nvec3 geometryNormal = normal;\nvec3 geometryViewDir = ( isOrthographic ) ? vec3( 0, 0, 1 ) : normalize( vViewPosition );\nvec3 geometryClearcoatNormal = vec3( 0.0 );\n#ifdef USE_CLEARCOAT\n\tgeometryClearcoatNormal = clearcoatNormal;\n#endif\n#ifdef USE_IRIDESCENCE\n\tfloat dotNVi = saturate( dot( normal, geometryViewDir ) );\n\tif ( material.iridescenceThickness == 0.0 ) {\n\t\tmaterial.iridescence = 0.0;\n\t} else {\n\t\tmaterial.iridescence = saturate( material.iridescence );\n\t}\n\tif ( material.iridescence > 0.0 ) {\n\t\tmaterial.iridescenceFresnel = evalIridescence( 1.0, material.iridescenceIOR, dotNVi, material.iridescenceThickness, material.specularColor );\n\t\tmaterial.iridescenceF0 = Schlick_to_F0( material.iridescenceFresnel, 1.0, dotNVi );\n\t}\n#endif\nIncidentLight directLight;\n#if ( NUM_POINT_LIGHTS > 0 ) && defined( RE_Direct )\n\tPointLight pointLight;\n\t#if defined( USE_SHADOWMAP ) && NUM_POINT_LIGHT_SHADOWS > 0\n\tPointLightShadow pointLightShadow;\n\t#endif\n\t#pragma unroll_loop_start\n\tfor ( int i = 0; i < NUM_POINT_LIGHTS; i ++ ) {\n\t\tpointLight = pointLights[ i ];\n\t\tgetPointLightInfo( pointLight, geometryPosition, directLight );\n\t\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_POINT_LIGHT_SHADOWS )\n\t\tpointLightShadow = pointLightShadows[ i ];\n\t\tdirectLight.color *= ( directLight.visible && receiveShadow ) ? getPointShadow( pointShadowMap[ i ], pointLightShadow.shadowMapSize, pointLightShadow.shadowIntensity, pointLightShadow.shadowBias, pointLightShadow.shadowRadius, vPointShadowCoord[ i ], pointLightShadow.shadowCameraNear, pointLightShadow.shadowCameraFar ) : 1.0;\n\t\t#endif\n\t\tRE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n\t}\n\t#pragma unroll_loop_end\n#endif\n#if ( NUM_SPOT_LIGHTS > 0 ) && defined( RE_Direct )\n\tSpotLight spotLight;\n\tvec4 spotColor;\n\tvec3 spotLightCoord;\n\tbool inSpotLightMap;\n\t#if defined( USE_SHADOWMAP ) && NUM_SPOT_LIGHT_SHADOWS > 0\n\tSpotLightShadow spotLightShadow;\n\t#endif\n\t#pragma unroll_loop_start\n\tfor ( int i = 0; i < NUM_SPOT_LIGHTS; i ++ ) {\n\t\tspotLight = spotLights[ i ];\n\t\tgetSpotLightInfo( spotLight, geometryPosition, directLight );\n\t\t#if ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS )\n\t\t#define SPOT_LIGHT_MAP_INDEX UNROLLED_LOOP_INDEX\n\t\t#elif ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\n\t\t#define SPOT_LIGHT_MAP_INDEX NUM_SPOT_LIGHT_MAPS\n\t\t#else\n\t\t#define SPOT_LIGHT_MAP_INDEX ( UNROLLED_LOOP_INDEX - NUM_SPOT_LIGHT_SHADOWS + NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS )\n\t\t#endif\n\t\t#if ( SPOT_LIGHT_MAP_INDEX < NUM_SPOT_LIGHT_MAPS )\n\t\t\tspotLightCoord = vSpotLightCoord[ i ].xyz / vSpotLightCoord[ i ].w;\n\t\t\tinSpotLightMap = all( lessThan( abs( spotLightCoord * 2. - 1. ), vec3( 1.0 ) ) );\n\t\t\tspotColor = texture2D( spotLightMap[ SPOT_LIGHT_MAP_INDEX ], spotLightCoord.xy );\n\t\t\tdirectLight.color = inSpotLightMap ? directLight.color * spotColor.rgb : directLight.color;\n\t\t#endif\n\t\t#undef SPOT_LIGHT_MAP_INDEX\n\t\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\n\t\tspotLightShadow = spotLightShadows[ i ];\n\t\tdirectLight.color *= ( directLight.visible && receiveShadow ) ? getShadow( spotShadowMap[ i ], spotLightShadow.shadowMapSize, spotLightShadow.shadowIntensity, spotLightShadow.shadowBias, spotLightShadow.shadowRadius, vSpotLightCoord[ i ] ) : 1.0;\n\t\t#endif\n\t\tRE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n\t}\n\t#pragma unroll_loop_end\n#endif\n#if ( NUM_DIR_LIGHTS > 0 ) && defined( RE_Direct )\n\tDirectionalLight directionalLight;\n\t#if defined( USE_SHADOWMAP ) && NUM_DIR_LIGHT_SHADOWS > 0\n\tDirectionalLightShadow directionalLightShadow;\n\t#endif\n\t#pragma unroll_loop_start\n\tfor ( int i = 0; i < NUM_DIR_LIGHTS; i ++ ) {\n\t\tdirectionalLight = directionalLights[ i ];\n\t\tgetDirectionalLightInfo( directionalLight, directLight );\n\t\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_DIR_LIGHT_SHADOWS )\n\t\tdirectionalLightShadow = directionalLightShadows[ i ];\n\t\tdirectLight.color *= ( directLight.visible && receiveShadow ) ? getShadow( directionalShadowMap[ i ], directionalLightShadow.shadowMapSize, directionalLightShadow.shadowIntensity, directionalLightShadow.shadowBias, directionalLightShadow.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;\n\t\t#endif\n\t\tRE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n\t}\n\t#pragma unroll_loop_end\n#endif\n#if ( NUM_RECT_AREA_LIGHTS > 0 ) && defined( RE_Direct_RectArea )\n\tRectAreaLight rectAreaLight;\n\t#pragma unroll_loop_start\n\tfor ( int i = 0; i < NUM_RECT_AREA_LIGHTS; i ++ ) {\n\t\trectAreaLight = rectAreaLights[ i ];\n\t\tRE_Direct_RectArea( rectAreaLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n\t}\n\t#pragma unroll_loop_end\n#endif\n#if defined( RE_IndirectDiffuse )\n\tvec3 iblIrradiance = vec3( 0.0 );\n\tvec3 irradiance = getAmbientLightIrradiance( ambientLightColor );\n\t#if defined( USE_LIGHT_PROBES )\n\t\tirradiance += getLightProbeIrradiance( lightProbe, geometryNormal );\n\t#endif\n\t#if ( NUM_HEMI_LIGHTS > 0 )\n\t\t#pragma unroll_loop_start\n\t\tfor ( int i = 0; i < NUM_HEMI_LIGHTS; i ++ ) {\n\t\t\tirradiance += getHemisphereLightIrradiance( hemisphereLights[ i ], geometryNormal );\n\t\t}\n\t\t#pragma unroll_loop_end\n\t#endif\n#endif\n#if defined( RE_IndirectSpecular )\n\tvec3 radiance = vec3( 0.0 );\n\tvec3 clearcoatRadiance = vec3( 0.0 );\n#endif";

	var lights_fragment_maps = "#if defined( RE_IndirectDiffuse )\n\t#ifdef USE_LIGHTMAP\n\t\tvec4 lightMapTexel = texture2D( lightMap, vLightMapUv );\n\t\tvec3 lightMapIrradiance = lightMapTexel.rgb * lightMapIntensity;\n\t\tirradiance += lightMapIrradiance;\n\t#endif\n\t#if defined( USE_ENVMAP ) && defined( STANDARD ) && defined( ENVMAP_TYPE_CUBE_UV )\n\t\tiblIrradiance += getIBLIrradiance( geometryNormal );\n\t#endif\n#endif\n#if defined( USE_ENVMAP ) && defined( RE_IndirectSpecular )\n\t#ifdef USE_ANISOTROPY\n\t\tradiance += getIBLAnisotropyRadiance( geometryViewDir, geometryNormal, material.roughness, material.anisotropyB, material.anisotropy );\n\t#else\n\t\tradiance += getIBLRadiance( geometryViewDir, geometryNormal, material.roughness );\n\t#endif\n\t#ifdef USE_CLEARCOAT\n\t\tclearcoatRadiance += getIBLRadiance( geometryViewDir, geometryClearcoatNormal, material.clearcoatRoughness );\n\t#endif\n#endif";

	var lights_fragment_end = "#if defined( RE_IndirectDiffuse )\n\tRE_IndirectDiffuse( irradiance, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n#endif\n#if defined( RE_IndirectSpecular )\n\tRE_IndirectSpecular( radiance, iblIrradiance, clearcoatRadiance, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n#endif";

	var logdepthbuf_fragment = "#if defined( USE_LOGDEPTHBUF )\n\tgl_FragDepth = vIsPerspective == 0.0 ? gl_FragCoord.z : log2( vFragDepth ) * logDepthBufFC * 0.5;\n#endif";

	var logdepthbuf_pars_fragment = "#if defined( USE_LOGDEPTHBUF )\n\tuniform float logDepthBufFC;\n\tvarying float vFragDepth;\n\tvarying float vIsPerspective;\n#endif";

	var logdepthbuf_pars_vertex = "#ifdef USE_LOGDEPTHBUF\n\tvarying float vFragDepth;\n\tvarying float vIsPerspective;\n#endif";

	var logdepthbuf_vertex = "#ifdef USE_LOGDEPTHBUF\n\tvFragDepth = 1.0 + gl_Position.w;\n\tvIsPerspective = float( isPerspectiveMatrix( projectionMatrix ) );\n#endif";

	var map_fragment = "#ifdef USE_MAP\n\tvec4 sampledDiffuseColor = texture2D( map, vMapUv );\n\t#ifdef DECODE_VIDEO_TEXTURE\n\t\tsampledDiffuseColor = sRGBTransferEOTF( sampledDiffuseColor );\n\t#endif\n\tdiffuseColor *= sampledDiffuseColor;\n#endif";

	var map_pars_fragment = "#ifdef USE_MAP\n\tuniform sampler2D map;\n#endif";

	var map_particle_fragment = "#if defined( USE_MAP ) || defined( USE_ALPHAMAP )\n\t#if defined( USE_POINTS_UV )\n\t\tvec2 uv = vUv;\n\t#else\n\t\tvec2 uv = ( uvTransform * vec3( gl_PointCoord.x, 1.0 - gl_PointCoord.y, 1 ) ).xy;\n\t#endif\n#endif\n#ifdef USE_MAP\n\tdiffuseColor *= texture2D( map, uv );\n#endif\n#ifdef USE_ALPHAMAP\n\tdiffuseColor.a *= texture2D( alphaMap, uv ).g;\n#endif";

	var map_particle_pars_fragment = "#if defined( USE_POINTS_UV )\n\tvarying vec2 vUv;\n#else\n\t#if defined( USE_MAP ) || defined( USE_ALPHAMAP )\n\t\tuniform mat3 uvTransform;\n\t#endif\n#endif\n#ifdef USE_MAP\n\tuniform sampler2D map;\n#endif\n#ifdef USE_ALPHAMAP\n\tuniform sampler2D alphaMap;\n#endif";

	var metalnessmap_fragment = "float metalnessFactor = metalness;\n#ifdef USE_METALNESSMAP\n\tvec4 texelMetalness = texture2D( metalnessMap, vMetalnessMapUv );\n\tmetalnessFactor *= texelMetalness.b;\n#endif";

	var metalnessmap_pars_fragment = "#ifdef USE_METALNESSMAP\n\tuniform sampler2D metalnessMap;\n#endif";

	var morphinstance_vertex = "#ifdef USE_INSTANCING_MORPH\n\tfloat morphTargetInfluences[ MORPHTARGETS_COUNT ];\n\tfloat morphTargetBaseInfluence = texelFetch( morphTexture, ivec2( 0, gl_InstanceID ), 0 ).r;\n\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\n\t\tmorphTargetInfluences[i] =  texelFetch( morphTexture, ivec2( i + 1, gl_InstanceID ), 0 ).r;\n\t}\n#endif";

	var morphcolor_vertex = "#if defined( USE_MORPHCOLORS )\n\tvColor *= morphTargetBaseInfluence;\n\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\n\t\t#if defined( USE_COLOR_ALPHA )\n\t\t\tif ( morphTargetInfluences[ i ] != 0.0 ) vColor += getMorph( gl_VertexID, i, 2 ) * morphTargetInfluences[ i ];\n\t\t#elif defined( USE_COLOR )\n\t\t\tif ( morphTargetInfluences[ i ] != 0.0 ) vColor += getMorph( gl_VertexID, i, 2 ).rgb * morphTargetInfluences[ i ];\n\t\t#endif\n\t}\n#endif";

	var morphnormal_vertex = "#ifdef USE_MORPHNORMALS\n\tobjectNormal *= morphTargetBaseInfluence;\n\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\n\t\tif ( morphTargetInfluences[ i ] != 0.0 ) objectNormal += getMorph( gl_VertexID, i, 1 ).xyz * morphTargetInfluences[ i ];\n\t}\n#endif";

	var morphtarget_pars_vertex = "#ifdef USE_MORPHTARGETS\n\t#ifndef USE_INSTANCING_MORPH\n\t\tuniform float morphTargetBaseInfluence;\n\t\tuniform float morphTargetInfluences[ MORPHTARGETS_COUNT ];\n\t#endif\n\tuniform sampler2DArray morphTargetsTexture;\n\tuniform ivec2 morphTargetsTextureSize;\n\tvec4 getMorph( const in int vertexIndex, const in int morphTargetIndex, const in int offset ) {\n\t\tint texelIndex = vertexIndex * MORPHTARGETS_TEXTURE_STRIDE + offset;\n\t\tint y = texelIndex / morphTargetsTextureSize.x;\n\t\tint x = texelIndex - y * morphTargetsTextureSize.x;\n\t\tivec3 morphUV = ivec3( x, y, morphTargetIndex );\n\t\treturn texelFetch( morphTargetsTexture, morphUV, 0 );\n\t}\n#endif";

	var morphtarget_vertex = "#ifdef USE_MORPHTARGETS\n\ttransformed *= morphTargetBaseInfluence;\n\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\n\t\tif ( morphTargetInfluences[ i ] != 0.0 ) transformed += getMorph( gl_VertexID, i, 0 ).xyz * morphTargetInfluences[ i ];\n\t}\n#endif";

	var normal_fragment_begin = "float faceDirection = gl_FrontFacing ? 1.0 : - 1.0;\n#ifdef FLAT_SHADED\n\tvec3 fdx = dFdx( vViewPosition );\n\tvec3 fdy = dFdy( vViewPosition );\n\tvec3 normal = normalize( cross( fdx, fdy ) );\n#else\n\tvec3 normal = normalize( vNormal );\n\t#ifdef DOUBLE_SIDED\n\t\tnormal *= faceDirection;\n\t#endif\n#endif\n#if defined( USE_NORMALMAP_TANGENTSPACE ) || defined( USE_CLEARCOAT_NORMALMAP ) || defined( USE_ANISOTROPY )\n\t#ifdef USE_TANGENT\n\t\tmat3 tbn = mat3( normalize( vTangent ), normalize( vBitangent ), normal );\n\t#else\n\t\tmat3 tbn = getTangentFrame( - vViewPosition, normal,\n\t\t#if defined( USE_NORMALMAP )\n\t\t\tvNormalMapUv\n\t\t#elif defined( USE_CLEARCOAT_NORMALMAP )\n\t\t\tvClearcoatNormalMapUv\n\t\t#else\n\t\t\tvUv\n\t\t#endif\n\t\t);\n\t#endif\n\t#if defined( DOUBLE_SIDED ) && ! defined( FLAT_SHADED )\n\t\ttbn[0] *= faceDirection;\n\t\ttbn[1] *= faceDirection;\n\t#endif\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n\t#ifdef USE_TANGENT\n\t\tmat3 tbn2 = mat3( normalize( vTangent ), normalize( vBitangent ), normal );\n\t#else\n\t\tmat3 tbn2 = getTangentFrame( - vViewPosition, normal, vClearcoatNormalMapUv );\n\t#endif\n\t#if defined( DOUBLE_SIDED ) && ! defined( FLAT_SHADED )\n\t\ttbn2[0] *= faceDirection;\n\t\ttbn2[1] *= faceDirection;\n\t#endif\n#endif\nvec3 nonPerturbedNormal = normal;";

	var normal_fragment_maps = "#ifdef USE_NORMALMAP_OBJECTSPACE\n\tnormal = texture2D( normalMap, vNormalMapUv ).xyz * 2.0 - 1.0;\n\t#ifdef FLIP_SIDED\n\t\tnormal = - normal;\n\t#endif\n\t#ifdef DOUBLE_SIDED\n\t\tnormal = normal * faceDirection;\n\t#endif\n\tnormal = normalize( normalMatrix * normal );\n#elif defined( USE_NORMALMAP_TANGENTSPACE )\n\tvec3 mapN = texture2D( normalMap, vNormalMapUv ).xyz * 2.0 - 1.0;\n\tmapN.xy *= normalScale;\n\tnormal = normalize( tbn * mapN );\n#elif defined( USE_BUMPMAP )\n\tnormal = perturbNormalArb( - vViewPosition, normal, dHdxy_fwd(), faceDirection );\n#endif";

	var normal_pars_fragment = "#ifndef FLAT_SHADED\n\tvarying vec3 vNormal;\n\t#ifdef USE_TANGENT\n\t\tvarying vec3 vTangent;\n\t\tvarying vec3 vBitangent;\n\t#endif\n#endif";

	var normal_pars_vertex = "#ifndef FLAT_SHADED\n\tvarying vec3 vNormal;\n\t#ifdef USE_TANGENT\n\t\tvarying vec3 vTangent;\n\t\tvarying vec3 vBitangent;\n\t#endif\n#endif";

	var normal_vertex = "#ifndef FLAT_SHADED\n\tvNormal = normalize( transformedNormal );\n\t#ifdef USE_TANGENT\n\t\tvTangent = normalize( transformedTangent );\n\t\tvBitangent = normalize( cross( vNormal, vTangent ) * tangent.w );\n\t#endif\n#endif";

	var normalmap_pars_fragment = "#ifdef USE_NORMALMAP\n\tuniform sampler2D normalMap;\n\tuniform vec2 normalScale;\n#endif\n#ifdef USE_NORMALMAP_OBJECTSPACE\n\tuniform mat3 normalMatrix;\n#endif\n#if ! defined ( USE_TANGENT ) && ( defined ( USE_NORMALMAP_TANGENTSPACE ) || defined ( USE_CLEARCOAT_NORMALMAP ) || defined( USE_ANISOTROPY ) )\n\tmat3 getTangentFrame( vec3 eye_pos, vec3 surf_norm, vec2 uv ) {\n\t\tvec3 q0 = dFdx( eye_pos.xyz );\n\t\tvec3 q1 = dFdy( eye_pos.xyz );\n\t\tvec2 st0 = dFdx( uv.st );\n\t\tvec2 st1 = dFdy( uv.st );\n\t\tvec3 N = surf_norm;\n\t\tvec3 q1perp = cross( q1, N );\n\t\tvec3 q0perp = cross( N, q0 );\n\t\tvec3 T = q1perp * st0.x + q0perp * st1.x;\n\t\tvec3 B = q1perp * st0.y + q0perp * st1.y;\n\t\tfloat det = max( dot( T, T ), dot( B, B ) );\n\t\tfloat scale = ( det == 0.0 ) ? 0.0 : inversesqrt( det );\n\t\treturn mat3( T * scale, B * scale, N );\n\t}\n#endif";

	var clearcoat_normal_fragment_begin = "#ifdef USE_CLEARCOAT\n\tvec3 clearcoatNormal = nonPerturbedNormal;\n#endif";

	var clearcoat_normal_fragment_maps = "#ifdef USE_CLEARCOAT_NORMALMAP\n\tvec3 clearcoatMapN = texture2D( clearcoatNormalMap, vClearcoatNormalMapUv ).xyz * 2.0 - 1.0;\n\tclearcoatMapN.xy *= clearcoatNormalScale;\n\tclearcoatNormal = normalize( tbn2 * clearcoatMapN );\n#endif";

	var clearcoat_pars_fragment = "#ifdef USE_CLEARCOATMAP\n\tuniform sampler2D clearcoatMap;\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n\tuniform sampler2D clearcoatNormalMap;\n\tuniform vec2 clearcoatNormalScale;\n#endif\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n\tuniform sampler2D clearcoatRoughnessMap;\n#endif";

	var iridescence_pars_fragment = "#ifdef USE_IRIDESCENCEMAP\n\tuniform sampler2D iridescenceMap;\n#endif\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\n\tuniform sampler2D iridescenceThicknessMap;\n#endif";

	var opaque_fragment = "#ifdef OPAQUE\ndiffuseColor.a = 1.0;\n#endif\n#ifdef USE_TRANSMISSION\ndiffuseColor.a *= material.transmissionAlpha;\n#endif\ngl_FragColor = vec4( outgoingLight, diffuseColor.a );";

	var packing = "vec3 packNormalToRGB( const in vec3 normal ) {\n\treturn normalize( normal ) * 0.5 + 0.5;\n}\nvec3 unpackRGBToNormal( const in vec3 rgb ) {\n\treturn 2.0 * rgb.xyz - 1.0;\n}\nconst float PackUpscale = 256. / 255.;const float UnpackDownscale = 255. / 256.;const float ShiftRight8 = 1. / 256.;\nconst float Inv255 = 1. / 255.;\nconst vec4 PackFactors = vec4( 1.0, 256.0, 256.0 * 256.0, 256.0 * 256.0 * 256.0 );\nconst vec2 UnpackFactors2 = vec2( UnpackDownscale, 1.0 / PackFactors.g );\nconst vec3 UnpackFactors3 = vec3( UnpackDownscale / PackFactors.rg, 1.0 / PackFactors.b );\nconst vec4 UnpackFactors4 = vec4( UnpackDownscale / PackFactors.rgb, 1.0 / PackFactors.a );\nvec4 packDepthToRGBA( const in float v ) {\n\tif( v <= 0.0 )\n\t\treturn vec4( 0., 0., 0., 0. );\n\tif( v >= 1.0 )\n\t\treturn vec4( 1., 1., 1., 1. );\n\tfloat vuf;\n\tfloat af = modf( v * PackFactors.a, vuf );\n\tfloat bf = modf( vuf * ShiftRight8, vuf );\n\tfloat gf = modf( vuf * ShiftRight8, vuf );\n\treturn vec4( vuf * Inv255, gf * PackUpscale, bf * PackUpscale, af );\n}\nvec3 packDepthToRGB( const in float v ) {\n\tif( v <= 0.0 )\n\t\treturn vec3( 0., 0., 0. );\n\tif( v >= 1.0 )\n\t\treturn vec3( 1., 1., 1. );\n\tfloat vuf;\n\tfloat bf = modf( v * PackFactors.b, vuf );\n\tfloat gf = modf( vuf * ShiftRight8, vuf );\n\treturn vec3( vuf * Inv255, gf * PackUpscale, bf );\n}\nvec2 packDepthToRG( const in float v ) {\n\tif( v <= 0.0 )\n\t\treturn vec2( 0., 0. );\n\tif( v >= 1.0 )\n\t\treturn vec2( 1., 1. );\n\tfloat vuf;\n\tfloat gf = modf( v * 256., vuf );\n\treturn vec2( vuf * Inv255, gf );\n}\nfloat unpackRGBAToDepth( const in vec4 v ) {\n\treturn dot( v, UnpackFactors4 );\n}\nfloat unpackRGBToDepth( const in vec3 v ) {\n\treturn dot( v, UnpackFactors3 );\n}\nfloat unpackRGToDepth( const in vec2 v ) {\n\treturn v.r * UnpackFactors2.r + v.g * UnpackFactors2.g;\n}\nvec4 pack2HalfToRGBA( const in vec2 v ) {\n\tvec4 r = vec4( v.x, fract( v.x * 255.0 ), v.y, fract( v.y * 255.0 ) );\n\treturn vec4( r.x - r.y / 255.0, r.y, r.z - r.w / 255.0, r.w );\n}\nvec2 unpackRGBATo2Half( const in vec4 v ) {\n\treturn vec2( v.x + ( v.y / 255.0 ), v.z + ( v.w / 255.0 ) );\n}\nfloat viewZToOrthographicDepth( const in float viewZ, const in float near, const in float far ) {\n\treturn ( viewZ + near ) / ( near - far );\n}\nfloat orthographicDepthToViewZ( const in float depth, const in float near, const in float far ) {\n\treturn depth * ( near - far ) - near;\n}\nfloat viewZToPerspectiveDepth( const in float viewZ, const in float near, const in float far ) {\n\treturn ( ( near + viewZ ) * far ) / ( ( far - near ) * viewZ );\n}\nfloat perspectiveDepthToViewZ( const in float depth, const in float near, const in float far ) {\n\treturn ( near * far ) / ( ( far - near ) * depth - far );\n}";

	var premultiplied_alpha_fragment = "#ifdef PREMULTIPLIED_ALPHA\n\tgl_FragColor.rgb *= gl_FragColor.a;\n#endif";

	var project_vertex = "vec4 mvPosition = vec4( transformed, 1.0 );\n#ifdef USE_BATCHING\n\tmvPosition = batchingMatrix * mvPosition;\n#endif\n#ifdef USE_INSTANCING\n\tmvPosition = instanceMatrix * mvPosition;\n#endif\nmvPosition = modelViewMatrix * mvPosition;\ngl_Position = projectionMatrix * mvPosition;";

	var dithering_fragment = "#ifdef DITHERING\n\tgl_FragColor.rgb = dithering( gl_FragColor.rgb );\n#endif";

	var dithering_pars_fragment = "#ifdef DITHERING\n\tvec3 dithering( vec3 color ) {\n\t\tfloat grid_position = rand( gl_FragCoord.xy );\n\t\tvec3 dither_shift_RGB = vec3( 0.25 / 255.0, -0.25 / 255.0, 0.25 / 255.0 );\n\t\tdither_shift_RGB = mix( 2.0 * dither_shift_RGB, -2.0 * dither_shift_RGB, grid_position );\n\t\treturn color + dither_shift_RGB;\n\t}\n#endif";

	var roughnessmap_fragment = "float roughnessFactor = roughness;\n#ifdef USE_ROUGHNESSMAP\n\tvec4 texelRoughness = texture2D( roughnessMap, vRoughnessMapUv );\n\troughnessFactor *= texelRoughness.g;\n#endif";

	var roughnessmap_pars_fragment = "#ifdef USE_ROUGHNESSMAP\n\tuniform sampler2D roughnessMap;\n#endif";

	var shadowmap_pars_fragment = "#if NUM_SPOT_LIGHT_COORDS > 0\n\tvarying vec4 vSpotLightCoord[ NUM_SPOT_LIGHT_COORDS ];\n#endif\n#if NUM_SPOT_LIGHT_MAPS > 0\n\tuniform sampler2D spotLightMap[ NUM_SPOT_LIGHT_MAPS ];\n#endif\n#ifdef USE_SHADOWMAP\n\t#if NUM_DIR_LIGHT_SHADOWS > 0\n\t\tuniform sampler2D directionalShadowMap[ NUM_DIR_LIGHT_SHADOWS ];\n\t\tvarying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];\n\t\tstruct DirectionalLightShadow {\n\t\t\tfloat shadowIntensity;\n\t\t\tfloat shadowBias;\n\t\t\tfloat shadowNormalBias;\n\t\t\tfloat shadowRadius;\n\t\t\tvec2 shadowMapSize;\n\t\t};\n\t\tuniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];\n\t#endif\n\t#if NUM_SPOT_LIGHT_SHADOWS > 0\n\t\tuniform sampler2D spotShadowMap[ NUM_SPOT_LIGHT_SHADOWS ];\n\t\tstruct SpotLightShadow {\n\t\t\tfloat shadowIntensity;\n\t\t\tfloat shadowBias;\n\t\t\tfloat shadowNormalBias;\n\t\t\tfloat shadowRadius;\n\t\t\tvec2 shadowMapSize;\n\t\t};\n\t\tuniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];\n\t#endif\n\t#if NUM_POINT_LIGHT_SHADOWS > 0\n\t\tuniform sampler2D pointShadowMap[ NUM_POINT_LIGHT_SHADOWS ];\n\t\tvarying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];\n\t\tstruct PointLightShadow {\n\t\t\tfloat shadowIntensity;\n\t\t\tfloat shadowBias;\n\t\t\tfloat shadowNormalBias;\n\t\t\tfloat shadowRadius;\n\t\t\tvec2 shadowMapSize;\n\t\t\tfloat shadowCameraNear;\n\t\t\tfloat shadowCameraFar;\n\t\t};\n\t\tuniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];\n\t#endif\n\tfloat texture2DCompare( sampler2D depths, vec2 uv, float compare ) {\n\t\treturn step( compare, unpackRGBAToDepth( texture2D( depths, uv ) ) );\n\t}\n\tvec2 texture2DDistribution( sampler2D shadow, vec2 uv ) {\n\t\treturn unpackRGBATo2Half( texture2D( shadow, uv ) );\n\t}\n\tfloat VSMShadow (sampler2D shadow, vec2 uv, float compare ){\n\t\tfloat occlusion = 1.0;\n\t\tvec2 distribution = texture2DDistribution( shadow, uv );\n\t\tfloat hard_shadow = step( compare , distribution.x );\n\t\tif (hard_shadow != 1.0 ) {\n\t\t\tfloat distance = compare - distribution.x ;\n\t\t\tfloat variance = max( 0.00000, distribution.y * distribution.y );\n\t\t\tfloat softness_probability = variance / (variance + distance * distance );\t\t\tsoftness_probability = clamp( ( softness_probability - 0.3 ) / ( 0.95 - 0.3 ), 0.0, 1.0 );\t\t\tocclusion = clamp( max( hard_shadow, softness_probability ), 0.0, 1.0 );\n\t\t}\n\t\treturn occlusion;\n\t}\n\tfloat getShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowIntensity, float shadowBias, float shadowRadius, vec4 shadowCoord ) {\n\t\tfloat shadow = 1.0;\n\t\tshadowCoord.xyz /= shadowCoord.w;\n\t\tshadowCoord.z += shadowBias;\n\t\tbool inFrustum = shadowCoord.x >= 0.0 && shadowCoord.x <= 1.0 && shadowCoord.y >= 0.0 && shadowCoord.y <= 1.0;\n\t\tbool frustumTest = inFrustum && shadowCoord.z <= 1.0;\n\t\tif ( frustumTest ) {\n\t\t#if defined( SHADOWMAP_TYPE_PCF )\n\t\t\tvec2 texelSize = vec2( 1.0 ) / shadowMapSize;\n\t\t\tfloat dx0 = - texelSize.x * shadowRadius;\n\t\t\tfloat dy0 = - texelSize.y * shadowRadius;\n\t\t\tfloat dx1 = + texelSize.x * shadowRadius;\n\t\t\tfloat dy1 = + texelSize.y * shadowRadius;\n\t\t\tfloat dx2 = dx0 / 2.0;\n\t\t\tfloat dy2 = dy0 / 2.0;\n\t\t\tfloat dx3 = dx1 / 2.0;\n\t\t\tfloat dy3 = dy1 / 2.0;\n\t\t\tshadow = (\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy0 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy0 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy0 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy2 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy2 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy2 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, 0.0 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, 0.0 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, 0.0 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, 0.0 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy3 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy3 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy3 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy1 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy1 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy1 ), shadowCoord.z )\n\t\t\t) * ( 1.0 / 17.0 );\n\t\t#elif defined( SHADOWMAP_TYPE_PCF_SOFT )\n\t\t\tvec2 texelSize = vec2( 1.0 ) / shadowMapSize;\n\t\t\tfloat dx = texelSize.x;\n\t\t\tfloat dy = texelSize.y;\n\t\t\tvec2 uv = shadowCoord.xy;\n\t\t\tvec2 f = fract( uv * shadowMapSize + 0.5 );\n\t\t\tuv -= f * texelSize;\n\t\t\tshadow = (\n\t\t\t\ttexture2DCompare( shadowMap, uv, shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, uv + vec2( dx, 0.0 ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, uv + vec2( 0.0, dy ), shadowCoord.z ) +\n\t\t\t\ttexture2DCompare( shadowMap, uv + texelSize, shadowCoord.z ) +\n\t\t\t\tmix( texture2DCompare( shadowMap, uv + vec2( -dx, 0.0 ), shadowCoord.z ),\n\t\t\t\t\t texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 0.0 ), shadowCoord.z ),\n\t\t\t\t\t f.x ) +\n\t\t\t\tmix( texture2DCompare( shadowMap, uv + vec2( -dx, dy ), shadowCoord.z ),\n\t\t\t\t\t texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, dy ), shadowCoord.z ),\n\t\t\t\t\t f.x ) +\n\t\t\t\tmix( texture2DCompare( shadowMap, uv + vec2( 0.0, -dy ), shadowCoord.z ),\n\t\t\t\t\t texture2DCompare( shadowMap, uv + vec2( 0.0, 2.0 * dy ), shadowCoord.z ),\n\t\t\t\t\t f.y ) +\n\t\t\t\tmix( texture2DCompare( shadowMap, uv + vec2( dx, -dy ), shadowCoord.z ),\n\t\t\t\t\t texture2DCompare( shadowMap, uv + vec2( dx, 2.0 * dy ), shadowCoord.z ),\n\t\t\t\t\t f.y ) +\n\t\t\t\tmix( mix( texture2DCompare( shadowMap, uv + vec2( -dx, -dy ), shadowCoord.z ),\n\t\t\t\t\t\t  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, -dy ), shadowCoord.z ),\n\t\t\t\t\t\t  f.x ),\n\t\t\t\t\t mix( texture2DCompare( shadowMap, uv + vec2( -dx, 2.0 * dy ), shadowCoord.z ),\n\t\t\t\t\t\t  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 2.0 * dy ), shadowCoord.z ),\n\t\t\t\t\t\t  f.x ),\n\t\t\t\t\t f.y )\n\t\t\t) * ( 1.0 / 9.0 );\n\t\t#elif defined( SHADOWMAP_TYPE_VSM )\n\t\t\tshadow = VSMShadow( shadowMap, shadowCoord.xy, shadowCoord.z );\n\t\t#else\n\t\t\tshadow = texture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z );\n\t\t#endif\n\t\t}\n\t\treturn mix( 1.0, shadow, shadowIntensity );\n\t}\n\tvec2 cubeToUV( vec3 v, float texelSizeY ) {\n\t\tvec3 absV = abs( v );\n\t\tfloat scaleToCube = 1.0 / max( absV.x, max( absV.y, absV.z ) );\n\t\tabsV *= scaleToCube;\n\t\tv *= scaleToCube * ( 1.0 - 2.0 * texelSizeY );\n\t\tvec2 planar = v.xy;\n\t\tfloat almostATexel = 1.5 * texelSizeY;\n\t\tfloat almostOne = 1.0 - almostATexel;\n\t\tif ( absV.z >= almostOne ) {\n\t\t\tif ( v.z > 0.0 )\n\t\t\t\tplanar.x = 4.0 - v.x;\n\t\t} else if ( absV.x >= almostOne ) {\n\t\t\tfloat signX = sign( v.x );\n\t\t\tplanar.x = v.z * signX + 2.0 * signX;\n\t\t} else if ( absV.y >= almostOne ) {\n\t\t\tfloat signY = sign( v.y );\n\t\t\tplanar.x = v.x + 2.0 * signY + 2.0;\n\t\t\tplanar.y = v.z * signY - 2.0;\n\t\t}\n\t\treturn vec2( 0.125, 0.25 ) * planar + vec2( 0.375, 0.75 );\n\t}\n\tfloat getPointShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowIntensity, float shadowBias, float shadowRadius, vec4 shadowCoord, float shadowCameraNear, float shadowCameraFar ) {\n\t\tfloat shadow = 1.0;\n\t\tvec3 lightToPosition = shadowCoord.xyz;\n\t\t\n\t\tfloat lightToPositionLength = length( lightToPosition );\n\t\tif ( lightToPositionLength - shadowCameraFar <= 0.0 && lightToPositionLength - shadowCameraNear >= 0.0 ) {\n\t\t\tfloat dp = ( lightToPositionLength - shadowCameraNear ) / ( shadowCameraFar - shadowCameraNear );\t\t\tdp += shadowBias;\n\t\t\tvec3 bd3D = normalize( lightToPosition );\n\t\t\tvec2 texelSize = vec2( 1.0 ) / ( shadowMapSize * vec2( 4.0, 2.0 ) );\n\t\t\t#if defined( SHADOWMAP_TYPE_PCF ) || defined( SHADOWMAP_TYPE_PCF_SOFT ) || defined( SHADOWMAP_TYPE_VSM )\n\t\t\t\tvec2 offset = vec2( - 1, 1 ) * shadowRadius * texelSize.y;\n\t\t\t\tshadow = (\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyy, texelSize.y ), dp ) +\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyy, texelSize.y ), dp ) +\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyx, texelSize.y ), dp ) +\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyx, texelSize.y ), dp ) +\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp ) +\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxy, texelSize.y ), dp ) +\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxy, texelSize.y ), dp ) +\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxx, texelSize.y ), dp ) +\n\t\t\t\t\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxx, texelSize.y ), dp )\n\t\t\t\t) * ( 1.0 / 9.0 );\n\t\t\t#else\n\t\t\t\tshadow = texture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp );\n\t\t\t#endif\n\t\t}\n\t\treturn mix( 1.0, shadow, shadowIntensity );\n\t}\n#endif";

	var shadowmap_pars_vertex = "#if NUM_SPOT_LIGHT_COORDS > 0\n\tuniform mat4 spotLightMatrix[ NUM_SPOT_LIGHT_COORDS ];\n\tvarying vec4 vSpotLightCoord[ NUM_SPOT_LIGHT_COORDS ];\n#endif\n#ifdef USE_SHADOWMAP\n\t#if NUM_DIR_LIGHT_SHADOWS > 0\n\t\tuniform mat4 directionalShadowMatrix[ NUM_DIR_LIGHT_SHADOWS ];\n\t\tvarying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];\n\t\tstruct DirectionalLightShadow {\n\t\t\tfloat shadowIntensity;\n\t\t\tfloat shadowBias;\n\t\t\tfloat shadowNormalBias;\n\t\t\tfloat shadowRadius;\n\t\t\tvec2 shadowMapSize;\n\t\t};\n\t\tuniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];\n\t#endif\n\t#if NUM_SPOT_LIGHT_SHADOWS > 0\n\t\tstruct SpotLightShadow {\n\t\t\tfloat shadowIntensity;\n\t\t\tfloat shadowBias;\n\t\t\tfloat shadowNormalBias;\n\t\t\tfloat shadowRadius;\n\t\t\tvec2 shadowMapSize;\n\t\t};\n\t\tuniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];\n\t#endif\n\t#if NUM_POINT_LIGHT_SHADOWS > 0\n\t\tuniform mat4 pointShadowMatrix[ NUM_POINT_LIGHT_SHADOWS ];\n\t\tvarying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];\n\t\tstruct PointLightShadow {\n\t\t\tfloat shadowIntensity;\n\t\t\tfloat shadowBias;\n\t\t\tfloat shadowNormalBias;\n\t\t\tfloat shadowRadius;\n\t\t\tvec2 shadowMapSize;\n\t\t\tfloat shadowCameraNear;\n\t\t\tfloat shadowCameraFar;\n\t\t};\n\t\tuniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];\n\t#endif\n#endif";

	var shadowmap_vertex = "#if ( defined( USE_SHADOWMAP ) && ( NUM_DIR_LIGHT_SHADOWS > 0 || NUM_POINT_LIGHT_SHADOWS > 0 ) ) || ( NUM_SPOT_LIGHT_COORDS > 0 )\n\tvec3 shadowWorldNormal = inverseTransformDirection( transformedNormal, viewMatrix );\n\tvec4 shadowWorldPosition;\n#endif\n#if defined( USE_SHADOWMAP )\n\t#if NUM_DIR_LIGHT_SHADOWS > 0\n\t\t#pragma unroll_loop_start\n\t\tfor ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {\n\t\t\tshadowWorldPosition = worldPosition + vec4( shadowWorldNormal * directionalLightShadows[ i ].shadowNormalBias, 0 );\n\t\t\tvDirectionalShadowCoord[ i ] = directionalShadowMatrix[ i ] * shadowWorldPosition;\n\t\t}\n\t\t#pragma unroll_loop_end\n\t#endif\n\t#if NUM_POINT_LIGHT_SHADOWS > 0\n\t\t#pragma unroll_loop_start\n\t\tfor ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {\n\t\t\tshadowWorldPosition = worldPosition + vec4( shadowWorldNormal * pointLightShadows[ i ].shadowNormalBias, 0 );\n\t\t\tvPointShadowCoord[ i ] = pointShadowMatrix[ i ] * shadowWorldPosition;\n\t\t}\n\t\t#pragma unroll_loop_end\n\t#endif\n#endif\n#if NUM_SPOT_LIGHT_COORDS > 0\n\t#pragma unroll_loop_start\n\tfor ( int i = 0; i < NUM_SPOT_LIGHT_COORDS; i ++ ) {\n\t\tshadowWorldPosition = worldPosition;\n\t\t#if ( defined( USE_SHADOWMAP ) && UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\n\t\t\tshadowWorldPosition.xyz += shadowWorldNormal * spotLightShadows[ i ].shadowNormalBias;\n\t\t#endif\n\t\tvSpotLightCoord[ i ] = spotLightMatrix[ i ] * shadowWorldPosition;\n\t}\n\t#pragma unroll_loop_end\n#endif";

	var shadowmask_pars_fragment = "float getShadowMask() {\n\tfloat shadow = 1.0;\n\t#ifdef USE_SHADOWMAP\n\t#if NUM_DIR_LIGHT_SHADOWS > 0\n\tDirectionalLightShadow directionalLight;\n\t#pragma unroll_loop_start\n\tfor ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {\n\t\tdirectionalLight = directionalLightShadows[ i ];\n\t\tshadow *= receiveShadow ? getShadow( directionalShadowMap[ i ], directionalLight.shadowMapSize, directionalLight.shadowIntensity, directionalLight.shadowBias, directionalLight.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;\n\t}\n\t#pragma unroll_loop_end\n\t#endif\n\t#if NUM_SPOT_LIGHT_SHADOWS > 0\n\tSpotLightShadow spotLight;\n\t#pragma unroll_loop_start\n\tfor ( int i = 0; i < NUM_SPOT_LIGHT_SHADOWS; i ++ ) {\n\t\tspotLight = spotLightShadows[ i ];\n\t\tshadow *= receiveShadow ? getShadow( spotShadowMap[ i ], spotLight.shadowMapSize, spotLight.shadowIntensity, spotLight.shadowBias, spotLight.shadowRadius, vSpotLightCoord[ i ] ) : 1.0;\n\t}\n\t#pragma unroll_loop_end\n\t#endif\n\t#if NUM_POINT_LIGHT_SHADOWS > 0\n\tPointLightShadow pointLight;\n\t#pragma unroll_loop_start\n\tfor ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {\n\t\tpointLight = pointLightShadows[ i ];\n\t\tshadow *= receiveShadow ? getPointShadow( pointShadowMap[ i ], pointLight.shadowMapSize, pointLight.shadowIntensity, pointLight.shadowBias, pointLight.shadowRadius, vPointShadowCoord[ i ], pointLight.shadowCameraNear, pointLight.shadowCameraFar ) : 1.0;\n\t}\n\t#pragma unroll_loop_end\n\t#endif\n\t#endif\n\treturn shadow;\n}";

	var skinbase_vertex = "#ifdef USE_SKINNING\n\tmat4 boneMatX = getBoneMatrix( skinIndex.x );\n\tmat4 boneMatY = getBoneMatrix( skinIndex.y );\n\tmat4 boneMatZ = getBoneMatrix( skinIndex.z );\n\tmat4 boneMatW = getBoneMatrix( skinIndex.w );\n#endif";

	var skinning_pars_vertex = "#ifdef USE_SKINNING\n\tuniform mat4 bindMatrix;\n\tuniform mat4 bindMatrixInverse;\n\tuniform highp sampler2D boneTexture;\n\tmat4 getBoneMatrix( const in float i ) {\n\t\tint size = textureSize( boneTexture, 0 ).x;\n\t\tint j = int( i ) * 4;\n\t\tint x = j % size;\n\t\tint y = j / size;\n\t\tvec4 v1 = texelFetch( boneTexture, ivec2( x, y ), 0 );\n\t\tvec4 v2 = texelFetch( boneTexture, ivec2( x + 1, y ), 0 );\n\t\tvec4 v3 = texelFetch( boneTexture, ivec2( x + 2, y ), 0 );\n\t\tvec4 v4 = texelFetch( boneTexture, ivec2( x + 3, y ), 0 );\n\t\treturn mat4( v1, v2, v3, v4 );\n\t}\n#endif";

	var skinning_vertex = "#ifdef USE_SKINNING\n\tvec4 skinVertex = bindMatrix * vec4( transformed, 1.0 );\n\tvec4 skinned = vec4( 0.0 );\n\tskinned += boneMatX * skinVertex * skinWeight.x;\n\tskinned += boneMatY * skinVertex * skinWeight.y;\n\tskinned += boneMatZ * skinVertex * skinWeight.z;\n\tskinned += boneMatW * skinVertex * skinWeight.w;\n\ttransformed = ( bindMatrixInverse * skinned ).xyz;\n#endif";

	var skinnormal_vertex = "#ifdef USE_SKINNING\n\tmat4 skinMatrix = mat4( 0.0 );\n\tskinMatrix += skinWeight.x * boneMatX;\n\tskinMatrix += skinWeight.y * boneMatY;\n\tskinMatrix += skinWeight.z * boneMatZ;\n\tskinMatrix += skinWeight.w * boneMatW;\n\tskinMatrix = bindMatrixInverse * skinMatrix * bindMatrix;\n\tobjectNormal = vec4( skinMatrix * vec4( objectNormal, 0.0 ) ).xyz;\n\t#ifdef USE_TANGENT\n\t\tobjectTangent = vec4( skinMatrix * vec4( objectTangent, 0.0 ) ).xyz;\n\t#endif\n#endif";

	var specularmap_fragment = "float specularStrength;\n#ifdef USE_SPECULARMAP\n\tvec4 texelSpecular = texture2D( specularMap, vSpecularMapUv );\n\tspecularStrength = texelSpecular.r;\n#else\n\tspecularStrength = 1.0;\n#endif";

	var specularmap_pars_fragment = "#ifdef USE_SPECULARMAP\n\tuniform sampler2D specularMap;\n#endif";

	var tonemapping_fragment = "#if defined( TONE_MAPPING )\n\tgl_FragColor.rgb = toneMapping( gl_FragColor.rgb );\n#endif";

	var tonemapping_pars_fragment = "#ifndef saturate\n#define saturate( a ) clamp( a, 0.0, 1.0 )\n#endif\nuniform float toneMappingExposure;\nvec3 LinearToneMapping( vec3 color ) {\n\treturn saturate( toneMappingExposure * color );\n}\nvec3 ReinhardToneMapping( vec3 color ) {\n\tcolor *= toneMappingExposure;\n\treturn saturate( color / ( vec3( 1.0 ) + color ) );\n}\nvec3 CineonToneMapping( vec3 color ) {\n\tcolor *= toneMappingExposure;\n\tcolor = max( vec3( 0.0 ), color - 0.004 );\n\treturn pow( ( color * ( 6.2 * color + 0.5 ) ) / ( color * ( 6.2 * color + 1.7 ) + 0.06 ), vec3( 2.2 ) );\n}\nvec3 RRTAndODTFit( vec3 v ) {\n\tvec3 a = v * ( v + 0.0245786 ) - 0.000090537;\n\tvec3 b = v * ( 0.983729 * v + 0.4329510 ) + 0.238081;\n\treturn a / b;\n}\nvec3 ACESFilmicToneMapping( vec3 color ) {\n\tconst mat3 ACESInputMat = mat3(\n\t\tvec3( 0.59719, 0.07600, 0.02840 ),\t\tvec3( 0.35458, 0.90834, 0.13383 ),\n\t\tvec3( 0.04823, 0.01566, 0.83777 )\n\t);\n\tconst mat3 ACESOutputMat = mat3(\n\t\tvec3(  1.60475, -0.10208, -0.00327 ),\t\tvec3( -0.53108,  1.10813, -0.07276 ),\n\t\tvec3( -0.07367, -0.00605,  1.07602 )\n\t);\n\tcolor *= toneMappingExposure / 0.6;\n\tcolor = ACESInputMat * color;\n\tcolor = RRTAndODTFit( color );\n\tcolor = ACESOutputMat * color;\n\treturn saturate( color );\n}\nconst mat3 LINEAR_REC2020_TO_LINEAR_SRGB = mat3(\n\tvec3( 1.6605, - 0.1246, - 0.0182 ),\n\tvec3( - 0.5876, 1.1329, - 0.1006 ),\n\tvec3( - 0.0728, - 0.0083, 1.1187 )\n);\nconst mat3 LINEAR_SRGB_TO_LINEAR_REC2020 = mat3(\n\tvec3( 0.6274, 0.0691, 0.0164 ),\n\tvec3( 0.3293, 0.9195, 0.0880 ),\n\tvec3( 0.0433, 0.0113, 0.8956 )\n);\nvec3 agxDefaultContrastApprox( vec3 x ) {\n\tvec3 x2 = x * x;\n\tvec3 x4 = x2 * x2;\n\treturn + 15.5 * x4 * x2\n\t\t- 40.14 * x4 * x\n\t\t+ 31.96 * x4\n\t\t- 6.868 * x2 * x\n\t\t+ 0.4298 * x2\n\t\t+ 0.1191 * x\n\t\t- 0.00232;\n}\nvec3 AgXToneMapping( vec3 color ) {\n\tconst mat3 AgXInsetMatrix = mat3(\n\t\tvec3( 0.856627153315983, 0.137318972929847, 0.11189821299995 ),\n\t\tvec3( 0.0951212405381588, 0.761241990602591, 0.0767994186031903 ),\n\t\tvec3( 0.0482516061458583, 0.101439036467562, 0.811302368396859 )\n\t);\n\tconst mat3 AgXOutsetMatrix = mat3(\n\t\tvec3( 1.1271005818144368, - 0.1413297634984383, - 0.14132976349843826 ),\n\t\tvec3( - 0.11060664309660323, 1.157823702216272, - 0.11060664309660294 ),\n\t\tvec3( - 0.016493938717834573, - 0.016493938717834257, 1.2519364065950405 )\n\t);\n\tconst float AgxMinEv = - 12.47393;\tconst float AgxMaxEv = 4.026069;\n\tcolor *= toneMappingExposure;\n\tcolor = LINEAR_SRGB_TO_LINEAR_REC2020 * color;\n\tcolor = AgXInsetMatrix * color;\n\tcolor = max( color, 1e-10 );\tcolor = log2( color );\n\tcolor = ( color - AgxMinEv ) / ( AgxMaxEv - AgxMinEv );\n\tcolor = clamp( color, 0.0, 1.0 );\n\tcolor = agxDefaultContrastApprox( color );\n\tcolor = AgXOutsetMatrix * color;\n\tcolor = pow( max( vec3( 0.0 ), color ), vec3( 2.2 ) );\n\tcolor = LINEAR_REC2020_TO_LINEAR_SRGB * color;\n\tcolor = clamp( color, 0.0, 1.0 );\n\treturn color;\n}\nvec3 NeutralToneMapping( vec3 color ) {\n\tconst float StartCompression = 0.8 - 0.04;\n\tconst float Desaturation = 0.15;\n\tcolor *= toneMappingExposure;\n\tfloat x = min( color.r, min( color.g, color.b ) );\n\tfloat offset = x < 0.08 ? x - 6.25 * x * x : 0.04;\n\tcolor -= offset;\n\tfloat peak = max( color.r, max( color.g, color.b ) );\n\tif ( peak < StartCompression ) return color;\n\tfloat d = 1. - StartCompression;\n\tfloat newPeak = 1. - d * d / ( peak + d - StartCompression );\n\tcolor *= newPeak / peak;\n\tfloat g = 1. - 1. / ( Desaturation * ( peak - newPeak ) + 1. );\n\treturn mix( color, vec3( newPeak ), g );\n}\nvec3 CustomToneMapping( vec3 color ) { return color; }";

	var transmission_fragment = "#ifdef USE_TRANSMISSION\n\tmaterial.transmission = transmission;\n\tmaterial.transmissionAlpha = 1.0;\n\tmaterial.thickness = thickness;\n\tmaterial.attenuationDistance = attenuationDistance;\n\tmaterial.attenuationColor = attenuationColor;\n\t#ifdef USE_TRANSMISSIONMAP\n\t\tmaterial.transmission *= texture2D( transmissionMap, vTransmissionMapUv ).r;\n\t#endif\n\t#ifdef USE_THICKNESSMAP\n\t\tmaterial.thickness *= texture2D( thicknessMap, vThicknessMapUv ).g;\n\t#endif\n\tvec3 pos = vWorldPosition;\n\tvec3 v = normalize( cameraPosition - pos );\n\tvec3 n = inverseTransformDirection( normal, viewMatrix );\n\tvec4 transmitted = getIBLVolumeRefraction(\n\t\tn, v, material.roughness, material.diffuseColor, material.specularColor, material.specularF90,\n\t\tpos, modelMatrix, viewMatrix, projectionMatrix, material.dispersion, material.ior, material.thickness,\n\t\tmaterial.attenuationColor, material.attenuationDistance );\n\tmaterial.transmissionAlpha = mix( material.transmissionAlpha, transmitted.a, material.transmission );\n\ttotalDiffuse = mix( totalDiffuse, transmitted.rgb, material.transmission );\n#endif";

	var transmission_pars_fragment = "#ifdef USE_TRANSMISSION\n\tuniform float transmission;\n\tuniform float thickness;\n\tuniform float attenuationDistance;\n\tuniform vec3 attenuationColor;\n\t#ifdef USE_TRANSMISSIONMAP\n\t\tuniform sampler2D transmissionMap;\n\t#endif\n\t#ifdef USE_THICKNESSMAP\n\t\tuniform sampler2D thicknessMap;\n\t#endif\n\tuniform vec2 transmissionSamplerSize;\n\tuniform sampler2D transmissionSamplerMap;\n\tuniform mat4 modelMatrix;\n\tuniform mat4 projectionMatrix;\n\tvarying vec3 vWorldPosition;\n\tfloat w0( float a ) {\n\t\treturn ( 1.0 / 6.0 ) * ( a * ( a * ( - a + 3.0 ) - 3.0 ) + 1.0 );\n\t}\n\tfloat w1( float a ) {\n\t\treturn ( 1.0 / 6.0 ) * ( a *  a * ( 3.0 * a - 6.0 ) + 4.0 );\n\t}\n\tfloat w2( float a ){\n\t\treturn ( 1.0 / 6.0 ) * ( a * ( a * ( - 3.0 * a + 3.0 ) + 3.0 ) + 1.0 );\n\t}\n\tfloat w3( float a ) {\n\t\treturn ( 1.0 / 6.0 ) * ( a * a * a );\n\t}\n\tfloat g0( float a ) {\n\t\treturn w0( a ) + w1( a );\n\t}\n\tfloat g1( float a ) {\n\t\treturn w2( a ) + w3( a );\n\t}\n\tfloat h0( float a ) {\n\t\treturn - 1.0 + w1( a ) / ( w0( a ) + w1( a ) );\n\t}\n\tfloat h1( float a ) {\n\t\treturn 1.0 + w3( a ) / ( w2( a ) + w3( a ) );\n\t}\n\tvec4 bicubic( sampler2D tex, vec2 uv, vec4 texelSize, float lod ) {\n\t\tuv = uv * texelSize.zw + 0.5;\n\t\tvec2 iuv = floor( uv );\n\t\tvec2 fuv = fract( uv );\n\t\tfloat g0x = g0( fuv.x );\n\t\tfloat g1x = g1( fuv.x );\n\t\tfloat h0x = h0( fuv.x );\n\t\tfloat h1x = h1( fuv.x );\n\t\tfloat h0y = h0( fuv.y );\n\t\tfloat h1y = h1( fuv.y );\n\t\tvec2 p0 = ( vec2( iuv.x + h0x, iuv.y + h0y ) - 0.5 ) * texelSize.xy;\n\t\tvec2 p1 = ( vec2( iuv.x + h1x, iuv.y + h0y ) - 0.5 ) * texelSize.xy;\n\t\tvec2 p2 = ( vec2( iuv.x + h0x, iuv.y + h1y ) - 0.5 ) * texelSize.xy;\n\t\tvec2 p3 = ( vec2( iuv.x + h1x, iuv.y + h1y ) - 0.5 ) * texelSize.xy;\n\t\treturn g0( fuv.y ) * ( g0x * textureLod( tex, p0, lod ) + g1x * textureLod( tex, p1, lod ) ) +\n\t\t\tg1( fuv.y ) * ( g0x * textureLod( tex, p2, lod ) + g1x * textureLod( tex, p3, lod ) );\n\t}\n\tvec4 textureBicubic( sampler2D sampler, vec2 uv, float lod ) {\n\t\tvec2 fLodSize = vec2( textureSize( sampler, int( lod ) ) );\n\t\tvec2 cLodSize = vec2( textureSize( sampler, int( lod + 1.0 ) ) );\n\t\tvec2 fLodSizeInv = 1.0 / fLodSize;\n\t\tvec2 cLodSizeInv = 1.0 / cLodSize;\n\t\tvec4 fSample = bicubic( sampler, uv, vec4( fLodSizeInv, fLodSize ), floor( lod ) );\n\t\tvec4 cSample = bicubic( sampler, uv, vec4( cLodSizeInv, cLodSize ), ceil( lod ) );\n\t\treturn mix( fSample, cSample, fract( lod ) );\n\t}\n\tvec3 getVolumeTransmissionRay( const in vec3 n, const in vec3 v, const in float thickness, const in float ior, const in mat4 modelMatrix ) {\n\t\tvec3 refractionVector = refract( - v, normalize( n ), 1.0 / ior );\n\t\tvec3 modelScale;\n\t\tmodelScale.x = length( vec3( modelMatrix[ 0 ].xyz ) );\n\t\tmodelScale.y = length( vec3( modelMatrix[ 1 ].xyz ) );\n\t\tmodelScale.z = length( vec3( modelMatrix[ 2 ].xyz ) );\n\t\treturn normalize( refractionVector ) * thickness * modelScale;\n\t}\n\tfloat applyIorToRoughness( const in float roughness, const in float ior ) {\n\t\treturn roughness * clamp( ior * 2.0 - 2.0, 0.0, 1.0 );\n\t}\n\tvec4 getTransmissionSample( const in vec2 fragCoord, const in float roughness, const in float ior ) {\n\t\tfloat lod = log2( transmissionSamplerSize.x ) * applyIorToRoughness( roughness, ior );\n\t\treturn textureBicubic( transmissionSamplerMap, fragCoord.xy, lod );\n\t}\n\tvec3 volumeAttenuation( const in float transmissionDistance, const in vec3 attenuationColor, const in float attenuationDistance ) {\n\t\tif ( isinf( attenuationDistance ) ) {\n\t\t\treturn vec3( 1.0 );\n\t\t} else {\n\t\t\tvec3 attenuationCoefficient = -log( attenuationColor ) / attenuationDistance;\n\t\t\tvec3 transmittance = exp( - attenuationCoefficient * transmissionDistance );\t\t\treturn transmittance;\n\t\t}\n\t}\n\tvec4 getIBLVolumeRefraction( const in vec3 n, const in vec3 v, const in float roughness, const in vec3 diffuseColor,\n\t\tconst in vec3 specularColor, const in float specularF90, const in vec3 position, const in mat4 modelMatrix,\n\t\tconst in mat4 viewMatrix, const in mat4 projMatrix, const in float dispersion, const in float ior, const in float thickness,\n\t\tconst in vec3 attenuationColor, const in float attenuationDistance ) {\n\t\tvec4 transmittedLight;\n\t\tvec3 transmittance;\n\t\t#ifdef USE_DISPERSION\n\t\t\tfloat halfSpread = ( ior - 1.0 ) * 0.025 * dispersion;\n\t\t\tvec3 iors = vec3( ior - halfSpread, ior, ior + halfSpread );\n\t\t\tfor ( int i = 0; i < 3; i ++ ) {\n\t\t\t\tvec3 transmissionRay = getVolumeTransmissionRay( n, v, thickness, iors[ i ], modelMatrix );\n\t\t\t\tvec3 refractedRayExit = position + transmissionRay;\n\t\t\t\tvec4 ndcPos = projMatrix * viewMatrix * vec4( refractedRayExit, 1.0 );\n\t\t\t\tvec2 refractionCoords = ndcPos.xy / ndcPos.w;\n\t\t\t\trefractionCoords += 1.0;\n\t\t\t\trefractionCoords /= 2.0;\n\t\t\t\tvec4 transmissionSample = getTransmissionSample( refractionCoords, roughness, iors[ i ] );\n\t\t\t\ttransmittedLight[ i ] = transmissionSample[ i ];\n\t\t\t\ttransmittedLight.a += transmissionSample.a;\n\t\t\t\ttransmittance[ i ] = diffuseColor[ i ] * volumeAttenuation( length( transmissionRay ), attenuationColor, attenuationDistance )[ i ];\n\t\t\t}\n\t\t\ttransmittedLight.a /= 3.0;\n\t\t#else\n\t\t\tvec3 transmissionRay = getVolumeTransmissionRay( n, v, thickness, ior, modelMatrix );\n\t\t\tvec3 refractedRayExit = position + transmissionRay;\n\t\t\tvec4 ndcPos = projMatrix * viewMatrix * vec4( refractedRayExit, 1.0 );\n\t\t\tvec2 refractionCoords = ndcPos.xy / ndcPos.w;\n\t\t\trefractionCoords += 1.0;\n\t\t\trefractionCoords /= 2.0;\n\t\t\ttransmittedLight = getTransmissionSample( refractionCoords, roughness, ior );\n\t\t\ttransmittance = diffuseColor * volumeAttenuation( length( transmissionRay ), attenuationColor, attenuationDistance );\n\t\t#endif\n\t\tvec3 attenuatedColor = transmittance * transmittedLight.rgb;\n\t\tvec3 F = EnvironmentBRDF( n, v, specularColor, specularF90, roughness );\n\t\tfloat transmittanceFactor = ( transmittance.r + transmittance.g + transmittance.b ) / 3.0;\n\t\treturn vec4( ( 1.0 - F ) * attenuatedColor, 1.0 - ( 1.0 - transmittedLight.a ) * transmittanceFactor );\n\t}\n#endif";

	var uv_pars_fragment = "#if defined( USE_UV ) || defined( USE_ANISOTROPY )\n\tvarying vec2 vUv;\n#endif\n#ifdef USE_MAP\n\tvarying vec2 vMapUv;\n#endif\n#ifdef USE_ALPHAMAP\n\tvarying vec2 vAlphaMapUv;\n#endif\n#ifdef USE_LIGHTMAP\n\tvarying vec2 vLightMapUv;\n#endif\n#ifdef USE_AOMAP\n\tvarying vec2 vAoMapUv;\n#endif\n#ifdef USE_BUMPMAP\n\tvarying vec2 vBumpMapUv;\n#endif\n#ifdef USE_NORMALMAP\n\tvarying vec2 vNormalMapUv;\n#endif\n#ifdef USE_EMISSIVEMAP\n\tvarying vec2 vEmissiveMapUv;\n#endif\n#ifdef USE_METALNESSMAP\n\tvarying vec2 vMetalnessMapUv;\n#endif\n#ifdef USE_ROUGHNESSMAP\n\tvarying vec2 vRoughnessMapUv;\n#endif\n#ifdef USE_ANISOTROPYMAP\n\tvarying vec2 vAnisotropyMapUv;\n#endif\n#ifdef USE_CLEARCOATMAP\n\tvarying vec2 vClearcoatMapUv;\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n\tvarying vec2 vClearcoatNormalMapUv;\n#endif\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n\tvarying vec2 vClearcoatRoughnessMapUv;\n#endif\n#ifdef USE_IRIDESCENCEMAP\n\tvarying vec2 vIridescenceMapUv;\n#endif\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\n\tvarying vec2 vIridescenceThicknessMapUv;\n#endif\n#ifdef USE_SHEEN_COLORMAP\n\tvarying vec2 vSheenColorMapUv;\n#endif\n#ifdef USE_SHEEN_ROUGHNESSMAP\n\tvarying vec2 vSheenRoughnessMapUv;\n#endif\n#ifdef USE_SPECULARMAP\n\tvarying vec2 vSpecularMapUv;\n#endif\n#ifdef USE_SPECULAR_COLORMAP\n\tvarying vec2 vSpecularColorMapUv;\n#endif\n#ifdef USE_SPECULAR_INTENSITYMAP\n\tvarying vec2 vSpecularIntensityMapUv;\n#endif\n#ifdef USE_TRANSMISSIONMAP\n\tuniform mat3 transmissionMapTransform;\n\tvarying vec2 vTransmissionMapUv;\n#endif\n#ifdef USE_THICKNESSMAP\n\tuniform mat3 thicknessMapTransform;\n\tvarying vec2 vThicknessMapUv;\n#endif";

	var uv_pars_vertex = "#if defined( USE_UV ) || defined( USE_ANISOTROPY )\n\tvarying vec2 vUv;\n#endif\n#ifdef USE_MAP\n\tuniform mat3 mapTransform;\n\tvarying vec2 vMapUv;\n#endif\n#ifdef USE_ALPHAMAP\n\tuniform mat3 alphaMapTransform;\n\tvarying vec2 vAlphaMapUv;\n#endif\n#ifdef USE_LIGHTMAP\n\tuniform mat3 lightMapTransform;\n\tvarying vec2 vLightMapUv;\n#endif\n#ifdef USE_AOMAP\n\tuniform mat3 aoMapTransform;\n\tvarying vec2 vAoMapUv;\n#endif\n#ifdef USE_BUMPMAP\n\tuniform mat3 bumpMapTransform;\n\tvarying vec2 vBumpMapUv;\n#endif\n#ifdef USE_NORMALMAP\n\tuniform mat3 normalMapTransform;\n\tvarying vec2 vNormalMapUv;\n#endif\n#ifdef USE_DISPLACEMENTMAP\n\tuniform mat3 displacementMapTransform;\n\tvarying vec2 vDisplacementMapUv;\n#endif\n#ifdef USE_EMISSIVEMAP\n\tuniform mat3 emissiveMapTransform;\n\tvarying vec2 vEmissiveMapUv;\n#endif\n#ifdef USE_METALNESSMAP\n\tuniform mat3 metalnessMapTransform;\n\tvarying vec2 vMetalnessMapUv;\n#endif\n#ifdef USE_ROUGHNESSMAP\n\tuniform mat3 roughnessMapTransform;\n\tvarying vec2 vRoughnessMapUv;\n#endif\n#ifdef USE_ANISOTROPYMAP\n\tuniform mat3 anisotropyMapTransform;\n\tvarying vec2 vAnisotropyMapUv;\n#endif\n#ifdef USE_CLEARCOATMAP\n\tuniform mat3 clearcoatMapTransform;\n\tvarying vec2 vClearcoatMapUv;\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n\tuniform mat3 clearcoatNormalMapTransform;\n\tvarying vec2 vClearcoatNormalMapUv;\n#endif\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n\tuniform mat3 clearcoatRoughnessMapTransform;\n\tvarying vec2 vClearcoatRoughnessMapUv;\n#endif\n#ifdef USE_SHEEN_COLORMAP\n\tuniform mat3 sheenColorMapTransform;\n\tvarying vec2 vSheenColorMapUv;\n#endif\n#ifdef USE_SHEEN_ROUGHNESSMAP\n\tuniform mat3 sheenRoughnessMapTransform;\n\tvarying vec2 vSheenRoughnessMapUv;\n#endif\n#ifdef USE_IRIDESCENCEMAP\n\tuniform mat3 iridescenceMapTransform;\n\tvarying vec2 vIridescenceMapUv;\n#endif\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\n\tuniform mat3 iridescenceThicknessMapTransform;\n\tvarying vec2 vIridescenceThicknessMapUv;\n#endif\n#ifdef USE_SPECULARMAP\n\tuniform mat3 specularMapTransform;\n\tvarying vec2 vSpecularMapUv;\n#endif\n#ifdef USE_SPECULAR_COLORMAP\n\tuniform mat3 specularColorMapTransform;\n\tvarying vec2 vSpecularColorMapUv;\n#endif\n#ifdef USE_SPECULAR_INTENSITYMAP\n\tuniform mat3 specularIntensityMapTransform;\n\tvarying vec2 vSpecularIntensityMapUv;\n#endif\n#ifdef USE_TRANSMISSIONMAP\n\tuniform mat3 transmissionMapTransform;\n\tvarying vec2 vTransmissionMapUv;\n#endif\n#ifdef USE_THICKNESSMAP\n\tuniform mat3 thicknessMapTransform;\n\tvarying vec2 vThicknessMapUv;\n#endif";

	var uv_vertex = "#if defined( USE_UV ) || defined( USE_ANISOTROPY )\n\tvUv = vec3( uv, 1 ).xy;\n#endif\n#ifdef USE_MAP\n\tvMapUv = ( mapTransform * vec3( MAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_ALPHAMAP\n\tvAlphaMapUv = ( alphaMapTransform * vec3( ALPHAMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_LIGHTMAP\n\tvLightMapUv = ( lightMapTransform * vec3( LIGHTMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_AOMAP\n\tvAoMapUv = ( aoMapTransform * vec3( AOMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_BUMPMAP\n\tvBumpMapUv = ( bumpMapTransform * vec3( BUMPMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_NORMALMAP\n\tvNormalMapUv = ( normalMapTransform * vec3( NORMALMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_DISPLACEMENTMAP\n\tvDisplacementMapUv = ( displacementMapTransform * vec3( DISPLACEMENTMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_EMISSIVEMAP\n\tvEmissiveMapUv = ( emissiveMapTransform * vec3( EMISSIVEMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_METALNESSMAP\n\tvMetalnessMapUv = ( metalnessMapTransform * vec3( METALNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_ROUGHNESSMAP\n\tvRoughnessMapUv = ( roughnessMapTransform * vec3( ROUGHNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_ANISOTROPYMAP\n\tvAnisotropyMapUv = ( anisotropyMapTransform * vec3( ANISOTROPYMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_CLEARCOATMAP\n\tvClearcoatMapUv = ( clearcoatMapTransform * vec3( CLEARCOATMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n\tvClearcoatNormalMapUv = ( clearcoatNormalMapTransform * vec3( CLEARCOAT_NORMALMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n\tvClearcoatRoughnessMapUv = ( clearcoatRoughnessMapTransform * vec3( CLEARCOAT_ROUGHNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_IRIDESCENCEMAP\n\tvIridescenceMapUv = ( iridescenceMapTransform * vec3( IRIDESCENCEMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\n\tvIridescenceThicknessMapUv = ( iridescenceThicknessMapTransform * vec3( IRIDESCENCE_THICKNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SHEEN_COLORMAP\n\tvSheenColorMapUv = ( sheenColorMapTransform * vec3( SHEEN_COLORMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SHEEN_ROUGHNESSMAP\n\tvSheenRoughnessMapUv = ( sheenRoughnessMapTransform * vec3( SHEEN_ROUGHNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SPECULARMAP\n\tvSpecularMapUv = ( specularMapTransform * vec3( SPECULARMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SPECULAR_COLORMAP\n\tvSpecularColorMapUv = ( specularColorMapTransform * vec3( SPECULAR_COLORMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SPECULAR_INTENSITYMAP\n\tvSpecularIntensityMapUv = ( specularIntensityMapTransform * vec3( SPECULAR_INTENSITYMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_TRANSMISSIONMAP\n\tvTransmissionMapUv = ( transmissionMapTransform * vec3( TRANSMISSIONMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_THICKNESSMAP\n\tvThicknessMapUv = ( thicknessMapTransform * vec3( THICKNESSMAP_UV, 1 ) ).xy;\n#endif";

	var worldpos_vertex = "#if defined( USE_ENVMAP ) || defined( DISTANCE ) || defined ( USE_SHADOWMAP ) || defined ( USE_TRANSMISSION ) || NUM_SPOT_LIGHT_COORDS > 0\n\tvec4 worldPosition = vec4( transformed, 1.0 );\n\t#ifdef USE_BATCHING\n\t\tworldPosition = batchingMatrix * worldPosition;\n\t#endif\n\t#ifdef USE_INSTANCING\n\t\tworldPosition = instanceMatrix * worldPosition;\n\t#endif\n\tworldPosition = modelMatrix * worldPosition;\n#endif";

	const vertex$h = "varying vec2 vUv;\nuniform mat3 uvTransform;\nvoid main() {\n\tvUv = ( uvTransform * vec3( uv, 1 ) ).xy;\n\tgl_Position = vec4( position.xy, 1.0, 1.0 );\n}";

	const fragment$h = "uniform sampler2D t2D;\nuniform float backgroundIntensity;\nvarying vec2 vUv;\nvoid main() {\n\tvec4 texColor = texture2D( t2D, vUv );\n\t#ifdef DECODE_VIDEO_TEXTURE\n\t\ttexColor = vec4( mix( pow( texColor.rgb * 0.9478672986 + vec3( 0.0521327014 ), vec3( 2.4 ) ), texColor.rgb * 0.0773993808, vec3( lessThanEqual( texColor.rgb, vec3( 0.04045 ) ) ) ), texColor.w );\n\t#endif\n\ttexColor.rgb *= backgroundIntensity;\n\tgl_FragColor = texColor;\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n}";

	const vertex$g = "varying vec3 vWorldDirection;\n#include <common>\nvoid main() {\n\tvWorldDirection = transformDirection( position, modelMatrix );\n\t#include <begin_vertex>\n\t#include <project_vertex>\n\tgl_Position.z = gl_Position.w;\n}";

	const fragment$g = "#ifdef ENVMAP_TYPE_CUBE\n\tuniform samplerCube envMap;\n#elif defined( ENVMAP_TYPE_CUBE_UV )\n\tuniform sampler2D envMap;\n#endif\nuniform float flipEnvMap;\nuniform float backgroundBlurriness;\nuniform float backgroundIntensity;\nuniform mat3 backgroundRotation;\nvarying vec3 vWorldDirection;\n#include <cube_uv_reflection_fragment>\nvoid main() {\n\t#ifdef ENVMAP_TYPE_CUBE\n\t\tvec4 texColor = textureCube( envMap, backgroundRotation * vec3( flipEnvMap * vWorldDirection.x, vWorldDirection.yz ) );\n\t#elif defined( ENVMAP_TYPE_CUBE_UV )\n\t\tvec4 texColor = textureCubeUV( envMap, backgroundRotation * vWorldDirection, backgroundBlurriness );\n\t#else\n\t\tvec4 texColor = vec4( 0.0, 0.0, 0.0, 1.0 );\n\t#endif\n\ttexColor.rgb *= backgroundIntensity;\n\tgl_FragColor = texColor;\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n}";

	const vertex$f = "varying vec3 vWorldDirection;\n#include <common>\nvoid main() {\n\tvWorldDirection = transformDirection( position, modelMatrix );\n\t#include <begin_vertex>\n\t#include <project_vertex>\n\tgl_Position.z = gl_Position.w;\n}";

	const fragment$f = "uniform samplerCube tCube;\nuniform float tFlip;\nuniform float opacity;\nvarying vec3 vWorldDirection;\nvoid main() {\n\tvec4 texColor = textureCube( tCube, vec3( tFlip * vWorldDirection.x, vWorldDirection.yz ) );\n\tgl_FragColor = texColor;\n\tgl_FragColor.a *= opacity;\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n}";

	const vertex$e = "#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvarying vec2 vHighPrecisionZW;\nvoid main() {\n\t#include <uv_vertex>\n\t#include <batching_vertex>\n\t#include <skinbase_vertex>\n\t#include <morphinstance_vertex>\n\t#ifdef USE_DISPLACEMENTMAP\n\t\t#include <beginnormal_vertex>\n\t\t#include <morphnormal_vertex>\n\t\t#include <skinnormal_vertex>\n\t#endif\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <displacementmap_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\tvHighPrecisionZW = gl_Position.zw;\n}";

	const fragment$e = "#if DEPTH_PACKING == 3200\n\tuniform float opacity;\n#endif\n#include <common>\n#include <packing>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvarying vec2 vHighPrecisionZW;\nvoid main() {\n\tvec4 diffuseColor = vec4( 1.0 );\n\t#include <clipping_planes_fragment>\n\t#if DEPTH_PACKING == 3200\n\t\tdiffuseColor.a = opacity;\n\t#endif\n\t#include <map_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\t#include <logdepthbuf_fragment>\n\tfloat fragCoordZ = 0.5 * vHighPrecisionZW[0] / vHighPrecisionZW[1] + 0.5;\n\t#if DEPTH_PACKING == 3200\n\t\tgl_FragColor = vec4( vec3( 1.0 - fragCoordZ ), opacity );\n\t#elif DEPTH_PACKING == 3201\n\t\tgl_FragColor = packDepthToRGBA( fragCoordZ );\n\t#elif DEPTH_PACKING == 3202\n\t\tgl_FragColor = vec4( packDepthToRGB( fragCoordZ ), 1.0 );\n\t#elif DEPTH_PACKING == 3203\n\t\tgl_FragColor = vec4( packDepthToRG( fragCoordZ ), 0.0, 1.0 );\n\t#endif\n}";

	const vertex$d = "#define DISTANCE\nvarying vec3 vWorldPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\t#include <batching_vertex>\n\t#include <skinbase_vertex>\n\t#include <morphinstance_vertex>\n\t#ifdef USE_DISPLACEMENTMAP\n\t\t#include <beginnormal_vertex>\n\t\t#include <morphnormal_vertex>\n\t\t#include <skinnormal_vertex>\n\t#endif\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <displacementmap_vertex>\n\t#include <project_vertex>\n\t#include <worldpos_vertex>\n\t#include <clipping_planes_vertex>\n\tvWorldPosition = worldPosition.xyz;\n}";

	const fragment$d = "#define DISTANCE\nuniform vec3 referencePosition;\nuniform float nearDistance;\nuniform float farDistance;\nvarying vec3 vWorldPosition;\n#include <common>\n#include <packing>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main () {\n\tvec4 diffuseColor = vec4( 1.0 );\n\t#include <clipping_planes_fragment>\n\t#include <map_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\tfloat dist = length( vWorldPosition - referencePosition );\n\tdist = ( dist - nearDistance ) / ( farDistance - nearDistance );\n\tdist = saturate( dist );\n\tgl_FragColor = packDepthToRGBA( dist );\n}";

	const vertex$c = "varying vec3 vWorldDirection;\n#include <common>\nvoid main() {\n\tvWorldDirection = transformDirection( position, modelMatrix );\n\t#include <begin_vertex>\n\t#include <project_vertex>\n}";

	const fragment$c = "uniform sampler2D tEquirect;\nvarying vec3 vWorldDirection;\n#include <common>\nvoid main() {\n\tvec3 direction = normalize( vWorldDirection );\n\tvec2 sampleUV = equirectUv( direction );\n\tgl_FragColor = texture2D( tEquirect, sampleUV );\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n}";

	const vertex$b = "uniform float scale;\nattribute float lineDistance;\nvarying float vLineDistance;\n#include <common>\n#include <uv_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\tvLineDistance = scale * lineDistance;\n\t#include <uv_vertex>\n\t#include <color_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphcolor_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\t#include <fog_vertex>\n}";

	const fragment$b = "uniform vec3 diffuse;\nuniform float opacity;\nuniform float dashSize;\nuniform float totalSize;\nvarying float vLineDistance;\n#include <common>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <fog_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\tif ( mod( vLineDistance, totalSize ) > dashSize ) {\n\t\tdiscard;\n\t}\n\tvec3 outgoingLight = vec3( 0.0 );\n\t#include <logdepthbuf_fragment>\n\t#include <map_fragment>\n\t#include <color_fragment>\n\toutgoingLight = diffuseColor.rgb;\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n\t#include <premultiplied_alpha_fragment>\n}";

	const vertex$a = "#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <envmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\t#include <color_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphcolor_vertex>\n\t#include <batching_vertex>\n\t#if defined ( USE_ENVMAP ) || defined ( USE_SKINNING )\n\t\t#include <beginnormal_vertex>\n\t\t#include <morphnormal_vertex>\n\t\t#include <skinbase_vertex>\n\t\t#include <skinnormal_vertex>\n\t\t#include <defaultnormal_vertex>\n\t#endif\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\t#include <worldpos_vertex>\n\t#include <envmap_vertex>\n\t#include <fog_vertex>\n}";

	const fragment$a = "uniform vec3 diffuse;\nuniform float opacity;\n#ifndef FLAT_SHADED\n\tvarying vec3 vNormal;\n#endif\n#include <common>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <envmap_common_pars_fragment>\n#include <envmap_pars_fragment>\n#include <fog_pars_fragment>\n#include <specularmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\t#include <logdepthbuf_fragment>\n\t#include <map_fragment>\n\t#include <color_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\t#include <specularmap_fragment>\n\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n\t#ifdef USE_LIGHTMAP\n\t\tvec4 lightMapTexel = texture2D( lightMap, vLightMapUv );\n\t\treflectedLight.indirectDiffuse += lightMapTexel.rgb * lightMapIntensity * RECIPROCAL_PI;\n\t#else\n\t\treflectedLight.indirectDiffuse += vec3( 1.0 );\n\t#endif\n\t#include <aomap_fragment>\n\treflectedLight.indirectDiffuse *= diffuseColor.rgb;\n\tvec3 outgoingLight = reflectedLight.indirectDiffuse;\n\t#include <envmap_fragment>\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n\t#include <premultiplied_alpha_fragment>\n\t#include <dithering_fragment>\n}";

	const vertex$9 = "#define LAMBERT\nvarying vec3 vViewPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <envmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <shadowmap_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\t#include <color_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphcolor_vertex>\n\t#include <batching_vertex>\n\t#include <beginnormal_vertex>\n\t#include <morphnormal_vertex>\n\t#include <skinbase_vertex>\n\t#include <skinnormal_vertex>\n\t#include <defaultnormal_vertex>\n\t#include <normal_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <displacementmap_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\tvViewPosition = - mvPosition.xyz;\n\t#include <worldpos_vertex>\n\t#include <envmap_vertex>\n\t#include <shadowmap_vertex>\n\t#include <fog_vertex>\n}";

	const fragment$9 = "#define LAMBERT\nuniform vec3 diffuse;\nuniform vec3 emissive;\nuniform float opacity;\n#include <common>\n#include <packing>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <emissivemap_pars_fragment>\n#include <envmap_common_pars_fragment>\n#include <envmap_pars_fragment>\n#include <fog_pars_fragment>\n#include <bsdfs>\n#include <lights_pars_begin>\n#include <normal_pars_fragment>\n#include <lights_lambert_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <specularmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n\tvec3 totalEmissiveRadiance = emissive;\n\t#include <logdepthbuf_fragment>\n\t#include <map_fragment>\n\t#include <color_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\t#include <specularmap_fragment>\n\t#include <normal_fragment_begin>\n\t#include <normal_fragment_maps>\n\t#include <emissivemap_fragment>\n\t#include <lights_lambert_fragment>\n\t#include <lights_fragment_begin>\n\t#include <lights_fragment_maps>\n\t#include <lights_fragment_end>\n\t#include <aomap_fragment>\n\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;\n\t#include <envmap_fragment>\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n\t#include <premultiplied_alpha_fragment>\n\t#include <dithering_fragment>\n}";

	const vertex$8 = "#define MATCAP\nvarying vec3 vViewPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <color_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\t#include <color_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphcolor_vertex>\n\t#include <batching_vertex>\n\t#include <beginnormal_vertex>\n\t#include <morphnormal_vertex>\n\t#include <skinbase_vertex>\n\t#include <skinnormal_vertex>\n\t#include <defaultnormal_vertex>\n\t#include <normal_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <displacementmap_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\t#include <fog_vertex>\n\tvViewPosition = - mvPosition.xyz;\n}";

	const fragment$8 = "#define MATCAP\nuniform vec3 diffuse;\nuniform float opacity;\nuniform sampler2D matcap;\nvarying vec3 vViewPosition;\n#include <common>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <fog_pars_fragment>\n#include <normal_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\t#include <logdepthbuf_fragment>\n\t#include <map_fragment>\n\t#include <color_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\t#include <normal_fragment_begin>\n\t#include <normal_fragment_maps>\n\tvec3 viewDir = normalize( vViewPosition );\n\tvec3 x = normalize( vec3( viewDir.z, 0.0, - viewDir.x ) );\n\tvec3 y = cross( viewDir, x );\n\tvec2 uv = vec2( dot( x, normal ), dot( y, normal ) ) * 0.495 + 0.5;\n\t#ifdef USE_MATCAP\n\t\tvec4 matcapColor = texture2D( matcap, uv );\n\t#else\n\t\tvec4 matcapColor = vec4( vec3( mix( 0.2, 0.8, uv.y ) ), 1.0 );\n\t#endif\n\tvec3 outgoingLight = diffuseColor.rgb * matcapColor.rgb;\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n\t#include <premultiplied_alpha_fragment>\n\t#include <dithering_fragment>\n}";

	const vertex$7 = "#define NORMAL\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\n\tvarying vec3 vViewPosition;\n#endif\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\t#include <batching_vertex>\n\t#include <beginnormal_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphnormal_vertex>\n\t#include <skinbase_vertex>\n\t#include <skinnormal_vertex>\n\t#include <defaultnormal_vertex>\n\t#include <normal_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <displacementmap_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\n\tvViewPosition = - mvPosition.xyz;\n#endif\n}";

	const fragment$7 = "#define NORMAL\nuniform float opacity;\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\n\tvarying vec3 vViewPosition;\n#endif\n#include <packing>\n#include <uv_pars_fragment>\n#include <normal_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( 0.0, 0.0, 0.0, opacity );\n\t#include <clipping_planes_fragment>\n\t#include <logdepthbuf_fragment>\n\t#include <normal_fragment_begin>\n\t#include <normal_fragment_maps>\n\tgl_FragColor = vec4( packNormalToRGB( normal ), diffuseColor.a );\n\t#ifdef OPAQUE\n\t\tgl_FragColor.a = 1.0;\n\t#endif\n}";

	const vertex$6 = "#define PHONG\nvarying vec3 vViewPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <envmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <shadowmap_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\t#include <color_vertex>\n\t#include <morphcolor_vertex>\n\t#include <batching_vertex>\n\t#include <beginnormal_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphnormal_vertex>\n\t#include <skinbase_vertex>\n\t#include <skinnormal_vertex>\n\t#include <defaultnormal_vertex>\n\t#include <normal_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <displacementmap_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\tvViewPosition = - mvPosition.xyz;\n\t#include <worldpos_vertex>\n\t#include <envmap_vertex>\n\t#include <shadowmap_vertex>\n\t#include <fog_vertex>\n}";

	const fragment$6 = "#define PHONG\nuniform vec3 diffuse;\nuniform vec3 emissive;\nuniform vec3 specular;\nuniform float shininess;\nuniform float opacity;\n#include <common>\n#include <packing>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <emissivemap_pars_fragment>\n#include <envmap_common_pars_fragment>\n#include <envmap_pars_fragment>\n#include <fog_pars_fragment>\n#include <bsdfs>\n#include <lights_pars_begin>\n#include <normal_pars_fragment>\n#include <lights_phong_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <specularmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n\tvec3 totalEmissiveRadiance = emissive;\n\t#include <logdepthbuf_fragment>\n\t#include <map_fragment>\n\t#include <color_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\t#include <specularmap_fragment>\n\t#include <normal_fragment_begin>\n\t#include <normal_fragment_maps>\n\t#include <emissivemap_fragment>\n\t#include <lights_phong_fragment>\n\t#include <lights_fragment_begin>\n\t#include <lights_fragment_maps>\n\t#include <lights_fragment_end>\n\t#include <aomap_fragment>\n\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + reflectedLight.directSpecular + reflectedLight.indirectSpecular + totalEmissiveRadiance;\n\t#include <envmap_fragment>\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n\t#include <premultiplied_alpha_fragment>\n\t#include <dithering_fragment>\n}";

	const vertex$5 = "#define STANDARD\nvarying vec3 vViewPosition;\n#ifdef USE_TRANSMISSION\n\tvarying vec3 vWorldPosition;\n#endif\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <shadowmap_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\t#include <color_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphcolor_vertex>\n\t#include <batching_vertex>\n\t#include <beginnormal_vertex>\n\t#include <morphnormal_vertex>\n\t#include <skinbase_vertex>\n\t#include <skinnormal_vertex>\n\t#include <defaultnormal_vertex>\n\t#include <normal_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <displacementmap_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\tvViewPosition = - mvPosition.xyz;\n\t#include <worldpos_vertex>\n\t#include <shadowmap_vertex>\n\t#include <fog_vertex>\n#ifdef USE_TRANSMISSION\n\tvWorldPosition = worldPosition.xyz;\n#endif\n}";

	const fragment$5 = "#define STANDARD\n#ifdef PHYSICAL\n\t#define IOR\n\t#define USE_SPECULAR\n#endif\nuniform vec3 diffuse;\nuniform vec3 emissive;\nuniform float roughness;\nuniform float metalness;\nuniform float opacity;\n#ifdef IOR\n\tuniform float ior;\n#endif\n#ifdef USE_SPECULAR\n\tuniform float specularIntensity;\n\tuniform vec3 specularColor;\n\t#ifdef USE_SPECULAR_COLORMAP\n\t\tuniform sampler2D specularColorMap;\n\t#endif\n\t#ifdef USE_SPECULAR_INTENSITYMAP\n\t\tuniform sampler2D specularIntensityMap;\n\t#endif\n#endif\n#ifdef USE_CLEARCOAT\n\tuniform float clearcoat;\n\tuniform float clearcoatRoughness;\n#endif\n#ifdef USE_DISPERSION\n\tuniform float dispersion;\n#endif\n#ifdef USE_IRIDESCENCE\n\tuniform float iridescence;\n\tuniform float iridescenceIOR;\n\tuniform float iridescenceThicknessMinimum;\n\tuniform float iridescenceThicknessMaximum;\n#endif\n#ifdef USE_SHEEN\n\tuniform vec3 sheenColor;\n\tuniform float sheenRoughness;\n\t#ifdef USE_SHEEN_COLORMAP\n\t\tuniform sampler2D sheenColorMap;\n\t#endif\n\t#ifdef USE_SHEEN_ROUGHNESSMAP\n\t\tuniform sampler2D sheenRoughnessMap;\n\t#endif\n#endif\n#ifdef USE_ANISOTROPY\n\tuniform vec2 anisotropyVector;\n\t#ifdef USE_ANISOTROPYMAP\n\t\tuniform sampler2D anisotropyMap;\n\t#endif\n#endif\nvarying vec3 vViewPosition;\n#include <common>\n#include <packing>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <emissivemap_pars_fragment>\n#include <iridescence_fragment>\n#include <cube_uv_reflection_fragment>\n#include <envmap_common_pars_fragment>\n#include <envmap_physical_pars_fragment>\n#include <fog_pars_fragment>\n#include <lights_pars_begin>\n#include <normal_pars_fragment>\n#include <lights_physical_pars_fragment>\n#include <transmission_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <clearcoat_pars_fragment>\n#include <iridescence_pars_fragment>\n#include <roughnessmap_pars_fragment>\n#include <metalnessmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n\tvec3 totalEmissiveRadiance = emissive;\n\t#include <logdepthbuf_fragment>\n\t#include <map_fragment>\n\t#include <color_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\t#include <roughnessmap_fragment>\n\t#include <metalnessmap_fragment>\n\t#include <normal_fragment_begin>\n\t#include <normal_fragment_maps>\n\t#include <clearcoat_normal_fragment_begin>\n\t#include <clearcoat_normal_fragment_maps>\n\t#include <emissivemap_fragment>\n\t#include <lights_physical_fragment>\n\t#include <lights_fragment_begin>\n\t#include <lights_fragment_maps>\n\t#include <lights_fragment_end>\n\t#include <aomap_fragment>\n\tvec3 totalDiffuse = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse;\n\tvec3 totalSpecular = reflectedLight.directSpecular + reflectedLight.indirectSpecular;\n\t#include <transmission_fragment>\n\tvec3 outgoingLight = totalDiffuse + totalSpecular + totalEmissiveRadiance;\n\t#ifdef USE_SHEEN\n\t\tfloat sheenEnergyComp = 1.0 - 0.157 * max3( material.sheenColor );\n\t\toutgoingLight = outgoingLight * sheenEnergyComp + sheenSpecularDirect + sheenSpecularIndirect;\n\t#endif\n\t#ifdef USE_CLEARCOAT\n\t\tfloat dotNVcc = saturate( dot( geometryClearcoatNormal, geometryViewDir ) );\n\t\tvec3 Fcc = F_Schlick( material.clearcoatF0, material.clearcoatF90, dotNVcc );\n\t\toutgoingLight = outgoingLight * ( 1.0 - material.clearcoat * Fcc ) + ( clearcoatSpecularDirect + clearcoatSpecularIndirect ) * material.clearcoat;\n\t#endif\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n\t#include <premultiplied_alpha_fragment>\n\t#include <dithering_fragment>\n}";

	const vertex$4 = "#define TOON\nvarying vec3 vViewPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <shadowmap_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\t#include <color_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphcolor_vertex>\n\t#include <batching_vertex>\n\t#include <beginnormal_vertex>\n\t#include <morphnormal_vertex>\n\t#include <skinbase_vertex>\n\t#include <skinnormal_vertex>\n\t#include <defaultnormal_vertex>\n\t#include <normal_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <displacementmap_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\tvViewPosition = - mvPosition.xyz;\n\t#include <worldpos_vertex>\n\t#include <shadowmap_vertex>\n\t#include <fog_vertex>\n}";

	const fragment$4 = "#define TOON\nuniform vec3 diffuse;\nuniform vec3 emissive;\nuniform float opacity;\n#include <common>\n#include <packing>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <emissivemap_pars_fragment>\n#include <gradientmap_pars_fragment>\n#include <fog_pars_fragment>\n#include <bsdfs>\n#include <lights_pars_begin>\n#include <normal_pars_fragment>\n#include <lights_toon_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n\tvec3 totalEmissiveRadiance = emissive;\n\t#include <logdepthbuf_fragment>\n\t#include <map_fragment>\n\t#include <color_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\t#include <normal_fragment_begin>\n\t#include <normal_fragment_maps>\n\t#include <emissivemap_fragment>\n\t#include <lights_toon_fragment>\n\t#include <lights_fragment_begin>\n\t#include <lights_fragment_maps>\n\t#include <lights_fragment_end>\n\t#include <aomap_fragment>\n\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n\t#include <premultiplied_alpha_fragment>\n\t#include <dithering_fragment>\n}";

	const vertex$3 = "uniform float size;\nuniform float scale;\n#include <common>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\n#ifdef USE_POINTS_UV\n\tvarying vec2 vUv;\n\tuniform mat3 uvTransform;\n#endif\nvoid main() {\n\t#ifdef USE_POINTS_UV\n\t\tvUv = ( uvTransform * vec3( uv, 1 ) ).xy;\n\t#endif\n\t#include <color_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphcolor_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <project_vertex>\n\tgl_PointSize = size;\n\t#ifdef USE_SIZEATTENUATION\n\t\tbool isPerspective = isPerspectiveMatrix( projectionMatrix );\n\t\tif ( isPerspective ) gl_PointSize *= ( scale / - mvPosition.z );\n\t#endif\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\t#include <worldpos_vertex>\n\t#include <fog_vertex>\n}";

	const fragment$3 = "uniform vec3 diffuse;\nuniform float opacity;\n#include <common>\n#include <color_pars_fragment>\n#include <map_particle_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <fog_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\tvec3 outgoingLight = vec3( 0.0 );\n\t#include <logdepthbuf_fragment>\n\t#include <map_particle_fragment>\n\t#include <color_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\toutgoingLight = diffuseColor.rgb;\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n\t#include <premultiplied_alpha_fragment>\n}";

	const vertex$2 = "#include <common>\n#include <batching_pars_vertex>\n#include <fog_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <shadowmap_pars_vertex>\nvoid main() {\n\t#include <batching_vertex>\n\t#include <beginnormal_vertex>\n\t#include <morphinstance_vertex>\n\t#include <morphnormal_vertex>\n\t#include <skinbase_vertex>\n\t#include <skinnormal_vertex>\n\t#include <defaultnormal_vertex>\n\t#include <begin_vertex>\n\t#include <morphtarget_vertex>\n\t#include <skinning_vertex>\n\t#include <project_vertex>\n\t#include <logdepthbuf_vertex>\n\t#include <worldpos_vertex>\n\t#include <shadowmap_vertex>\n\t#include <fog_vertex>\n}";

	const fragment$2 = "uniform vec3 color;\nuniform float opacity;\n#include <common>\n#include <packing>\n#include <fog_pars_fragment>\n#include <bsdfs>\n#include <lights_pars_begin>\n#include <logdepthbuf_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <shadowmask_pars_fragment>\nvoid main() {\n\t#include <logdepthbuf_fragment>\n\tgl_FragColor = vec4( color, opacity * ( 1.0 - getShadowMask() ) );\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n}";

	const vertex$1 = "uniform float rotation;\nuniform vec2 center;\n#include <common>\n#include <uv_pars_vertex>\n#include <fog_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n\t#include <uv_vertex>\n\tvec4 mvPosition = modelViewMatrix[ 3 ];\n\tvec2 scale = vec2( length( modelMatrix[ 0 ].xyz ), length( modelMatrix[ 1 ].xyz ) );\n\t#ifndef USE_SIZEATTENUATION\n\t\tbool isPerspective = isPerspectiveMatrix( projectionMatrix );\n\t\tif ( isPerspective ) scale *= - mvPosition.z;\n\t#endif\n\tvec2 alignedPosition = ( position.xy - ( center - vec2( 0.5 ) ) ) * scale;\n\tvec2 rotatedPosition;\n\trotatedPosition.x = cos( rotation ) * alignedPosition.x - sin( rotation ) * alignedPosition.y;\n\trotatedPosition.y = sin( rotation ) * alignedPosition.x + cos( rotation ) * alignedPosition.y;\n\tmvPosition.xy += rotatedPosition;\n\tgl_Position = projectionMatrix * mvPosition;\n\t#include <logdepthbuf_vertex>\n\t#include <clipping_planes_vertex>\n\t#include <fog_vertex>\n}";

	const fragment$1 = "uniform vec3 diffuse;\nuniform float opacity;\n#include <common>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <fog_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n\tvec4 diffuseColor = vec4( diffuse, opacity );\n\t#include <clipping_planes_fragment>\n\tvec3 outgoingLight = vec3( 0.0 );\n\t#include <logdepthbuf_fragment>\n\t#include <map_fragment>\n\t#include <alphamap_fragment>\n\t#include <alphatest_fragment>\n\t#include <alphahash_fragment>\n\toutgoingLight = diffuseColor.rgb;\n\t#include <opaque_fragment>\n\t#include <tonemapping_fragment>\n\t#include <colorspace_fragment>\n\t#include <fog_fragment>\n}";

	const ShaderChunk = {
		alphahash_fragment: alphahash_fragment,
		alphahash_pars_fragment: alphahash_pars_fragment,
		alphamap_fragment: alphamap_fragment,
		alphamap_pars_fragment: alphamap_pars_fragment,
		alphatest_fragment: alphatest_fragment,
		alphatest_pars_fragment: alphatest_pars_fragment,
		aomap_fragment: aomap_fragment,
		aomap_pars_fragment: aomap_pars_fragment,
		batching_pars_vertex: batching_pars_vertex,
		batching_vertex: batching_vertex,
		begin_vertex: begin_vertex,
		beginnormal_vertex: beginnormal_vertex,
		bsdfs: bsdfs,
		iridescence_fragment: iridescence_fragment,
		bumpmap_pars_fragment: bumpmap_pars_fragment,
		clipping_planes_fragment: clipping_planes_fragment,
		clipping_planes_pars_fragment: clipping_planes_pars_fragment,
		clipping_planes_pars_vertex: clipping_planes_pars_vertex,
		clipping_planes_vertex: clipping_planes_vertex,
		color_fragment: color_fragment,
		color_pars_fragment: color_pars_fragment,
		color_pars_vertex: color_pars_vertex,
		color_vertex: color_vertex,
		common: common,
		cube_uv_reflection_fragment: cube_uv_reflection_fragment,
		defaultnormal_vertex: defaultnormal_vertex,
		displacementmap_pars_vertex: displacementmap_pars_vertex,
		displacementmap_vertex: displacementmap_vertex,
		emissivemap_fragment: emissivemap_fragment,
		emissivemap_pars_fragment: emissivemap_pars_fragment,
		colorspace_fragment: colorspace_fragment,
		colorspace_pars_fragment: colorspace_pars_fragment,
		envmap_fragment: envmap_fragment,
		envmap_common_pars_fragment: envmap_common_pars_fragment,
		envmap_pars_fragment: envmap_pars_fragment,
		envmap_pars_vertex: envmap_pars_vertex,
		envmap_physical_pars_fragment: envmap_physical_pars_fragment,
		envmap_vertex: envmap_vertex,
		fog_vertex: fog_vertex,
		fog_pars_vertex: fog_pars_vertex,
		fog_fragment: fog_fragment,
		fog_pars_fragment: fog_pars_fragment,
		gradientmap_pars_fragment: gradientmap_pars_fragment,
		lightmap_pars_fragment: lightmap_pars_fragment,
		lights_lambert_fragment: lights_lambert_fragment,
		lights_lambert_pars_fragment: lights_lambert_pars_fragment,
		lights_pars_begin: lights_pars_begin,
		lights_toon_fragment: lights_toon_fragment,
		lights_toon_pars_fragment: lights_toon_pars_fragment,
		lights_phong_fragment: lights_phong_fragment,
		lights_phong_pars_fragment: lights_phong_pars_fragment,
		lights_physical_fragment: lights_physical_fragment,
		lights_physical_pars_fragment: lights_physical_pars_fragment,
		lights_fragment_begin: lights_fragment_begin,
		lights_fragment_maps: lights_fragment_maps,
		lights_fragment_end: lights_fragment_end,
		logdepthbuf_fragment: logdepthbuf_fragment,
		logdepthbuf_pars_fragment: logdepthbuf_pars_fragment,
		logdepthbuf_pars_vertex: logdepthbuf_pars_vertex,
		logdepthbuf_vertex: logdepthbuf_vertex,
		map_fragment: map_fragment,
		map_pars_fragment: map_pars_fragment,
		map_particle_fragment: map_particle_fragment,
		map_particle_pars_fragment: map_particle_pars_fragment,
		metalnessmap_fragment: metalnessmap_fragment,
		metalnessmap_pars_fragment: metalnessmap_pars_fragment,
		morphinstance_vertex: morphinstance_vertex,
		morphcolor_vertex: morphcolor_vertex,
		morphnormal_vertex: morphnormal_vertex,
		morphtarget_pars_vertex: morphtarget_pars_vertex,
		morphtarget_vertex: morphtarget_vertex,
		normal_fragment_begin: normal_fragment_begin,
		normal_fragment_maps: normal_fragment_maps,
		normal_pars_fragment: normal_pars_fragment,
		normal_pars_vertex: normal_pars_vertex,
		normal_vertex: normal_vertex,
		normalmap_pars_fragment: normalmap_pars_fragment,
		clearcoat_normal_fragment_begin: clearcoat_normal_fragment_begin,
		clearcoat_normal_fragment_maps: clearcoat_normal_fragment_maps,
		clearcoat_pars_fragment: clearcoat_pars_fragment,
		iridescence_pars_fragment: iridescence_pars_fragment,
		opaque_fragment: opaque_fragment,
		packing: packing,
		premultiplied_alpha_fragment: premultiplied_alpha_fragment,
		project_vertex: project_vertex,
		dithering_fragment: dithering_fragment,
		dithering_pars_fragment: dithering_pars_fragment,
		roughnessmap_fragment: roughnessmap_fragment,
		roughnessmap_pars_fragment: roughnessmap_pars_fragment,
		shadowmap_pars_fragment: shadowmap_pars_fragment,
		shadowmap_pars_vertex: shadowmap_pars_vertex,
		shadowmap_vertex: shadowmap_vertex,
		shadowmask_pars_fragment: shadowmask_pars_fragment,
		skinbase_vertex: skinbase_vertex,
		skinning_pars_vertex: skinning_pars_vertex,
		skinning_vertex: skinning_vertex,
		skinnormal_vertex: skinnormal_vertex,
		specularmap_fragment: specularmap_fragment,
		specularmap_pars_fragment: specularmap_pars_fragment,
		tonemapping_fragment: tonemapping_fragment,
		tonemapping_pars_fragment: tonemapping_pars_fragment,
		transmission_fragment: transmission_fragment,
		transmission_pars_fragment: transmission_pars_fragment,
		uv_pars_fragment: uv_pars_fragment,
		uv_pars_vertex: uv_pars_vertex,
		uv_vertex: uv_vertex,
		worldpos_vertex: worldpos_vertex,

		background_vert: vertex$h,
		background_frag: fragment$h,
		backgroundCube_vert: vertex$g,
		backgroundCube_frag: fragment$g,
		cube_vert: vertex$f,
		cube_frag: fragment$f,
		depth_vert: vertex$e,
		depth_frag: fragment$e,
		distanceRGBA_vert: vertex$d,
		distanceRGBA_frag: fragment$d,
		equirect_vert: vertex$c,
		equirect_frag: fragment$c,
		linedashed_vert: vertex$b,
		linedashed_frag: fragment$b,
		meshbasic_vert: vertex$a,
		meshbasic_frag: fragment$a,
		meshlambert_vert: vertex$9,
		meshlambert_frag: fragment$9,
		meshmatcap_vert: vertex$8,
		meshmatcap_frag: fragment$8,
		meshnormal_vert: vertex$7,
		meshnormal_frag: fragment$7,
		meshphong_vert: vertex$6,
		meshphong_frag: fragment$6,
		meshphysical_vert: vertex$5,
		meshphysical_frag: fragment$5,
		meshtoon_vert: vertex$4,
		meshtoon_frag: fragment$4,
		points_vert: vertex$3,
		points_frag: fragment$3,
		shadow_vert: vertex$2,
		shadow_frag: fragment$2,
		sprite_vert: vertex$1,
		sprite_frag: fragment$1
	};

	// Uniforms library for shared webgl shaders
	const UniformsLib = {

		common: {

			diffuse: { value: /*@__PURE__*/ new Color( 0xffffff ) },
			opacity: { value: 1.0 },

			map: { value: null },
			mapTransform: { value: /*@__PURE__*/ new Matrix3() },

			alphaMap: { value: null },
			alphaMapTransform: { value: /*@__PURE__*/ new Matrix3() },

			alphaTest: { value: 0 }

		},

		specularmap: {

			specularMap: { value: null },
			specularMapTransform: { value: /*@__PURE__*/ new Matrix3() }

		},

		envmap: {

			envMap: { value: null },
			envMapRotation: { value: /*@__PURE__*/ new Matrix3() },
			flipEnvMap: { value: -1 },
			reflectivity: { value: 1.0 }, // basic, lambert, phong
			ior: { value: 1.5 }, // physical
			refractionRatio: { value: 0.98 }, // basic, lambert, phong

		},

		aomap: {

			aoMap: { value: null },
			aoMapIntensity: { value: 1 },
			aoMapTransform: { value: /*@__PURE__*/ new Matrix3() }

		},

		lightmap: {

			lightMap: { value: null },
			lightMapIntensity: { value: 1 },
			lightMapTransform: { value: /*@__PURE__*/ new Matrix3() }

		},

		bumpmap: {

			bumpMap: { value: null },
			bumpMapTransform: { value: /*@__PURE__*/ new Matrix3() },
			bumpScale: { value: 1 }

		},

		normalmap: {

			normalMap: { value: null },
			normalMapTransform: { value: /*@__PURE__*/ new Matrix3() },
			normalScale: { value: /*@__PURE__*/ new Vector2( 1, 1 ) }

		},

		displacementmap: {

			displacementMap: { value: null },
			displacementMapTransform: { value: /*@__PURE__*/ new Matrix3() },
			displacementScale: { value: 1 },
			displacementBias: { value: 0 }

		},

		emissivemap: {

			emissiveMap: { value: null },
			emissiveMapTransform: { value: /*@__PURE__*/ new Matrix3() }

		},

		metalnessmap: {

			metalnessMap: { value: null },
			metalnessMapTransform: { value: /*@__PURE__*/ new Matrix3() }

		},

		roughnessmap: {

			roughnessMap: { value: null },
			roughnessMapTransform: { value: /*@__PURE__*/ new Matrix3() }

		},

		gradientmap: {

			gradientMap: { value: null }

		},

		fog: {

			fogDensity: { value: 0.00025 },
			fogNear: { value: 1 },
			fogFar: { value: 2000 },
			fogColor: { value: /*@__PURE__*/ new Color( 0xffffff ) }

		},

		lights: {

			ambientLightColor: { value: [] },

			lightProbe: { value: [] },

			directionalLights: { value: [], properties: {
				direction: {},
				color: {}
			} },

			directionalLightShadows: { value: [], properties: {
				shadowIntensity: 1,
				shadowBias: {},
				shadowNormalBias: {},
				shadowRadius: {},
				shadowMapSize: {}
			} },

			directionalShadowMap: { value: [] },
			directionalShadowMatrix: { value: [] },

			spotLights: { value: [], properties: {
				color: {},
				position: {},
				direction: {},
				distance: {},
				coneCos: {},
				penumbraCos: {},
				decay: {}
			} },

			spotLightShadows: { value: [], properties: {
				shadowIntensity: 1,
				shadowBias: {},
				shadowNormalBias: {},
				shadowRadius: {},
				shadowMapSize: {}
			} },

			spotLightMap: { value: [] },
			spotShadowMap: { value: [] },
			spotLightMatrix: { value: [] },

			pointLights: { value: [], properties: {
				color: {},
				position: {},
				decay: {},
				distance: {}
			} },

			pointLightShadows: { value: [], properties: {
				shadowIntensity: 1,
				shadowBias: {},
				shadowNormalBias: {},
				shadowRadius: {},
				shadowMapSize: {},
				shadowCameraNear: {},
				shadowCameraFar: {}
			} },

			pointShadowMap: { value: [] },
			pointShadowMatrix: { value: [] },

			hemisphereLights: { value: [], properties: {
				direction: {},
				skyColor: {},
				groundColor: {}
			} },

			// TODO (abelnation): RectAreaLight BRDF data needs to be moved from example to main src
			rectAreaLights: { value: [], properties: {
				color: {},
				position: {},
				width: {},
				height: {}
			} },

			ltc_1: { value: null },
			ltc_2: { value: null }

		},

		points: {

			diffuse: { value: /*@__PURE__*/ new Color( 0xffffff ) },
			opacity: { value: 1.0 },
			size: { value: 1.0 },
			scale: { value: 1.0 },
			map: { value: null },
			alphaMap: { value: null },
			alphaMapTransform: { value: /*@__PURE__*/ new Matrix3() },
			alphaTest: { value: 0 },
			uvTransform: { value: /*@__PURE__*/ new Matrix3() }

		},

		sprite: {

			diffuse: { value: /*@__PURE__*/ new Color( 0xffffff ) },
			opacity: { value: 1.0 },
			center: { value: /*@__PURE__*/ new Vector2( 0.5, 0.5 ) },
			rotation: { value: 0.0 },
			map: { value: null },
			mapTransform: { value: /*@__PURE__*/ new Matrix3() },
			alphaMap: { value: null },
			alphaMapTransform: { value: /*@__PURE__*/ new Matrix3() },
			alphaTest: { value: 0 }

		}

	};

	const ShaderLib = {

		basic: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.specularmap,
				UniformsLib.envmap,
				UniformsLib.aomap,
				UniformsLib.lightmap,
				UniformsLib.fog
			] ),

			vertexShader: ShaderChunk.meshbasic_vert,
			fragmentShader: ShaderChunk.meshbasic_frag

		},

		lambert: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.specularmap,
				UniformsLib.envmap,
				UniformsLib.aomap,
				UniformsLib.lightmap,
				UniformsLib.emissivemap,
				UniformsLib.bumpmap,
				UniformsLib.normalmap,
				UniformsLib.displacementmap,
				UniformsLib.fog,
				UniformsLib.lights,
				{
					emissive: { value: /*@__PURE__*/ new Color( 0x000000 ) }
				}
			] ),

			vertexShader: ShaderChunk.meshlambert_vert,
			fragmentShader: ShaderChunk.meshlambert_frag

		},

		phong: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.specularmap,
				UniformsLib.envmap,
				UniformsLib.aomap,
				UniformsLib.lightmap,
				UniformsLib.emissivemap,
				UniformsLib.bumpmap,
				UniformsLib.normalmap,
				UniformsLib.displacementmap,
				UniformsLib.fog,
				UniformsLib.lights,
				{
					emissive: { value: /*@__PURE__*/ new Color( 0x000000 ) },
					specular: { value: /*@__PURE__*/ new Color( 0x111111 ) },
					shininess: { value: 30 }
				}
			] ),

			vertexShader: ShaderChunk.meshphong_vert,
			fragmentShader: ShaderChunk.meshphong_frag

		},

		standard: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.envmap,
				UniformsLib.aomap,
				UniformsLib.lightmap,
				UniformsLib.emissivemap,
				UniformsLib.bumpmap,
				UniformsLib.normalmap,
				UniformsLib.displacementmap,
				UniformsLib.roughnessmap,
				UniformsLib.metalnessmap,
				UniformsLib.fog,
				UniformsLib.lights,
				{
					emissive: { value: /*@__PURE__*/ new Color( 0x000000 ) },
					roughness: { value: 1.0 },
					metalness: { value: 0.0 },
					envMapIntensity: { value: 1 }
				}
			] ),

			vertexShader: ShaderChunk.meshphysical_vert,
			fragmentShader: ShaderChunk.meshphysical_frag

		},

		toon: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.aomap,
				UniformsLib.lightmap,
				UniformsLib.emissivemap,
				UniformsLib.bumpmap,
				UniformsLib.normalmap,
				UniformsLib.displacementmap,
				UniformsLib.gradientmap,
				UniformsLib.fog,
				UniformsLib.lights,
				{
					emissive: { value: /*@__PURE__*/ new Color( 0x000000 ) }
				}
			] ),

			vertexShader: ShaderChunk.meshtoon_vert,
			fragmentShader: ShaderChunk.meshtoon_frag

		},

		matcap: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.bumpmap,
				UniformsLib.normalmap,
				UniformsLib.displacementmap,
				UniformsLib.fog,
				{
					matcap: { value: null }
				}
			] ),

			vertexShader: ShaderChunk.meshmatcap_vert,
			fragmentShader: ShaderChunk.meshmatcap_frag

		},

		points: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.points,
				UniformsLib.fog
			] ),

			vertexShader: ShaderChunk.points_vert,
			fragmentShader: ShaderChunk.points_frag

		},

		dashed: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.fog,
				{
					scale: { value: 1 },
					dashSize: { value: 1 },
					totalSize: { value: 2 }
				}
			] ),

			vertexShader: ShaderChunk.linedashed_vert,
			fragmentShader: ShaderChunk.linedashed_frag

		},

		depth: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.displacementmap
			] ),

			vertexShader: ShaderChunk.depth_vert,
			fragmentShader: ShaderChunk.depth_frag

		},

		normal: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.bumpmap,
				UniformsLib.normalmap,
				UniformsLib.displacementmap,
				{
					opacity: { value: 1.0 }
				}
			] ),

			vertexShader: ShaderChunk.meshnormal_vert,
			fragmentShader: ShaderChunk.meshnormal_frag

		},

		sprite: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.sprite,
				UniformsLib.fog
			] ),

			vertexShader: ShaderChunk.sprite_vert,
			fragmentShader: ShaderChunk.sprite_frag

		},

		background: {

			uniforms: {
				uvTransform: { value: /*@__PURE__*/ new Matrix3() },
				t2D: { value: null },
				backgroundIntensity: { value: 1 }
			},

			vertexShader: ShaderChunk.background_vert,
			fragmentShader: ShaderChunk.background_frag

		},

		backgroundCube: {

			uniforms: {
				envMap: { value: null },
				flipEnvMap: { value: -1 },
				backgroundBlurriness: { value: 0 },
				backgroundIntensity: { value: 1 },
				backgroundRotation: { value: /*@__PURE__*/ new Matrix3() }
			},

			vertexShader: ShaderChunk.backgroundCube_vert,
			fragmentShader: ShaderChunk.backgroundCube_frag

		},

		cube: {

			uniforms: {
				tCube: { value: null },
				tFlip: { value: -1 },
				opacity: { value: 1.0 }
			},

			vertexShader: ShaderChunk.cube_vert,
			fragmentShader: ShaderChunk.cube_frag

		},

		equirect: {

			uniforms: {
				tEquirect: { value: null },
			},

			vertexShader: ShaderChunk.equirect_vert,
			fragmentShader: ShaderChunk.equirect_frag

		},

		distanceRGBA: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.common,
				UniformsLib.displacementmap,
				{
					referencePosition: { value: /*@__PURE__*/ new Vector3() },
					nearDistance: { value: 1 },
					farDistance: { value: 1000 }
				}
			] ),

			vertexShader: ShaderChunk.distanceRGBA_vert,
			fragmentShader: ShaderChunk.distanceRGBA_frag

		},

		shadow: {

			uniforms: /*@__PURE__*/ mergeUniforms( [
				UniformsLib.lights,
				UniformsLib.fog,
				{
					color: { value: /*@__PURE__*/ new Color( 0x00000 ) },
					opacity: { value: 1.0 }
				},
			] ),

			vertexShader: ShaderChunk.shadow_vert,
			fragmentShader: ShaderChunk.shadow_frag

		}

	};

	ShaderLib.physical = {

		uniforms: /*@__PURE__*/ mergeUniforms( [
			ShaderLib.standard.uniforms,
			{
				clearcoat: { value: 0 },
				clearcoatMap: { value: null },
				clearcoatMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				clearcoatNormalMap: { value: null },
				clearcoatNormalMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				clearcoatNormalScale: { value: /*@__PURE__*/ new Vector2( 1, 1 ) },
				clearcoatRoughness: { value: 0 },
				clearcoatRoughnessMap: { value: null },
				clearcoatRoughnessMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				dispersion: { value: 0 },
				iridescence: { value: 0 },
				iridescenceMap: { value: null },
				iridescenceMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				iridescenceIOR: { value: 1.3 },
				iridescenceThicknessMinimum: { value: 100 },
				iridescenceThicknessMaximum: { value: 400 },
				iridescenceThicknessMap: { value: null },
				iridescenceThicknessMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				sheen: { value: 0 },
				sheenColor: { value: /*@__PURE__*/ new Color( 0x000000 ) },
				sheenColorMap: { value: null },
				sheenColorMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				sheenRoughness: { value: 1 },
				sheenRoughnessMap: { value: null },
				sheenRoughnessMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				transmission: { value: 0 },
				transmissionMap: { value: null },
				transmissionMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				transmissionSamplerSize: { value: /*@__PURE__*/ new Vector2() },
				transmissionSamplerMap: { value: null },
				thickness: { value: 0 },
				thicknessMap: { value: null },
				thicknessMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				attenuationDistance: { value: 0 },
				attenuationColor: { value: /*@__PURE__*/ new Color( 0x000000 ) },
				specularColor: { value: /*@__PURE__*/ new Color( 1, 1, 1 ) },
				specularColorMap: { value: null },
				specularColorMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				specularIntensity: { value: 1 },
				specularIntensityMap: { value: null },
				specularIntensityMapTransform: { value: /*@__PURE__*/ new Matrix3() },
				anisotropyVector: { value: /*@__PURE__*/ new Vector2() },
				anisotropyMap: { value: null },
				anisotropyMapTransform: { value: /*@__PURE__*/ new Matrix3() },
			}
		] ),

		vertexShader: ShaderChunk.meshphysical_vert,
		fragmentShader: ShaderChunk.meshphysical_frag

	};

	const _rgb = { r: 0, b: 0, g: 0 };
	const _e1$1 = /*@__PURE__*/ new Euler();
	const _m1$1$1 = /*@__PURE__*/ new Matrix4();

	function WebGLBackground( renderer, cubemaps, cubeuvmaps, state, objects, alpha, premultipliedAlpha ) {

		const clearColor = new Color( 0x000000 );
		let clearAlpha = alpha === true ? 0 : 1;

		let planeMesh;
		let boxMesh;

		let currentBackground = null;
		let currentBackgroundVersion = 0;
		let currentTonemapping = null;

		function getBackground( scene ) {

			let background = scene.isScene === true ? scene.background : null;

			if ( background && background.isTexture ) {

				const usePMREM = scene.backgroundBlurriness > 0; // use PMREM if the user wants to blur the background
				background = ( usePMREM ? cubeuvmaps : cubemaps ).get( background );

			}

			return background;

		}

		function render( scene ) {

			let forceClear = false;
			const background = getBackground( scene );

			if ( background === null ) {

				setClear( clearColor, clearAlpha );

			} else if ( background && background.isColor ) {

				setClear( background, 1 );
				forceClear = true;

			}

			const environmentBlendMode = renderer.xr.getEnvironmentBlendMode();

			if ( environmentBlendMode === 'additive' ) {

				state.buffers.color.setClear( 0, 0, 0, 1, premultipliedAlpha );

			} else if ( environmentBlendMode === 'alpha-blend' ) {

				state.buffers.color.setClear( 0, 0, 0, 0, premultipliedAlpha );

			}

			if ( renderer.autoClear || forceClear ) {

				// buffers might not be writable which is required to ensure a correct clear

				state.buffers.depth.setTest( true );
				state.buffers.depth.setMask( true );
				state.buffers.color.setMask( true );

				renderer.clear( renderer.autoClearColor, renderer.autoClearDepth, renderer.autoClearStencil );

			}

		}

		function addToRenderList( renderList, scene ) {

			const background = getBackground( scene );

			if ( background && ( background.isCubeTexture || background.mapping === CubeUVReflectionMapping ) ) {

				if ( boxMesh === undefined ) {

					boxMesh = new Mesh(
						new BoxGeometry( 1, 1, 1 ),
						new ShaderMaterial( {
							name: 'BackgroundCubeMaterial',
							uniforms: cloneUniforms( ShaderLib.backgroundCube.uniforms ),
							vertexShader: ShaderLib.backgroundCube.vertexShader,
							fragmentShader: ShaderLib.backgroundCube.fragmentShader,
							side: BackSide,
							depthTest: false,
							depthWrite: false,
							fog: false,
							allowOverride: false
						} )
					);

					boxMesh.geometry.deleteAttribute( 'normal' );
					boxMesh.geometry.deleteAttribute( 'uv' );

					boxMesh.onBeforeRender = function ( renderer, scene, camera ) {

						this.matrixWorld.copyPosition( camera.matrixWorld );

					};

					// add "envMap" material property so the renderer can evaluate it like for built-in materials
					Object.defineProperty( boxMesh.material, 'envMap', {

						get: function () {

							return this.uniforms.envMap.value;

						}

					} );

					objects.update( boxMesh );

				}

				_e1$1.copy( scene.backgroundRotation );

				// accommodate left-handed frame
				_e1$1.x *= -1; _e1$1.y *= -1; _e1$1.z *= -1;

				if ( background.isCubeTexture && background.isRenderTargetTexture === false ) {

					// environment maps which are not cube render targets or PMREMs follow a different convention
					_e1$1.y *= -1;
					_e1$1.z *= -1;

				}

				boxMesh.material.uniforms.envMap.value = background;
				boxMesh.material.uniforms.flipEnvMap.value = ( background.isCubeTexture && background.isRenderTargetTexture === false ) ? -1 : 1;
				boxMesh.material.uniforms.backgroundBlurriness.value = scene.backgroundBlurriness;
				boxMesh.material.uniforms.backgroundIntensity.value = scene.backgroundIntensity;
				boxMesh.material.uniforms.backgroundRotation.value.setFromMatrix4( _m1$1$1.makeRotationFromEuler( _e1$1 ) );
				boxMesh.material.toneMapped = ColorManagement.getTransfer( background.colorSpace ) !== SRGBTransfer;

				if ( currentBackground !== background ||
					currentBackgroundVersion !== background.version ||
					currentTonemapping !== renderer.toneMapping ) {

					boxMesh.material.needsUpdate = true;

					currentBackground = background;
					currentBackgroundVersion = background.version;
					currentTonemapping = renderer.toneMapping;

				}

				boxMesh.layers.enableAll();

				// push to the pre-sorted opaque render list
				renderList.unshift( boxMesh, boxMesh.geometry, boxMesh.material, 0, 0, null );

			} else if ( background && background.isTexture ) {

				if ( planeMesh === undefined ) {

					planeMesh = new Mesh(
						new PlaneGeometry( 2, 2 ),
						new ShaderMaterial( {
							name: 'BackgroundMaterial',
							uniforms: cloneUniforms( ShaderLib.background.uniforms ),
							vertexShader: ShaderLib.background.vertexShader,
							fragmentShader: ShaderLib.background.fragmentShader,
							side: FrontSide,
							depthTest: false,
							depthWrite: false,
							fog: false,
							allowOverride: false
						} )
					);

					planeMesh.geometry.deleteAttribute( 'normal' );

					// add "map" material property so the renderer can evaluate it like for built-in materials
					Object.defineProperty( planeMesh.material, 'map', {

						get: function () {

							return this.uniforms.t2D.value;

						}

					} );

					objects.update( planeMesh );

				}

				planeMesh.material.uniforms.t2D.value = background;
				planeMesh.material.uniforms.backgroundIntensity.value = scene.backgroundIntensity;
				planeMesh.material.toneMapped = ColorManagement.getTransfer( background.colorSpace ) !== SRGBTransfer;

				if ( background.matrixAutoUpdate === true ) {

					background.updateMatrix();

				}

				planeMesh.material.uniforms.uvTransform.value.copy( background.matrix );

				if ( currentBackground !== background ||
					currentBackgroundVersion !== background.version ||
					currentTonemapping !== renderer.toneMapping ) {

					planeMesh.material.needsUpdate = true;

					currentBackground = background;
					currentBackgroundVersion = background.version;
					currentTonemapping = renderer.toneMapping;

				}

				planeMesh.layers.enableAll();

				// push to the pre-sorted opaque render list
				renderList.unshift( planeMesh, planeMesh.geometry, planeMesh.material, 0, 0, null );

			}

		}

		function setClear( color, alpha ) {

			color.getRGB( _rgb, getUnlitUniformColorSpace( renderer ) );

			state.buffers.color.setClear( _rgb.r, _rgb.g, _rgb.b, alpha, premultipliedAlpha );

		}

		function dispose() {

			if ( boxMesh !== undefined ) {

				boxMesh.geometry.dispose();
				boxMesh.material.dispose();

				boxMesh = undefined;

			}

			if ( planeMesh !== undefined ) {

				planeMesh.geometry.dispose();
				planeMesh.material.dispose();

				planeMesh = undefined;

			}

		}

		return {

			getClearColor: function () {

				return clearColor;

			},
			setClearColor: function ( color, alpha = 1 ) {

				clearColor.set( color );
				clearAlpha = alpha;
				setClear( clearColor, clearAlpha );

			},
			getClearAlpha: function () {

				return clearAlpha;

			},
			setClearAlpha: function ( alpha ) {

				clearAlpha = alpha;
				setClear( clearColor, clearAlpha );

			},
			render: render,
			addToRenderList: addToRenderList,
			dispose: dispose

		};

	}

	function WebGLBindingStates( gl, attributes ) {

		const maxVertexAttributes = gl.getParameter( gl.MAX_VERTEX_ATTRIBS );

		const bindingStates = {};

		const defaultState = createBindingState( null );
		let currentState = defaultState;
		let forceUpdate = false;

		function setup( object, material, program, geometry, index ) {

			let updateBuffers = false;

			const state = getBindingState( geometry, program, material );

			if ( currentState !== state ) {

				currentState = state;
				bindVertexArrayObject( currentState.object );

			}

			updateBuffers = needsUpdate( object, geometry, program, index );

			if ( updateBuffers ) saveCache( object, geometry, program, index );

			if ( index !== null ) {

				attributes.update( index, gl.ELEMENT_ARRAY_BUFFER );

			}

			if ( updateBuffers || forceUpdate ) {

				forceUpdate = false;

				setupVertexAttributes( object, material, program, geometry );

				if ( index !== null ) {

					gl.bindBuffer( gl.ELEMENT_ARRAY_BUFFER, attributes.get( index ).buffer );

				}

			}

		}

		function createVertexArrayObject() {

			return gl.createVertexArray();

		}

		function bindVertexArrayObject( vao ) {

			return gl.bindVertexArray( vao );

		}

		function deleteVertexArrayObject( vao ) {

			return gl.deleteVertexArray( vao );

		}

		function getBindingState( geometry, program, material ) {

			const wireframe = ( material.wireframe === true );

			let programMap = bindingStates[ geometry.id ];

			if ( programMap === undefined ) {

				programMap = {};
				bindingStates[ geometry.id ] = programMap;

			}

			let stateMap = programMap[ program.id ];

			if ( stateMap === undefined ) {

				stateMap = {};
				programMap[ program.id ] = stateMap;

			}

			let state = stateMap[ wireframe ];

			if ( state === undefined ) {

				state = createBindingState( createVertexArrayObject() );
				stateMap[ wireframe ] = state;

			}

			return state;

		}

		function createBindingState( vao ) {

			const newAttributes = [];
			const enabledAttributes = [];
			const attributeDivisors = [];

			for ( let i = 0; i < maxVertexAttributes; i ++ ) {

				newAttributes[ i ] = 0;
				enabledAttributes[ i ] = 0;
				attributeDivisors[ i ] = 0;

			}

			return {

				// for backward compatibility on non-VAO support browser
				geometry: null,
				program: null,
				wireframe: false,

				newAttributes: newAttributes,
				enabledAttributes: enabledAttributes,
				attributeDivisors: attributeDivisors,
				object: vao,
				attributes: {},
				index: null

			};

		}

		function needsUpdate( object, geometry, program, index ) {

			const cachedAttributes = currentState.attributes;
			const geometryAttributes = geometry.attributes;

			let attributesNum = 0;

			const programAttributes = program.getAttributes();

			for ( const name in programAttributes ) {

				const programAttribute = programAttributes[ name ];

				if ( programAttribute.location >= 0 ) {

					const cachedAttribute = cachedAttributes[ name ];
					let geometryAttribute = geometryAttributes[ name ];

					if ( geometryAttribute === undefined ) {

						if ( name === 'instanceMatrix' && object.instanceMatrix ) geometryAttribute = object.instanceMatrix;
						if ( name === 'instanceColor' && object.instanceColor ) geometryAttribute = object.instanceColor;

					}

					if ( cachedAttribute === undefined ) return true;

					if ( cachedAttribute.attribute !== geometryAttribute ) return true;

					if ( geometryAttribute && cachedAttribute.data !== geometryAttribute.data ) return true;

					attributesNum ++;

				}

			}

			if ( currentState.attributesNum !== attributesNum ) return true;

			if ( currentState.index !== index ) return true;

			return false;

		}

		function saveCache( object, geometry, program, index ) {

			const cache = {};
			const attributes = geometry.attributes;
			let attributesNum = 0;

			const programAttributes = program.getAttributes();

			for ( const name in programAttributes ) {

				const programAttribute = programAttributes[ name ];

				if ( programAttribute.location >= 0 ) {

					let attribute = attributes[ name ];

					if ( attribute === undefined ) {

						if ( name === 'instanceMatrix' && object.instanceMatrix ) attribute = object.instanceMatrix;
						if ( name === 'instanceColor' && object.instanceColor ) attribute = object.instanceColor;

					}

					const data = {};
					data.attribute = attribute;

					if ( attribute && attribute.data ) {

						data.data = attribute.data;

					}

					cache[ name ] = data;

					attributesNum ++;

				}

			}

			currentState.attributes = cache;
			currentState.attributesNum = attributesNum;

			currentState.index = index;

		}

		function initAttributes() {

			const newAttributes = currentState.newAttributes;

			for ( let i = 0, il = newAttributes.length; i < il; i ++ ) {

				newAttributes[ i ] = 0;

			}

		}

		function enableAttribute( attribute ) {

			enableAttributeAndDivisor( attribute, 0 );

		}

		function enableAttributeAndDivisor( attribute, meshPerAttribute ) {

			const newAttributes = currentState.newAttributes;
			const enabledAttributes = currentState.enabledAttributes;
			const attributeDivisors = currentState.attributeDivisors;

			newAttributes[ attribute ] = 1;

			if ( enabledAttributes[ attribute ] === 0 ) {

				gl.enableVertexAttribArray( attribute );
				enabledAttributes[ attribute ] = 1;

			}

			if ( attributeDivisors[ attribute ] !== meshPerAttribute ) {

				gl.vertexAttribDivisor( attribute, meshPerAttribute );
				attributeDivisors[ attribute ] = meshPerAttribute;

			}

		}

		function disableUnusedAttributes() {

			const newAttributes = currentState.newAttributes;
			const enabledAttributes = currentState.enabledAttributes;

			for ( let i = 0, il = enabledAttributes.length; i < il; i ++ ) {

				if ( enabledAttributes[ i ] !== newAttributes[ i ] ) {

					gl.disableVertexAttribArray( i );
					enabledAttributes[ i ] = 0;

				}

			}

		}

		function vertexAttribPointer( index, size, type, normalized, stride, offset, integer ) {

			if ( integer === true ) {

				gl.vertexAttribIPointer( index, size, type, stride, offset );

			} else {

				gl.vertexAttribPointer( index, size, type, normalized, stride, offset );

			}

		}

		function setupVertexAttributes( object, material, program, geometry ) {

			initAttributes();

			const geometryAttributes = geometry.attributes;

			const programAttributes = program.getAttributes();

			const materialDefaultAttributeValues = material.defaultAttributeValues;

			for ( const name in programAttributes ) {

				const programAttribute = programAttributes[ name ];

				if ( programAttribute.location >= 0 ) {

					let geometryAttribute = geometryAttributes[ name ];

					if ( geometryAttribute === undefined ) {

						if ( name === 'instanceMatrix' && object.instanceMatrix ) geometryAttribute = object.instanceMatrix;
						if ( name === 'instanceColor' && object.instanceColor ) geometryAttribute = object.instanceColor;

					}

					if ( geometryAttribute !== undefined ) {

						const normalized = geometryAttribute.normalized;
						const size = geometryAttribute.itemSize;

						const attribute = attributes.get( geometryAttribute );

						// TODO Attribute may not be available on context restore

						if ( attribute === undefined ) continue;

						const buffer = attribute.buffer;
						const type = attribute.type;
						const bytesPerElement = attribute.bytesPerElement;

						// check for integer attributes

						const integer = ( type === gl.INT || type === gl.UNSIGNED_INT || geometryAttribute.gpuType === IntType );

						if ( geometryAttribute.isInterleavedBufferAttribute ) {

							const data = geometryAttribute.data;
							const stride = data.stride;
							const offset = geometryAttribute.offset;

							if ( data.isInstancedInterleavedBuffer ) {

								for ( let i = 0; i < programAttribute.locationSize; i ++ ) {

									enableAttributeAndDivisor( programAttribute.location + i, data.meshPerAttribute );

								}

								if ( object.isInstancedMesh !== true && geometry._maxInstanceCount === undefined ) {

									geometry._maxInstanceCount = data.meshPerAttribute * data.count;

								}

							} else {

								for ( let i = 0; i < programAttribute.locationSize; i ++ ) {

									enableAttribute( programAttribute.location + i );

								}

							}

							gl.bindBuffer( gl.ARRAY_BUFFER, buffer );

							for ( let i = 0; i < programAttribute.locationSize; i ++ ) {

								vertexAttribPointer(
									programAttribute.location + i,
									size / programAttribute.locationSize,
									type,
									normalized,
									stride * bytesPerElement,
									( offset + ( size / programAttribute.locationSize ) * i ) * bytesPerElement,
									integer
								);

							}

						} else {

							if ( geometryAttribute.isInstancedBufferAttribute ) {

								for ( let i = 0; i < programAttribute.locationSize; i ++ ) {

									enableAttributeAndDivisor( programAttribute.location + i, geometryAttribute.meshPerAttribute );

								}

								if ( object.isInstancedMesh !== true && geometry._maxInstanceCount === undefined ) {

									geometry._maxInstanceCount = geometryAttribute.meshPerAttribute * geometryAttribute.count;

								}

							} else {

								for ( let i = 0; i < programAttribute.locationSize; i ++ ) {

									enableAttribute( programAttribute.location + i );

								}

							}

							gl.bindBuffer( gl.ARRAY_BUFFER, buffer );

							for ( let i = 0; i < programAttribute.locationSize; i ++ ) {

								vertexAttribPointer(
									programAttribute.location + i,
									size / programAttribute.locationSize,
									type,
									normalized,
									size * bytesPerElement,
									( size / programAttribute.locationSize ) * i * bytesPerElement,
									integer
								);

							}

						}

					} else if ( materialDefaultAttributeValues !== undefined ) {

						const value = materialDefaultAttributeValues[ name ];

						if ( value !== undefined ) {

							switch ( value.length ) {

								case 2:
									gl.vertexAttrib2fv( programAttribute.location, value );
									break;

								case 3:
									gl.vertexAttrib3fv( programAttribute.location, value );
									break;

								case 4:
									gl.vertexAttrib4fv( programAttribute.location, value );
									break;

								default:
									gl.vertexAttrib1fv( programAttribute.location, value );

							}

						}

					}

				}

			}

			disableUnusedAttributes();

		}

		function dispose() {

			reset();

			for ( const geometryId in bindingStates ) {

				const programMap = bindingStates[ geometryId ];

				for ( const programId in programMap ) {

					const stateMap = programMap[ programId ];

					for ( const wireframe in stateMap ) {

						deleteVertexArrayObject( stateMap[ wireframe ].object );

						delete stateMap[ wireframe ];

					}

					delete programMap[ programId ];

				}

				delete bindingStates[ geometryId ];

			}

		}

		function releaseStatesOfGeometry( geometry ) {

			if ( bindingStates[ geometry.id ] === undefined ) return;

			const programMap = bindingStates[ geometry.id ];

			for ( const programId in programMap ) {

				const stateMap = programMap[ programId ];

				for ( const wireframe in stateMap ) {

					deleteVertexArrayObject( stateMap[ wireframe ].object );

					delete stateMap[ wireframe ];

				}

				delete programMap[ programId ];

			}

			delete bindingStates[ geometry.id ];

		}

		function releaseStatesOfProgram( program ) {

			for ( const geometryId in bindingStates ) {

				const programMap = bindingStates[ geometryId ];

				if ( programMap[ program.id ] === undefined ) continue;

				const stateMap = programMap[ program.id ];

				for ( const wireframe in stateMap ) {

					deleteVertexArrayObject( stateMap[ wireframe ].object );

					delete stateMap[ wireframe ];

				}

				delete programMap[ program.id ];

			}

		}

		function reset() {

			resetDefaultState();
			forceUpdate = true;

			if ( currentState === defaultState ) return;

			currentState = defaultState;
			bindVertexArrayObject( currentState.object );

		}

		// for backward-compatibility

		function resetDefaultState() {

			defaultState.geometry = null;
			defaultState.program = null;
			defaultState.wireframe = false;

		}

		return {

			setup: setup,
			reset: reset,
			resetDefaultState: resetDefaultState,
			dispose: dispose,
			releaseStatesOfGeometry: releaseStatesOfGeometry,
			releaseStatesOfProgram: releaseStatesOfProgram,

			initAttributes: initAttributes,
			enableAttribute: enableAttribute,
			disableUnusedAttributes: disableUnusedAttributes

		};

	}

	function WebGLBufferRenderer( gl, extensions, info ) {

		let mode;

		function setMode( value ) {

			mode = value;

		}

		function render( start, count ) {

			gl.drawArrays( mode, start, count );

			info.update( count, mode, 1 );

		}

		function renderInstances( start, count, primcount ) {

			if ( primcount === 0 ) return;

			gl.drawArraysInstanced( mode, start, count, primcount );

			info.update( count, mode, primcount );

		}

		function renderMultiDraw( starts, counts, drawCount ) {

			if ( drawCount === 0 ) return;

			const extension = extensions.get( 'WEBGL_multi_draw' );
			extension.multiDrawArraysWEBGL( mode, starts, 0, counts, 0, drawCount );

			let elementCount = 0;
			for ( let i = 0; i < drawCount; i ++ ) {

				elementCount += counts[ i ];

			}

			info.update( elementCount, mode, 1 );

		}

		function renderMultiDrawInstances( starts, counts, drawCount, primcount ) {

			if ( drawCount === 0 ) return;

			const extension = extensions.get( 'WEBGL_multi_draw' );

			if ( extension === null ) {

				for ( let i = 0; i < starts.length; i ++ ) {

					renderInstances( starts[ i ], counts[ i ], primcount[ i ] );

				}

			} else {

				extension.multiDrawArraysInstancedWEBGL( mode, starts, 0, counts, 0, primcount, 0, drawCount );

				let elementCount = 0;
				for ( let i = 0; i < drawCount; i ++ ) {

					elementCount += counts[ i ] * primcount[ i ];

				}

				info.update( elementCount, mode, 1 );

			}

		}

		//

		this.setMode = setMode;
		this.render = render;
		this.renderInstances = renderInstances;
		this.renderMultiDraw = renderMultiDraw;
		this.renderMultiDrawInstances = renderMultiDrawInstances;

	}

	function WebGLCapabilities( gl, extensions, parameters, utils ) {

		let maxAnisotropy;

		function getMaxAnisotropy() {

			if ( maxAnisotropy !== undefined ) return maxAnisotropy;

			if ( extensions.has( 'EXT_texture_filter_anisotropic' ) === true ) {

				const extension = extensions.get( 'EXT_texture_filter_anisotropic' );

				maxAnisotropy = gl.getParameter( extension.MAX_TEXTURE_MAX_ANISOTROPY_EXT );

			} else {

				maxAnisotropy = 0;

			}

			return maxAnisotropy;

		}

		function textureFormatReadable( textureFormat ) {

			if ( textureFormat !== RGBAFormat && utils.convert( textureFormat ) !== gl.getParameter( gl.IMPLEMENTATION_COLOR_READ_FORMAT ) ) {

				return false;

			}

			return true;

		}

		function textureTypeReadable( textureType ) {

			const halfFloatSupportedByExt = ( textureType === HalfFloatType ) && ( extensions.has( 'EXT_color_buffer_half_float' ) || extensions.has( 'EXT_color_buffer_float' ) );

			if ( textureType !== UnsignedByteType && utils.convert( textureType ) !== gl.getParameter( gl.IMPLEMENTATION_COLOR_READ_TYPE ) && // Edge and Chrome Mac < 52 (#9513)
				textureType !== FloatType && ! halfFloatSupportedByExt ) {

				return false;

			}

			return true;

		}

		function getMaxPrecision( precision ) {

			if ( precision === 'highp' ) {

				if ( gl.getShaderPrecisionFormat( gl.VERTEX_SHADER, gl.HIGH_FLOAT ).precision > 0 &&
					gl.getShaderPrecisionFormat( gl.FRAGMENT_SHADER, gl.HIGH_FLOAT ).precision > 0 ) {

					return 'highp';

				}

				precision = 'mediump';

			}

			if ( precision === 'mediump' ) {

				if ( gl.getShaderPrecisionFormat( gl.VERTEX_SHADER, gl.MEDIUM_FLOAT ).precision > 0 &&
					gl.getShaderPrecisionFormat( gl.FRAGMENT_SHADER, gl.MEDIUM_FLOAT ).precision > 0 ) {

					return 'mediump';

				}

			}

			return 'lowp';

		}

		let precision = parameters.precision !== undefined ? parameters.precision : 'highp';
		const maxPrecision = getMaxPrecision( precision );

		if ( maxPrecision !== precision ) {

			console.warn( 'THREE.WebGLRenderer:', precision, 'not supported, using', maxPrecision, 'instead.' );
			precision = maxPrecision;

		}

		const logarithmicDepthBuffer = parameters.logarithmicDepthBuffer === true;
		const reverseDepthBuffer = parameters.reverseDepthBuffer === true && extensions.has( 'EXT_clip_control' );

		const maxTextures = gl.getParameter( gl.MAX_TEXTURE_IMAGE_UNITS );
		const maxVertexTextures = gl.getParameter( gl.MAX_VERTEX_TEXTURE_IMAGE_UNITS );
		const maxTextureSize = gl.getParameter( gl.MAX_TEXTURE_SIZE );
		const maxCubemapSize = gl.getParameter( gl.MAX_CUBE_MAP_TEXTURE_SIZE );

		const maxAttributes = gl.getParameter( gl.MAX_VERTEX_ATTRIBS );
		const maxVertexUniforms = gl.getParameter( gl.MAX_VERTEX_UNIFORM_VECTORS );
		const maxVaryings = gl.getParameter( gl.MAX_VARYING_VECTORS );
		const maxFragmentUniforms = gl.getParameter( gl.MAX_FRAGMENT_UNIFORM_VECTORS );

		const vertexTextures = maxVertexTextures > 0;

		const maxSamples = gl.getParameter( gl.MAX_SAMPLES );

		return {

			isWebGL2: true, // keeping this for backwards compatibility

			getMaxAnisotropy: getMaxAnisotropy,
			getMaxPrecision: getMaxPrecision,

			textureFormatReadable: textureFormatReadable,
			textureTypeReadable: textureTypeReadable,

			precision: precision,
			logarithmicDepthBuffer: logarithmicDepthBuffer,
			reverseDepthBuffer: reverseDepthBuffer,

			maxTextures: maxTextures,
			maxVertexTextures: maxVertexTextures,
			maxTextureSize: maxTextureSize,
			maxCubemapSize: maxCubemapSize,

			maxAttributes: maxAttributes,
			maxVertexUniforms: maxVertexUniforms,
			maxVaryings: maxVaryings,
			maxFragmentUniforms: maxFragmentUniforms,

			vertexTextures: vertexTextures,

			maxSamples: maxSamples

		};

	}

	function WebGLClipping( properties ) {

		const scope = this;

		let globalState = null,
			numGlobalPlanes = 0,
			localClippingEnabled = false,
			renderingShadows = false;

		const plane = new Plane(),
			viewNormalMatrix = new Matrix3(),

			uniform = { value: null, needsUpdate: false };

		this.uniform = uniform;
		this.numPlanes = 0;
		this.numIntersection = 0;

		this.init = function ( planes, enableLocalClipping ) {

			const enabled =
				planes.length !== 0 ||
				enableLocalClipping ||
				// enable state of previous frame - the clipping code has to
				// run another frame in order to reset the state:
				numGlobalPlanes !== 0 ||
				localClippingEnabled;

			localClippingEnabled = enableLocalClipping;

			numGlobalPlanes = planes.length;

			return enabled;

		};

		this.beginShadows = function () {

			renderingShadows = true;
			projectPlanes( null );

		};

		this.endShadows = function () {

			renderingShadows = false;

		};

		this.setGlobalState = function ( planes, camera ) {

			globalState = projectPlanes( planes, camera, 0 );

		};

		this.setState = function ( material, camera, useCache ) {

			const planes = material.clippingPlanes,
				clipIntersection = material.clipIntersection,
				clipShadows = material.clipShadows;

			const materialProperties = properties.get( material );

			if ( ! localClippingEnabled || planes === null || planes.length === 0 || renderingShadows && ! clipShadows ) {

				// there's no local clipping

				if ( renderingShadows ) {

					// there's no global clipping

					projectPlanes( null );

				} else {

					resetGlobalState();

				}

			} else {

				const nGlobal = renderingShadows ? 0 : numGlobalPlanes,
					lGlobal = nGlobal * 4;

				let dstArray = materialProperties.clippingState || null;

				uniform.value = dstArray; // ensure unique state

				dstArray = projectPlanes( planes, camera, lGlobal, useCache );

				for ( let i = 0; i !== lGlobal; ++ i ) {

					dstArray[ i ] = globalState[ i ];

				}

				materialProperties.clippingState = dstArray;
				this.numIntersection = clipIntersection ? this.numPlanes : 0;
				this.numPlanes += nGlobal;

			}


		};

		function resetGlobalState() {

			if ( uniform.value !== globalState ) {

				uniform.value = globalState;
				uniform.needsUpdate = numGlobalPlanes > 0;

			}

			scope.numPlanes = numGlobalPlanes;
			scope.numIntersection = 0;

		}

		function projectPlanes( planes, camera, dstOffset, skipTransform ) {

			const nPlanes = planes !== null ? planes.length : 0;
			let dstArray = null;

			if ( nPlanes !== 0 ) {

				dstArray = uniform.value;

				if ( skipTransform !== true || dstArray === null ) {

					const flatSize = dstOffset + nPlanes * 4,
						viewMatrix = camera.matrixWorldInverse;

					viewNormalMatrix.getNormalMatrix( viewMatrix );

					if ( dstArray === null || dstArray.length < flatSize ) {

						dstArray = new Float32Array( flatSize );

					}

					for ( let i = 0, i4 = dstOffset; i !== nPlanes; ++ i, i4 += 4 ) {

						plane.copy( planes[ i ] ).applyMatrix4( viewMatrix, viewNormalMatrix );

						plane.normal.toArray( dstArray, i4 );
						dstArray[ i4 + 3 ] = plane.constant;

					}

				}

				uniform.value = dstArray;
				uniform.needsUpdate = true;

			}

			scope.numPlanes = nPlanes;
			scope.numIntersection = 0;

			return dstArray;

		}

	}

	function WebGLCubeMaps( renderer ) {

		let cubemaps = new WeakMap();

		function mapTextureMapping( texture, mapping ) {

			if ( mapping === EquirectangularReflectionMapping ) {

				texture.mapping = CubeReflectionMapping;

			} else if ( mapping === EquirectangularRefractionMapping ) {

				texture.mapping = CubeRefractionMapping;

			}

			return texture;

		}

		function get( texture ) {

			if ( texture && texture.isTexture ) {

				const mapping = texture.mapping;

				if ( mapping === EquirectangularReflectionMapping || mapping === EquirectangularRefractionMapping ) {

					if ( cubemaps.has( texture ) ) {

						const cubemap = cubemaps.get( texture ).texture;
						return mapTextureMapping( cubemap, texture.mapping );

					} else {

						const image = texture.image;

						if ( image && image.height > 0 ) {

							const renderTarget = new WebGLCubeRenderTarget( image.height );
							renderTarget.fromEquirectangularTexture( renderer, texture );
							cubemaps.set( texture, renderTarget );

							texture.addEventListener( 'dispose', onTextureDispose );

							return mapTextureMapping( renderTarget.texture, texture.mapping );

						} else {

							// image not yet ready. try the conversion next frame

							return null;

						}

					}

				}

			}

			return texture;

		}

		function onTextureDispose( event ) {

			const texture = event.target;

			texture.removeEventListener( 'dispose', onTextureDispose );

			const cubemap = cubemaps.get( texture );

			if ( cubemap !== undefined ) {

				cubemaps.delete( texture );
				cubemap.dispose();

			}

		}

		function dispose() {

			cubemaps = new WeakMap();

		}

		return {
			get: get,
			dispose: dispose
		};

	}

	const LOD_MIN = 4;

	// The standard deviations (radians) associated with the extra mips. These are
	// chosen to approximate a Trowbridge-Reitz distribution function times the
	// geometric shadowing function. These sigma values squared must match the
	// variance #defines in cube_uv_reflection_fragment.glsl.js.
	const EXTRA_LOD_SIGMA = [ 0.125, 0.215, 0.35, 0.446, 0.526, 0.582 ];

	// The maximum length of the blur for loop. Smaller sigmas will use fewer
	// samples and exit early, but not recompile the shader.
	const MAX_SAMPLES = 20;

	const _flatCamera = /*@__PURE__*/ new OrthographicCamera();
	const _clearColor = /*@__PURE__*/ new Color();
	let _oldTarget = null;
	let _oldActiveCubeFace = 0;
	let _oldActiveMipmapLevel = 0;
	let _oldXrEnabled = false;

	// Golden Ratio
	const PHI = ( 1 + Math.sqrt( 5 ) ) / 2;
	const INV_PHI = 1 / PHI;

	// Vertices of a dodecahedron (except the opposites, which represent the
	// same axis), used as axis directions evenly spread on a sphere.
	const _axisDirections = [
		/*@__PURE__*/ new Vector3( - PHI, INV_PHI, 0 ),
		/*@__PURE__*/ new Vector3( PHI, INV_PHI, 0 ),
		/*@__PURE__*/ new Vector3( - INV_PHI, 0, PHI ),
		/*@__PURE__*/ new Vector3( INV_PHI, 0, PHI ),
		/*@__PURE__*/ new Vector3( 0, PHI, - INV_PHI ),
		/*@__PURE__*/ new Vector3( 0, PHI, INV_PHI ),
		/*@__PURE__*/ new Vector3( -1, 1, -1 ),
		/*@__PURE__*/ new Vector3( 1, 1, -1 ),
		/*@__PURE__*/ new Vector3( -1, 1, 1 ),
		/*@__PURE__*/ new Vector3( 1, 1, 1 ) ];

	const _origin = /*@__PURE__*/ new Vector3();

	/**
	 * This class generates a Prefiltered, Mipmapped Radiance Environment Map
	 * (PMREM) from a cubeMap environment texture. This allows different levels of
	 * blur to be quickly accessed based on material roughness. It is packed into a
	 * special CubeUV format that allows us to perform custom interpolation so that
	 * we can support nonlinear formats such as RGBE. Unlike a traditional mipmap
	 * chain, it only goes down to the LOD_MIN level (above), and then creates extra
	 * even more filtered 'mips' at the same LOD_MIN resolution, associated with
	 * higher roughness levels. In this way we maintain resolution to smoothly
	 * interpolate diffuse lighting while limiting sampling computation.
	 *
	 * Paper: Fast, Accurate Image-Based Lighting:
	 * {@link https://drive.google.com/file/d/15y8r_UpKlU9SvV4ILb0C3qCPecS8pvLz/view}
	*/
	class PMREMGenerator {

		/**
		 * Constructs a new PMREM generator.
		 *
		 * @param {WebGLRenderer} renderer - The renderer.
		 */
		constructor( renderer ) {

			this._renderer = renderer;
			this._pingPongRenderTarget = null;

			this._lodMax = 0;
			this._cubeSize = 0;
			this._lodPlanes = [];
			this._sizeLods = [];
			this._sigmas = [];

			this._blurMaterial = null;
			this._cubemapMaterial = null;
			this._equirectMaterial = null;

			this._compileMaterial( this._blurMaterial );

		}

		/**
		 * Generates a PMREM from a supplied Scene, which can be faster than using an
		 * image if networking bandwidth is low. Optional sigma specifies a blur radius
		 * in radians to be applied to the scene before PMREM generation. Optional near
		 * and far planes ensure the scene is rendered in its entirety.
		 *
		 * @param {Scene} scene - The scene to be captured.
		 * @param {number} [sigma=0] - The blur radius in radians.
		 * @param {number} [near=0.1] - The near plane distance.
		 * @param {number} [far=100] - The far plane distance.
		 * @param {Object} [options={}] - The configuration options.
		 * @param {number} [options.size=256] - The texture size of the PMREM.
		 * @param {Vector3} [options.renderTarget=origin] - The position of the internal cube camera that renders the scene.
		 * @return {WebGLRenderTarget} The resulting PMREM.
		 */
		fromScene( scene, sigma = 0, near = 0.1, far = 100, options = {} ) {

			const {
				size = 256,
				position = _origin,
			} = options;

			_oldTarget = this._renderer.getRenderTarget();
			_oldActiveCubeFace = this._renderer.getActiveCubeFace();
			_oldActiveMipmapLevel = this._renderer.getActiveMipmapLevel();
			_oldXrEnabled = this._renderer.xr.enabled;

			this._renderer.xr.enabled = false;

			this._setSize( size );

			const cubeUVRenderTarget = this._allocateTargets();
			cubeUVRenderTarget.depthBuffer = true;

			this._sceneToCubeUV( scene, near, far, cubeUVRenderTarget, position );

			if ( sigma > 0 ) {

				this._blur( cubeUVRenderTarget, 0, 0, sigma );

			}

			this._applyPMREM( cubeUVRenderTarget );
			this._cleanup( cubeUVRenderTarget );

			return cubeUVRenderTarget;

		}

		/**
		 * Generates a PMREM from an equirectangular texture, which can be either LDR
		 * or HDR. The ideal input image size is 1k (1024 x 512),
		 * as this matches best with the 256 x 256 cubemap output.
		 *
		 * @param {Texture} equirectangular - The equirectangular texture to be converted.
		 * @param {?WebGLRenderTarget} [renderTarget=null] - The render target to use.
		 * @return {WebGLRenderTarget} The resulting PMREM.
		 */
		fromEquirectangular( equirectangular, renderTarget = null ) {

			return this._fromTexture( equirectangular, renderTarget );

		}

		/**
		 * Generates a PMREM from an cubemap texture, which can be either LDR
		 * or HDR. The ideal input cube size is 256 x 256,
		 * as this matches best with the 256 x 256 cubemap output.
		 *
		 * @param {Texture} cubemap - The cubemap texture to be converted.
		 * @param {?WebGLRenderTarget} [renderTarget=null] - The render target to use.
		 * @return {WebGLRenderTarget} The resulting PMREM.
		 */
		fromCubemap( cubemap, renderTarget = null ) {

			return this._fromTexture( cubemap, renderTarget );

		}

		/**
		 * Pre-compiles the cubemap shader. You can get faster start-up by invoking this method during
		 * your texture's network fetch for increased concurrency.
		 */
		compileCubemapShader() {

			if ( this._cubemapMaterial === null ) {

				this._cubemapMaterial = _getCubemapMaterial();
				this._compileMaterial( this._cubemapMaterial );

			}

		}

		/**
		 * Pre-compiles the equirectangular shader. You can get faster start-up by invoking this method during
		 * your texture's network fetch for increased concurrency.
		 */
		compileEquirectangularShader() {

			if ( this._equirectMaterial === null ) {

				this._equirectMaterial = _getEquirectMaterial();
				this._compileMaterial( this._equirectMaterial );

			}

		}

		/**
		 * Disposes of the PMREMGenerator's internal memory. Note that PMREMGenerator is a static class,
		 * so you should not need more than one PMREMGenerator object. If you do, calling dispose() on
		 * one of them will cause any others to also become unusable.
		 */
		dispose() {

			this._dispose();

			if ( this._cubemapMaterial !== null ) this._cubemapMaterial.dispose();
			if ( this._equirectMaterial !== null ) this._equirectMaterial.dispose();

		}

		// private interface

		_setSize( cubeSize ) {

			this._lodMax = Math.floor( Math.log2( cubeSize ) );
			this._cubeSize = Math.pow( 2, this._lodMax );

		}

		_dispose() {

			if ( this._blurMaterial !== null ) this._blurMaterial.dispose();

			if ( this._pingPongRenderTarget !== null ) this._pingPongRenderTarget.dispose();

			for ( let i = 0; i < this._lodPlanes.length; i ++ ) {

				this._lodPlanes[ i ].dispose();

			}

		}

		_cleanup( outputTarget ) {

			this._renderer.setRenderTarget( _oldTarget, _oldActiveCubeFace, _oldActiveMipmapLevel );
			this._renderer.xr.enabled = _oldXrEnabled;

			outputTarget.scissorTest = false;
			_setViewport( outputTarget, 0, 0, outputTarget.width, outputTarget.height );

		}

		_fromTexture( texture, renderTarget ) {

			if ( texture.mapping === CubeReflectionMapping || texture.mapping === CubeRefractionMapping ) {

				this._setSize( texture.image.length === 0 ? 16 : ( texture.image[ 0 ].width || texture.image[ 0 ].image.width ) );

			} else { // Equirectangular

				this._setSize( texture.image.width / 4 );

			}

			_oldTarget = this._renderer.getRenderTarget();
			_oldActiveCubeFace = this._renderer.getActiveCubeFace();
			_oldActiveMipmapLevel = this._renderer.getActiveMipmapLevel();
			_oldXrEnabled = this._renderer.xr.enabled;

			this._renderer.xr.enabled = false;

			const cubeUVRenderTarget = renderTarget || this._allocateTargets();
			this._textureToCubeUV( texture, cubeUVRenderTarget );
			this._applyPMREM( cubeUVRenderTarget );
			this._cleanup( cubeUVRenderTarget );

			return cubeUVRenderTarget;

		}

		_allocateTargets() {

			const width = 3 * Math.max( this._cubeSize, 16 * 7 );
			const height = 4 * this._cubeSize;

			const params = {
				magFilter: LinearFilter,
				minFilter: LinearFilter,
				generateMipmaps: false,
				type: HalfFloatType,
				format: RGBAFormat,
				colorSpace: LinearSRGBColorSpace,
				depthBuffer: false
			};

			const cubeUVRenderTarget = _createRenderTarget( width, height, params );

			if ( this._pingPongRenderTarget === null || this._pingPongRenderTarget.width !== width || this._pingPongRenderTarget.height !== height ) {

				if ( this._pingPongRenderTarget !== null ) {

					this._dispose();

				}

				this._pingPongRenderTarget = _createRenderTarget( width, height, params );

				const { _lodMax } = this;
				( { sizeLods: this._sizeLods, lodPlanes: this._lodPlanes, sigmas: this._sigmas } = _createPlanes( _lodMax ) );

				this._blurMaterial = _getBlurShader( _lodMax, width, height );

			}

			return cubeUVRenderTarget;

		}

		_compileMaterial( material ) {

			const tmpMesh = new Mesh( this._lodPlanes[ 0 ], material );
			this._renderer.compile( tmpMesh, _flatCamera );

		}

		_sceneToCubeUV( scene, near, far, cubeUVRenderTarget, position ) {

			const fov = 90;
			const aspect = 1;
			const cubeCamera = new PerspectiveCamera( fov, aspect, near, far );
			const upSign = [ 1, -1, 1, 1, 1, 1 ];
			const forwardSign = [ 1, 1, 1, -1, -1, -1 ];
			const renderer = this._renderer;

			const originalAutoClear = renderer.autoClear;
			const toneMapping = renderer.toneMapping;
			renderer.getClearColor( _clearColor );

			renderer.toneMapping = NoToneMapping;
			renderer.autoClear = false;

			const backgroundMaterial = new MeshBasicMaterial( {
				name: 'PMREM.Background',
				side: BackSide,
				depthWrite: false,
				depthTest: false,
			} );

			const backgroundBox = new Mesh( new BoxGeometry(), backgroundMaterial );

			let useSolidColor = false;
			const background = scene.background;

			if ( background ) {

				if ( background.isColor ) {

					backgroundMaterial.color.copy( background );
					scene.background = null;
					useSolidColor = true;

				}

			} else {

				backgroundMaterial.color.copy( _clearColor );
				useSolidColor = true;

			}

			for ( let i = 0; i < 6; i ++ ) {

				const col = i % 3;

				if ( col === 0 ) {

					cubeCamera.up.set( 0, upSign[ i ], 0 );
					cubeCamera.position.set( position.x, position.y, position.z );
					cubeCamera.lookAt( position.x + forwardSign[ i ], position.y, position.z );

				} else if ( col === 1 ) {

					cubeCamera.up.set( 0, 0, upSign[ i ] );
					cubeCamera.position.set( position.x, position.y, position.z );
					cubeCamera.lookAt( position.x, position.y + forwardSign[ i ], position.z );


				} else {

					cubeCamera.up.set( 0, upSign[ i ], 0 );
					cubeCamera.position.set( position.x, position.y, position.z );
					cubeCamera.lookAt( position.x, position.y, position.z + forwardSign[ i ] );

				}

				const size = this._cubeSize;

				_setViewport( cubeUVRenderTarget, col * size, i > 2 ? size : 0, size, size );

				renderer.setRenderTarget( cubeUVRenderTarget );

				if ( useSolidColor ) {

					renderer.render( backgroundBox, cubeCamera );

				}

				renderer.render( scene, cubeCamera );

			}

			backgroundBox.geometry.dispose();
			backgroundBox.material.dispose();

			renderer.toneMapping = toneMapping;
			renderer.autoClear = originalAutoClear;
			scene.background = background;

		}

		_textureToCubeUV( texture, cubeUVRenderTarget ) {

			const renderer = this._renderer;

			const isCubeTexture = ( texture.mapping === CubeReflectionMapping || texture.mapping === CubeRefractionMapping );

			if ( isCubeTexture ) {

				if ( this._cubemapMaterial === null ) {

					this._cubemapMaterial = _getCubemapMaterial();

				}

				this._cubemapMaterial.uniforms.flipEnvMap.value = ( texture.isRenderTargetTexture === false ) ? -1 : 1;

			} else {

				if ( this._equirectMaterial === null ) {

					this._equirectMaterial = _getEquirectMaterial();

				}

			}

			const material = isCubeTexture ? this._cubemapMaterial : this._equirectMaterial;
			const mesh = new Mesh( this._lodPlanes[ 0 ], material );

			const uniforms = material.uniforms;

			uniforms[ 'envMap' ].value = texture;

			const size = this._cubeSize;

			_setViewport( cubeUVRenderTarget, 0, 0, 3 * size, 2 * size );

			renderer.setRenderTarget( cubeUVRenderTarget );
			renderer.render( mesh, _flatCamera );

		}

		_applyPMREM( cubeUVRenderTarget ) {

			const renderer = this._renderer;
			const autoClear = renderer.autoClear;
			renderer.autoClear = false;
			const n = this._lodPlanes.length;

			for ( let i = 1; i < n; i ++ ) {

				const sigma = Math.sqrt( this._sigmas[ i ] * this._sigmas[ i ] - this._sigmas[ i - 1 ] * this._sigmas[ i - 1 ] );

				const poleAxis = _axisDirections[ ( n - i - 1 ) % _axisDirections.length ];

				this._blur( cubeUVRenderTarget, i - 1, i, sigma, poleAxis );

			}

			renderer.autoClear = autoClear;

		}

		/**
		 * This is a two-pass Gaussian blur for a cubemap. Normally this is done
		 * vertically and horizontally, but this breaks down on a cube. Here we apply
		 * the blur latitudinally (around the poles), and then longitudinally (towards
		 * the poles) to approximate the orthogonally-separable blur. It is least
		 * accurate at the poles, but still does a decent job.
		 *
		 * @private
		 * @param {WebGLRenderTarget} cubeUVRenderTarget
		 * @param {number} lodIn
		 * @param {number} lodOut
		 * @param {number} sigma
		 * @param {Vector3} [poleAxis]
		 */
		_blur( cubeUVRenderTarget, lodIn, lodOut, sigma, poleAxis ) {

			const pingPongRenderTarget = this._pingPongRenderTarget;

			this._halfBlur(
				cubeUVRenderTarget,
				pingPongRenderTarget,
				lodIn,
				lodOut,
				sigma,
				'latitudinal',
				poleAxis );

			this._halfBlur(
				pingPongRenderTarget,
				cubeUVRenderTarget,
				lodOut,
				lodOut,
				sigma,
				'longitudinal',
				poleAxis );

		}

		_halfBlur( targetIn, targetOut, lodIn, lodOut, sigmaRadians, direction, poleAxis ) {

			const renderer = this._renderer;
			const blurMaterial = this._blurMaterial;

			if ( direction !== 'latitudinal' && direction !== 'longitudinal' ) {

				console.error(
					'blur direction must be either latitudinal or longitudinal!' );

			}

			// Number of standard deviations at which to cut off the discrete approximation.
			const STANDARD_DEVIATIONS = 3;

			const blurMesh = new Mesh( this._lodPlanes[ lodOut ], blurMaterial );
			const blurUniforms = blurMaterial.uniforms;

			const pixels = this._sizeLods[ lodIn ] - 1;
			const radiansPerPixel = isFinite( sigmaRadians ) ? Math.PI / ( 2 * pixels ) : 2 * Math.PI / ( 2 * MAX_SAMPLES - 1 );
			const sigmaPixels = sigmaRadians / radiansPerPixel;
			const samples = isFinite( sigmaRadians ) ? 1 + Math.floor( STANDARD_DEVIATIONS * sigmaPixels ) : MAX_SAMPLES;

			if ( samples > MAX_SAMPLES ) {

				console.warn( `sigmaRadians, ${
				sigmaRadians}, is too large and will clip, as it requested ${
				samples} samples when the maximum is set to ${MAX_SAMPLES}` );

			}

			const weights = [];
			let sum = 0;

			for ( let i = 0; i < MAX_SAMPLES; ++ i ) {

				const x = i / sigmaPixels;
				const weight = Math.exp( - x * x / 2 );
				weights.push( weight );

				if ( i === 0 ) {

					sum += weight;

				} else if ( i < samples ) {

					sum += 2 * weight;

				}

			}

			for ( let i = 0; i < weights.length; i ++ ) {

				weights[ i ] = weights[ i ] / sum;

			}

			blurUniforms[ 'envMap' ].value = targetIn.texture;
			blurUniforms[ 'samples' ].value = samples;
			blurUniforms[ 'weights' ].value = weights;
			blurUniforms[ 'latitudinal' ].value = direction === 'latitudinal';

			if ( poleAxis ) {

				blurUniforms[ 'poleAxis' ].value = poleAxis;

			}

			const { _lodMax } = this;
			blurUniforms[ 'dTheta' ].value = radiansPerPixel;
			blurUniforms[ 'mipInt' ].value = _lodMax - lodIn;

			const outputSize = this._sizeLods[ lodOut ];
			const x = 3 * outputSize * ( lodOut > _lodMax - LOD_MIN ? lodOut - _lodMax + LOD_MIN : 0 );
			const y = 4 * ( this._cubeSize - outputSize );

			_setViewport( targetOut, x, y, 3 * outputSize, 2 * outputSize );
			renderer.setRenderTarget( targetOut );
			renderer.render( blurMesh, _flatCamera );

		}

	}



	function _createPlanes( lodMax ) {

		const lodPlanes = [];
		const sizeLods = [];
		const sigmas = [];

		let lod = lodMax;

		const totalLods = lodMax - LOD_MIN + 1 + EXTRA_LOD_SIGMA.length;

		for ( let i = 0; i < totalLods; i ++ ) {

			const sizeLod = Math.pow( 2, lod );
			sizeLods.push( sizeLod );
			let sigma = 1.0 / sizeLod;

			if ( i > lodMax - LOD_MIN ) {

				sigma = EXTRA_LOD_SIGMA[ i - lodMax + LOD_MIN - 1 ];

			} else if ( i === 0 ) {

				sigma = 0;

			}

			sigmas.push( sigma );

			const texelSize = 1.0 / ( sizeLod - 2 );
			const min = - texelSize;
			const max = 1 + texelSize;
			const uv1 = [ min, min, max, min, max, max, min, min, max, max, min, max ];

			const cubeFaces = 6;
			const vertices = 6;
			const positionSize = 3;
			const uvSize = 2;
			const faceIndexSize = 1;

			const position = new Float32Array( positionSize * vertices * cubeFaces );
			const uv = new Float32Array( uvSize * vertices * cubeFaces );
			const faceIndex = new Float32Array( faceIndexSize * vertices * cubeFaces );

			for ( let face = 0; face < cubeFaces; face ++ ) {

				const x = ( face % 3 ) * 2 / 3 - 1;
				const y = face > 2 ? 0 : -1;
				const coordinates = [
					x, y, 0,
					x + 2 / 3, y, 0,
					x + 2 / 3, y + 1, 0,
					x, y, 0,
					x + 2 / 3, y + 1, 0,
					x, y + 1, 0
				];
				position.set( coordinates, positionSize * vertices * face );
				uv.set( uv1, uvSize * vertices * face );
				const fill = [ face, face, face, face, face, face ];
				faceIndex.set( fill, faceIndexSize * vertices * face );

			}

			const planes = new BufferGeometry();
			planes.setAttribute( 'position', new BufferAttribute( position, positionSize ) );
			planes.setAttribute( 'uv', new BufferAttribute( uv, uvSize ) );
			planes.setAttribute( 'faceIndex', new BufferAttribute( faceIndex, faceIndexSize ) );
			lodPlanes.push( planes );

			if ( lod > LOD_MIN ) {

				lod --;

			}

		}

		return { lodPlanes, sizeLods, sigmas };

	}

	function _createRenderTarget( width, height, params ) {

		const cubeUVRenderTarget = new WebGLRenderTarget( width, height, params );
		cubeUVRenderTarget.texture.mapping = CubeUVReflectionMapping;
		cubeUVRenderTarget.texture.name = 'PMREM.cubeUv';
		cubeUVRenderTarget.scissorTest = true;
		return cubeUVRenderTarget;

	}

	function _setViewport( target, x, y, width, height ) {

		target.viewport.set( x, y, width, height );
		target.scissor.set( x, y, width, height );

	}

	function _getBlurShader( lodMax, width, height ) {

		const weights = new Float32Array( MAX_SAMPLES );
		const poleAxis = new Vector3( 0, 1, 0 );
		const shaderMaterial = new ShaderMaterial( {

			name: 'SphericalGaussianBlur',

			defines: {
				'n': MAX_SAMPLES,
				'CUBEUV_TEXEL_WIDTH': 1.0 / width,
				'CUBEUV_TEXEL_HEIGHT': 1.0 / height,
				'CUBEUV_MAX_MIP': `${lodMax}.0`,
			},

			uniforms: {
				'envMap': { value: null },
				'samples': { value: 1 },
				'weights': { value: weights },
				'latitudinal': { value: false },
				'dTheta': { value: 0 },
				'mipInt': { value: 0 },
				'poleAxis': { value: poleAxis }
			},

			vertexShader: _getCommonVertexShader(),

			fragmentShader: /* glsl */`

			precision mediump float;
			precision mediump int;

			varying vec3 vOutputDirection;

			uniform sampler2D envMap;
			uniform int samples;
			uniform float weights[ n ];
			uniform bool latitudinal;
			uniform float dTheta;
			uniform float mipInt;
			uniform vec3 poleAxis;

			#define ENVMAP_TYPE_CUBE_UV
			#include <cube_uv_reflection_fragment>

			vec3 getSample( float theta, vec3 axis ) {

				float cosTheta = cos( theta );
				// Rodrigues' axis-angle rotation
				vec3 sampleDirection = vOutputDirection * cosTheta
					+ cross( axis, vOutputDirection ) * sin( theta )
					+ axis * dot( axis, vOutputDirection ) * ( 1.0 - cosTheta );

				return bilinearCubeUV( envMap, sampleDirection, mipInt );

			}

			void main() {

				vec3 axis = latitudinal ? poleAxis : cross( poleAxis, vOutputDirection );

				if ( all( equal( axis, vec3( 0.0 ) ) ) ) {

					axis = vec3( vOutputDirection.z, 0.0, - vOutputDirection.x );

				}

				axis = normalize( axis );

				gl_FragColor = vec4( 0.0, 0.0, 0.0, 1.0 );
				gl_FragColor.rgb += weights[ 0 ] * getSample( 0.0, axis );

				for ( int i = 1; i < n; i++ ) {

					if ( i >= samples ) {

						break;

					}

					float theta = dTheta * float( i );
					gl_FragColor.rgb += weights[ i ] * getSample( -1.0 * theta, axis );
					gl_FragColor.rgb += weights[ i ] * getSample( theta, axis );

				}

			}
		`,

			blending: NoBlending,
			depthTest: false,
			depthWrite: false

		} );

		return shaderMaterial;

	}

	function _getEquirectMaterial() {

		return new ShaderMaterial( {

			name: 'EquirectangularToCubeUV',

			uniforms: {
				'envMap': { value: null }
			},

			vertexShader: _getCommonVertexShader(),

			fragmentShader: /* glsl */`

			precision mediump float;
			precision mediump int;

			varying vec3 vOutputDirection;

			uniform sampler2D envMap;

			#include <common>

			void main() {

				vec3 outputDirection = normalize( vOutputDirection );
				vec2 uv = equirectUv( outputDirection );

				gl_FragColor = vec4( texture2D ( envMap, uv ).rgb, 1.0 );

			}
		`,

			blending: NoBlending,
			depthTest: false,
			depthWrite: false

		} );

	}

	function _getCubemapMaterial() {

		return new ShaderMaterial( {

			name: 'CubemapToCubeUV',

			uniforms: {
				'envMap': { value: null },
				'flipEnvMap': { value: -1 }
			},

			vertexShader: _getCommonVertexShader(),

			fragmentShader: /* glsl */`

			precision mediump float;
			precision mediump int;

			uniform float flipEnvMap;

			varying vec3 vOutputDirection;

			uniform samplerCube envMap;

			void main() {

				gl_FragColor = textureCube( envMap, vec3( flipEnvMap * vOutputDirection.x, vOutputDirection.yz ) );

			}
		`,

			blending: NoBlending,
			depthTest: false,
			depthWrite: false

		} );

	}

	function _getCommonVertexShader() {

		return /* glsl */`

		precision mediump float;
		precision mediump int;

		attribute float faceIndex;

		varying vec3 vOutputDirection;

		// RH coordinate system; PMREM face-indexing convention
		vec3 getDirection( vec2 uv, float face ) {

			uv = 2.0 * uv - 1.0;

			vec3 direction = vec3( uv, 1.0 );

			if ( face == 0.0 ) {

				direction = direction.zyx; // ( 1, v, u ) pos x

			} else if ( face == 1.0 ) {

				direction = direction.xzy;
				direction.xz *= -1.0; // ( -u, 1, -v ) pos y

			} else if ( face == 2.0 ) {

				direction.x *= -1.0; // ( -u, v, 1 ) pos z

			} else if ( face == 3.0 ) {

				direction = direction.zyx;
				direction.xz *= -1.0; // ( -1, v, -u ) neg x

			} else if ( face == 4.0 ) {

				direction = direction.xzy;
				direction.xy *= -1.0; // ( -u, -1, v ) neg y

			} else if ( face == 5.0 ) {

				direction.z *= -1.0; // ( u, v, -1 ) neg z

			}

			return direction;

		}

		void main() {

			vOutputDirection = getDirection( uv, faceIndex );
			gl_Position = vec4( position, 1.0 );

		}
	`;

	}

	function WebGLCubeUVMaps( renderer ) {

		let cubeUVmaps = new WeakMap();

		let pmremGenerator = null;

		function get( texture ) {

			if ( texture && texture.isTexture ) {

				const mapping = texture.mapping;

				const isEquirectMap = ( mapping === EquirectangularReflectionMapping || mapping === EquirectangularRefractionMapping );
				const isCubeMap = ( mapping === CubeReflectionMapping || mapping === CubeRefractionMapping );

				// equirect/cube map to cubeUV conversion

				if ( isEquirectMap || isCubeMap ) {

					let renderTarget = cubeUVmaps.get( texture );

					const currentPMREMVersion = renderTarget !== undefined ? renderTarget.texture.pmremVersion : 0;

					if ( texture.isRenderTargetTexture && texture.pmremVersion !== currentPMREMVersion ) {

						if ( pmremGenerator === null ) pmremGenerator = new PMREMGenerator( renderer );

						renderTarget = isEquirectMap ? pmremGenerator.fromEquirectangular( texture, renderTarget ) : pmremGenerator.fromCubemap( texture, renderTarget );
						renderTarget.texture.pmremVersion = texture.pmremVersion;

						cubeUVmaps.set( texture, renderTarget );

						return renderTarget.texture;

					} else {

						if ( renderTarget !== undefined ) {

							return renderTarget.texture;

						} else {

							const image = texture.image;

							if ( ( isEquirectMap && image && image.height > 0 ) || ( isCubeMap && image && isCubeTextureComplete( image ) ) ) {

								if ( pmremGenerator === null ) pmremGenerator = new PMREMGenerator( renderer );

								renderTarget = isEquirectMap ? pmremGenerator.fromEquirectangular( texture ) : pmremGenerator.fromCubemap( texture );
								renderTarget.texture.pmremVersion = texture.pmremVersion;

								cubeUVmaps.set( texture, renderTarget );

								texture.addEventListener( 'dispose', onTextureDispose );

								return renderTarget.texture;

							} else {

								// image not yet ready. try the conversion next frame

								return null;

							}

						}

					}

				}

			}

			return texture;

		}

		function isCubeTextureComplete( image ) {

			let count = 0;
			const length = 6;

			for ( let i = 0; i < length; i ++ ) {

				if ( image[ i ] !== undefined ) count ++;

			}

			return count === length;


		}

		function onTextureDispose( event ) {

			const texture = event.target;

			texture.removeEventListener( 'dispose', onTextureDispose );

			const cubemapUV = cubeUVmaps.get( texture );

			if ( cubemapUV !== undefined ) {

				cubeUVmaps.delete( texture );
				cubemapUV.dispose();

			}

		}

		function dispose() {

			cubeUVmaps = new WeakMap();

			if ( pmremGenerator !== null ) {

				pmremGenerator.dispose();
				pmremGenerator = null;

			}

		}

		return {
			get: get,
			dispose: dispose
		};

	}

	function WebGLExtensions( gl ) {

		const extensions = {};

		function getExtension( name ) {

			if ( extensions[ name ] !== undefined ) {

				return extensions[ name ];

			}

			let extension;

			switch ( name ) {

				case 'WEBGL_depth_texture':
					extension = gl.getExtension( 'WEBGL_depth_texture' ) || gl.getExtension( 'MOZ_WEBGL_depth_texture' ) || gl.getExtension( 'WEBKIT_WEBGL_depth_texture' );
					break;

				case 'EXT_texture_filter_anisotropic':
					extension = gl.getExtension( 'EXT_texture_filter_anisotropic' ) || gl.getExtension( 'MOZ_EXT_texture_filter_anisotropic' ) || gl.getExtension( 'WEBKIT_EXT_texture_filter_anisotropic' );
					break;

				case 'WEBGL_compressed_texture_s3tc':
					extension = gl.getExtension( 'WEBGL_compressed_texture_s3tc' ) || gl.getExtension( 'MOZ_WEBGL_compressed_texture_s3tc' ) || gl.getExtension( 'WEBKIT_WEBGL_compressed_texture_s3tc' );
					break;

				case 'WEBGL_compressed_texture_pvrtc':
					extension = gl.getExtension( 'WEBGL_compressed_texture_pvrtc' ) || gl.getExtension( 'WEBKIT_WEBGL_compressed_texture_pvrtc' );
					break;

				default:
					extension = gl.getExtension( name );

			}

			extensions[ name ] = extension;

			return extension;

		}

		return {

			has: function ( name ) {

				return getExtension( name ) !== null;

			},

			init: function () {

				getExtension( 'EXT_color_buffer_float' );
				getExtension( 'WEBGL_clip_cull_distance' );
				getExtension( 'OES_texture_float_linear' );
				getExtension( 'EXT_color_buffer_half_float' );
				getExtension( 'WEBGL_multisampled_render_to_texture' );
				getExtension( 'WEBGL_render_shared_exponent' );

			},

			get: function ( name ) {

				const extension = getExtension( name );

				if ( extension === null ) {

					warnOnce( 'THREE.WebGLRenderer: ' + name + ' extension not supported.' );

				}

				return extension;

			}

		};

	}

	function WebGLGeometries( gl, attributes, info, bindingStates ) {

		const geometries = {};
		const wireframeAttributes = new WeakMap();

		function onGeometryDispose( event ) {

			const geometry = event.target;

			if ( geometry.index !== null ) {

				attributes.remove( geometry.index );

			}

			for ( const name in geometry.attributes ) {

				attributes.remove( geometry.attributes[ name ] );

			}

			geometry.removeEventListener( 'dispose', onGeometryDispose );

			delete geometries[ geometry.id ];

			const attribute = wireframeAttributes.get( geometry );

			if ( attribute ) {

				attributes.remove( attribute );
				wireframeAttributes.delete( geometry );

			}

			bindingStates.releaseStatesOfGeometry( geometry );

			if ( geometry.isInstancedBufferGeometry === true ) {

				delete geometry._maxInstanceCount;

			}

			//

			info.memory.geometries --;

		}

		function get( object, geometry ) {

			if ( geometries[ geometry.id ] === true ) return geometry;

			geometry.addEventListener( 'dispose', onGeometryDispose );

			geometries[ geometry.id ] = true;

			info.memory.geometries ++;

			return geometry;

		}

		function update( geometry ) {

			const geometryAttributes = geometry.attributes;

			// Updating index buffer in VAO now. See WebGLBindingStates.

			for ( const name in geometryAttributes ) {

				attributes.update( geometryAttributes[ name ], gl.ARRAY_BUFFER );

			}

		}

		function updateWireframeAttribute( geometry ) {

			const indices = [];

			const geometryIndex = geometry.index;
			const geometryPosition = geometry.attributes.position;
			let version = 0;

			if ( geometryIndex !== null ) {

				const array = geometryIndex.array;
				version = geometryIndex.version;

				for ( let i = 0, l = array.length; i < l; i += 3 ) {

					const a = array[ i + 0 ];
					const b = array[ i + 1 ];
					const c = array[ i + 2 ];

					indices.push( a, b, b, c, c, a );

				}

			} else if ( geometryPosition !== undefined ) {

				const array = geometryPosition.array;
				version = geometryPosition.version;

				for ( let i = 0, l = ( array.length / 3 ) - 1; i < l; i += 3 ) {

					const a = i + 0;
					const b = i + 1;
					const c = i + 2;

					indices.push( a, b, b, c, c, a );

				}

			} else {

				return;

			}

			const attribute = new ( arrayNeedsUint32( indices ) ? Uint32BufferAttribute : Uint16BufferAttribute )( indices, 1 );
			attribute.version = version;

			// Updating index buffer in VAO now. See WebGLBindingStates

			//

			const previousAttribute = wireframeAttributes.get( geometry );

			if ( previousAttribute ) attributes.remove( previousAttribute );

			//

			wireframeAttributes.set( geometry, attribute );

		}

		function getWireframeAttribute( geometry ) {

			const currentAttribute = wireframeAttributes.get( geometry );

			if ( currentAttribute ) {

				const geometryIndex = geometry.index;

				if ( geometryIndex !== null ) {

					// if the attribute is obsolete, create a new one

					if ( currentAttribute.version < geometryIndex.version ) {

						updateWireframeAttribute( geometry );

					}

				}

			} else {

				updateWireframeAttribute( geometry );

			}

			return wireframeAttributes.get( geometry );

		}

		return {

			get: get,
			update: update,

			getWireframeAttribute: getWireframeAttribute

		};

	}

	function WebGLIndexedBufferRenderer( gl, extensions, info ) {

		let mode;

		function setMode( value ) {

			mode = value;

		}

		let type, bytesPerElement;

		function setIndex( value ) {

			type = value.type;
			bytesPerElement = value.bytesPerElement;

		}

		function render( start, count ) {

			gl.drawElements( mode, count, type, start * bytesPerElement );

			info.update( count, mode, 1 );

		}

		function renderInstances( start, count, primcount ) {

			if ( primcount === 0 ) return;

			gl.drawElementsInstanced( mode, count, type, start * bytesPerElement, primcount );

			info.update( count, mode, primcount );

		}

		function renderMultiDraw( starts, counts, drawCount ) {

			if ( drawCount === 0 ) return;

			const extension = extensions.get( 'WEBGL_multi_draw' );
			extension.multiDrawElementsWEBGL( mode, counts, 0, type, starts, 0, drawCount );

			let elementCount = 0;
			for ( let i = 0; i < drawCount; i ++ ) {

				elementCount += counts[ i ];

			}

			info.update( elementCount, mode, 1 );


		}

		function renderMultiDrawInstances( starts, counts, drawCount, primcount ) {

			if ( drawCount === 0 ) return;

			const extension = extensions.get( 'WEBGL_multi_draw' );

			if ( extension === null ) {

				for ( let i = 0; i < starts.length; i ++ ) {

					renderInstances( starts[ i ] / bytesPerElement, counts[ i ], primcount[ i ] );

				}

			} else {

				extension.multiDrawElementsInstancedWEBGL( mode, counts, 0, type, starts, 0, primcount, 0, drawCount );

				let elementCount = 0;
				for ( let i = 0; i < drawCount; i ++ ) {

					elementCount += counts[ i ] * primcount[ i ];

				}

				info.update( elementCount, mode, 1 );

			}

		}

		//

		this.setMode = setMode;
		this.setIndex = setIndex;
		this.render = render;
		this.renderInstances = renderInstances;
		this.renderMultiDraw = renderMultiDraw;
		this.renderMultiDrawInstances = renderMultiDrawInstances;

	}

	function WebGLInfo( gl ) {

		const memory = {
			geometries: 0,
			textures: 0
		};

		const render = {
			frame: 0,
			calls: 0,
			triangles: 0,
			points: 0,
			lines: 0
		};

		function update( count, mode, instanceCount ) {

			render.calls ++;

			switch ( mode ) {

				case gl.TRIANGLES:
					render.triangles += instanceCount * ( count / 3 );
					break;

				case gl.LINES:
					render.lines += instanceCount * ( count / 2 );
					break;

				case gl.LINE_STRIP:
					render.lines += instanceCount * ( count - 1 );
					break;

				case gl.LINE_LOOP:
					render.lines += instanceCount * count;
					break;

				case gl.POINTS:
					render.points += instanceCount * count;
					break;

				default:
					console.error( 'THREE.WebGLInfo: Unknown draw mode:', mode );
					break;

			}

		}

		function reset() {

			render.calls = 0;
			render.triangles = 0;
			render.points = 0;
			render.lines = 0;

		}

		return {
			memory: memory,
			render: render,
			programs: null,
			autoReset: true,
			reset: reset,
			update: update
		};

	}

	function WebGLMorphtargets( gl, capabilities, textures ) {

		const morphTextures = new WeakMap();
		const morph = new Vector4();

		function update( object, geometry, program ) {

			const objectInfluences = object.morphTargetInfluences;

			// the following encodes morph targets into an array of data textures. Each layer represents a single morph target.

			const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;
			const morphTargetsCount = ( morphAttribute !== undefined ) ? morphAttribute.length : 0;

			let entry = morphTextures.get( geometry );

			if ( entry === undefined || entry.count !== morphTargetsCount ) {

				if ( entry !== undefined ) entry.texture.dispose();

				const hasMorphPosition = geometry.morphAttributes.position !== undefined;
				const hasMorphNormals = geometry.morphAttributes.normal !== undefined;
				const hasMorphColors = geometry.morphAttributes.color !== undefined;

				const morphTargets = geometry.morphAttributes.position || [];
				const morphNormals = geometry.morphAttributes.normal || [];
				const morphColors = geometry.morphAttributes.color || [];

				let vertexDataCount = 0;

				if ( hasMorphPosition === true ) vertexDataCount = 1;
				if ( hasMorphNormals === true ) vertexDataCount = 2;
				if ( hasMorphColors === true ) vertexDataCount = 3;

				let width = geometry.attributes.position.count * vertexDataCount;
				let height = 1;

				if ( width > capabilities.maxTextureSize ) {

					height = Math.ceil( width / capabilities.maxTextureSize );
					width = capabilities.maxTextureSize;

				}

				const buffer = new Float32Array( width * height * 4 * morphTargetsCount );

				const texture = new DataArrayTexture( buffer, width, height, morphTargetsCount );
				texture.type = FloatType;
				texture.needsUpdate = true;

				// fill buffer

				const vertexDataStride = vertexDataCount * 4;

				for ( let i = 0; i < morphTargetsCount; i ++ ) {

					const morphTarget = morphTargets[ i ];
					const morphNormal = morphNormals[ i ];
					const morphColor = morphColors[ i ];

					const offset = width * height * 4 * i;

					for ( let j = 0; j < morphTarget.count; j ++ ) {

						const stride = j * vertexDataStride;

						if ( hasMorphPosition === true ) {

							morph.fromBufferAttribute( morphTarget, j );

							buffer[ offset + stride + 0 ] = morph.x;
							buffer[ offset + stride + 1 ] = morph.y;
							buffer[ offset + stride + 2 ] = morph.z;
							buffer[ offset + stride + 3 ] = 0;

						}

						if ( hasMorphNormals === true ) {

							morph.fromBufferAttribute( morphNormal, j );

							buffer[ offset + stride + 4 ] = morph.x;
							buffer[ offset + stride + 5 ] = morph.y;
							buffer[ offset + stride + 6 ] = morph.z;
							buffer[ offset + stride + 7 ] = 0;

						}

						if ( hasMorphColors === true ) {

							morph.fromBufferAttribute( morphColor, j );

							buffer[ offset + stride + 8 ] = morph.x;
							buffer[ offset + stride + 9 ] = morph.y;
							buffer[ offset + stride + 10 ] = morph.z;
							buffer[ offset + stride + 11 ] = ( morphColor.itemSize === 4 ) ? morph.w : 1;

						}

					}

				}

				entry = {
					count: morphTargetsCount,
					texture: texture,
					size: new Vector2( width, height )
				};

				morphTextures.set( geometry, entry );

				function disposeTexture() {

					texture.dispose();

					morphTextures.delete( geometry );

					geometry.removeEventListener( 'dispose', disposeTexture );

				}

				geometry.addEventListener( 'dispose', disposeTexture );

			}

			//
			if ( object.isInstancedMesh === true && object.morphTexture !== null ) {

				program.getUniforms().setValue( gl, 'morphTexture', object.morphTexture, textures );

			} else {

				let morphInfluencesSum = 0;

				for ( let i = 0; i < objectInfluences.length; i ++ ) {

					morphInfluencesSum += objectInfluences[ i ];

				}

				const morphBaseInfluence = geometry.morphTargetsRelative ? 1 : 1 - morphInfluencesSum;


				program.getUniforms().setValue( gl, 'morphTargetBaseInfluence', morphBaseInfluence );
				program.getUniforms().setValue( gl, 'morphTargetInfluences', objectInfluences );

			}

			program.getUniforms().setValue( gl, 'morphTargetsTexture', entry.texture, textures );
			program.getUniforms().setValue( gl, 'morphTargetsTextureSize', entry.size );

		}

		return {

			update: update

		};

	}

	function WebGLObjects( gl, geometries, attributes, info ) {

		let updateMap = new WeakMap();

		function update( object ) {

			const frame = info.render.frame;

			const geometry = object.geometry;
			const buffergeometry = geometries.get( object, geometry );

			// Update once per frame

			if ( updateMap.get( buffergeometry ) !== frame ) {

				geometries.update( buffergeometry );

				updateMap.set( buffergeometry, frame );

			}

			if ( object.isInstancedMesh ) {

				if ( object.hasEventListener( 'dispose', onInstancedMeshDispose ) === false ) {

					object.addEventListener( 'dispose', onInstancedMeshDispose );

				}

				if ( updateMap.get( object ) !== frame ) {

					attributes.update( object.instanceMatrix, gl.ARRAY_BUFFER );

					if ( object.instanceColor !== null ) {

						attributes.update( object.instanceColor, gl.ARRAY_BUFFER );

					}

					updateMap.set( object, frame );

				}

			}

			if ( object.isSkinnedMesh ) {

				const skeleton = object.skeleton;

				if ( updateMap.get( skeleton ) !== frame ) {

					skeleton.update();

					updateMap.set( skeleton, frame );

				}

			}

			return buffergeometry;

		}

		function dispose() {

			updateMap = new WeakMap();

		}

		function onInstancedMeshDispose( event ) {

			const instancedMesh = event.target;

			instancedMesh.removeEventListener( 'dispose', onInstancedMeshDispose );

			attributes.remove( instancedMesh.instanceMatrix );

			if ( instancedMesh.instanceColor !== null ) attributes.remove( instancedMesh.instanceColor );

		}

		return {

			update: update,
			dispose: dispose

		};

	}

	/**
	 * Uniforms of a program.
	 * Those form a tree structure with a special top-level container for the root,
	 * which you get by calling 'new WebGLUniforms( gl, program )'.
	 *
	 *
	 * Properties of inner nodes including the top-level container:
	 *
	 * .seq - array of nested uniforms
	 * .map - nested uniforms by name
	 *
	 *
	 * Methods of all nodes except the top-level container:
	 *
	 * .setValue( gl, value, [textures] )
	 *
	 * 		uploads a uniform value(s)
	 *  	the 'textures' parameter is needed for sampler uniforms
	 *
	 *
	 * Static methods of the top-level container (textures factorizations):
	 *
	 * .upload( gl, seq, values, textures )
	 *
	 * 		sets uniforms in 'seq' to 'values[id].value'
	 *
	 * .seqWithValue( seq, values ) : filteredSeq
	 *
	 * 		filters 'seq' entries with corresponding entry in values
	 *
	 *
	 * Methods of the top-level container (textures factorizations):
	 *
	 * .setValue( gl, name, value, textures )
	 *
	 * 		sets uniform with  name 'name' to 'value'
	 *
	 * .setOptional( gl, obj, prop )
	 *
	 * 		like .set for an optional property of the object
	 *
	 */


	const emptyTexture = /*@__PURE__*/ new Texture();

	const emptyShadowTexture = /*@__PURE__*/ new DepthTexture( 1, 1 );

	const emptyArrayTexture = /*@__PURE__*/ new DataArrayTexture();
	const empty3dTexture = /*@__PURE__*/ new Data3DTexture();
	const emptyCubeTexture = /*@__PURE__*/ new CubeTexture();

	// --- Utilities ---

	// Array Caches (provide typed arrays for temporary by size)

	const arrayCacheF32 = [];
	const arrayCacheI32 = [];

	// Float32Array caches used for uploading Matrix uniforms

	const mat4array = new Float32Array( 16 );
	const mat3array = new Float32Array( 9 );
	const mat2array = new Float32Array( 4 );

	// Flattening for arrays of vectors and matrices

	function flatten( array, nBlocks, blockSize ) {

		const firstElem = array[ 0 ];

		if ( firstElem <= 0 || firstElem > 0 ) return array;
		// unoptimized: ! isNaN( firstElem )
		// see http://jacksondunstan.com/articles/983

		const n = nBlocks * blockSize;
		let r = arrayCacheF32[ n ];

		if ( r === undefined ) {

			r = new Float32Array( n );
			arrayCacheF32[ n ] = r;

		}

		if ( nBlocks !== 0 ) {

			firstElem.toArray( r, 0 );

			for ( let i = 1, offset = 0; i !== nBlocks; ++ i ) {

				offset += blockSize;
				array[ i ].toArray( r, offset );

			}

		}

		return r;

	}

	function arraysEqual( a, b ) {

		if ( a.length !== b.length ) return false;

		for ( let i = 0, l = a.length; i < l; i ++ ) {

			if ( a[ i ] !== b[ i ] ) return false;

		}

		return true;

	}

	function copyArray( a, b ) {

		for ( let i = 0, l = b.length; i < l; i ++ ) {

			a[ i ] = b[ i ];

		}

	}

	// Texture unit allocation

	function allocTexUnits( textures, n ) {

		let r = arrayCacheI32[ n ];

		if ( r === undefined ) {

			r = new Int32Array( n );
			arrayCacheI32[ n ] = r;

		}

		for ( let i = 0; i !== n; ++ i ) {

			r[ i ] = textures.allocateTextureUnit();

		}

		return r;

	}

	// --- Setters ---

	// Note: Defining these methods externally, because they come in a bunch
	// and this way their names minify.

	// Single scalar

	function setValueV1f( gl, v ) {

		const cache = this.cache;

		if ( cache[ 0 ] === v ) return;

		gl.uniform1f( this.addr, v );

		cache[ 0 ] = v;

	}

	// Single float vector (from flat array or THREE.VectorN)

	function setValueV2f( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y ) {

				gl.uniform2f( this.addr, v.x, v.y );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform2fv( this.addr, v );

			copyArray( cache, v );

		}

	}

	function setValueV3f( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y || cache[ 2 ] !== v.z ) {

				gl.uniform3f( this.addr, v.x, v.y, v.z );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;
				cache[ 2 ] = v.z;

			}

		} else if ( v.r !== undefined ) {

			if ( cache[ 0 ] !== v.r || cache[ 1 ] !== v.g || cache[ 2 ] !== v.b ) {

				gl.uniform3f( this.addr, v.r, v.g, v.b );

				cache[ 0 ] = v.r;
				cache[ 1 ] = v.g;
				cache[ 2 ] = v.b;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform3fv( this.addr, v );

			copyArray( cache, v );

		}

	}

	function setValueV4f( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y || cache[ 2 ] !== v.z || cache[ 3 ] !== v.w ) {

				gl.uniform4f( this.addr, v.x, v.y, v.z, v.w );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;
				cache[ 2 ] = v.z;
				cache[ 3 ] = v.w;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform4fv( this.addr, v );

			copyArray( cache, v );

		}

	}

	// Single matrix (from flat array or THREE.MatrixN)

	function setValueM2( gl, v ) {

		const cache = this.cache;
		const elements = v.elements;

		if ( elements === undefined ) {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniformMatrix2fv( this.addr, false, v );

			copyArray( cache, v );

		} else {

			if ( arraysEqual( cache, elements ) ) return;

			mat2array.set( elements );

			gl.uniformMatrix2fv( this.addr, false, mat2array );

			copyArray( cache, elements );

		}

	}

	function setValueM3( gl, v ) {

		const cache = this.cache;
		const elements = v.elements;

		if ( elements === undefined ) {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniformMatrix3fv( this.addr, false, v );

			copyArray( cache, v );

		} else {

			if ( arraysEqual( cache, elements ) ) return;

			mat3array.set( elements );

			gl.uniformMatrix3fv( this.addr, false, mat3array );

			copyArray( cache, elements );

		}

	}

	function setValueM4( gl, v ) {

		const cache = this.cache;
		const elements = v.elements;

		if ( elements === undefined ) {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniformMatrix4fv( this.addr, false, v );

			copyArray( cache, v );

		} else {

			if ( arraysEqual( cache, elements ) ) return;

			mat4array.set( elements );

			gl.uniformMatrix4fv( this.addr, false, mat4array );

			copyArray( cache, elements );

		}

	}

	// Single integer / boolean

	function setValueV1i( gl, v ) {

		const cache = this.cache;

		if ( cache[ 0 ] === v ) return;

		gl.uniform1i( this.addr, v );

		cache[ 0 ] = v;

	}

	// Single integer / boolean vector (from flat array or THREE.VectorN)

	function setValueV2i( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y ) {

				gl.uniform2i( this.addr, v.x, v.y );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform2iv( this.addr, v );

			copyArray( cache, v );

		}

	}

	function setValueV3i( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y || cache[ 2 ] !== v.z ) {

				gl.uniform3i( this.addr, v.x, v.y, v.z );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;
				cache[ 2 ] = v.z;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform3iv( this.addr, v );

			copyArray( cache, v );

		}

	}

	function setValueV4i( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y || cache[ 2 ] !== v.z || cache[ 3 ] !== v.w ) {

				gl.uniform4i( this.addr, v.x, v.y, v.z, v.w );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;
				cache[ 2 ] = v.z;
				cache[ 3 ] = v.w;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform4iv( this.addr, v );

			copyArray( cache, v );

		}

	}

	// Single unsigned integer

	function setValueV1ui( gl, v ) {

		const cache = this.cache;

		if ( cache[ 0 ] === v ) return;

		gl.uniform1ui( this.addr, v );

		cache[ 0 ] = v;

	}

	// Single unsigned integer vector (from flat array or THREE.VectorN)

	function setValueV2ui( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y ) {

				gl.uniform2ui( this.addr, v.x, v.y );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform2uiv( this.addr, v );

			copyArray( cache, v );

		}

	}

	function setValueV3ui( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y || cache[ 2 ] !== v.z ) {

				gl.uniform3ui( this.addr, v.x, v.y, v.z );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;
				cache[ 2 ] = v.z;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform3uiv( this.addr, v );

			copyArray( cache, v );

		}

	}

	function setValueV4ui( gl, v ) {

		const cache = this.cache;

		if ( v.x !== undefined ) {

			if ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y || cache[ 2 ] !== v.z || cache[ 3 ] !== v.w ) {

				gl.uniform4ui( this.addr, v.x, v.y, v.z, v.w );

				cache[ 0 ] = v.x;
				cache[ 1 ] = v.y;
				cache[ 2 ] = v.z;
				cache[ 3 ] = v.w;

			}

		} else {

			if ( arraysEqual( cache, v ) ) return;

			gl.uniform4uiv( this.addr, v );

			copyArray( cache, v );

		}

	}


	// Single texture (2D / Cube)

	function setValueT1( gl, v, textures ) {

		const cache = this.cache;
		const unit = textures.allocateTextureUnit();

		if ( cache[ 0 ] !== unit ) {

			gl.uniform1i( this.addr, unit );
			cache[ 0 ] = unit;

		}

		let emptyTexture2D;

		if ( this.type === gl.SAMPLER_2D_SHADOW ) {

			emptyShadowTexture.compareFunction = LessEqualCompare; // #28670
			emptyTexture2D = emptyShadowTexture;

		} else {

			emptyTexture2D = emptyTexture;

		}

		textures.setTexture2D( v || emptyTexture2D, unit );

	}

	function setValueT3D1( gl, v, textures ) {

		const cache = this.cache;
		const unit = textures.allocateTextureUnit();

		if ( cache[ 0 ] !== unit ) {

			gl.uniform1i( this.addr, unit );
			cache[ 0 ] = unit;

		}

		textures.setTexture3D( v || empty3dTexture, unit );

	}

	function setValueT6( gl, v, textures ) {

		const cache = this.cache;
		const unit = textures.allocateTextureUnit();

		if ( cache[ 0 ] !== unit ) {

			gl.uniform1i( this.addr, unit );
			cache[ 0 ] = unit;

		}

		textures.setTextureCube( v || emptyCubeTexture, unit );

	}

	function setValueT2DArray1( gl, v, textures ) {

		const cache = this.cache;
		const unit = textures.allocateTextureUnit();

		if ( cache[ 0 ] !== unit ) {

			gl.uniform1i( this.addr, unit );
			cache[ 0 ] = unit;

		}

		textures.setTexture2DArray( v || emptyArrayTexture, unit );

	}

	// Helper to pick the right setter for the singular case

	function getSingularSetter( type ) {

		switch ( type ) {

			case 0x1406: return setValueV1f; // FLOAT
			case 0x8b50: return setValueV2f; // _VEC2
			case 0x8b51: return setValueV3f; // _VEC3
			case 0x8b52: return setValueV4f; // _VEC4

			case 0x8b5a: return setValueM2; // _MAT2
			case 0x8b5b: return setValueM3; // _MAT3
			case 0x8b5c: return setValueM4; // _MAT4

			case 0x1404: case 0x8b56: return setValueV1i; // INT, BOOL
			case 0x8b53: case 0x8b57: return setValueV2i; // _VEC2
			case 0x8b54: case 0x8b58: return setValueV3i; // _VEC3
			case 0x8b55: case 0x8b59: return setValueV4i; // _VEC4

			case 0x1405: return setValueV1ui; // UINT
			case 0x8dc6: return setValueV2ui; // _VEC2
			case 0x8dc7: return setValueV3ui; // _VEC3
			case 0x8dc8: return setValueV4ui; // _VEC4

			case 0x8b5e: // SAMPLER_2D
			case 0x8d66: // SAMPLER_EXTERNAL_OES
			case 0x8dca: // INT_SAMPLER_2D
			case 0x8dd2: // UNSIGNED_INT_SAMPLER_2D
			case 0x8b62: // SAMPLER_2D_SHADOW
				return setValueT1;

			case 0x8b5f: // SAMPLER_3D
			case 0x8dcb: // INT_SAMPLER_3D
			case 0x8dd3: // UNSIGNED_INT_SAMPLER_3D
				return setValueT3D1;

			case 0x8b60: // SAMPLER_CUBE
			case 0x8dcc: // INT_SAMPLER_CUBE
			case 0x8dd4: // UNSIGNED_INT_SAMPLER_CUBE
			case 0x8dc5: // SAMPLER_CUBE_SHADOW
				return setValueT6;

			case 0x8dc1: // SAMPLER_2D_ARRAY
			case 0x8dcf: // INT_SAMPLER_2D_ARRAY
			case 0x8dd7: // UNSIGNED_INT_SAMPLER_2D_ARRAY
			case 0x8dc4: // SAMPLER_2D_ARRAY_SHADOW
				return setValueT2DArray1;

		}

	}


	// Array of scalars

	function setValueV1fArray( gl, v ) {

		gl.uniform1fv( this.addr, v );

	}

	// Array of vectors (from flat array or array of THREE.VectorN)

	function setValueV2fArray( gl, v ) {

		const data = flatten( v, this.size, 2 );

		gl.uniform2fv( this.addr, data );

	}

	function setValueV3fArray( gl, v ) {

		const data = flatten( v, this.size, 3 );

		gl.uniform3fv( this.addr, data );

	}

	function setValueV4fArray( gl, v ) {

		const data = flatten( v, this.size, 4 );

		gl.uniform4fv( this.addr, data );

	}

	// Array of matrices (from flat array or array of THREE.MatrixN)

	function setValueM2Array( gl, v ) {

		const data = flatten( v, this.size, 4 );

		gl.uniformMatrix2fv( this.addr, false, data );

	}

	function setValueM3Array( gl, v ) {

		const data = flatten( v, this.size, 9 );

		gl.uniformMatrix3fv( this.addr, false, data );

	}

	function setValueM4Array( gl, v ) {

		const data = flatten( v, this.size, 16 );

		gl.uniformMatrix4fv( this.addr, false, data );

	}

	// Array of integer / boolean

	function setValueV1iArray( gl, v ) {

		gl.uniform1iv( this.addr, v );

	}

	// Array of integer / boolean vectors (from flat array)

	function setValueV2iArray( gl, v ) {

		gl.uniform2iv( this.addr, v );

	}

	function setValueV3iArray( gl, v ) {

		gl.uniform3iv( this.addr, v );

	}

	function setValueV4iArray( gl, v ) {

		gl.uniform4iv( this.addr, v );

	}

	// Array of unsigned integer

	function setValueV1uiArray( gl, v ) {

		gl.uniform1uiv( this.addr, v );

	}

	// Array of unsigned integer vectors (from flat array)

	function setValueV2uiArray( gl, v ) {

		gl.uniform2uiv( this.addr, v );

	}

	function setValueV3uiArray( gl, v ) {

		gl.uniform3uiv( this.addr, v );

	}

	function setValueV4uiArray( gl, v ) {

		gl.uniform4uiv( this.addr, v );

	}


	// Array of textures (2D / 3D / Cube / 2DArray)

	function setValueT1Array( gl, v, textures ) {

		const cache = this.cache;

		const n = v.length;

		const units = allocTexUnits( textures, n );

		if ( ! arraysEqual( cache, units ) ) {

			gl.uniform1iv( this.addr, units );

			copyArray( cache, units );

		}

		for ( let i = 0; i !== n; ++ i ) {

			textures.setTexture2D( v[ i ] || emptyTexture, units[ i ] );

		}

	}

	function setValueT3DArray( gl, v, textures ) {

		const cache = this.cache;

		const n = v.length;

		const units = allocTexUnits( textures, n );

		if ( ! arraysEqual( cache, units ) ) {

			gl.uniform1iv( this.addr, units );

			copyArray( cache, units );

		}

		for ( let i = 0; i !== n; ++ i ) {

			textures.setTexture3D( v[ i ] || empty3dTexture, units[ i ] );

		}

	}

	function setValueT6Array( gl, v, textures ) {

		const cache = this.cache;

		const n = v.length;

		const units = allocTexUnits( textures, n );

		if ( ! arraysEqual( cache, units ) ) {

			gl.uniform1iv( this.addr, units );

			copyArray( cache, units );

		}

		for ( let i = 0; i !== n; ++ i ) {

			textures.setTextureCube( v[ i ] || emptyCubeTexture, units[ i ] );

		}

	}

	function setValueT2DArrayArray( gl, v, textures ) {

		const cache = this.cache;

		const n = v.length;

		const units = allocTexUnits( textures, n );

		if ( ! arraysEqual( cache, units ) ) {

			gl.uniform1iv( this.addr, units );

			copyArray( cache, units );

		}

		for ( let i = 0; i !== n; ++ i ) {

			textures.setTexture2DArray( v[ i ] || emptyArrayTexture, units[ i ] );

		}

	}


	// Helper to pick the right setter for a pure (bottom-level) array

	function getPureArraySetter( type ) {

		switch ( type ) {

			case 0x1406: return setValueV1fArray; // FLOAT
			case 0x8b50: return setValueV2fArray; // _VEC2
			case 0x8b51: return setValueV3fArray; // _VEC3
			case 0x8b52: return setValueV4fArray; // _VEC4

			case 0x8b5a: return setValueM2Array; // _MAT2
			case 0x8b5b: return setValueM3Array; // _MAT3
			case 0x8b5c: return setValueM4Array; // _MAT4

			case 0x1404: case 0x8b56: return setValueV1iArray; // INT, BOOL
			case 0x8b53: case 0x8b57: return setValueV2iArray; // _VEC2
			case 0x8b54: case 0x8b58: return setValueV3iArray; // _VEC3
			case 0x8b55: case 0x8b59: return setValueV4iArray; // _VEC4

			case 0x1405: return setValueV1uiArray; // UINT
			case 0x8dc6: return setValueV2uiArray; // _VEC2
			case 0x8dc7: return setValueV3uiArray; // _VEC3
			case 0x8dc8: return setValueV4uiArray; // _VEC4

			case 0x8b5e: // SAMPLER_2D
			case 0x8d66: // SAMPLER_EXTERNAL_OES
			case 0x8dca: // INT_SAMPLER_2D
			case 0x8dd2: // UNSIGNED_INT_SAMPLER_2D
			case 0x8b62: // SAMPLER_2D_SHADOW
				return setValueT1Array;

			case 0x8b5f: // SAMPLER_3D
			case 0x8dcb: // INT_SAMPLER_3D
			case 0x8dd3: // UNSIGNED_INT_SAMPLER_3D
				return setValueT3DArray;

			case 0x8b60: // SAMPLER_CUBE
			case 0x8dcc: // INT_SAMPLER_CUBE
			case 0x8dd4: // UNSIGNED_INT_SAMPLER_CUBE
			case 0x8dc5: // SAMPLER_CUBE_SHADOW
				return setValueT6Array;

			case 0x8dc1: // SAMPLER_2D_ARRAY
			case 0x8dcf: // INT_SAMPLER_2D_ARRAY
			case 0x8dd7: // UNSIGNED_INT_SAMPLER_2D_ARRAY
			case 0x8dc4: // SAMPLER_2D_ARRAY_SHADOW
				return setValueT2DArrayArray;

		}

	}

	// --- Uniform Classes ---

	class SingleUniform {

		constructor( id, activeInfo, addr ) {

			this.id = id;
			this.addr = addr;
			this.cache = [];
			this.type = activeInfo.type;
			this.setValue = getSingularSetter( activeInfo.type );

			// this.path = activeInfo.name; // DEBUG

		}

	}

	class PureArrayUniform {

		constructor( id, activeInfo, addr ) {

			this.id = id;
			this.addr = addr;
			this.cache = [];
			this.type = activeInfo.type;
			this.size = activeInfo.size;
			this.setValue = getPureArraySetter( activeInfo.type );

			// this.path = activeInfo.name; // DEBUG

		}

	}

	class StructuredUniform {

		constructor( id ) {

			this.id = id;

			this.seq = [];
			this.map = {};

		}

		setValue( gl, value, textures ) {

			const seq = this.seq;

			for ( let i = 0, n = seq.length; i !== n; ++ i ) {

				const u = seq[ i ];
				u.setValue( gl, value[ u.id ], textures );

			}

		}

	}

	// --- Top-level ---

	// Parser - builds up the property tree from the path strings

	const RePathPart = /(\w+)(\])?(\[|\.)?/g;

	// extracts
	// 	- the identifier (member name or array index)
	//  - followed by an optional right bracket (found when array index)
	//  - followed by an optional left bracket or dot (type of subscript)
	//
	// Note: These portions can be read in a non-overlapping fashion and
	// allow straightforward parsing of the hierarchy that WebGL encodes
	// in the uniform names.

	function addUniform( container, uniformObject ) {

		container.seq.push( uniformObject );
		container.map[ uniformObject.id ] = uniformObject;

	}

	function parseUniform( activeInfo, addr, container ) {

		const path = activeInfo.name,
			pathLength = path.length;

		// reset RegExp object, because of the early exit of a previous run
		RePathPart.lastIndex = 0;

		while ( true ) {

			const match = RePathPart.exec( path ),
				matchEnd = RePathPart.lastIndex;

			let id = match[ 1 ];
			const idIsIndex = match[ 2 ] === ']',
				subscript = match[ 3 ];

			if ( idIsIndex ) id = id | 0; // convert to integer

			if ( subscript === undefined || subscript === '[' && matchEnd + 2 === pathLength ) {

				// bare name or "pure" bottom-level array "[0]" suffix

				addUniform( container, subscript === undefined ?
					new SingleUniform( id, activeInfo, addr ) :
					new PureArrayUniform( id, activeInfo, addr ) );

				break;

			} else {

				// step into inner node / create it in case it doesn't exist

				const map = container.map;
				let next = map[ id ];

				if ( next === undefined ) {

					next = new StructuredUniform( id );
					addUniform( container, next );

				}

				container = next;

			}

		}

	}

	// Root Container

	class WebGLUniforms {

		constructor( gl, program ) {

			this.seq = [];
			this.map = {};

			const n = gl.getProgramParameter( program, gl.ACTIVE_UNIFORMS );

			for ( let i = 0; i < n; ++ i ) {

				const info = gl.getActiveUniform( program, i ),
					addr = gl.getUniformLocation( program, info.name );

				parseUniform( info, addr, this );

			}

		}

		setValue( gl, name, value, textures ) {

			const u = this.map[ name ];

			if ( u !== undefined ) u.setValue( gl, value, textures );

		}

		setOptional( gl, object, name ) {

			const v = object[ name ];

			if ( v !== undefined ) this.setValue( gl, name, v );

		}

		static upload( gl, seq, values, textures ) {

			for ( let i = 0, n = seq.length; i !== n; ++ i ) {

				const u = seq[ i ],
					v = values[ u.id ];

				if ( v.needsUpdate !== false ) {

					// note: always updating when .needsUpdate is undefined
					u.setValue( gl, v.value, textures );

				}

			}

		}

		static seqWithValue( seq, values ) {

			const r = [];

			for ( let i = 0, n = seq.length; i !== n; ++ i ) {

				const u = seq[ i ];
				if ( u.id in values ) r.push( u );

			}

			return r;

		}

	}

	function WebGLShader( gl, type, string ) {

		const shader = gl.createShader( type );

		gl.shaderSource( shader, string );
		gl.compileShader( shader );

		return shader;

	}

	// From https://www.khronos.org/registry/webgl/extensions/KHR_parallel_shader_compile/
	const COMPLETION_STATUS_KHR = 0x91B1;

	let programIdCount = 0;

	function handleSource( string, errorLine ) {

		const lines = string.split( '\n' );
		const lines2 = [];

		const from = Math.max( errorLine - 6, 0 );
		const to = Math.min( errorLine + 6, lines.length );

		for ( let i = from; i < to; i ++ ) {

			const line = i + 1;
			lines2.push( `${line === errorLine ? '>' : ' '} ${line}: ${lines[ i ]}` );

		}

		return lines2.join( '\n' );

	}

	const _m0 = /*@__PURE__*/ new Matrix3();

	function getEncodingComponents( colorSpace ) {

		ColorManagement._getMatrix( _m0, ColorManagement.workingColorSpace, colorSpace );

		const encodingMatrix = `mat3( ${ _m0.elements.map( ( v ) => v.toFixed( 4 ) ) } )`;

		switch ( ColorManagement.getTransfer( colorSpace ) ) {

			case LinearTransfer:
				return [ encodingMatrix, 'LinearTransferOETF' ];

			case SRGBTransfer:
				return [ encodingMatrix, 'sRGBTransferOETF' ];

			default:
				console.warn( 'THREE.WebGLProgram: Unsupported color space: ', colorSpace );
				return [ encodingMatrix, 'LinearTransferOETF' ];

		}

	}

	function getShaderErrors( gl, shader, type ) {

		const status = gl.getShaderParameter( shader, gl.COMPILE_STATUS );
		const errors = gl.getShaderInfoLog( shader ).trim();

		if ( status && errors === '' ) return '';

		const errorMatches = /ERROR: 0:(\d+)/.exec( errors );
		if ( errorMatches ) {

			// --enable-privileged-webgl-extension
			// console.log( '**' + type + '**', gl.getExtension( 'WEBGL_debug_shaders' ).getTranslatedShaderSource( shader ) );

			const errorLine = parseInt( errorMatches[ 1 ] );
			return type.toUpperCase() + '\n\n' + errors + '\n\n' + handleSource( gl.getShaderSource( shader ), errorLine );

		} else {

			return errors;

		}

	}

	function getTexelEncodingFunction( functionName, colorSpace ) {

		const components = getEncodingComponents( colorSpace );

		return [

			`vec4 ${functionName}( vec4 value ) {`,

			`	return ${components[ 1 ]}( vec4( value.rgb * ${components[ 0 ]}, value.a ) );`,

			'}',

		].join( '\n' );

	}

	function getToneMappingFunction( functionName, toneMapping ) {

		let toneMappingName;

		switch ( toneMapping ) {

			case LinearToneMapping:
				toneMappingName = 'Linear';
				break;

			case ReinhardToneMapping:
				toneMappingName = 'Reinhard';
				break;

			case CineonToneMapping:
				toneMappingName = 'Cineon';
				break;

			case ACESFilmicToneMapping:
				toneMappingName = 'ACESFilmic';
				break;

			case AgXToneMapping:
				toneMappingName = 'AgX';
				break;

			case NeutralToneMapping:
				toneMappingName = 'Neutral';
				break;

			case CustomToneMapping:
				toneMappingName = 'Custom';
				break;

			default:
				console.warn( 'THREE.WebGLProgram: Unsupported toneMapping:', toneMapping );
				toneMappingName = 'Linear';

		}

		return 'vec3 ' + functionName + '( vec3 color ) { return ' + toneMappingName + 'ToneMapping( color ); }';

	}

	const _v0 = /*@__PURE__*/ new Vector3();

	function getLuminanceFunction() {

		ColorManagement.getLuminanceCoefficients( _v0 );

		const r = _v0.x.toFixed( 4 );
		const g = _v0.y.toFixed( 4 );
		const b = _v0.z.toFixed( 4 );

		return [

			'float luminance( const in vec3 rgb ) {',

			`	const vec3 weights = vec3( ${ r }, ${ g }, ${ b } );`,

			'	return dot( weights, rgb );',

			'}'

		].join( '\n' );

	}

	function generateVertexExtensions( parameters ) {

		const chunks = [
			parameters.extensionClipCullDistance ? '#extension GL_ANGLE_clip_cull_distance : require' : '',
			parameters.extensionMultiDraw ? '#extension GL_ANGLE_multi_draw : require' : '',
		];

		return chunks.filter( filterEmptyLine ).join( '\n' );

	}

	function generateDefines( defines ) {

		const chunks = [];

		for ( const name in defines ) {

			const value = defines[ name ];

			if ( value === false ) continue;

			chunks.push( '#define ' + name + ' ' + value );

		}

		return chunks.join( '\n' );

	}

	function fetchAttributeLocations( gl, program ) {

		const attributes = {};

		const n = gl.getProgramParameter( program, gl.ACTIVE_ATTRIBUTES );

		for ( let i = 0; i < n; i ++ ) {

			const info = gl.getActiveAttrib( program, i );
			const name = info.name;

			let locationSize = 1;
			if ( info.type === gl.FLOAT_MAT2 ) locationSize = 2;
			if ( info.type === gl.FLOAT_MAT3 ) locationSize = 3;
			if ( info.type === gl.FLOAT_MAT4 ) locationSize = 4;

			// console.log( 'THREE.WebGLProgram: ACTIVE VERTEX ATTRIBUTE:', name, i );

			attributes[ name ] = {
				type: info.type,
				location: gl.getAttribLocation( program, name ),
				locationSize: locationSize
			};

		}

		return attributes;

	}

	function filterEmptyLine( string ) {

		return string !== '';

	}

	function replaceLightNums( string, parameters ) {

		const numSpotLightCoords = parameters.numSpotLightShadows + parameters.numSpotLightMaps - parameters.numSpotLightShadowsWithMaps;

		return string
			.replace( /NUM_DIR_LIGHTS/g, parameters.numDirLights )
			.replace( /NUM_SPOT_LIGHTS/g, parameters.numSpotLights )
			.replace( /NUM_SPOT_LIGHT_MAPS/g, parameters.numSpotLightMaps )
			.replace( /NUM_SPOT_LIGHT_COORDS/g, numSpotLightCoords )
			.replace( /NUM_RECT_AREA_LIGHTS/g, parameters.numRectAreaLights )
			.replace( /NUM_POINT_LIGHTS/g, parameters.numPointLights )
			.replace( /NUM_HEMI_LIGHTS/g, parameters.numHemiLights )
			.replace( /NUM_DIR_LIGHT_SHADOWS/g, parameters.numDirLightShadows )
			.replace( /NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS/g, parameters.numSpotLightShadowsWithMaps )
			.replace( /NUM_SPOT_LIGHT_SHADOWS/g, parameters.numSpotLightShadows )
			.replace( /NUM_POINT_LIGHT_SHADOWS/g, parameters.numPointLightShadows );

	}

	function replaceClippingPlaneNums( string, parameters ) {

		return string
			.replace( /NUM_CLIPPING_PLANES/g, parameters.numClippingPlanes )
			.replace( /UNION_CLIPPING_PLANES/g, ( parameters.numClippingPlanes - parameters.numClipIntersection ) );

	}

	// Resolve Includes

	const includePattern = /^[ \t]*#include +<([\w\d./]+)>/gm;

	function resolveIncludes( string ) {

		return string.replace( includePattern, includeReplacer );

	}

	const shaderChunkMap = new Map();

	function includeReplacer( match, include ) {

		let string = ShaderChunk[ include ];

		if ( string === undefined ) {

			const newInclude = shaderChunkMap.get( include );

			if ( newInclude !== undefined ) {

				string = ShaderChunk[ newInclude ];
				console.warn( 'THREE.WebGLRenderer: Shader chunk "%s" has been deprecated. Use "%s" instead.', include, newInclude );

			} else {

				throw new Error( 'Can not resolve #include <' + include + '>' );

			}

		}

		return resolveIncludes( string );

	}

	// Unroll Loops

	const unrollLoopPattern = /#pragma unroll_loop_start\s+for\s*\(\s*int\s+i\s*=\s*(\d+)\s*;\s*i\s*<\s*(\d+)\s*;\s*i\s*\+\+\s*\)\s*{([\s\S]+?)}\s+#pragma unroll_loop_end/g;

	function unrollLoops( string ) {

		return string.replace( unrollLoopPattern, loopReplacer );

	}

	function loopReplacer( match, start, end, snippet ) {

		let string = '';

		for ( let i = parseInt( start ); i < parseInt( end ); i ++ ) {

			string += snippet
				.replace( /\[\s*i\s*\]/g, '[ ' + i + ' ]' )
				.replace( /UNROLLED_LOOP_INDEX/g, i );

		}

		return string;

	}

	//

	function generatePrecision( parameters ) {

		let precisionstring = `precision ${parameters.precision} float;
	precision ${parameters.precision} int;
	precision ${parameters.precision} sampler2D;
	precision ${parameters.precision} samplerCube;
	precision ${parameters.precision} sampler3D;
	precision ${parameters.precision} sampler2DArray;
	precision ${parameters.precision} sampler2DShadow;
	precision ${parameters.precision} samplerCubeShadow;
	precision ${parameters.precision} sampler2DArrayShadow;
	precision ${parameters.precision} isampler2D;
	precision ${parameters.precision} isampler3D;
	precision ${parameters.precision} isamplerCube;
	precision ${parameters.precision} isampler2DArray;
	precision ${parameters.precision} usampler2D;
	precision ${parameters.precision} usampler3D;
	precision ${parameters.precision} usamplerCube;
	precision ${parameters.precision} usampler2DArray;
	`;

		if ( parameters.precision === 'highp' ) {

			precisionstring += '\n#define HIGH_PRECISION';

		} else if ( parameters.precision === 'mediump' ) {

			precisionstring += '\n#define MEDIUM_PRECISION';

		} else if ( parameters.precision === 'lowp' ) {

			precisionstring += '\n#define LOW_PRECISION';

		}

		return precisionstring;

	}

	function generateShadowMapTypeDefine( parameters ) {

		let shadowMapTypeDefine = 'SHADOWMAP_TYPE_BASIC';

		if ( parameters.shadowMapType === PCFShadowMap ) {

			shadowMapTypeDefine = 'SHADOWMAP_TYPE_PCF';

		} else if ( parameters.shadowMapType === PCFSoftShadowMap ) {

			shadowMapTypeDefine = 'SHADOWMAP_TYPE_PCF_SOFT';

		} else if ( parameters.shadowMapType === VSMShadowMap ) {

			shadowMapTypeDefine = 'SHADOWMAP_TYPE_VSM';

		}

		return shadowMapTypeDefine;

	}

	function generateEnvMapTypeDefine( parameters ) {

		let envMapTypeDefine = 'ENVMAP_TYPE_CUBE';

		if ( parameters.envMap ) {

			switch ( parameters.envMapMode ) {

				case CubeReflectionMapping:
				case CubeRefractionMapping:
					envMapTypeDefine = 'ENVMAP_TYPE_CUBE';
					break;

				case CubeUVReflectionMapping:
					envMapTypeDefine = 'ENVMAP_TYPE_CUBE_UV';
					break;

			}

		}

		return envMapTypeDefine;

	}

	function generateEnvMapModeDefine( parameters ) {

		let envMapModeDefine = 'ENVMAP_MODE_REFLECTION';

		if ( parameters.envMap ) {

			switch ( parameters.envMapMode ) {

				case CubeRefractionMapping:

					envMapModeDefine = 'ENVMAP_MODE_REFRACTION';
					break;

			}

		}

		return envMapModeDefine;

	}

	function generateEnvMapBlendingDefine( parameters ) {

		let envMapBlendingDefine = 'ENVMAP_BLENDING_NONE';

		if ( parameters.envMap ) {

			switch ( parameters.combine ) {

				case MultiplyOperation:
					envMapBlendingDefine = 'ENVMAP_BLENDING_MULTIPLY';
					break;

				case MixOperation:
					envMapBlendingDefine = 'ENVMAP_BLENDING_MIX';
					break;

				case AddOperation:
					envMapBlendingDefine = 'ENVMAP_BLENDING_ADD';
					break;

			}

		}

		return envMapBlendingDefine;

	}

	function generateCubeUVSize( parameters ) {

		const imageHeight = parameters.envMapCubeUVHeight;

		if ( imageHeight === null ) return null;

		const maxMip = Math.log2( imageHeight ) - 2;

		const texelHeight = 1.0 / imageHeight;

		const texelWidth = 1.0 / ( 3 * Math.max( Math.pow( 2, maxMip ), 7 * 16 ) );

		return { texelWidth, texelHeight, maxMip };

	}

	function WebGLProgram( renderer, cacheKey, parameters, bindingStates ) {

		// TODO Send this event to Three.js DevTools
		// console.log( 'WebGLProgram', cacheKey );

		const gl = renderer.getContext();

		const defines = parameters.defines;

		let vertexShader = parameters.vertexShader;
		let fragmentShader = parameters.fragmentShader;

		const shadowMapTypeDefine = generateShadowMapTypeDefine( parameters );
		const envMapTypeDefine = generateEnvMapTypeDefine( parameters );
		const envMapModeDefine = generateEnvMapModeDefine( parameters );
		const envMapBlendingDefine = generateEnvMapBlendingDefine( parameters );
		const envMapCubeUVSize = generateCubeUVSize( parameters );

		const customVertexExtensions = generateVertexExtensions( parameters );

		const customDefines = generateDefines( defines );

		const program = gl.createProgram();

		let prefixVertex, prefixFragment;
		let versionString = parameters.glslVersion ? '#version ' + parameters.glslVersion + '\n' : '';

		if ( parameters.isRawShaderMaterial ) {

			prefixVertex = [

				'#define SHADER_TYPE ' + parameters.shaderType,
				'#define SHADER_NAME ' + parameters.shaderName,

				customDefines

			].filter( filterEmptyLine ).join( '\n' );

			if ( prefixVertex.length > 0 ) {

				prefixVertex += '\n';

			}

			prefixFragment = [

				'#define SHADER_TYPE ' + parameters.shaderType,
				'#define SHADER_NAME ' + parameters.shaderName,

				customDefines

			].filter( filterEmptyLine ).join( '\n' );

			if ( prefixFragment.length > 0 ) {

				prefixFragment += '\n';

			}

		} else {

			prefixVertex = [

				generatePrecision( parameters ),

				'#define SHADER_TYPE ' + parameters.shaderType,
				'#define SHADER_NAME ' + parameters.shaderName,

				customDefines,

				parameters.extensionClipCullDistance ? '#define USE_CLIP_DISTANCE' : '',
				parameters.batching ? '#define USE_BATCHING' : '',
				parameters.batchingColor ? '#define USE_BATCHING_COLOR' : '',
				parameters.instancing ? '#define USE_INSTANCING' : '',
				parameters.instancingColor ? '#define USE_INSTANCING_COLOR' : '',
				parameters.instancingMorph ? '#define USE_INSTANCING_MORPH' : '',

				parameters.useFog && parameters.fog ? '#define USE_FOG' : '',
				parameters.useFog && parameters.fogExp2 ? '#define FOG_EXP2' : '',

				parameters.map ? '#define USE_MAP' : '',
				parameters.envMap ? '#define USE_ENVMAP' : '',
				parameters.envMap ? '#define ' + envMapModeDefine : '',
				parameters.lightMap ? '#define USE_LIGHTMAP' : '',
				parameters.aoMap ? '#define USE_AOMAP' : '',
				parameters.bumpMap ? '#define USE_BUMPMAP' : '',
				parameters.normalMap ? '#define USE_NORMALMAP' : '',
				parameters.normalMapObjectSpace ? '#define USE_NORMALMAP_OBJECTSPACE' : '',
				parameters.normalMapTangentSpace ? '#define USE_NORMALMAP_TANGENTSPACE' : '',
				parameters.displacementMap ? '#define USE_DISPLACEMENTMAP' : '',
				parameters.emissiveMap ? '#define USE_EMISSIVEMAP' : '',

				parameters.anisotropy ? '#define USE_ANISOTROPY' : '',
				parameters.anisotropyMap ? '#define USE_ANISOTROPYMAP' : '',

				parameters.clearcoatMap ? '#define USE_CLEARCOATMAP' : '',
				parameters.clearcoatRoughnessMap ? '#define USE_CLEARCOAT_ROUGHNESSMAP' : '',
				parameters.clearcoatNormalMap ? '#define USE_CLEARCOAT_NORMALMAP' : '',

				parameters.iridescenceMap ? '#define USE_IRIDESCENCEMAP' : '',
				parameters.iridescenceThicknessMap ? '#define USE_IRIDESCENCE_THICKNESSMAP' : '',

				parameters.specularMap ? '#define USE_SPECULARMAP' : '',
				parameters.specularColorMap ? '#define USE_SPECULAR_COLORMAP' : '',
				parameters.specularIntensityMap ? '#define USE_SPECULAR_INTENSITYMAP' : '',

				parameters.roughnessMap ? '#define USE_ROUGHNESSMAP' : '',
				parameters.metalnessMap ? '#define USE_METALNESSMAP' : '',
				parameters.alphaMap ? '#define USE_ALPHAMAP' : '',
				parameters.alphaHash ? '#define USE_ALPHAHASH' : '',

				parameters.transmission ? '#define USE_TRANSMISSION' : '',
				parameters.transmissionMap ? '#define USE_TRANSMISSIONMAP' : '',
				parameters.thicknessMap ? '#define USE_THICKNESSMAP' : '',

				parameters.sheenColorMap ? '#define USE_SHEEN_COLORMAP' : '',
				parameters.sheenRoughnessMap ? '#define USE_SHEEN_ROUGHNESSMAP' : '',

				//

				parameters.mapUv ? '#define MAP_UV ' + parameters.mapUv : '',
				parameters.alphaMapUv ? '#define ALPHAMAP_UV ' + parameters.alphaMapUv : '',
				parameters.lightMapUv ? '#define LIGHTMAP_UV ' + parameters.lightMapUv : '',
				parameters.aoMapUv ? '#define AOMAP_UV ' + parameters.aoMapUv : '',
				parameters.emissiveMapUv ? '#define EMISSIVEMAP_UV ' + parameters.emissiveMapUv : '',
				parameters.bumpMapUv ? '#define BUMPMAP_UV ' + parameters.bumpMapUv : '',
				parameters.normalMapUv ? '#define NORMALMAP_UV ' + parameters.normalMapUv : '',
				parameters.displacementMapUv ? '#define DISPLACEMENTMAP_UV ' + parameters.displacementMapUv : '',

				parameters.metalnessMapUv ? '#define METALNESSMAP_UV ' + parameters.metalnessMapUv : '',
				parameters.roughnessMapUv ? '#define ROUGHNESSMAP_UV ' + parameters.roughnessMapUv : '',

				parameters.anisotropyMapUv ? '#define ANISOTROPYMAP_UV ' + parameters.anisotropyMapUv : '',

				parameters.clearcoatMapUv ? '#define CLEARCOATMAP_UV ' + parameters.clearcoatMapUv : '',
				parameters.clearcoatNormalMapUv ? '#define CLEARCOAT_NORMALMAP_UV ' + parameters.clearcoatNormalMapUv : '',
				parameters.clearcoatRoughnessMapUv ? '#define CLEARCOAT_ROUGHNESSMAP_UV ' + parameters.clearcoatRoughnessMapUv : '',

				parameters.iridescenceMapUv ? '#define IRIDESCENCEMAP_UV ' + parameters.iridescenceMapUv : '',
				parameters.iridescenceThicknessMapUv ? '#define IRIDESCENCE_THICKNESSMAP_UV ' + parameters.iridescenceThicknessMapUv : '',

				parameters.sheenColorMapUv ? '#define SHEEN_COLORMAP_UV ' + parameters.sheenColorMapUv : '',
				parameters.sheenRoughnessMapUv ? '#define SHEEN_ROUGHNESSMAP_UV ' + parameters.sheenRoughnessMapUv : '',

				parameters.specularMapUv ? '#define SPECULARMAP_UV ' + parameters.specularMapUv : '',
				parameters.specularColorMapUv ? '#define SPECULAR_COLORMAP_UV ' + parameters.specularColorMapUv : '',
				parameters.specularIntensityMapUv ? '#define SPECULAR_INTENSITYMAP_UV ' + parameters.specularIntensityMapUv : '',

				parameters.transmissionMapUv ? '#define TRANSMISSIONMAP_UV ' + parameters.transmissionMapUv : '',
				parameters.thicknessMapUv ? '#define THICKNESSMAP_UV ' + parameters.thicknessMapUv : '',

				//

				parameters.vertexTangents && parameters.flatShading === false ? '#define USE_TANGENT' : '',
				parameters.vertexColors ? '#define USE_COLOR' : '',
				parameters.vertexAlphas ? '#define USE_COLOR_ALPHA' : '',
				parameters.vertexUv1s ? '#define USE_UV1' : '',
				parameters.vertexUv2s ? '#define USE_UV2' : '',
				parameters.vertexUv3s ? '#define USE_UV3' : '',

				parameters.pointsUvs ? '#define USE_POINTS_UV' : '',

				parameters.flatShading ? '#define FLAT_SHADED' : '',

				parameters.skinning ? '#define USE_SKINNING' : '',

				parameters.morphTargets ? '#define USE_MORPHTARGETS' : '',
				parameters.morphNormals && parameters.flatShading === false ? '#define USE_MORPHNORMALS' : '',
				( parameters.morphColors ) ? '#define USE_MORPHCOLORS' : '',
				( parameters.morphTargetsCount > 0 ) ? '#define MORPHTARGETS_TEXTURE_STRIDE ' + parameters.morphTextureStride : '',
				( parameters.morphTargetsCount > 0 ) ? '#define MORPHTARGETS_COUNT ' + parameters.morphTargetsCount : '',
				parameters.doubleSided ? '#define DOUBLE_SIDED' : '',
				parameters.flipSided ? '#define FLIP_SIDED' : '',

				parameters.shadowMapEnabled ? '#define USE_SHADOWMAP' : '',
				parameters.shadowMapEnabled ? '#define ' + shadowMapTypeDefine : '',

				parameters.sizeAttenuation ? '#define USE_SIZEATTENUATION' : '',

				parameters.numLightProbes > 0 ? '#define USE_LIGHT_PROBES' : '',

				parameters.logarithmicDepthBuffer ? '#define USE_LOGDEPTHBUF' : '',
				parameters.reverseDepthBuffer ? '#define USE_REVERSEDEPTHBUF' : '',

				'uniform mat4 modelMatrix;',
				'uniform mat4 modelViewMatrix;',
				'uniform mat4 projectionMatrix;',
				'uniform mat4 viewMatrix;',
				'uniform mat3 normalMatrix;',
				'uniform vec3 cameraPosition;',
				'uniform bool isOrthographic;',

				'#ifdef USE_INSTANCING',

				'	attribute mat4 instanceMatrix;',

				'#endif',

				'#ifdef USE_INSTANCING_COLOR',

				'	attribute vec3 instanceColor;',

				'#endif',

				'#ifdef USE_INSTANCING_MORPH',

				'	uniform sampler2D morphTexture;',

				'#endif',

				'attribute vec3 position;',
				'attribute vec3 normal;',
				'attribute vec2 uv;',

				'#ifdef USE_UV1',

				'	attribute vec2 uv1;',

				'#endif',

				'#ifdef USE_UV2',

				'	attribute vec2 uv2;',

				'#endif',

				'#ifdef USE_UV3',

				'	attribute vec2 uv3;',

				'#endif',

				'#ifdef USE_TANGENT',

				'	attribute vec4 tangent;',

				'#endif',

				'#if defined( USE_COLOR_ALPHA )',

				'	attribute vec4 color;',

				'#elif defined( USE_COLOR )',

				'	attribute vec3 color;',

				'#endif',

				'#ifdef USE_SKINNING',

				'	attribute vec4 skinIndex;',
				'	attribute vec4 skinWeight;',

				'#endif',

				'\n'

			].filter( filterEmptyLine ).join( '\n' );

			prefixFragment = [

				generatePrecision( parameters ),

				'#define SHADER_TYPE ' + parameters.shaderType,
				'#define SHADER_NAME ' + parameters.shaderName,

				customDefines,

				parameters.useFog && parameters.fog ? '#define USE_FOG' : '',
				parameters.useFog && parameters.fogExp2 ? '#define FOG_EXP2' : '',

				parameters.alphaToCoverage ? '#define ALPHA_TO_COVERAGE' : '',
				parameters.map ? '#define USE_MAP' : '',
				parameters.matcap ? '#define USE_MATCAP' : '',
				parameters.envMap ? '#define USE_ENVMAP' : '',
				parameters.envMap ? '#define ' + envMapTypeDefine : '',
				parameters.envMap ? '#define ' + envMapModeDefine : '',
				parameters.envMap ? '#define ' + envMapBlendingDefine : '',
				envMapCubeUVSize ? '#define CUBEUV_TEXEL_WIDTH ' + envMapCubeUVSize.texelWidth : '',
				envMapCubeUVSize ? '#define CUBEUV_TEXEL_HEIGHT ' + envMapCubeUVSize.texelHeight : '',
				envMapCubeUVSize ? '#define CUBEUV_MAX_MIP ' + envMapCubeUVSize.maxMip + '.0' : '',
				parameters.lightMap ? '#define USE_LIGHTMAP' : '',
				parameters.aoMap ? '#define USE_AOMAP' : '',
				parameters.bumpMap ? '#define USE_BUMPMAP' : '',
				parameters.normalMap ? '#define USE_NORMALMAP' : '',
				parameters.normalMapObjectSpace ? '#define USE_NORMALMAP_OBJECTSPACE' : '',
				parameters.normalMapTangentSpace ? '#define USE_NORMALMAP_TANGENTSPACE' : '',
				parameters.emissiveMap ? '#define USE_EMISSIVEMAP' : '',

				parameters.anisotropy ? '#define USE_ANISOTROPY' : '',
				parameters.anisotropyMap ? '#define USE_ANISOTROPYMAP' : '',

				parameters.clearcoat ? '#define USE_CLEARCOAT' : '',
				parameters.clearcoatMap ? '#define USE_CLEARCOATMAP' : '',
				parameters.clearcoatRoughnessMap ? '#define USE_CLEARCOAT_ROUGHNESSMAP' : '',
				parameters.clearcoatNormalMap ? '#define USE_CLEARCOAT_NORMALMAP' : '',

				parameters.dispersion ? '#define USE_DISPERSION' : '',

				parameters.iridescence ? '#define USE_IRIDESCENCE' : '',
				parameters.iridescenceMap ? '#define USE_IRIDESCENCEMAP' : '',
				parameters.iridescenceThicknessMap ? '#define USE_IRIDESCENCE_THICKNESSMAP' : '',

				parameters.specularMap ? '#define USE_SPECULARMAP' : '',
				parameters.specularColorMap ? '#define USE_SPECULAR_COLORMAP' : '',
				parameters.specularIntensityMap ? '#define USE_SPECULAR_INTENSITYMAP' : '',

				parameters.roughnessMap ? '#define USE_ROUGHNESSMAP' : '',
				parameters.metalnessMap ? '#define USE_METALNESSMAP' : '',

				parameters.alphaMap ? '#define USE_ALPHAMAP' : '',
				parameters.alphaTest ? '#define USE_ALPHATEST' : '',
				parameters.alphaHash ? '#define USE_ALPHAHASH' : '',

				parameters.sheen ? '#define USE_SHEEN' : '',
				parameters.sheenColorMap ? '#define USE_SHEEN_COLORMAP' : '',
				parameters.sheenRoughnessMap ? '#define USE_SHEEN_ROUGHNESSMAP' : '',

				parameters.transmission ? '#define USE_TRANSMISSION' : '',
				parameters.transmissionMap ? '#define USE_TRANSMISSIONMAP' : '',
				parameters.thicknessMap ? '#define USE_THICKNESSMAP' : '',

				parameters.vertexTangents && parameters.flatShading === false ? '#define USE_TANGENT' : '',
				parameters.vertexColors || parameters.instancingColor || parameters.batchingColor ? '#define USE_COLOR' : '',
				parameters.vertexAlphas ? '#define USE_COLOR_ALPHA' : '',
				parameters.vertexUv1s ? '#define USE_UV1' : '',
				parameters.vertexUv2s ? '#define USE_UV2' : '',
				parameters.vertexUv3s ? '#define USE_UV3' : '',

				parameters.pointsUvs ? '#define USE_POINTS_UV' : '',

				parameters.gradientMap ? '#define USE_GRADIENTMAP' : '',

				parameters.flatShading ? '#define FLAT_SHADED' : '',

				parameters.doubleSided ? '#define DOUBLE_SIDED' : '',
				parameters.flipSided ? '#define FLIP_SIDED' : '',

				parameters.shadowMapEnabled ? '#define USE_SHADOWMAP' : '',
				parameters.shadowMapEnabled ? '#define ' + shadowMapTypeDefine : '',

				parameters.premultipliedAlpha ? '#define PREMULTIPLIED_ALPHA' : '',

				parameters.numLightProbes > 0 ? '#define USE_LIGHT_PROBES' : '',

				parameters.decodeVideoTexture ? '#define DECODE_VIDEO_TEXTURE' : '',
				parameters.decodeVideoTextureEmissive ? '#define DECODE_VIDEO_TEXTURE_EMISSIVE' : '',

				parameters.logarithmicDepthBuffer ? '#define USE_LOGDEPTHBUF' : '',
				parameters.reverseDepthBuffer ? '#define USE_REVERSEDEPTHBUF' : '',

				'uniform mat4 viewMatrix;',
				'uniform vec3 cameraPosition;',
				'uniform bool isOrthographic;',

				( parameters.toneMapping !== NoToneMapping ) ? '#define TONE_MAPPING' : '',
				( parameters.toneMapping !== NoToneMapping ) ? ShaderChunk[ 'tonemapping_pars_fragment' ] : '', // this code is required here because it is used by the toneMapping() function defined below
				( parameters.toneMapping !== NoToneMapping ) ? getToneMappingFunction( 'toneMapping', parameters.toneMapping ) : '',

				parameters.dithering ? '#define DITHERING' : '',
				parameters.opaque ? '#define OPAQUE' : '',

				ShaderChunk[ 'colorspace_pars_fragment' ], // this code is required here because it is used by the various encoding/decoding function defined below
				getTexelEncodingFunction( 'linearToOutputTexel', parameters.outputColorSpace ),
				getLuminanceFunction(),

				parameters.useDepthPacking ? '#define DEPTH_PACKING ' + parameters.depthPacking : '',

				'\n'

			].filter( filterEmptyLine ).join( '\n' );

		}

		vertexShader = resolveIncludes( vertexShader );
		vertexShader = replaceLightNums( vertexShader, parameters );
		vertexShader = replaceClippingPlaneNums( vertexShader, parameters );

		fragmentShader = resolveIncludes( fragmentShader );
		fragmentShader = replaceLightNums( fragmentShader, parameters );
		fragmentShader = replaceClippingPlaneNums( fragmentShader, parameters );

		vertexShader = unrollLoops( vertexShader );
		fragmentShader = unrollLoops( fragmentShader );

		if ( parameters.isRawShaderMaterial !== true ) {

			// GLSL 3.0 conversion for built-in materials and ShaderMaterial

			versionString = '#version 300 es\n';

			prefixVertex = [
				customVertexExtensions,
				'#define attribute in',
				'#define varying out',
				'#define texture2D texture'
			].join( '\n' ) + '\n' + prefixVertex;

			prefixFragment = [
				'#define varying in',
				( parameters.glslVersion === GLSL3 ) ? '' : 'layout(location = 0) out highp vec4 pc_fragColor;',
				( parameters.glslVersion === GLSL3 ) ? '' : '#define gl_FragColor pc_fragColor',
				'#define gl_FragDepthEXT gl_FragDepth',
				'#define texture2D texture',
				'#define textureCube texture',
				'#define texture2DProj textureProj',
				'#define texture2DLodEXT textureLod',
				'#define texture2DProjLodEXT textureProjLod',
				'#define textureCubeLodEXT textureLod',
				'#define texture2DGradEXT textureGrad',
				'#define texture2DProjGradEXT textureProjGrad',
				'#define textureCubeGradEXT textureGrad'
			].join( '\n' ) + '\n' + prefixFragment;

		}

		const vertexGlsl = versionString + prefixVertex + vertexShader;
		const fragmentGlsl = versionString + prefixFragment + fragmentShader;

		// console.log( '*VERTEX*', vertexGlsl );
		// console.log( '*FRAGMENT*', fragmentGlsl );

		const glVertexShader = WebGLShader( gl, gl.VERTEX_SHADER, vertexGlsl );
		const glFragmentShader = WebGLShader( gl, gl.FRAGMENT_SHADER, fragmentGlsl );

		gl.attachShader( program, glVertexShader );
		gl.attachShader( program, glFragmentShader );

		// Force a particular attribute to index 0.

		if ( parameters.index0AttributeName !== undefined ) {

			gl.bindAttribLocation( program, 0, parameters.index0AttributeName );

		} else if ( parameters.morphTargets === true ) {

			// programs with morphTargets displace position out of attribute 0
			gl.bindAttribLocation( program, 0, 'position' );

		}

		gl.linkProgram( program );

		function onFirstUse( self ) {

			// check for link errors
			if ( renderer.debug.checkShaderErrors ) {

				const programLog = gl.getProgramInfoLog( program ).trim();
				const vertexLog = gl.getShaderInfoLog( glVertexShader ).trim();
				const fragmentLog = gl.getShaderInfoLog( glFragmentShader ).trim();

				let runnable = true;
				let haveDiagnostics = true;

				if ( gl.getProgramParameter( program, gl.LINK_STATUS ) === false ) {

					runnable = false;

					if ( typeof renderer.debug.onShaderError === 'function' ) {

						renderer.debug.onShaderError( gl, program, glVertexShader, glFragmentShader );

					} else {

						// default error reporting

						const vertexErrors = getShaderErrors( gl, glVertexShader, 'vertex' );
						const fragmentErrors = getShaderErrors( gl, glFragmentShader, 'fragment' );

						console.error(
							'THREE.WebGLProgram: Shader Error ' + gl.getError() + ' - ' +
							'VALIDATE_STATUS ' + gl.getProgramParameter( program, gl.VALIDATE_STATUS ) + '\n\n' +
							'Material Name: ' + self.name + '\n' +
							'Material Type: ' + self.type + '\n\n' +
							'Program Info Log: ' + programLog + '\n' +
							vertexErrors + '\n' +
							fragmentErrors
						);

					}

				} else if ( programLog !== '' ) {

					console.warn( 'THREE.WebGLProgram: Program Info Log:', programLog );

				} else if ( vertexLog === '' || fragmentLog === '' ) {

					haveDiagnostics = false;

				}

				if ( haveDiagnostics ) {

					self.diagnostics = {

						runnable: runnable,

						programLog: programLog,

						vertexShader: {

							log: vertexLog,
							prefix: prefixVertex

						},

						fragmentShader: {

							log: fragmentLog,
							prefix: prefixFragment

						}

					};

				}

			}

			// Clean up

			// Crashes in iOS9 and iOS10. #18402
			// gl.detachShader( program, glVertexShader );
			// gl.detachShader( program, glFragmentShader );

			gl.deleteShader( glVertexShader );
			gl.deleteShader( glFragmentShader );

			cachedUniforms = new WebGLUniforms( gl, program );
			cachedAttributes = fetchAttributeLocations( gl, program );

		}

		// set up caching for uniform locations

		let cachedUniforms;

		this.getUniforms = function () {

			if ( cachedUniforms === undefined ) {

				// Populates cachedUniforms and cachedAttributes
				onFirstUse( this );

			}

			return cachedUniforms;

		};

		// set up caching for attribute locations

		let cachedAttributes;

		this.getAttributes = function () {

			if ( cachedAttributes === undefined ) {

				// Populates cachedAttributes and cachedUniforms
				onFirstUse( this );

			}

			return cachedAttributes;

		};

		// indicate when the program is ready to be used. if the KHR_parallel_shader_compile extension isn't supported,
		// flag the program as ready immediately. It may cause a stall when it's first used.

		let programReady = ( parameters.rendererExtensionParallelShaderCompile === false );

		this.isReady = function () {

			if ( programReady === false ) {

				programReady = gl.getProgramParameter( program, COMPLETION_STATUS_KHR );

			}

			return programReady;

		};

		// free resource

		this.destroy = function () {

			bindingStates.releaseStatesOfProgram( this );

			gl.deleteProgram( program );
			this.program = undefined;

		};

		//

		this.type = parameters.shaderType;
		this.name = parameters.shaderName;
		this.id = programIdCount ++;
		this.cacheKey = cacheKey;
		this.usedTimes = 1;
		this.program = program;
		this.vertexShader = glVertexShader;
		this.fragmentShader = glFragmentShader;

		return this;

	}

	let _id = 0;

	class WebGLShaderCache {

		constructor() {

			this.shaderCache = new Map();
			this.materialCache = new Map();

		}

		update( material ) {

			const vertexShader = material.vertexShader;
			const fragmentShader = material.fragmentShader;

			const vertexShaderStage = this._getShaderStage( vertexShader );
			const fragmentShaderStage = this._getShaderStage( fragmentShader );

			const materialShaders = this._getShaderCacheForMaterial( material );

			if ( materialShaders.has( vertexShaderStage ) === false ) {

				materialShaders.add( vertexShaderStage );
				vertexShaderStage.usedTimes ++;

			}

			if ( materialShaders.has( fragmentShaderStage ) === false ) {

				materialShaders.add( fragmentShaderStage );
				fragmentShaderStage.usedTimes ++;

			}

			return this;

		}

		remove( material ) {

			const materialShaders = this.materialCache.get( material );

			for ( const shaderStage of materialShaders ) {

				shaderStage.usedTimes --;

				if ( shaderStage.usedTimes === 0 ) this.shaderCache.delete( shaderStage.code );

			}

			this.materialCache.delete( material );

			return this;

		}

		getVertexShaderID( material ) {

			return this._getShaderStage( material.vertexShader ).id;

		}

		getFragmentShaderID( material ) {

			return this._getShaderStage( material.fragmentShader ).id;

		}

		dispose() {

			this.shaderCache.clear();
			this.materialCache.clear();

		}

		_getShaderCacheForMaterial( material ) {

			const cache = this.materialCache;
			let set = cache.get( material );

			if ( set === undefined ) {

				set = new Set();
				cache.set( material, set );

			}

			return set;

		}

		_getShaderStage( code ) {

			const cache = this.shaderCache;
			let stage = cache.get( code );

			if ( stage === undefined ) {

				stage = new WebGLShaderStage( code );
				cache.set( code, stage );

			}

			return stage;

		}

	}

	class WebGLShaderStage {

		constructor( code ) {

			this.id = _id ++;

			this.code = code;
			this.usedTimes = 0;

		}

	}

	function WebGLPrograms( renderer, cubemaps, cubeuvmaps, extensions, capabilities, bindingStates, clipping ) {

		const _programLayers = new Layers();
		const _customShaders = new WebGLShaderCache();
		const _activeChannels = new Set();
		const programs = [];

		const logarithmicDepthBuffer = capabilities.logarithmicDepthBuffer;
		const SUPPORTS_VERTEX_TEXTURES = capabilities.vertexTextures;

		let precision = capabilities.precision;

		const shaderIDs = {
			MeshDepthMaterial: 'depth',
			MeshDistanceMaterial: 'distanceRGBA',
			MeshNormalMaterial: 'normal',
			MeshBasicMaterial: 'basic',
			MeshLambertMaterial: 'lambert',
			MeshPhongMaterial: 'phong',
			MeshToonMaterial: 'toon',
			MeshStandardMaterial: 'physical',
			MeshPhysicalMaterial: 'physical',
			MeshMatcapMaterial: 'matcap',
			LineBasicMaterial: 'basic',
			LineDashedMaterial: 'dashed',
			PointsMaterial: 'points',
			ShadowMaterial: 'shadow',
			SpriteMaterial: 'sprite'
		};

		function getChannel( value ) {

			_activeChannels.add( value );

			if ( value === 0 ) return 'uv';

			return `uv${ value }`;

		}

		function getParameters( material, lights, shadows, scene, object ) {

			const fog = scene.fog;
			const geometry = object.geometry;
			const environment = material.isMeshStandardMaterial ? scene.environment : null;

			const envMap = ( material.isMeshStandardMaterial ? cubeuvmaps : cubemaps ).get( material.envMap || environment );
			const envMapCubeUVHeight = ( !! envMap ) && ( envMap.mapping === CubeUVReflectionMapping ) ? envMap.image.height : null;

			const shaderID = shaderIDs[ material.type ];

			// heuristics to create shader parameters according to lights in the scene
			// (not to blow over maxLights budget)

			if ( material.precision !== null ) {

				precision = capabilities.getMaxPrecision( material.precision );

				if ( precision !== material.precision ) {

					console.warn( 'THREE.WebGLProgram.getParameters:', material.precision, 'not supported, using', precision, 'instead.' );

				}

			}

			//

			const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;
			const morphTargetsCount = ( morphAttribute !== undefined ) ? morphAttribute.length : 0;

			let morphTextureStride = 0;

			if ( geometry.morphAttributes.position !== undefined ) morphTextureStride = 1;
			if ( geometry.morphAttributes.normal !== undefined ) morphTextureStride = 2;
			if ( geometry.morphAttributes.color !== undefined ) morphTextureStride = 3;

			//

			let vertexShader, fragmentShader;
			let customVertexShaderID, customFragmentShaderID;

			if ( shaderID ) {

				const shader = ShaderLib[ shaderID ];

				vertexShader = shader.vertexShader;
				fragmentShader = shader.fragmentShader;

			} else {

				vertexShader = material.vertexShader;
				fragmentShader = material.fragmentShader;

				_customShaders.update( material );

				customVertexShaderID = _customShaders.getVertexShaderID( material );
				customFragmentShaderID = _customShaders.getFragmentShaderID( material );

			}

			const currentRenderTarget = renderer.getRenderTarget();
			const reverseDepthBuffer = renderer.state.buffers.depth.getReversed();

			const IS_INSTANCEDMESH = object.isInstancedMesh === true;
			const IS_BATCHEDMESH = object.isBatchedMesh === true;

			const HAS_MAP = !! material.map;
			const HAS_MATCAP = !! material.matcap;
			const HAS_ENVMAP = !! envMap;
			const HAS_AOMAP = !! material.aoMap;
			const HAS_LIGHTMAP = !! material.lightMap;
			const HAS_BUMPMAP = !! material.bumpMap;
			const HAS_NORMALMAP = !! material.normalMap;
			const HAS_DISPLACEMENTMAP = !! material.displacementMap;
			const HAS_EMISSIVEMAP = !! material.emissiveMap;

			const HAS_METALNESSMAP = !! material.metalnessMap;
			const HAS_ROUGHNESSMAP = !! material.roughnessMap;

			const HAS_ANISOTROPY = material.anisotropy > 0;
			const HAS_CLEARCOAT = material.clearcoat > 0;
			const HAS_DISPERSION = material.dispersion > 0;
			const HAS_IRIDESCENCE = material.iridescence > 0;
			const HAS_SHEEN = material.sheen > 0;
			const HAS_TRANSMISSION = material.transmission > 0;

			const HAS_ANISOTROPYMAP = HAS_ANISOTROPY && !! material.anisotropyMap;

			const HAS_CLEARCOATMAP = HAS_CLEARCOAT && !! material.clearcoatMap;
			const HAS_CLEARCOAT_NORMALMAP = HAS_CLEARCOAT && !! material.clearcoatNormalMap;
			const HAS_CLEARCOAT_ROUGHNESSMAP = HAS_CLEARCOAT && !! material.clearcoatRoughnessMap;

			const HAS_IRIDESCENCEMAP = HAS_IRIDESCENCE && !! material.iridescenceMap;
			const HAS_IRIDESCENCE_THICKNESSMAP = HAS_IRIDESCENCE && !! material.iridescenceThicknessMap;

			const HAS_SHEEN_COLORMAP = HAS_SHEEN && !! material.sheenColorMap;
			const HAS_SHEEN_ROUGHNESSMAP = HAS_SHEEN && !! material.sheenRoughnessMap;

			const HAS_SPECULARMAP = !! material.specularMap;
			const HAS_SPECULAR_COLORMAP = !! material.specularColorMap;
			const HAS_SPECULAR_INTENSITYMAP = !! material.specularIntensityMap;

			const HAS_TRANSMISSIONMAP = HAS_TRANSMISSION && !! material.transmissionMap;
			const HAS_THICKNESSMAP = HAS_TRANSMISSION && !! material.thicknessMap;

			const HAS_GRADIENTMAP = !! material.gradientMap;

			const HAS_ALPHAMAP = !! material.alphaMap;

			const HAS_ALPHATEST = material.alphaTest > 0;

			const HAS_ALPHAHASH = !! material.alphaHash;

			const HAS_EXTENSIONS = !! material.extensions;

			let toneMapping = NoToneMapping;

			if ( material.toneMapped ) {

				if ( currentRenderTarget === null || currentRenderTarget.isXRRenderTarget === true ) {

					toneMapping = renderer.toneMapping;

				}

			}

			const parameters = {

				shaderID: shaderID,
				shaderType: material.type,
				shaderName: material.name,

				vertexShader: vertexShader,
				fragmentShader: fragmentShader,
				defines: material.defines,

				customVertexShaderID: customVertexShaderID,
				customFragmentShaderID: customFragmentShaderID,

				isRawShaderMaterial: material.isRawShaderMaterial === true,
				glslVersion: material.glslVersion,

				precision: precision,

				batching: IS_BATCHEDMESH,
				batchingColor: IS_BATCHEDMESH && object._colorsTexture !== null,
				instancing: IS_INSTANCEDMESH,
				instancingColor: IS_INSTANCEDMESH && object.instanceColor !== null,
				instancingMorph: IS_INSTANCEDMESH && object.morphTexture !== null,

				supportsVertexTextures: SUPPORTS_VERTEX_TEXTURES,
				outputColorSpace: ( currentRenderTarget === null ) ? renderer.outputColorSpace : ( currentRenderTarget.isXRRenderTarget === true ? currentRenderTarget.texture.colorSpace : LinearSRGBColorSpace ),
				alphaToCoverage: !! material.alphaToCoverage,

				map: HAS_MAP,
				matcap: HAS_MATCAP,
				envMap: HAS_ENVMAP,
				envMapMode: HAS_ENVMAP && envMap.mapping,
				envMapCubeUVHeight: envMapCubeUVHeight,
				aoMap: HAS_AOMAP,
				lightMap: HAS_LIGHTMAP,
				bumpMap: HAS_BUMPMAP,
				normalMap: HAS_NORMALMAP,
				displacementMap: SUPPORTS_VERTEX_TEXTURES && HAS_DISPLACEMENTMAP,
				emissiveMap: HAS_EMISSIVEMAP,

				normalMapObjectSpace: HAS_NORMALMAP && material.normalMapType === ObjectSpaceNormalMap,
				normalMapTangentSpace: HAS_NORMALMAP && material.normalMapType === TangentSpaceNormalMap,

				metalnessMap: HAS_METALNESSMAP,
				roughnessMap: HAS_ROUGHNESSMAP,

				anisotropy: HAS_ANISOTROPY,
				anisotropyMap: HAS_ANISOTROPYMAP,

				clearcoat: HAS_CLEARCOAT,
				clearcoatMap: HAS_CLEARCOATMAP,
				clearcoatNormalMap: HAS_CLEARCOAT_NORMALMAP,
				clearcoatRoughnessMap: HAS_CLEARCOAT_ROUGHNESSMAP,

				dispersion: HAS_DISPERSION,

				iridescence: HAS_IRIDESCENCE,
				iridescenceMap: HAS_IRIDESCENCEMAP,
				iridescenceThicknessMap: HAS_IRIDESCENCE_THICKNESSMAP,

				sheen: HAS_SHEEN,
				sheenColorMap: HAS_SHEEN_COLORMAP,
				sheenRoughnessMap: HAS_SHEEN_ROUGHNESSMAP,

				specularMap: HAS_SPECULARMAP,
				specularColorMap: HAS_SPECULAR_COLORMAP,
				specularIntensityMap: HAS_SPECULAR_INTENSITYMAP,

				transmission: HAS_TRANSMISSION,
				transmissionMap: HAS_TRANSMISSIONMAP,
				thicknessMap: HAS_THICKNESSMAP,

				gradientMap: HAS_GRADIENTMAP,

				opaque: material.transparent === false && material.blending === NormalBlending && material.alphaToCoverage === false,

				alphaMap: HAS_ALPHAMAP,
				alphaTest: HAS_ALPHATEST,
				alphaHash: HAS_ALPHAHASH,

				combine: material.combine,

				//

				mapUv: HAS_MAP && getChannel( material.map.channel ),
				aoMapUv: HAS_AOMAP && getChannel( material.aoMap.channel ),
				lightMapUv: HAS_LIGHTMAP && getChannel( material.lightMap.channel ),
				bumpMapUv: HAS_BUMPMAP && getChannel( material.bumpMap.channel ),
				normalMapUv: HAS_NORMALMAP && getChannel( material.normalMap.channel ),
				displacementMapUv: HAS_DISPLACEMENTMAP && getChannel( material.displacementMap.channel ),
				emissiveMapUv: HAS_EMISSIVEMAP && getChannel( material.emissiveMap.channel ),

				metalnessMapUv: HAS_METALNESSMAP && getChannel( material.metalnessMap.channel ),
				roughnessMapUv: HAS_ROUGHNESSMAP && getChannel( material.roughnessMap.channel ),

				anisotropyMapUv: HAS_ANISOTROPYMAP && getChannel( material.anisotropyMap.channel ),

				clearcoatMapUv: HAS_CLEARCOATMAP && getChannel( material.clearcoatMap.channel ),
				clearcoatNormalMapUv: HAS_CLEARCOAT_NORMALMAP && getChannel( material.clearcoatNormalMap.channel ),
				clearcoatRoughnessMapUv: HAS_CLEARCOAT_ROUGHNESSMAP && getChannel( material.clearcoatRoughnessMap.channel ),

				iridescenceMapUv: HAS_IRIDESCENCEMAP && getChannel( material.iridescenceMap.channel ),
				iridescenceThicknessMapUv: HAS_IRIDESCENCE_THICKNESSMAP && getChannel( material.iridescenceThicknessMap.channel ),

				sheenColorMapUv: HAS_SHEEN_COLORMAP && getChannel( material.sheenColorMap.channel ),
				sheenRoughnessMapUv: HAS_SHEEN_ROUGHNESSMAP && getChannel( material.sheenRoughnessMap.channel ),

				specularMapUv: HAS_SPECULARMAP && getChannel( material.specularMap.channel ),
				specularColorMapUv: HAS_SPECULAR_COLORMAP && getChannel( material.specularColorMap.channel ),
				specularIntensityMapUv: HAS_SPECULAR_INTENSITYMAP && getChannel( material.specularIntensityMap.channel ),

				transmissionMapUv: HAS_TRANSMISSIONMAP && getChannel( material.transmissionMap.channel ),
				thicknessMapUv: HAS_THICKNESSMAP && getChannel( material.thicknessMap.channel ),

				alphaMapUv: HAS_ALPHAMAP && getChannel( material.alphaMap.channel ),

				//

				vertexTangents: !! geometry.attributes.tangent && ( HAS_NORMALMAP || HAS_ANISOTROPY ),
				vertexColors: material.vertexColors,
				vertexAlphas: material.vertexColors === true && !! geometry.attributes.color && geometry.attributes.color.itemSize === 4,

				pointsUvs: object.isPoints === true && !! geometry.attributes.uv && ( HAS_MAP || HAS_ALPHAMAP ),

				fog: !! fog,
				useFog: material.fog === true,
				fogExp2: ( !! fog && fog.isFogExp2 ),

				flatShading: material.flatShading === true,

				sizeAttenuation: material.sizeAttenuation === true,
				logarithmicDepthBuffer: logarithmicDepthBuffer,
				reverseDepthBuffer: reverseDepthBuffer,

				skinning: object.isSkinnedMesh === true,

				morphTargets: geometry.morphAttributes.position !== undefined,
				morphNormals: geometry.morphAttributes.normal !== undefined,
				morphColors: geometry.morphAttributes.color !== undefined,
				morphTargetsCount: morphTargetsCount,
				morphTextureStride: morphTextureStride,

				numDirLights: lights.directional.length,
				numPointLights: lights.point.length,
				numSpotLights: lights.spot.length,
				numSpotLightMaps: lights.spotLightMap.length,
				numRectAreaLights: lights.rectArea.length,
				numHemiLights: lights.hemi.length,

				numDirLightShadows: lights.directionalShadowMap.length,
				numPointLightShadows: lights.pointShadowMap.length,
				numSpotLightShadows: lights.spotShadowMap.length,
				numSpotLightShadowsWithMaps: lights.numSpotLightShadowsWithMaps,

				numLightProbes: lights.numLightProbes,

				numClippingPlanes: clipping.numPlanes,
				numClipIntersection: clipping.numIntersection,

				dithering: material.dithering,

				shadowMapEnabled: renderer.shadowMap.enabled && shadows.length > 0,
				shadowMapType: renderer.shadowMap.type,

				toneMapping: toneMapping,

				decodeVideoTexture: HAS_MAP && ( material.map.isVideoTexture === true ) && ( ColorManagement.getTransfer( material.map.colorSpace ) === SRGBTransfer ),
				decodeVideoTextureEmissive: HAS_EMISSIVEMAP && ( material.emissiveMap.isVideoTexture === true ) && ( ColorManagement.getTransfer( material.emissiveMap.colorSpace ) === SRGBTransfer ),

				premultipliedAlpha: material.premultipliedAlpha,

				doubleSided: material.side === DoubleSide,
				flipSided: material.side === BackSide,

				useDepthPacking: material.depthPacking >= 0,
				depthPacking: material.depthPacking || 0,

				index0AttributeName: material.index0AttributeName,

				extensionClipCullDistance: HAS_EXTENSIONS && material.extensions.clipCullDistance === true && extensions.has( 'WEBGL_clip_cull_distance' ),
				extensionMultiDraw: ( HAS_EXTENSIONS && material.extensions.multiDraw === true || IS_BATCHEDMESH ) && extensions.has( 'WEBGL_multi_draw' ),

				rendererExtensionParallelShaderCompile: extensions.has( 'KHR_parallel_shader_compile' ),

				customProgramCacheKey: material.customProgramCacheKey()

			};

			// the usage of getChannel() determines the active texture channels for this shader

			parameters.vertexUv1s = _activeChannels.has( 1 );
			parameters.vertexUv2s = _activeChannels.has( 2 );
			parameters.vertexUv3s = _activeChannels.has( 3 );

			_activeChannels.clear();

			return parameters;

		}

		function getProgramCacheKey( parameters ) {

			const array = [];

			if ( parameters.shaderID ) {

				array.push( parameters.shaderID );

			} else {

				array.push( parameters.customVertexShaderID );
				array.push( parameters.customFragmentShaderID );

			}

			if ( parameters.defines !== undefined ) {

				for ( const name in parameters.defines ) {

					array.push( name );
					array.push( parameters.defines[ name ] );

				}

			}

			if ( parameters.isRawShaderMaterial === false ) {

				getProgramCacheKeyParameters( array, parameters );
				getProgramCacheKeyBooleans( array, parameters );
				array.push( renderer.outputColorSpace );

			}

			array.push( parameters.customProgramCacheKey );

			return array.join();

		}

		function getProgramCacheKeyParameters( array, parameters ) {

			array.push( parameters.precision );
			array.push( parameters.outputColorSpace );
			array.push( parameters.envMapMode );
			array.push( parameters.envMapCubeUVHeight );
			array.push( parameters.mapUv );
			array.push( parameters.alphaMapUv );
			array.push( parameters.lightMapUv );
			array.push( parameters.aoMapUv );
			array.push( parameters.bumpMapUv );
			array.push( parameters.normalMapUv );
			array.push( parameters.displacementMapUv );
			array.push( parameters.emissiveMapUv );
			array.push( parameters.metalnessMapUv );
			array.push( parameters.roughnessMapUv );
			array.push( parameters.anisotropyMapUv );
			array.push( parameters.clearcoatMapUv );
			array.push( parameters.clearcoatNormalMapUv );
			array.push( parameters.clearcoatRoughnessMapUv );
			array.push( parameters.iridescenceMapUv );
			array.push( parameters.iridescenceThicknessMapUv );
			array.push( parameters.sheenColorMapUv );
			array.push( parameters.sheenRoughnessMapUv );
			array.push( parameters.specularMapUv );
			array.push( parameters.specularColorMapUv );
			array.push( parameters.specularIntensityMapUv );
			array.push( parameters.transmissionMapUv );
			array.push( parameters.thicknessMapUv );
			array.push( parameters.combine );
			array.push( parameters.fogExp2 );
			array.push( parameters.sizeAttenuation );
			array.push( parameters.morphTargetsCount );
			array.push( parameters.morphAttributeCount );
			array.push( parameters.numDirLights );
			array.push( parameters.numPointLights );
			array.push( parameters.numSpotLights );
			array.push( parameters.numSpotLightMaps );
			array.push( parameters.numHemiLights );
			array.push( parameters.numRectAreaLights );
			array.push( parameters.numDirLightShadows );
			array.push( parameters.numPointLightShadows );
			array.push( parameters.numSpotLightShadows );
			array.push( parameters.numSpotLightShadowsWithMaps );
			array.push( parameters.numLightProbes );
			array.push( parameters.shadowMapType );
			array.push( parameters.toneMapping );
			array.push( parameters.numClippingPlanes );
			array.push( parameters.numClipIntersection );
			array.push( parameters.depthPacking );

		}

		function getProgramCacheKeyBooleans( array, parameters ) {

			_programLayers.disableAll();

			if ( parameters.supportsVertexTextures )
				_programLayers.enable( 0 );
			if ( parameters.instancing )
				_programLayers.enable( 1 );
			if ( parameters.instancingColor )
				_programLayers.enable( 2 );
			if ( parameters.instancingMorph )
				_programLayers.enable( 3 );
			if ( parameters.matcap )
				_programLayers.enable( 4 );
			if ( parameters.envMap )
				_programLayers.enable( 5 );
			if ( parameters.normalMapObjectSpace )
				_programLayers.enable( 6 );
			if ( parameters.normalMapTangentSpace )
				_programLayers.enable( 7 );
			if ( parameters.clearcoat )
				_programLayers.enable( 8 );
			if ( parameters.iridescence )
				_programLayers.enable( 9 );
			if ( parameters.alphaTest )
				_programLayers.enable( 10 );
			if ( parameters.vertexColors )
				_programLayers.enable( 11 );
			if ( parameters.vertexAlphas )
				_programLayers.enable( 12 );
			if ( parameters.vertexUv1s )
				_programLayers.enable( 13 );
			if ( parameters.vertexUv2s )
				_programLayers.enable( 14 );
			if ( parameters.vertexUv3s )
				_programLayers.enable( 15 );
			if ( parameters.vertexTangents )
				_programLayers.enable( 16 );
			if ( parameters.anisotropy )
				_programLayers.enable( 17 );
			if ( parameters.alphaHash )
				_programLayers.enable( 18 );
			if ( parameters.batching )
				_programLayers.enable( 19 );
			if ( parameters.dispersion )
				_programLayers.enable( 20 );
			if ( parameters.batchingColor )
				_programLayers.enable( 21 );

			array.push( _programLayers.mask );
			_programLayers.disableAll();

			if ( parameters.fog )
				_programLayers.enable( 0 );
			if ( parameters.useFog )
				_programLayers.enable( 1 );
			if ( parameters.flatShading )
				_programLayers.enable( 2 );
			if ( parameters.logarithmicDepthBuffer )
				_programLayers.enable( 3 );
			if ( parameters.reverseDepthBuffer )
				_programLayers.enable( 4 );
			if ( parameters.skinning )
				_programLayers.enable( 5 );
			if ( parameters.morphTargets )
				_programLayers.enable( 6 );
			if ( parameters.morphNormals )
				_programLayers.enable( 7 );
			if ( parameters.morphColors )
				_programLayers.enable( 8 );
			if ( parameters.premultipliedAlpha )
				_programLayers.enable( 9 );
			if ( parameters.shadowMapEnabled )
				_programLayers.enable( 10 );
			if ( parameters.doubleSided )
				_programLayers.enable( 11 );
			if ( parameters.flipSided )
				_programLayers.enable( 12 );
			if ( parameters.useDepthPacking )
				_programLayers.enable( 13 );
			if ( parameters.dithering )
				_programLayers.enable( 14 );
			if ( parameters.transmission )
				_programLayers.enable( 15 );
			if ( parameters.sheen )
				_programLayers.enable( 16 );
			if ( parameters.opaque )
				_programLayers.enable( 17 );
			if ( parameters.pointsUvs )
				_programLayers.enable( 18 );
			if ( parameters.decodeVideoTexture )
				_programLayers.enable( 19 );
			if ( parameters.decodeVideoTextureEmissive )
				_programLayers.enable( 20 );
			if ( parameters.alphaToCoverage )
				_programLayers.enable( 21 );

			array.push( _programLayers.mask );

		}

		function getUniforms( material ) {

			const shaderID = shaderIDs[ material.type ];
			let uniforms;

			if ( shaderID ) {

				const shader = ShaderLib[ shaderID ];
				uniforms = UniformsUtils.clone( shader.uniforms );

			} else {

				uniforms = material.uniforms;

			}

			return uniforms;

		}

		function acquireProgram( parameters, cacheKey ) {

			let program;

			// Check if code has been already compiled
			for ( let p = 0, pl = programs.length; p < pl; p ++ ) {

				const preexistingProgram = programs[ p ];

				if ( preexistingProgram.cacheKey === cacheKey ) {

					program = preexistingProgram;
					++ program.usedTimes;

					break;

				}

			}

			if ( program === undefined ) {

				program = new WebGLProgram( renderer, cacheKey, parameters, bindingStates );
				programs.push( program );

			}

			return program;

		}

		function releaseProgram( program ) {

			if ( -- program.usedTimes === 0 ) {

				// Remove from unordered set
				const i = programs.indexOf( program );
				programs[ i ] = programs[ programs.length - 1 ];
				programs.pop();

				// Free WebGL resources
				program.destroy();

			}

		}

		function releaseShaderCache( material ) {

			_customShaders.remove( material );

		}

		function dispose() {

			_customShaders.dispose();

		}

		return {
			getParameters: getParameters,
			getProgramCacheKey: getProgramCacheKey,
			getUniforms: getUniforms,
			acquireProgram: acquireProgram,
			releaseProgram: releaseProgram,
			releaseShaderCache: releaseShaderCache,
			// Exposed for resource monitoring & error feedback via renderer.info:
			programs: programs,
			dispose: dispose
		};

	}

	function WebGLProperties() {

		let properties = new WeakMap();

		function has( object ) {

			return properties.has( object );

		}

		function get( object ) {

			let map = properties.get( object );

			if ( map === undefined ) {

				map = {};
				properties.set( object, map );

			}

			return map;

		}

		function remove( object ) {

			properties.delete( object );

		}

		function update( object, key, value ) {

			properties.get( object )[ key ] = value;

		}

		function dispose() {

			properties = new WeakMap();

		}

		return {
			has: has,
			get: get,
			remove: remove,
			update: update,
			dispose: dispose
		};

	}

	function painterSortStable( a, b ) {

		if ( a.groupOrder !== b.groupOrder ) {

			return a.groupOrder - b.groupOrder;

		} else if ( a.renderOrder !== b.renderOrder ) {

			return a.renderOrder - b.renderOrder;

		} else if ( a.material.id !== b.material.id ) {

			return a.material.id - b.material.id;

		} else if ( a.z !== b.z ) {

			return a.z - b.z;

		} else {

			return a.id - b.id;

		}

	}

	function reversePainterSortStable( a, b ) {

		if ( a.groupOrder !== b.groupOrder ) {

			return a.groupOrder - b.groupOrder;

		} else if ( a.renderOrder !== b.renderOrder ) {

			return a.renderOrder - b.renderOrder;

		} else if ( a.z !== b.z ) {

			return b.z - a.z;

		} else {

			return a.id - b.id;

		}

	}


	function WebGLRenderList() {

		const renderItems = [];
		let renderItemsIndex = 0;

		const opaque = [];
		const transmissive = [];
		const transparent = [];

		function init() {

			renderItemsIndex = 0;

			opaque.length = 0;
			transmissive.length = 0;
			transparent.length = 0;

		}

		function getNextRenderItem( object, geometry, material, groupOrder, z, group ) {

			let renderItem = renderItems[ renderItemsIndex ];

			if ( renderItem === undefined ) {

				renderItem = {
					id: object.id,
					object: object,
					geometry: geometry,
					material: material,
					groupOrder: groupOrder,
					renderOrder: object.renderOrder,
					z: z,
					group: group
				};

				renderItems[ renderItemsIndex ] = renderItem;

			} else {

				renderItem.id = object.id;
				renderItem.object = object;
				renderItem.geometry = geometry;
				renderItem.material = material;
				renderItem.groupOrder = groupOrder;
				renderItem.renderOrder = object.renderOrder;
				renderItem.z = z;
				renderItem.group = group;

			}

			renderItemsIndex ++;

			return renderItem;

		}

		function push( object, geometry, material, groupOrder, z, group ) {

			const renderItem = getNextRenderItem( object, geometry, material, groupOrder, z, group );

			if ( material.transmission > 0.0 ) {

				transmissive.push( renderItem );

			} else if ( material.transparent === true ) {

				transparent.push( renderItem );

			} else {

				opaque.push( renderItem );

			}

		}

		function unshift( object, geometry, material, groupOrder, z, group ) {

			const renderItem = getNextRenderItem( object, geometry, material, groupOrder, z, group );

			if ( material.transmission > 0.0 ) {

				transmissive.unshift( renderItem );

			} else if ( material.transparent === true ) {

				transparent.unshift( renderItem );

			} else {

				opaque.unshift( renderItem );

			}

		}

		function sort( customOpaqueSort, customTransparentSort ) {

			if ( opaque.length > 1 ) opaque.sort( customOpaqueSort || painterSortStable );
			if ( transmissive.length > 1 ) transmissive.sort( customTransparentSort || reversePainterSortStable );
			if ( transparent.length > 1 ) transparent.sort( customTransparentSort || reversePainterSortStable );

		}

		function finish() {

			// Clear references from inactive renderItems in the list

			for ( let i = renderItemsIndex, il = renderItems.length; i < il; i ++ ) {

				const renderItem = renderItems[ i ];

				if ( renderItem.id === null ) break;

				renderItem.id = null;
				renderItem.object = null;
				renderItem.geometry = null;
				renderItem.material = null;
				renderItem.group = null;

			}

		}

		return {

			opaque: opaque,
			transmissive: transmissive,
			transparent: transparent,

			init: init,
			push: push,
			unshift: unshift,
			finish: finish,

			sort: sort
		};

	}

	function WebGLRenderLists() {

		let lists = new WeakMap();

		function get( scene, renderCallDepth ) {

			const listArray = lists.get( scene );
			let list;

			if ( listArray === undefined ) {

				list = new WebGLRenderList();
				lists.set( scene, [ list ] );

			} else {

				if ( renderCallDepth >= listArray.length ) {

					list = new WebGLRenderList();
					listArray.push( list );

				} else {

					list = listArray[ renderCallDepth ];

				}

			}

			return list;

		}

		function dispose() {

			lists = new WeakMap();

		}

		return {
			get: get,
			dispose: dispose
		};

	}

	function UniformsCache() {

		const lights = {};

		return {

			get: function ( light ) {

				if ( lights[ light.id ] !== undefined ) {

					return lights[ light.id ];

				}

				let uniforms;

				switch ( light.type ) {

					case 'DirectionalLight':
						uniforms = {
							direction: new Vector3(),
							color: new Color()
						};
						break;

					case 'SpotLight':
						uniforms = {
							position: new Vector3(),
							direction: new Vector3(),
							color: new Color(),
							distance: 0,
							coneCos: 0,
							penumbraCos: 0,
							decay: 0
						};
						break;

					case 'PointLight':
						uniforms = {
							position: new Vector3(),
							color: new Color(),
							distance: 0,
							decay: 0
						};
						break;

					case 'HemisphereLight':
						uniforms = {
							direction: new Vector3(),
							skyColor: new Color(),
							groundColor: new Color()
						};
						break;

					case 'RectAreaLight':
						uniforms = {
							color: new Color(),
							position: new Vector3(),
							halfWidth: new Vector3(),
							halfHeight: new Vector3()
						};
						break;

				}

				lights[ light.id ] = uniforms;

				return uniforms;

			}

		};

	}

	function ShadowUniformsCache() {

		const lights = {};

		return {

			get: function ( light ) {

				if ( lights[ light.id ] !== undefined ) {

					return lights[ light.id ];

				}

				let uniforms;

				switch ( light.type ) {

					case 'DirectionalLight':
						uniforms = {
							shadowIntensity: 1,
							shadowBias: 0,
							shadowNormalBias: 0,
							shadowRadius: 1,
							shadowMapSize: new Vector2()
						};
						break;

					case 'SpotLight':
						uniforms = {
							shadowIntensity: 1,
							shadowBias: 0,
							shadowNormalBias: 0,
							shadowRadius: 1,
							shadowMapSize: new Vector2()
						};
						break;

					case 'PointLight':
						uniforms = {
							shadowIntensity: 1,
							shadowBias: 0,
							shadowNormalBias: 0,
							shadowRadius: 1,
							shadowMapSize: new Vector2(),
							shadowCameraNear: 1,
							shadowCameraFar: 1000
						};
						break;

					// TODO (abelnation): set RectAreaLight shadow uniforms

				}

				lights[ light.id ] = uniforms;

				return uniforms;

			}

		};

	}



	let nextVersion = 0;

	function shadowCastingAndTexturingLightsFirst( lightA, lightB ) {

		return ( lightB.castShadow ? 2 : 0 ) - ( lightA.castShadow ? 2 : 0 ) + ( lightB.map ? 1 : 0 ) - ( lightA.map ? 1 : 0 );

	}

	function WebGLLights( extensions ) {

		const cache = new UniformsCache();

		const shadowCache = ShadowUniformsCache();

		const state = {

			version: 0,

			hash: {
				directionalLength: -1,
				pointLength: -1,
				spotLength: -1,
				rectAreaLength: -1,
				hemiLength: -1,

				numDirectionalShadows: -1,
				numPointShadows: -1,
				numSpotShadows: -1,
				numSpotMaps: -1,

				numLightProbes: -1
			},

			ambient: [ 0, 0, 0 ],
			probe: [],
			directional: [],
			directionalShadow: [],
			directionalShadowMap: [],
			directionalShadowMatrix: [],
			spot: [],
			spotLightMap: [],
			spotShadow: [],
			spotShadowMap: [],
			spotLightMatrix: [],
			rectArea: [],
			rectAreaLTC1: null,
			rectAreaLTC2: null,
			point: [],
			pointShadow: [],
			pointShadowMap: [],
			pointShadowMatrix: [],
			hemi: [],
			numSpotLightShadowsWithMaps: 0,
			numLightProbes: 0

		};

		for ( let i = 0; i < 9; i ++ ) state.probe.push( new Vector3() );

		const vector3 = new Vector3();
		const matrix4 = new Matrix4();
		const matrix42 = new Matrix4();

		function setup( lights ) {

			let r = 0, g = 0, b = 0;

			for ( let i = 0; i < 9; i ++ ) state.probe[ i ].set( 0, 0, 0 );

			let directionalLength = 0;
			let pointLength = 0;
			let spotLength = 0;
			let rectAreaLength = 0;
			let hemiLength = 0;

			let numDirectionalShadows = 0;
			let numPointShadows = 0;
			let numSpotShadows = 0;
			let numSpotMaps = 0;
			let numSpotShadowsWithMaps = 0;

			let numLightProbes = 0;

			// ordering : [shadow casting + map texturing, map texturing, shadow casting, none ]
			lights.sort( shadowCastingAndTexturingLightsFirst );

			for ( let i = 0, l = lights.length; i < l; i ++ ) {

				const light = lights[ i ];

				const color = light.color;
				const intensity = light.intensity;
				const distance = light.distance;

				const shadowMap = ( light.shadow && light.shadow.map ) ? light.shadow.map.texture : null;

				if ( light.isAmbientLight ) {

					r += color.r * intensity;
					g += color.g * intensity;
					b += color.b * intensity;

				} else if ( light.isLightProbe ) {

					for ( let j = 0; j < 9; j ++ ) {

						state.probe[ j ].addScaledVector( light.sh.coefficients[ j ], intensity );

					}

					numLightProbes ++;

				} else if ( light.isDirectionalLight ) {

					const uniforms = cache.get( light );

					uniforms.color.copy( light.color ).multiplyScalar( light.intensity );

					if ( light.castShadow ) {

						const shadow = light.shadow;

						const shadowUniforms = shadowCache.get( light );

						shadowUniforms.shadowIntensity = shadow.intensity;
						shadowUniforms.shadowBias = shadow.bias;
						shadowUniforms.shadowNormalBias = shadow.normalBias;
						shadowUniforms.shadowRadius = shadow.radius;
						shadowUniforms.shadowMapSize = shadow.mapSize;

						state.directionalShadow[ directionalLength ] = shadowUniforms;
						state.directionalShadowMap[ directionalLength ] = shadowMap;
						state.directionalShadowMatrix[ directionalLength ] = light.shadow.matrix;

						numDirectionalShadows ++;

					}

					state.directional[ directionalLength ] = uniforms;

					directionalLength ++;

				} else if ( light.isSpotLight ) {

					const uniforms = cache.get( light );

					uniforms.position.setFromMatrixPosition( light.matrixWorld );

					uniforms.color.copy( color ).multiplyScalar( intensity );
					uniforms.distance = distance;

					uniforms.coneCos = Math.cos( light.angle );
					uniforms.penumbraCos = Math.cos( light.angle * ( 1 - light.penumbra ) );
					uniforms.decay = light.decay;

					state.spot[ spotLength ] = uniforms;

					const shadow = light.shadow;

					if ( light.map ) {

						state.spotLightMap[ numSpotMaps ] = light.map;
						numSpotMaps ++;

						// make sure the lightMatrix is up to date
						// TODO : do it if required only
						shadow.updateMatrices( light );

						if ( light.castShadow ) numSpotShadowsWithMaps ++;

					}

					state.spotLightMatrix[ spotLength ] = shadow.matrix;

					if ( light.castShadow ) {

						const shadowUniforms = shadowCache.get( light );

						shadowUniforms.shadowIntensity = shadow.intensity;
						shadowUniforms.shadowBias = shadow.bias;
						shadowUniforms.shadowNormalBias = shadow.normalBias;
						shadowUniforms.shadowRadius = shadow.radius;
						shadowUniforms.shadowMapSize = shadow.mapSize;

						state.spotShadow[ spotLength ] = shadowUniforms;
						state.spotShadowMap[ spotLength ] = shadowMap;

						numSpotShadows ++;

					}

					spotLength ++;

				} else if ( light.isRectAreaLight ) {

					const uniforms = cache.get( light );

					uniforms.color.copy( color ).multiplyScalar( intensity );

					uniforms.halfWidth.set( light.width * 0.5, 0.0, 0.0 );
					uniforms.halfHeight.set( 0.0, light.height * 0.5, 0.0 );

					state.rectArea[ rectAreaLength ] = uniforms;

					rectAreaLength ++;

				} else if ( light.isPointLight ) {

					const uniforms = cache.get( light );

					uniforms.color.copy( light.color ).multiplyScalar( light.intensity );
					uniforms.distance = light.distance;
					uniforms.decay = light.decay;

					if ( light.castShadow ) {

						const shadow = light.shadow;

						const shadowUniforms = shadowCache.get( light );

						shadowUniforms.shadowIntensity = shadow.intensity;
						shadowUniforms.shadowBias = shadow.bias;
						shadowUniforms.shadowNormalBias = shadow.normalBias;
						shadowUniforms.shadowRadius = shadow.radius;
						shadowUniforms.shadowMapSize = shadow.mapSize;
						shadowUniforms.shadowCameraNear = shadow.camera.near;
						shadowUniforms.shadowCameraFar = shadow.camera.far;

						state.pointShadow[ pointLength ] = shadowUniforms;
						state.pointShadowMap[ pointLength ] = shadowMap;
						state.pointShadowMatrix[ pointLength ] = light.shadow.matrix;

						numPointShadows ++;

					}

					state.point[ pointLength ] = uniforms;

					pointLength ++;

				} else if ( light.isHemisphereLight ) {

					const uniforms = cache.get( light );

					uniforms.skyColor.copy( light.color ).multiplyScalar( intensity );
					uniforms.groundColor.copy( light.groundColor ).multiplyScalar( intensity );

					state.hemi[ hemiLength ] = uniforms;

					hemiLength ++;

				}

			}

			if ( rectAreaLength > 0 ) {

				if ( extensions.has( 'OES_texture_float_linear' ) === true ) {

					state.rectAreaLTC1 = UniformsLib.LTC_FLOAT_1;
					state.rectAreaLTC2 = UniformsLib.LTC_FLOAT_2;

				} else {

					state.rectAreaLTC1 = UniformsLib.LTC_HALF_1;
					state.rectAreaLTC2 = UniformsLib.LTC_HALF_2;

				}

			}

			state.ambient[ 0 ] = r;
			state.ambient[ 1 ] = g;
			state.ambient[ 2 ] = b;

			const hash = state.hash;

			if ( hash.directionalLength !== directionalLength ||
				hash.pointLength !== pointLength ||
				hash.spotLength !== spotLength ||
				hash.rectAreaLength !== rectAreaLength ||
				hash.hemiLength !== hemiLength ||
				hash.numDirectionalShadows !== numDirectionalShadows ||
				hash.numPointShadows !== numPointShadows ||
				hash.numSpotShadows !== numSpotShadows ||
				hash.numSpotMaps !== numSpotMaps ||
				hash.numLightProbes !== numLightProbes ) {

				state.directional.length = directionalLength;
				state.spot.length = spotLength;
				state.rectArea.length = rectAreaLength;
				state.point.length = pointLength;
				state.hemi.length = hemiLength;

				state.directionalShadow.length = numDirectionalShadows;
				state.directionalShadowMap.length = numDirectionalShadows;
				state.pointShadow.length = numPointShadows;
				state.pointShadowMap.length = numPointShadows;
				state.spotShadow.length = numSpotShadows;
				state.spotShadowMap.length = numSpotShadows;
				state.directionalShadowMatrix.length = numDirectionalShadows;
				state.pointShadowMatrix.length = numPointShadows;
				state.spotLightMatrix.length = numSpotShadows + numSpotMaps - numSpotShadowsWithMaps;
				state.spotLightMap.length = numSpotMaps;
				state.numSpotLightShadowsWithMaps = numSpotShadowsWithMaps;
				state.numLightProbes = numLightProbes;

				hash.directionalLength = directionalLength;
				hash.pointLength = pointLength;
				hash.spotLength = spotLength;
				hash.rectAreaLength = rectAreaLength;
				hash.hemiLength = hemiLength;

				hash.numDirectionalShadows = numDirectionalShadows;
				hash.numPointShadows = numPointShadows;
				hash.numSpotShadows = numSpotShadows;
				hash.numSpotMaps = numSpotMaps;

				hash.numLightProbes = numLightProbes;

				state.version = nextVersion ++;

			}

		}

		function setupView( lights, camera ) {

			let directionalLength = 0;
			let pointLength = 0;
			let spotLength = 0;
			let rectAreaLength = 0;
			let hemiLength = 0;

			const viewMatrix = camera.matrixWorldInverse;

			for ( let i = 0, l = lights.length; i < l; i ++ ) {

				const light = lights[ i ];

				if ( light.isDirectionalLight ) {

					const uniforms = state.directional[ directionalLength ];

					uniforms.direction.setFromMatrixPosition( light.matrixWorld );
					vector3.setFromMatrixPosition( light.target.matrixWorld );
					uniforms.direction.sub( vector3 );
					uniforms.direction.transformDirection( viewMatrix );

					directionalLength ++;

				} else if ( light.isSpotLight ) {

					const uniforms = state.spot[ spotLength ];

					uniforms.position.setFromMatrixPosition( light.matrixWorld );
					uniforms.position.applyMatrix4( viewMatrix );

					uniforms.direction.setFromMatrixPosition( light.matrixWorld );
					vector3.setFromMatrixPosition( light.target.matrixWorld );
					uniforms.direction.sub( vector3 );
					uniforms.direction.transformDirection( viewMatrix );

					spotLength ++;

				} else if ( light.isRectAreaLight ) {

					const uniforms = state.rectArea[ rectAreaLength ];

					uniforms.position.setFromMatrixPosition( light.matrixWorld );
					uniforms.position.applyMatrix4( viewMatrix );

					// extract local rotation of light to derive width/height half vectors
					matrix42.identity();
					matrix4.copy( light.matrixWorld );
					matrix4.premultiply( viewMatrix );
					matrix42.extractRotation( matrix4 );

					uniforms.halfWidth.set( light.width * 0.5, 0.0, 0.0 );
					uniforms.halfHeight.set( 0.0, light.height * 0.5, 0.0 );

					uniforms.halfWidth.applyMatrix4( matrix42 );
					uniforms.halfHeight.applyMatrix4( matrix42 );

					rectAreaLength ++;

				} else if ( light.isPointLight ) {

					const uniforms = state.point[ pointLength ];

					uniforms.position.setFromMatrixPosition( light.matrixWorld );
					uniforms.position.applyMatrix4( viewMatrix );

					pointLength ++;

				} else if ( light.isHemisphereLight ) {

					const uniforms = state.hemi[ hemiLength ];

					uniforms.direction.setFromMatrixPosition( light.matrixWorld );
					uniforms.direction.transformDirection( viewMatrix );

					hemiLength ++;

				}

			}

		}

		return {
			setup: setup,
			setupView: setupView,
			state: state
		};

	}

	function WebGLRenderState( extensions ) {

		const lights = new WebGLLights( extensions );

		const lightsArray = [];
		const shadowsArray = [];

		function init( camera ) {

			state.camera = camera;

			lightsArray.length = 0;
			shadowsArray.length = 0;

		}

		function pushLight( light ) {

			lightsArray.push( light );

		}

		function pushShadow( shadowLight ) {

			shadowsArray.push( shadowLight );

		}

		function setupLights() {

			lights.setup( lightsArray );

		}

		function setupLightsView( camera ) {

			lights.setupView( lightsArray, camera );

		}

		const state = {
			lightsArray: lightsArray,
			shadowsArray: shadowsArray,

			camera: null,

			lights: lights,

			transmissionRenderTarget: {}
		};

		return {
			init: init,
			state: state,
			setupLights: setupLights,
			setupLightsView: setupLightsView,

			pushLight: pushLight,
			pushShadow: pushShadow
		};

	}

	function WebGLRenderStates( extensions ) {

		let renderStates = new WeakMap();

		function get( scene, renderCallDepth = 0 ) {

			const renderStateArray = renderStates.get( scene );
			let renderState;

			if ( renderStateArray === undefined ) {

				renderState = new WebGLRenderState( extensions );
				renderStates.set( scene, [ renderState ] );

			} else {

				if ( renderCallDepth >= renderStateArray.length ) {

					renderState = new WebGLRenderState( extensions );
					renderStateArray.push( renderState );

				} else {

					renderState = renderStateArray[ renderCallDepth ];

				}

			}

			return renderState;

		}

		function dispose() {

			renderStates = new WeakMap();

		}

		return {
			get: get,
			dispose: dispose
		};

	}

	const vertex = "void main() {\n\tgl_Position = vec4( position, 1.0 );\n}";

	const fragment = "uniform sampler2D shadow_pass;\nuniform vec2 resolution;\nuniform float radius;\n#include <packing>\nvoid main() {\n\tconst float samples = float( VSM_SAMPLES );\n\tfloat mean = 0.0;\n\tfloat squared_mean = 0.0;\n\tfloat uvStride = samples <= 1.0 ? 0.0 : 2.0 / ( samples - 1.0 );\n\tfloat uvStart = samples <= 1.0 ? 0.0 : - 1.0;\n\tfor ( float i = 0.0; i < samples; i ++ ) {\n\t\tfloat uvOffset = uvStart + i * uvStride;\n\t\t#ifdef HORIZONTAL_PASS\n\t\t\tvec2 distribution = unpackRGBATo2Half( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( uvOffset, 0.0 ) * radius ) / resolution ) );\n\t\t\tmean += distribution.x;\n\t\t\tsquared_mean += distribution.y * distribution.y + distribution.x * distribution.x;\n\t\t#else\n\t\t\tfloat depth = unpackRGBAToDepth( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( 0.0, uvOffset ) * radius ) / resolution ) );\n\t\t\tmean += depth;\n\t\t\tsquared_mean += depth * depth;\n\t\t#endif\n\t}\n\tmean = mean / samples;\n\tsquared_mean = squared_mean / samples;\n\tfloat std_dev = sqrt( squared_mean - mean * mean );\n\tgl_FragColor = pack2HalfToRGBA( vec2( mean, std_dev ) );\n}";

	function WebGLShadowMap( renderer, objects, capabilities ) {

		let _frustum = new Frustum();

		const _shadowMapSize = new Vector2(),
			_viewportSize = new Vector2(),

			_viewport = new Vector4(),

			_depthMaterial = new MeshDepthMaterial( { depthPacking: RGBADepthPacking } ),
			_distanceMaterial = new MeshDistanceMaterial(),

			_materialCache = {},

			_maxTextureSize = capabilities.maxTextureSize;

		const shadowSide = { [ FrontSide ]: BackSide, [ BackSide ]: FrontSide, [ DoubleSide ]: DoubleSide };

		const shadowMaterialVertical = new ShaderMaterial( {
			defines: {
				VSM_SAMPLES: 8
			},
			uniforms: {
				shadow_pass: { value: null },
				resolution: { value: new Vector2() },
				radius: { value: 4.0 }
			},

			vertexShader: vertex,
			fragmentShader: fragment

		} );

		const shadowMaterialHorizontal = shadowMaterialVertical.clone();
		shadowMaterialHorizontal.defines.HORIZONTAL_PASS = 1;

		const fullScreenTri = new BufferGeometry();
		fullScreenTri.setAttribute(
			'position',
			new BufferAttribute(
				new Float32Array( [ -1, -1, 0.5, 3, -1, 0.5, -1, 3, 0.5 ] ),
				3
			)
		);

		const fullScreenMesh = new Mesh( fullScreenTri, shadowMaterialVertical );

		const scope = this;

		this.enabled = false;

		this.autoUpdate = true;
		this.needsUpdate = false;

		this.type = PCFShadowMap;
		let _previousType = this.type;

		this.render = function ( lights, scene, camera ) {

			if ( scope.enabled === false ) return;
			if ( scope.autoUpdate === false && scope.needsUpdate === false ) return;

			if ( lights.length === 0 ) return;

			const currentRenderTarget = renderer.getRenderTarget();
			const activeCubeFace = renderer.getActiveCubeFace();
			const activeMipmapLevel = renderer.getActiveMipmapLevel();

			const _state = renderer.state;

			// Set GL state for depth map.
			_state.setBlending( NoBlending );
			_state.buffers.color.setClear( 1, 1, 1, 1 );
			_state.buffers.depth.setTest( true );
			_state.setScissorTest( false );

			// check for shadow map type changes

			const toVSM = ( _previousType !== VSMShadowMap && this.type === VSMShadowMap );
			const fromVSM = ( _previousType === VSMShadowMap && this.type !== VSMShadowMap );

			// render depth map

			for ( let i = 0, il = lights.length; i < il; i ++ ) {

				const light = lights[ i ];
				const shadow = light.shadow;

				if ( shadow === undefined ) {

					console.warn( 'THREE.WebGLShadowMap:', light, 'has no shadow.' );
					continue;

				}

				if ( shadow.autoUpdate === false && shadow.needsUpdate === false ) continue;

				_shadowMapSize.copy( shadow.mapSize );

				const shadowFrameExtents = shadow.getFrameExtents();

				_shadowMapSize.multiply( shadowFrameExtents );

				_viewportSize.copy( shadow.mapSize );

				if ( _shadowMapSize.x > _maxTextureSize || _shadowMapSize.y > _maxTextureSize ) {

					if ( _shadowMapSize.x > _maxTextureSize ) {

						_viewportSize.x = Math.floor( _maxTextureSize / shadowFrameExtents.x );
						_shadowMapSize.x = _viewportSize.x * shadowFrameExtents.x;
						shadow.mapSize.x = _viewportSize.x;

					}

					if ( _shadowMapSize.y > _maxTextureSize ) {

						_viewportSize.y = Math.floor( _maxTextureSize / shadowFrameExtents.y );
						_shadowMapSize.y = _viewportSize.y * shadowFrameExtents.y;
						shadow.mapSize.y = _viewportSize.y;

					}

				}

				if ( shadow.map === null || toVSM === true || fromVSM === true ) {

					const pars = ( this.type !== VSMShadowMap ) ? { minFilter: NearestFilter, magFilter: NearestFilter } : {};

					if ( shadow.map !== null ) {

						shadow.map.dispose();

					}

					shadow.map = new WebGLRenderTarget( _shadowMapSize.x, _shadowMapSize.y, pars );
					shadow.map.texture.name = light.name + '.shadowMap';

					shadow.camera.updateProjectionMatrix();

				}

				renderer.setRenderTarget( shadow.map );
				renderer.clear();

				const viewportCount = shadow.getViewportCount();

				for ( let vp = 0; vp < viewportCount; vp ++ ) {

					const viewport = shadow.getViewport( vp );

					_viewport.set(
						_viewportSize.x * viewport.x,
						_viewportSize.y * viewport.y,
						_viewportSize.x * viewport.z,
						_viewportSize.y * viewport.w
					);

					_state.viewport( _viewport );

					shadow.updateMatrices( light, vp );

					_frustum = shadow.getFrustum();

					renderObject( scene, camera, shadow.camera, light, this.type );

				}

				// do blur pass for VSM

				if ( shadow.isPointLightShadow !== true && this.type === VSMShadowMap ) {

					VSMPass( shadow, camera );

				}

				shadow.needsUpdate = false;

			}

			_previousType = this.type;

			scope.needsUpdate = false;

			renderer.setRenderTarget( currentRenderTarget, activeCubeFace, activeMipmapLevel );

		};

		function VSMPass( shadow, camera ) {

			const geometry = objects.update( fullScreenMesh );

			if ( shadowMaterialVertical.defines.VSM_SAMPLES !== shadow.blurSamples ) {

				shadowMaterialVertical.defines.VSM_SAMPLES = shadow.blurSamples;
				shadowMaterialHorizontal.defines.VSM_SAMPLES = shadow.blurSamples;

				shadowMaterialVertical.needsUpdate = true;
				shadowMaterialHorizontal.needsUpdate = true;

			}

			if ( shadow.mapPass === null ) {

				shadow.mapPass = new WebGLRenderTarget( _shadowMapSize.x, _shadowMapSize.y );

			}

			// vertical pass

			shadowMaterialVertical.uniforms.shadow_pass.value = shadow.map.texture;
			shadowMaterialVertical.uniforms.resolution.value = shadow.mapSize;
			shadowMaterialVertical.uniforms.radius.value = shadow.radius;
			renderer.setRenderTarget( shadow.mapPass );
			renderer.clear();
			renderer.renderBufferDirect( camera, null, geometry, shadowMaterialVertical, fullScreenMesh, null );

			// horizontal pass

			shadowMaterialHorizontal.uniforms.shadow_pass.value = shadow.mapPass.texture;
			shadowMaterialHorizontal.uniforms.resolution.value = shadow.mapSize;
			shadowMaterialHorizontal.uniforms.radius.value = shadow.radius;
			renderer.setRenderTarget( shadow.map );
			renderer.clear();
			renderer.renderBufferDirect( camera, null, geometry, shadowMaterialHorizontal, fullScreenMesh, null );

		}

		function getDepthMaterial( object, material, light, type ) {

			let result = null;

			const customMaterial = ( light.isPointLight === true ) ? object.customDistanceMaterial : object.customDepthMaterial;

			if ( customMaterial !== undefined ) {

				result = customMaterial;

			} else {

				result = ( light.isPointLight === true ) ? _distanceMaterial : _depthMaterial;

				if ( ( renderer.localClippingEnabled && material.clipShadows === true && Array.isArray( material.clippingPlanes ) && material.clippingPlanes.length !== 0 ) ||
					( material.displacementMap && material.displacementScale !== 0 ) ||
					( material.alphaMap && material.alphaTest > 0 ) ||
					( material.map && material.alphaTest > 0 ) ||
					( material.alphaToCoverage === true ) ) {

					// in this case we need a unique material instance reflecting the
					// appropriate state

					const keyA = result.uuid, keyB = material.uuid;

					let materialsForVariant = _materialCache[ keyA ];

					if ( materialsForVariant === undefined ) {

						materialsForVariant = {};
						_materialCache[ keyA ] = materialsForVariant;

					}

					let cachedMaterial = materialsForVariant[ keyB ];

					if ( cachedMaterial === undefined ) {

						cachedMaterial = result.clone();
						materialsForVariant[ keyB ] = cachedMaterial;
						material.addEventListener( 'dispose', onMaterialDispose );

					}

					result = cachedMaterial;

				}

			}

			result.visible = material.visible;
			result.wireframe = material.wireframe;

			if ( type === VSMShadowMap ) {

				result.side = ( material.shadowSide !== null ) ? material.shadowSide : material.side;

			} else {

				result.side = ( material.shadowSide !== null ) ? material.shadowSide : shadowSide[ material.side ];

			}

			result.alphaMap = material.alphaMap;
			result.alphaTest = ( material.alphaToCoverage === true ) ? 0.5 : material.alphaTest; // approximate alphaToCoverage by using a fixed alphaTest value
			result.map = material.map;

			result.clipShadows = material.clipShadows;
			result.clippingPlanes = material.clippingPlanes;
			result.clipIntersection = material.clipIntersection;

			result.displacementMap = material.displacementMap;
			result.displacementScale = material.displacementScale;
			result.displacementBias = material.displacementBias;

			result.wireframeLinewidth = material.wireframeLinewidth;
			result.linewidth = material.linewidth;

			if ( light.isPointLight === true && result.isMeshDistanceMaterial === true ) {

				const materialProperties = renderer.properties.get( result );
				materialProperties.light = light;

			}

			return result;

		}

		function renderObject( object, camera, shadowCamera, light, type ) {

			if ( object.visible === false ) return;

			const visible = object.layers.test( camera.layers );

			if ( visible && ( object.isMesh || object.isLine || object.isPoints ) ) {

				if ( ( object.castShadow || ( object.receiveShadow && type === VSMShadowMap ) ) && ( ! object.frustumCulled || _frustum.intersectsObject( object ) ) ) {

					object.modelViewMatrix.multiplyMatrices( shadowCamera.matrixWorldInverse, object.matrixWorld );

					const geometry = objects.update( object );
					const material = object.material;

					if ( Array.isArray( material ) ) {

						const groups = geometry.groups;

						for ( let k = 0, kl = groups.length; k < kl; k ++ ) {

							const group = groups[ k ];
							const groupMaterial = material[ group.materialIndex ];

							if ( groupMaterial && groupMaterial.visible ) {

								const depthMaterial = getDepthMaterial( object, groupMaterial, light, type );

								object.onBeforeShadow( renderer, object, camera, shadowCamera, geometry, depthMaterial, group );

								renderer.renderBufferDirect( shadowCamera, null, geometry, depthMaterial, object, group );

								object.onAfterShadow( renderer, object, camera, shadowCamera, geometry, depthMaterial, group );

							}

						}

					} else if ( material.visible ) {

						const depthMaterial = getDepthMaterial( object, material, light, type );

						object.onBeforeShadow( renderer, object, camera, shadowCamera, geometry, depthMaterial, null );

						renderer.renderBufferDirect( shadowCamera, null, geometry, depthMaterial, object, null );

						object.onAfterShadow( renderer, object, camera, shadowCamera, geometry, depthMaterial, null );

					}

				}

			}

			const children = object.children;

			for ( let i = 0, l = children.length; i < l; i ++ ) {

				renderObject( children[ i ], camera, shadowCamera, light, type );

			}

		}

		function onMaterialDispose( event ) {

			const material = event.target;

			material.removeEventListener( 'dispose', onMaterialDispose );

			// make sure to remove the unique distance/depth materials used for shadow map rendering

			for ( const id in _materialCache ) {

				const cache = _materialCache[ id ];

				const uuid = event.target.uuid;

				if ( uuid in cache ) {

					const shadowMaterial = cache[ uuid ];
					shadowMaterial.dispose();
					delete cache[ uuid ];

				}

			}

		}

	}

	const reversedFuncs = {
		[ NeverDepth ]: AlwaysDepth,
		[ LessDepth ]: GreaterDepth,
		[ EqualDepth ]: NotEqualDepth,
		[ LessEqualDepth ]: GreaterEqualDepth,

		[ AlwaysDepth ]: NeverDepth,
		[ GreaterDepth ]: LessDepth,
		[ NotEqualDepth ]: EqualDepth,
		[ GreaterEqualDepth ]: LessEqualDepth,
	};

	function WebGLState( gl, extensions ) {

		function ColorBuffer() {

			let locked = false;

			const color = new Vector4();
			let currentColorMask = null;
			const currentColorClear = new Vector4( 0, 0, 0, 0 );

			return {

				setMask: function ( colorMask ) {

					if ( currentColorMask !== colorMask && ! locked ) {

						gl.colorMask( colorMask, colorMask, colorMask, colorMask );
						currentColorMask = colorMask;

					}

				},

				setLocked: function ( lock ) {

					locked = lock;

				},

				setClear: function ( r, g, b, a, premultipliedAlpha ) {

					if ( premultipliedAlpha === true ) {

						r *= a; g *= a; b *= a;

					}

					color.set( r, g, b, a );

					if ( currentColorClear.equals( color ) === false ) {

						gl.clearColor( r, g, b, a );
						currentColorClear.copy( color );

					}

				},

				reset: function () {

					locked = false;

					currentColorMask = null;
					currentColorClear.set( -1, 0, 0, 0 ); // set to invalid state

				}

			};

		}

		function DepthBuffer() {

			let locked = false;

			let currentReversed = false;
			let currentDepthMask = null;
			let currentDepthFunc = null;
			let currentDepthClear = null;

			return {

				setReversed: function ( reversed ) {

					if ( currentReversed !== reversed ) {

						const ext = extensions.get( 'EXT_clip_control' );

						if ( reversed ) {

							ext.clipControlEXT( ext.LOWER_LEFT_EXT, ext.ZERO_TO_ONE_EXT );

						} else {

							ext.clipControlEXT( ext.LOWER_LEFT_EXT, ext.NEGATIVE_ONE_TO_ONE_EXT );

						}

						currentReversed = reversed;

						const oldDepth = currentDepthClear;
						currentDepthClear = null;
						this.setClear( oldDepth );

					}

				},

				getReversed: function () {

					return currentReversed;

				},

				setTest: function ( depthTest ) {

					if ( depthTest ) {

						enable( gl.DEPTH_TEST );

					} else {

						disable( gl.DEPTH_TEST );

					}

				},

				setMask: function ( depthMask ) {

					if ( currentDepthMask !== depthMask && ! locked ) {

						gl.depthMask( depthMask );
						currentDepthMask = depthMask;

					}

				},

				setFunc: function ( depthFunc ) {

					if ( currentReversed ) depthFunc = reversedFuncs[ depthFunc ];

					if ( currentDepthFunc !== depthFunc ) {

						switch ( depthFunc ) {

							case NeverDepth:

								gl.depthFunc( gl.NEVER );
								break;

							case AlwaysDepth:

								gl.depthFunc( gl.ALWAYS );
								break;

							case LessDepth:

								gl.depthFunc( gl.LESS );
								break;

							case LessEqualDepth:

								gl.depthFunc( gl.LEQUAL );
								break;

							case EqualDepth:

								gl.depthFunc( gl.EQUAL );
								break;

							case GreaterEqualDepth:

								gl.depthFunc( gl.GEQUAL );
								break;

							case GreaterDepth:

								gl.depthFunc( gl.GREATER );
								break;

							case NotEqualDepth:

								gl.depthFunc( gl.NOTEQUAL );
								break;

							default:

								gl.depthFunc( gl.LEQUAL );

						}

						currentDepthFunc = depthFunc;

					}

				},

				setLocked: function ( lock ) {

					locked = lock;

				},

				setClear: function ( depth ) {

					if ( currentDepthClear !== depth ) {

						if ( currentReversed ) {

							depth = 1 - depth;

						}

						gl.clearDepth( depth );
						currentDepthClear = depth;

					}

				},

				reset: function () {

					locked = false;

					currentDepthMask = null;
					currentDepthFunc = null;
					currentDepthClear = null;
					currentReversed = false;

				}

			};

		}

		function StencilBuffer() {

			let locked = false;

			let currentStencilMask = null;
			let currentStencilFunc = null;
			let currentStencilRef = null;
			let currentStencilFuncMask = null;
			let currentStencilFail = null;
			let currentStencilZFail = null;
			let currentStencilZPass = null;
			let currentStencilClear = null;

			return {

				setTest: function ( stencilTest ) {

					if ( ! locked ) {

						if ( stencilTest ) {

							enable( gl.STENCIL_TEST );

						} else {

							disable( gl.STENCIL_TEST );

						}

					}

				},

				setMask: function ( stencilMask ) {

					if ( currentStencilMask !== stencilMask && ! locked ) {

						gl.stencilMask( stencilMask );
						currentStencilMask = stencilMask;

					}

				},

				setFunc: function ( stencilFunc, stencilRef, stencilMask ) {

					if ( currentStencilFunc !== stencilFunc ||
					     currentStencilRef !== stencilRef ||
					     currentStencilFuncMask !== stencilMask ) {

						gl.stencilFunc( stencilFunc, stencilRef, stencilMask );

						currentStencilFunc = stencilFunc;
						currentStencilRef = stencilRef;
						currentStencilFuncMask = stencilMask;

					}

				},

				setOp: function ( stencilFail, stencilZFail, stencilZPass ) {

					if ( currentStencilFail !== stencilFail ||
					     currentStencilZFail !== stencilZFail ||
					     currentStencilZPass !== stencilZPass ) {

						gl.stencilOp( stencilFail, stencilZFail, stencilZPass );

						currentStencilFail = stencilFail;
						currentStencilZFail = stencilZFail;
						currentStencilZPass = stencilZPass;

					}

				},

				setLocked: function ( lock ) {

					locked = lock;

				},

				setClear: function ( stencil ) {

					if ( currentStencilClear !== stencil ) {

						gl.clearStencil( stencil );
						currentStencilClear = stencil;

					}

				},

				reset: function () {

					locked = false;

					currentStencilMask = null;
					currentStencilFunc = null;
					currentStencilRef = null;
					currentStencilFuncMask = null;
					currentStencilFail = null;
					currentStencilZFail = null;
					currentStencilZPass = null;
					currentStencilClear = null;

				}

			};

		}

		//

		const colorBuffer = new ColorBuffer();
		const depthBuffer = new DepthBuffer();
		const stencilBuffer = new StencilBuffer();

		const uboBindings = new WeakMap();
		const uboProgramMap = new WeakMap();

		let enabledCapabilities = {};

		let currentBoundFramebuffers = {};
		let currentDrawbuffers = new WeakMap();
		let defaultDrawbuffers = [];

		let currentProgram = null;

		let currentBlendingEnabled = false;
		let currentBlending = null;
		let currentBlendEquation = null;
		let currentBlendSrc = null;
		let currentBlendDst = null;
		let currentBlendEquationAlpha = null;
		let currentBlendSrcAlpha = null;
		let currentBlendDstAlpha = null;
		let currentBlendColor = new Color( 0, 0, 0 );
		let currentBlendAlpha = 0;
		let currentPremultipledAlpha = false;

		let currentFlipSided = null;
		let currentCullFace = null;

		let currentLineWidth = null;

		let currentPolygonOffsetFactor = null;
		let currentPolygonOffsetUnits = null;

		const maxTextures = gl.getParameter( gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS );

		let lineWidthAvailable = false;
		let version = 0;
		const glVersion = gl.getParameter( gl.VERSION );

		if ( glVersion.indexOf( 'WebGL' ) !== -1 ) {

			version = parseFloat( /^WebGL (\d)/.exec( glVersion )[ 1 ] );
			lineWidthAvailable = ( version >= 1.0 );

		} else if ( glVersion.indexOf( 'OpenGL ES' ) !== -1 ) {

			version = parseFloat( /^OpenGL ES (\d)/.exec( glVersion )[ 1 ] );
			lineWidthAvailable = ( version >= 2.0 );

		}

		let currentTextureSlot = null;
		let currentBoundTextures = {};

		const scissorParam = gl.getParameter( gl.SCISSOR_BOX );
		const viewportParam = gl.getParameter( gl.VIEWPORT );

		const currentScissor = new Vector4().fromArray( scissorParam );
		const currentViewport = new Vector4().fromArray( viewportParam );

		function createTexture( type, target, count, dimensions ) {

			const data = new Uint8Array( 4 ); // 4 is required to match default unpack alignment of 4.
			const texture = gl.createTexture();

			gl.bindTexture( type, texture );
			gl.texParameteri( type, gl.TEXTURE_MIN_FILTER, gl.NEAREST );
			gl.texParameteri( type, gl.TEXTURE_MAG_FILTER, gl.NEAREST );

			for ( let i = 0; i < count; i ++ ) {

				if ( type === gl.TEXTURE_3D || type === gl.TEXTURE_2D_ARRAY ) {

					gl.texImage3D( target, 0, gl.RGBA, 1, 1, dimensions, 0, gl.RGBA, gl.UNSIGNED_BYTE, data );

				} else {

					gl.texImage2D( target + i, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, data );

				}

			}

			return texture;

		}

		const emptyTextures = {};
		emptyTextures[ gl.TEXTURE_2D ] = createTexture( gl.TEXTURE_2D, gl.TEXTURE_2D, 1 );
		emptyTextures[ gl.TEXTURE_CUBE_MAP ] = createTexture( gl.TEXTURE_CUBE_MAP, gl.TEXTURE_CUBE_MAP_POSITIVE_X, 6 );
		emptyTextures[ gl.TEXTURE_2D_ARRAY ] = createTexture( gl.TEXTURE_2D_ARRAY, gl.TEXTURE_2D_ARRAY, 1, 1 );
		emptyTextures[ gl.TEXTURE_3D ] = createTexture( gl.TEXTURE_3D, gl.TEXTURE_3D, 1, 1 );

		// init

		colorBuffer.setClear( 0, 0, 0, 1 );
		depthBuffer.setClear( 1 );
		stencilBuffer.setClear( 0 );

		enable( gl.DEPTH_TEST );
		depthBuffer.setFunc( LessEqualDepth );

		setFlipSided( false );
		setCullFace( CullFaceBack );
		enable( gl.CULL_FACE );

		setBlending( NoBlending );

		//

		function enable( id ) {

			if ( enabledCapabilities[ id ] !== true ) {

				gl.enable( id );
				enabledCapabilities[ id ] = true;

			}

		}

		function disable( id ) {

			if ( enabledCapabilities[ id ] !== false ) {

				gl.disable( id );
				enabledCapabilities[ id ] = false;

			}

		}

		function bindFramebuffer( target, framebuffer ) {

			if ( currentBoundFramebuffers[ target ] !== framebuffer ) {

				gl.bindFramebuffer( target, framebuffer );

				currentBoundFramebuffers[ target ] = framebuffer;

				// gl.DRAW_FRAMEBUFFER is equivalent to gl.FRAMEBUFFER

				if ( target === gl.DRAW_FRAMEBUFFER ) {

					currentBoundFramebuffers[ gl.FRAMEBUFFER ] = framebuffer;

				}

				if ( target === gl.FRAMEBUFFER ) {

					currentBoundFramebuffers[ gl.DRAW_FRAMEBUFFER ] = framebuffer;

				}

				return true;

			}

			return false;

		}

		function drawBuffers( renderTarget, framebuffer ) {

			let drawBuffers = defaultDrawbuffers;

			let needsUpdate = false;

			if ( renderTarget ) {

				drawBuffers = currentDrawbuffers.get( framebuffer );

				if ( drawBuffers === undefined ) {

					drawBuffers = [];
					currentDrawbuffers.set( framebuffer, drawBuffers );

				}

				const textures = renderTarget.textures;

				if ( drawBuffers.length !== textures.length || drawBuffers[ 0 ] !== gl.COLOR_ATTACHMENT0 ) {

					for ( let i = 0, il = textures.length; i < il; i ++ ) {

						drawBuffers[ i ] = gl.COLOR_ATTACHMENT0 + i;

					}

					drawBuffers.length = textures.length;

					needsUpdate = true;

				}

			} else {

				if ( drawBuffers[ 0 ] !== gl.BACK ) {

					drawBuffers[ 0 ] = gl.BACK;

					needsUpdate = true;

				}

			}

			if ( needsUpdate ) {

				gl.drawBuffers( drawBuffers );

			}

		}

		function useProgram( program ) {

			if ( currentProgram !== program ) {

				gl.useProgram( program );

				currentProgram = program;

				return true;

			}

			return false;

		}

		const equationToGL = {
			[ AddEquation ]: gl.FUNC_ADD,
			[ SubtractEquation ]: gl.FUNC_SUBTRACT,
			[ ReverseSubtractEquation ]: gl.FUNC_REVERSE_SUBTRACT
		};

		equationToGL[ MinEquation ] = gl.MIN;
		equationToGL[ MaxEquation ] = gl.MAX;

		const factorToGL = {
			[ ZeroFactor ]: gl.ZERO,
			[ OneFactor ]: gl.ONE,
			[ SrcColorFactor ]: gl.SRC_COLOR,
			[ SrcAlphaFactor ]: gl.SRC_ALPHA,
			[ SrcAlphaSaturateFactor ]: gl.SRC_ALPHA_SATURATE,
			[ DstColorFactor ]: gl.DST_COLOR,
			[ DstAlphaFactor ]: gl.DST_ALPHA,
			[ OneMinusSrcColorFactor ]: gl.ONE_MINUS_SRC_COLOR,
			[ OneMinusSrcAlphaFactor ]: gl.ONE_MINUS_SRC_ALPHA,
			[ OneMinusDstColorFactor ]: gl.ONE_MINUS_DST_COLOR,
			[ OneMinusDstAlphaFactor ]: gl.ONE_MINUS_DST_ALPHA,
			[ ConstantColorFactor ]: gl.CONSTANT_COLOR,
			[ OneMinusConstantColorFactor ]: gl.ONE_MINUS_CONSTANT_COLOR,
			[ ConstantAlphaFactor ]: gl.CONSTANT_ALPHA,
			[ OneMinusConstantAlphaFactor ]: gl.ONE_MINUS_CONSTANT_ALPHA
		};

		function setBlending( blending, blendEquation, blendSrc, blendDst, blendEquationAlpha, blendSrcAlpha, blendDstAlpha, blendColor, blendAlpha, premultipliedAlpha ) {

			if ( blending === NoBlending ) {

				if ( currentBlendingEnabled === true ) {

					disable( gl.BLEND );
					currentBlendingEnabled = false;

				}

				return;

			}

			if ( currentBlendingEnabled === false ) {

				enable( gl.BLEND );
				currentBlendingEnabled = true;

			}

			if ( blending !== CustomBlending ) {

				if ( blending !== currentBlending || premultipliedAlpha !== currentPremultipledAlpha ) {

					if ( currentBlendEquation !== AddEquation || currentBlendEquationAlpha !== AddEquation ) {

						gl.blendEquation( gl.FUNC_ADD );

						currentBlendEquation = AddEquation;
						currentBlendEquationAlpha = AddEquation;

					}

					if ( premultipliedAlpha ) {

						switch ( blending ) {

							case NormalBlending:
								gl.blendFuncSeparate( gl.ONE, gl.ONE_MINUS_SRC_ALPHA, gl.ONE, gl.ONE_MINUS_SRC_ALPHA );
								break;

							case AdditiveBlending:
								gl.blendFunc( gl.ONE, gl.ONE );
								break;

							case SubtractiveBlending:
								gl.blendFuncSeparate( gl.ZERO, gl.ONE_MINUS_SRC_COLOR, gl.ZERO, gl.ONE );
								break;

							case MultiplyBlending:
								gl.blendFuncSeparate( gl.ZERO, gl.SRC_COLOR, gl.ZERO, gl.SRC_ALPHA );
								break;

							default:
								console.error( 'THREE.WebGLState: Invalid blending: ', blending );
								break;

						}

					} else {

						switch ( blending ) {

							case NormalBlending:
								gl.blendFuncSeparate( gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA, gl.ONE, gl.ONE_MINUS_SRC_ALPHA );
								break;

							case AdditiveBlending:
								gl.blendFunc( gl.SRC_ALPHA, gl.ONE );
								break;

							case SubtractiveBlending:
								gl.blendFuncSeparate( gl.ZERO, gl.ONE_MINUS_SRC_COLOR, gl.ZERO, gl.ONE );
								break;

							case MultiplyBlending:
								gl.blendFunc( gl.ZERO, gl.SRC_COLOR );
								break;

							default:
								console.error( 'THREE.WebGLState: Invalid blending: ', blending );
								break;

						}

					}

					currentBlendSrc = null;
					currentBlendDst = null;
					currentBlendSrcAlpha = null;
					currentBlendDstAlpha = null;
					currentBlendColor.set( 0, 0, 0 );
					currentBlendAlpha = 0;

					currentBlending = blending;
					currentPremultipledAlpha = premultipliedAlpha;

				}

				return;

			}

			// custom blending

			blendEquationAlpha = blendEquationAlpha || blendEquation;
			blendSrcAlpha = blendSrcAlpha || blendSrc;
			blendDstAlpha = blendDstAlpha || blendDst;

			if ( blendEquation !== currentBlendEquation || blendEquationAlpha !== currentBlendEquationAlpha ) {

				gl.blendEquationSeparate( equationToGL[ blendEquation ], equationToGL[ blendEquationAlpha ] );

				currentBlendEquation = blendEquation;
				currentBlendEquationAlpha = blendEquationAlpha;

			}

			if ( blendSrc !== currentBlendSrc || blendDst !== currentBlendDst || blendSrcAlpha !== currentBlendSrcAlpha || blendDstAlpha !== currentBlendDstAlpha ) {

				gl.blendFuncSeparate( factorToGL[ blendSrc ], factorToGL[ blendDst ], factorToGL[ blendSrcAlpha ], factorToGL[ blendDstAlpha ] );

				currentBlendSrc = blendSrc;
				currentBlendDst = blendDst;
				currentBlendSrcAlpha = blendSrcAlpha;
				currentBlendDstAlpha = blendDstAlpha;

			}

			if ( blendColor.equals( currentBlendColor ) === false || blendAlpha !== currentBlendAlpha ) {

				gl.blendColor( blendColor.r, blendColor.g, blendColor.b, blendAlpha );

				currentBlendColor.copy( blendColor );
				currentBlendAlpha = blendAlpha;

			}

			currentBlending = blending;
			currentPremultipledAlpha = false;

		}

		function setMaterial( material, frontFaceCW ) {

			material.side === DoubleSide
				? disable( gl.CULL_FACE )
				: enable( gl.CULL_FACE );

			let flipSided = ( material.side === BackSide );
			if ( frontFaceCW ) flipSided = ! flipSided;

			setFlipSided( flipSided );

			( material.blending === NormalBlending && material.transparent === false )
				? setBlending( NoBlending )
				: setBlending( material.blending, material.blendEquation, material.blendSrc, material.blendDst, material.blendEquationAlpha, material.blendSrcAlpha, material.blendDstAlpha, material.blendColor, material.blendAlpha, material.premultipliedAlpha );

			depthBuffer.setFunc( material.depthFunc );
			depthBuffer.setTest( material.depthTest );
			depthBuffer.setMask( material.depthWrite );
			colorBuffer.setMask( material.colorWrite );

			const stencilWrite = material.stencilWrite;
			stencilBuffer.setTest( stencilWrite );
			if ( stencilWrite ) {

				stencilBuffer.setMask( material.stencilWriteMask );
				stencilBuffer.setFunc( material.stencilFunc, material.stencilRef, material.stencilFuncMask );
				stencilBuffer.setOp( material.stencilFail, material.stencilZFail, material.stencilZPass );

			}

			setPolygonOffset( material.polygonOffset, material.polygonOffsetFactor, material.polygonOffsetUnits );

			material.alphaToCoverage === true
				? enable( gl.SAMPLE_ALPHA_TO_COVERAGE )
				: disable( gl.SAMPLE_ALPHA_TO_COVERAGE );

		}

		//

		function setFlipSided( flipSided ) {

			if ( currentFlipSided !== flipSided ) {

				if ( flipSided ) {

					gl.frontFace( gl.CW );

				} else {

					gl.frontFace( gl.CCW );

				}

				currentFlipSided = flipSided;

			}

		}

		function setCullFace( cullFace ) {

			if ( cullFace !== CullFaceNone ) {

				enable( gl.CULL_FACE );

				if ( cullFace !== currentCullFace ) {

					if ( cullFace === CullFaceBack ) {

						gl.cullFace( gl.BACK );

					} else if ( cullFace === CullFaceFront ) {

						gl.cullFace( gl.FRONT );

					} else {

						gl.cullFace( gl.FRONT_AND_BACK );

					}

				}

			} else {

				disable( gl.CULL_FACE );

			}

			currentCullFace = cullFace;

		}

		function setLineWidth( width ) {

			if ( width !== currentLineWidth ) {

				if ( lineWidthAvailable ) gl.lineWidth( width );

				currentLineWidth = width;

			}

		}

		function setPolygonOffset( polygonOffset, factor, units ) {

			if ( polygonOffset ) {

				enable( gl.POLYGON_OFFSET_FILL );

				if ( currentPolygonOffsetFactor !== factor || currentPolygonOffsetUnits !== units ) {

					gl.polygonOffset( factor, units );

					currentPolygonOffsetFactor = factor;
					currentPolygonOffsetUnits = units;

				}

			} else {

				disable( gl.POLYGON_OFFSET_FILL );

			}

		}

		function setScissorTest( scissorTest ) {

			if ( scissorTest ) {

				enable( gl.SCISSOR_TEST );

			} else {

				disable( gl.SCISSOR_TEST );

			}

		}

		// texture

		function activeTexture( webglSlot ) {

			if ( webglSlot === undefined ) webglSlot = gl.TEXTURE0 + maxTextures - 1;

			if ( currentTextureSlot !== webglSlot ) {

				gl.activeTexture( webglSlot );
				currentTextureSlot = webglSlot;

			}

		}

		function bindTexture( webglType, webglTexture, webglSlot ) {

			if ( webglSlot === undefined ) {

				if ( currentTextureSlot === null ) {

					webglSlot = gl.TEXTURE0 + maxTextures - 1;

				} else {

					webglSlot = currentTextureSlot;

				}

			}

			let boundTexture = currentBoundTextures[ webglSlot ];

			if ( boundTexture === undefined ) {

				boundTexture = { type: undefined, texture: undefined };
				currentBoundTextures[ webglSlot ] = boundTexture;

			}

			if ( boundTexture.type !== webglType || boundTexture.texture !== webglTexture ) {

				if ( currentTextureSlot !== webglSlot ) {

					gl.activeTexture( webglSlot );
					currentTextureSlot = webglSlot;

				}

				gl.bindTexture( webglType, webglTexture || emptyTextures[ webglType ] );

				boundTexture.type = webglType;
				boundTexture.texture = webglTexture;

			}

		}

		function unbindTexture() {

			const boundTexture = currentBoundTextures[ currentTextureSlot ];

			if ( boundTexture !== undefined && boundTexture.type !== undefined ) {

				gl.bindTexture( boundTexture.type, null );

				boundTexture.type = undefined;
				boundTexture.texture = undefined;

			}

		}

		function compressedTexImage2D() {

			try {

				gl.compressedTexImage2D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function compressedTexImage3D() {

			try {

				gl.compressedTexImage3D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function texSubImage2D() {

			try {

				gl.texSubImage2D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function texSubImage3D() {

			try {

				gl.texSubImage3D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function compressedTexSubImage2D() {

			try {

				gl.compressedTexSubImage2D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function compressedTexSubImage3D() {

			try {

				gl.compressedTexSubImage3D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function texStorage2D() {

			try {

				gl.texStorage2D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function texStorage3D() {

			try {

				gl.texStorage3D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function texImage2D() {

			try {

				gl.texImage2D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		function texImage3D() {

			try {

				gl.texImage3D( ...arguments );

			} catch ( error ) {

				console.error( 'THREE.WebGLState:', error );

			}

		}

		//

		function scissor( scissor ) {

			if ( currentScissor.equals( scissor ) === false ) {

				gl.scissor( scissor.x, scissor.y, scissor.z, scissor.w );
				currentScissor.copy( scissor );

			}

		}

		function viewport( viewport ) {

			if ( currentViewport.equals( viewport ) === false ) {

				gl.viewport( viewport.x, viewport.y, viewport.z, viewport.w );
				currentViewport.copy( viewport );

			}

		}

		function updateUBOMapping( uniformsGroup, program ) {

			let mapping = uboProgramMap.get( program );

			if ( mapping === undefined ) {

				mapping = new WeakMap();

				uboProgramMap.set( program, mapping );

			}

			let blockIndex = mapping.get( uniformsGroup );

			if ( blockIndex === undefined ) {

				blockIndex = gl.getUniformBlockIndex( program, uniformsGroup.name );

				mapping.set( uniformsGroup, blockIndex );

			}

		}

		function uniformBlockBinding( uniformsGroup, program ) {

			const mapping = uboProgramMap.get( program );
			const blockIndex = mapping.get( uniformsGroup );

			if ( uboBindings.get( program ) !== blockIndex ) {

				// bind shader specific block index to global block point
				gl.uniformBlockBinding( program, blockIndex, uniformsGroup.__bindingPointIndex );

				uboBindings.set( program, blockIndex );

			}

		}

		//

		function reset() {

			// reset state

			gl.disable( gl.BLEND );
			gl.disable( gl.CULL_FACE );
			gl.disable( gl.DEPTH_TEST );
			gl.disable( gl.POLYGON_OFFSET_FILL );
			gl.disable( gl.SCISSOR_TEST );
			gl.disable( gl.STENCIL_TEST );
			gl.disable( gl.SAMPLE_ALPHA_TO_COVERAGE );

			gl.blendEquation( gl.FUNC_ADD );
			gl.blendFunc( gl.ONE, gl.ZERO );
			gl.blendFuncSeparate( gl.ONE, gl.ZERO, gl.ONE, gl.ZERO );
			gl.blendColor( 0, 0, 0, 0 );

			gl.colorMask( true, true, true, true );
			gl.clearColor( 0, 0, 0, 0 );

			gl.depthMask( true );
			gl.depthFunc( gl.LESS );

			depthBuffer.setReversed( false );

			gl.clearDepth( 1 );

			gl.stencilMask( 0xffffffff );
			gl.stencilFunc( gl.ALWAYS, 0, 0xffffffff );
			gl.stencilOp( gl.KEEP, gl.KEEP, gl.KEEP );
			gl.clearStencil( 0 );

			gl.cullFace( gl.BACK );
			gl.frontFace( gl.CCW );

			gl.polygonOffset( 0, 0 );

			gl.activeTexture( gl.TEXTURE0 );

			gl.bindFramebuffer( gl.FRAMEBUFFER, null );
			gl.bindFramebuffer( gl.DRAW_FRAMEBUFFER, null );
			gl.bindFramebuffer( gl.READ_FRAMEBUFFER, null );

			gl.useProgram( null );

			gl.lineWidth( 1 );

			gl.scissor( 0, 0, gl.canvas.width, gl.canvas.height );
			gl.viewport( 0, 0, gl.canvas.width, gl.canvas.height );

			// reset internals

			enabledCapabilities = {};

			currentTextureSlot = null;
			currentBoundTextures = {};

			currentBoundFramebuffers = {};
			currentDrawbuffers = new WeakMap();
			defaultDrawbuffers = [];

			currentProgram = null;

			currentBlendingEnabled = false;
			currentBlending = null;
			currentBlendEquation = null;
			currentBlendSrc = null;
			currentBlendDst = null;
			currentBlendEquationAlpha = null;
			currentBlendSrcAlpha = null;
			currentBlendDstAlpha = null;
			currentBlendColor = new Color( 0, 0, 0 );
			currentBlendAlpha = 0;
			currentPremultipledAlpha = false;

			currentFlipSided = null;
			currentCullFace = null;

			currentLineWidth = null;

			currentPolygonOffsetFactor = null;
			currentPolygonOffsetUnits = null;

			currentScissor.set( 0, 0, gl.canvas.width, gl.canvas.height );
			currentViewport.set( 0, 0, gl.canvas.width, gl.canvas.height );

			colorBuffer.reset();
			depthBuffer.reset();
			stencilBuffer.reset();

		}

		return {

			buffers: {
				color: colorBuffer,
				depth: depthBuffer,
				stencil: stencilBuffer
			},

			enable: enable,
			disable: disable,

			bindFramebuffer: bindFramebuffer,
			drawBuffers: drawBuffers,

			useProgram: useProgram,

			setBlending: setBlending,
			setMaterial: setMaterial,

			setFlipSided: setFlipSided,
			setCullFace: setCullFace,

			setLineWidth: setLineWidth,
			setPolygonOffset: setPolygonOffset,

			setScissorTest: setScissorTest,

			activeTexture: activeTexture,
			bindTexture: bindTexture,
			unbindTexture: unbindTexture,
			compressedTexImage2D: compressedTexImage2D,
			compressedTexImage3D: compressedTexImage3D,
			texImage2D: texImage2D,
			texImage3D: texImage3D,

			updateUBOMapping: updateUBOMapping,
			uniformBlockBinding: uniformBlockBinding,

			texStorage2D: texStorage2D,
			texStorage3D: texStorage3D,
			texSubImage2D: texSubImage2D,
			texSubImage3D: texSubImage3D,
			compressedTexSubImage2D: compressedTexSubImage2D,
			compressedTexSubImage3D: compressedTexSubImage3D,

			scissor: scissor,
			viewport: viewport,

			reset: reset

		};

	}

	function WebGLTextures( _gl, extensions, state, properties, capabilities, utils, info ) {

		const multisampledRTTExt = extensions.has( 'WEBGL_multisampled_render_to_texture' ) ? extensions.get( 'WEBGL_multisampled_render_to_texture' ) : null;
		const supportsInvalidateFramebuffer = typeof navigator === 'undefined' ? false : /OculusBrowser/g.test( navigator.userAgent );

		const _imageDimensions = new Vector2();
		const _videoTextures = new WeakMap();
		let _canvas;

		const _sources = new WeakMap(); // maps WebglTexture objects to instances of Source

		// cordova iOS (as of 5.0) still uses UIWebView, which provides OffscreenCanvas,
		// also OffscreenCanvas.getContext("webgl"), but not OffscreenCanvas.getContext("2d")!
		// Some implementations may only implement OffscreenCanvas partially (e.g. lacking 2d).

		let useOffscreenCanvas = false;

		try {

			useOffscreenCanvas = typeof OffscreenCanvas !== 'undefined'
				// eslint-disable-next-line compat/compat
				&& ( new OffscreenCanvas( 1, 1 ).getContext( '2d' ) ) !== null;

		} catch ( err ) {

			// Ignore any errors

		}

		function createCanvas( width, height ) {

			// Use OffscreenCanvas when available. Specially needed in web workers

			return useOffscreenCanvas ?
				// eslint-disable-next-line compat/compat
				new OffscreenCanvas( width, height ) : createElementNS( 'canvas' );

		}

		function resizeImage( image, needsNewCanvas, maxSize ) {

			let scale = 1;

			const dimensions = getDimensions( image );

			// handle case if texture exceeds max size

			if ( dimensions.width > maxSize || dimensions.height > maxSize ) {

				scale = maxSize / Math.max( dimensions.width, dimensions.height );

			}

			// only perform resize if necessary

			if ( scale < 1 ) {

				// only perform resize for certain image types

				if ( ( typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement ) ||
					( typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement ) ||
					( typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap ) ||
					( typeof VideoFrame !== 'undefined' && image instanceof VideoFrame ) ) {

					const width = Math.floor( scale * dimensions.width );
					const height = Math.floor( scale * dimensions.height );

					if ( _canvas === undefined ) _canvas = createCanvas( width, height );

					// cube textures can't reuse the same canvas

					const canvas = needsNewCanvas ? createCanvas( width, height ) : _canvas;

					canvas.width = width;
					canvas.height = height;

					const context = canvas.getContext( '2d' );
					context.drawImage( image, 0, 0, width, height );

					console.warn( 'THREE.WebGLRenderer: Texture has been resized from (' + dimensions.width + 'x' + dimensions.height + ') to (' + width + 'x' + height + ').' );

					return canvas;

				} else {

					if ( 'data' in image ) {

						console.warn( 'THREE.WebGLRenderer: Image in DataTexture is too big (' + dimensions.width + 'x' + dimensions.height + ').' );

					}

					return image;

				}

			}

			return image;

		}

		function textureNeedsGenerateMipmaps( texture ) {

			return texture.generateMipmaps;

		}

		function generateMipmap( target ) {

			_gl.generateMipmap( target );

		}

		function getTargetType( texture ) {

			if ( texture.isWebGLCubeRenderTarget ) return _gl.TEXTURE_CUBE_MAP;
			if ( texture.isWebGL3DRenderTarget ) return _gl.TEXTURE_3D;
			if ( texture.isWebGLArrayRenderTarget || texture.isCompressedArrayTexture ) return _gl.TEXTURE_2D_ARRAY;
			return _gl.TEXTURE_2D;

		}

		function getInternalFormat( internalFormatName, glFormat, glType, colorSpace, forceLinearTransfer = false ) {

			if ( internalFormatName !== null ) {

				if ( _gl[ internalFormatName ] !== undefined ) return _gl[ internalFormatName ];

				console.warn( 'THREE.WebGLRenderer: Attempt to use non-existing WebGL internal format \'' + internalFormatName + '\'' );

			}

			let internalFormat = glFormat;

			if ( glFormat === _gl.RED ) {

				if ( glType === _gl.FLOAT ) internalFormat = _gl.R32F;
				if ( glType === _gl.HALF_FLOAT ) internalFormat = _gl.R16F;
				if ( glType === _gl.UNSIGNED_BYTE ) internalFormat = _gl.R8;

			}

			if ( glFormat === _gl.RED_INTEGER ) {

				if ( glType === _gl.UNSIGNED_BYTE ) internalFormat = _gl.R8UI;
				if ( glType === _gl.UNSIGNED_SHORT ) internalFormat = _gl.R16UI;
				if ( glType === _gl.UNSIGNED_INT ) internalFormat = _gl.R32UI;
				if ( glType === _gl.BYTE ) internalFormat = _gl.R8I;
				if ( glType === _gl.SHORT ) internalFormat = _gl.R16I;
				if ( glType === _gl.INT ) internalFormat = _gl.R32I;

			}

			if ( glFormat === _gl.RG ) {

				if ( glType === _gl.FLOAT ) internalFormat = _gl.RG32F;
				if ( glType === _gl.HALF_FLOAT ) internalFormat = _gl.RG16F;
				if ( glType === _gl.UNSIGNED_BYTE ) internalFormat = _gl.RG8;

			}

			if ( glFormat === _gl.RG_INTEGER ) {

				if ( glType === _gl.UNSIGNED_BYTE ) internalFormat = _gl.RG8UI;
				if ( glType === _gl.UNSIGNED_SHORT ) internalFormat = _gl.RG16UI;
				if ( glType === _gl.UNSIGNED_INT ) internalFormat = _gl.RG32UI;
				if ( glType === _gl.BYTE ) internalFormat = _gl.RG8I;
				if ( glType === _gl.SHORT ) internalFormat = _gl.RG16I;
				if ( glType === _gl.INT ) internalFormat = _gl.RG32I;

			}

			if ( glFormat === _gl.RGB_INTEGER ) {

				if ( glType === _gl.UNSIGNED_BYTE ) internalFormat = _gl.RGB8UI;
				if ( glType === _gl.UNSIGNED_SHORT ) internalFormat = _gl.RGB16UI;
				if ( glType === _gl.UNSIGNED_INT ) internalFormat = _gl.RGB32UI;
				if ( glType === _gl.BYTE ) internalFormat = _gl.RGB8I;
				if ( glType === _gl.SHORT ) internalFormat = _gl.RGB16I;
				if ( glType === _gl.INT ) internalFormat = _gl.RGB32I;

			}

			if ( glFormat === _gl.RGBA_INTEGER ) {

				if ( glType === _gl.UNSIGNED_BYTE ) internalFormat = _gl.RGBA8UI;
				if ( glType === _gl.UNSIGNED_SHORT ) internalFormat = _gl.RGBA16UI;
				if ( glType === _gl.UNSIGNED_INT ) internalFormat = _gl.RGBA32UI;
				if ( glType === _gl.BYTE ) internalFormat = _gl.RGBA8I;
				if ( glType === _gl.SHORT ) internalFormat = _gl.RGBA16I;
				if ( glType === _gl.INT ) internalFormat = _gl.RGBA32I;

			}

			if ( glFormat === _gl.RGB ) {

				if ( glType === _gl.UNSIGNED_INT_5_9_9_9_REV ) internalFormat = _gl.RGB9_E5;

			}

			if ( glFormat === _gl.RGBA ) {

				const transfer = forceLinearTransfer ? LinearTransfer : ColorManagement.getTransfer( colorSpace );

				if ( glType === _gl.FLOAT ) internalFormat = _gl.RGBA32F;
				if ( glType === _gl.HALF_FLOAT ) internalFormat = _gl.RGBA16F;
				if ( glType === _gl.UNSIGNED_BYTE ) internalFormat = ( transfer === SRGBTransfer ) ? _gl.SRGB8_ALPHA8 : _gl.RGBA8;
				if ( glType === _gl.UNSIGNED_SHORT_4_4_4_4 ) internalFormat = _gl.RGBA4;
				if ( glType === _gl.UNSIGNED_SHORT_5_5_5_1 ) internalFormat = _gl.RGB5_A1;

			}

			if ( internalFormat === _gl.R16F || internalFormat === _gl.R32F ||
				internalFormat === _gl.RG16F || internalFormat === _gl.RG32F ||
				internalFormat === _gl.RGBA16F || internalFormat === _gl.RGBA32F ) {

				extensions.get( 'EXT_color_buffer_float' );

			}

			return internalFormat;

		}

		function getInternalDepthFormat( useStencil, depthType ) {

			let glInternalFormat;
			if ( useStencil ) {

				if ( depthType === null || depthType === UnsignedIntType || depthType === UnsignedInt248Type ) {

					glInternalFormat = _gl.DEPTH24_STENCIL8;

				} else if ( depthType === FloatType ) {

					glInternalFormat = _gl.DEPTH32F_STENCIL8;

				} else if ( depthType === UnsignedShortType ) {

					glInternalFormat = _gl.DEPTH24_STENCIL8;
					console.warn( 'DepthTexture: 16 bit depth attachment is not supported with stencil. Using 24-bit attachment.' );

				}

			} else {

				if ( depthType === null || depthType === UnsignedIntType || depthType === UnsignedInt248Type ) {

					glInternalFormat = _gl.DEPTH_COMPONENT24;

				} else if ( depthType === FloatType ) {

					glInternalFormat = _gl.DEPTH_COMPONENT32F;

				} else if ( depthType === UnsignedShortType ) {

					glInternalFormat = _gl.DEPTH_COMPONENT16;

				}

			}

			return glInternalFormat;

		}

		function getMipLevels( texture, image ) {

			if ( textureNeedsGenerateMipmaps( texture ) === true || ( texture.isFramebufferTexture && texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter ) ) {

				return Math.log2( Math.max( image.width, image.height ) ) + 1;

			} else if ( texture.mipmaps !== undefined && texture.mipmaps.length > 0 ) {

				// user-defined mipmaps

				return texture.mipmaps.length;

			} else if ( texture.isCompressedTexture && Array.isArray( texture.image ) ) {

				return image.mipmaps.length;

			} else {

				// texture without mipmaps (only base level)

				return 1;

			}

		}

		//

		function onTextureDispose( event ) {

			const texture = event.target;

			texture.removeEventListener( 'dispose', onTextureDispose );

			deallocateTexture( texture );

			if ( texture.isVideoTexture ) {

				_videoTextures.delete( texture );

			}

		}

		function onRenderTargetDispose( event ) {

			const renderTarget = event.target;

			renderTarget.removeEventListener( 'dispose', onRenderTargetDispose );

			deallocateRenderTarget( renderTarget );

		}

		//

		function deallocateTexture( texture ) {

			const textureProperties = properties.get( texture );

			if ( textureProperties.__webglInit === undefined ) return;

			// check if it's necessary to remove the WebGLTexture object

			const source = texture.source;
			const webglTextures = _sources.get( source );

			if ( webglTextures ) {

				const webglTexture = webglTextures[ textureProperties.__cacheKey ];
				webglTexture.usedTimes --;

				// the WebGLTexture object is not used anymore, remove it

				if ( webglTexture.usedTimes === 0 ) {

					deleteTexture( texture );

				}

				// remove the weak map entry if no WebGLTexture uses the source anymore

				if ( Object.keys( webglTextures ).length === 0 ) {

					_sources.delete( source );

				}

			}

			properties.remove( texture );

		}

		function deleteTexture( texture ) {

			const textureProperties = properties.get( texture );
			_gl.deleteTexture( textureProperties.__webglTexture );

			const source = texture.source;
			const webglTextures = _sources.get( source );
			delete webglTextures[ textureProperties.__cacheKey ];

			info.memory.textures --;

		}

		function deallocateRenderTarget( renderTarget ) {

			const renderTargetProperties = properties.get( renderTarget );

			if ( renderTarget.depthTexture ) {

				renderTarget.depthTexture.dispose();

				properties.remove( renderTarget.depthTexture );

			}

			if ( renderTarget.isWebGLCubeRenderTarget ) {

				for ( let i = 0; i < 6; i ++ ) {

					if ( Array.isArray( renderTargetProperties.__webglFramebuffer[ i ] ) ) {

						for ( let level = 0; level < renderTargetProperties.__webglFramebuffer[ i ].length; level ++ ) _gl.deleteFramebuffer( renderTargetProperties.__webglFramebuffer[ i ][ level ] );

					} else {

						_gl.deleteFramebuffer( renderTargetProperties.__webglFramebuffer[ i ] );

					}

					if ( renderTargetProperties.__webglDepthbuffer ) _gl.deleteRenderbuffer( renderTargetProperties.__webglDepthbuffer[ i ] );

				}

			} else {

				if ( Array.isArray( renderTargetProperties.__webglFramebuffer ) ) {

					for ( let level = 0; level < renderTargetProperties.__webglFramebuffer.length; level ++ ) _gl.deleteFramebuffer( renderTargetProperties.__webglFramebuffer[ level ] );

				} else {

					_gl.deleteFramebuffer( renderTargetProperties.__webglFramebuffer );

				}

				if ( renderTargetProperties.__webglDepthbuffer ) _gl.deleteRenderbuffer( renderTargetProperties.__webglDepthbuffer );
				if ( renderTargetProperties.__webglMultisampledFramebuffer ) _gl.deleteFramebuffer( renderTargetProperties.__webglMultisampledFramebuffer );

				if ( renderTargetProperties.__webglColorRenderbuffer ) {

					for ( let i = 0; i < renderTargetProperties.__webglColorRenderbuffer.length; i ++ ) {

						if ( renderTargetProperties.__webglColorRenderbuffer[ i ] ) _gl.deleteRenderbuffer( renderTargetProperties.__webglColorRenderbuffer[ i ] );

					}

				}

				if ( renderTargetProperties.__webglDepthRenderbuffer ) _gl.deleteRenderbuffer( renderTargetProperties.__webglDepthRenderbuffer );

			}

			const textures = renderTarget.textures;

			for ( let i = 0, il = textures.length; i < il; i ++ ) {

				const attachmentProperties = properties.get( textures[ i ] );

				if ( attachmentProperties.__webglTexture ) {

					_gl.deleteTexture( attachmentProperties.__webglTexture );

					info.memory.textures --;

				}

				properties.remove( textures[ i ] );

			}

			properties.remove( renderTarget );

		}

		//

		let textureUnits = 0;

		function resetTextureUnits() {

			textureUnits = 0;

		}

		function allocateTextureUnit() {

			const textureUnit = textureUnits;

			if ( textureUnit >= capabilities.maxTextures ) {

				console.warn( 'THREE.WebGLTextures: Trying to use ' + textureUnit + ' texture units while this GPU supports only ' + capabilities.maxTextures );

			}

			textureUnits += 1;

			return textureUnit;

		}

		function getTextureCacheKey( texture ) {

			const array = [];

			array.push( texture.wrapS );
			array.push( texture.wrapT );
			array.push( texture.wrapR || 0 );
			array.push( texture.magFilter );
			array.push( texture.minFilter );
			array.push( texture.anisotropy );
			array.push( texture.internalFormat );
			array.push( texture.format );
			array.push( texture.type );
			array.push( texture.generateMipmaps );
			array.push( texture.premultiplyAlpha );
			array.push( texture.flipY );
			array.push( texture.unpackAlignment );
			array.push( texture.colorSpace );

			return array.join();

		}

		//

		function setTexture2D( texture, slot ) {

			const textureProperties = properties.get( texture );

			if ( texture.isVideoTexture ) updateVideoTexture( texture );

			if ( texture.isRenderTargetTexture === false && texture.version > 0 && textureProperties.__version !== texture.version ) {

				const image = texture.image;

				if ( image === null ) {

					console.warn( 'THREE.WebGLRenderer: Texture marked for update but no image data found.' );

				} else if ( image.complete === false ) {

					console.warn( 'THREE.WebGLRenderer: Texture marked for update but image is incomplete' );

				} else {

					uploadTexture( textureProperties, texture, slot );
					return;

				}

			}

			state.bindTexture( _gl.TEXTURE_2D, textureProperties.__webglTexture, _gl.TEXTURE0 + slot );

		}

		function setTexture2DArray( texture, slot ) {

			const textureProperties = properties.get( texture );

			if ( texture.version > 0 && textureProperties.__version !== texture.version ) {

				uploadTexture( textureProperties, texture, slot );
				return;

			}

			state.bindTexture( _gl.TEXTURE_2D_ARRAY, textureProperties.__webglTexture, _gl.TEXTURE0 + slot );

		}

		function setTexture3D( texture, slot ) {

			const textureProperties = properties.get( texture );

			if ( texture.version > 0 && textureProperties.__version !== texture.version ) {

				uploadTexture( textureProperties, texture, slot );
				return;

			}

			state.bindTexture( _gl.TEXTURE_3D, textureProperties.__webglTexture, _gl.TEXTURE0 + slot );

		}

		function setTextureCube( texture, slot ) {

			const textureProperties = properties.get( texture );

			if ( texture.version > 0 && textureProperties.__version !== texture.version ) {

				uploadCubeTexture( textureProperties, texture, slot );
				return;

			}

			state.bindTexture( _gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture, _gl.TEXTURE0 + slot );

		}

		const wrappingToGL = {
			[ RepeatWrapping ]: _gl.REPEAT,
			[ ClampToEdgeWrapping ]: _gl.CLAMP_TO_EDGE,
			[ MirroredRepeatWrapping ]: _gl.MIRRORED_REPEAT
		};

		const filterToGL = {
			[ NearestFilter ]: _gl.NEAREST,
			[ NearestMipmapNearestFilter ]: _gl.NEAREST_MIPMAP_NEAREST,
			[ NearestMipmapLinearFilter ]: _gl.NEAREST_MIPMAP_LINEAR,

			[ LinearFilter ]: _gl.LINEAR,
			[ LinearMipmapNearestFilter ]: _gl.LINEAR_MIPMAP_NEAREST,
			[ LinearMipmapLinearFilter ]: _gl.LINEAR_MIPMAP_LINEAR
		};

		const compareToGL = {
			[ NeverCompare ]: _gl.NEVER,
			[ AlwaysCompare ]: _gl.ALWAYS,
			[ LessCompare ]: _gl.LESS,
			[ LessEqualCompare ]: _gl.LEQUAL,
			[ EqualCompare ]: _gl.EQUAL,
			[ GreaterEqualCompare ]: _gl.GEQUAL,
			[ GreaterCompare ]: _gl.GREATER,
			[ NotEqualCompare ]: _gl.NOTEQUAL
		};

		function setTextureParameters( textureType, texture ) {

			if ( texture.type === FloatType && extensions.has( 'OES_texture_float_linear' ) === false &&
				( texture.magFilter === LinearFilter || texture.magFilter === LinearMipmapNearestFilter || texture.magFilter === NearestMipmapLinearFilter || texture.magFilter === LinearMipmapLinearFilter ||
				texture.minFilter === LinearFilter || texture.minFilter === LinearMipmapNearestFilter || texture.minFilter === NearestMipmapLinearFilter || texture.minFilter === LinearMipmapLinearFilter ) ) {

				console.warn( 'THREE.WebGLRenderer: Unable to use linear filtering with floating point textures. OES_texture_float_linear not supported on this device.' );

			}

			_gl.texParameteri( textureType, _gl.TEXTURE_WRAP_S, wrappingToGL[ texture.wrapS ] );
			_gl.texParameteri( textureType, _gl.TEXTURE_WRAP_T, wrappingToGL[ texture.wrapT ] );

			if ( textureType === _gl.TEXTURE_3D || textureType === _gl.TEXTURE_2D_ARRAY ) {

				_gl.texParameteri( textureType, _gl.TEXTURE_WRAP_R, wrappingToGL[ texture.wrapR ] );

			}

			_gl.texParameteri( textureType, _gl.TEXTURE_MAG_FILTER, filterToGL[ texture.magFilter ] );
			_gl.texParameteri( textureType, _gl.TEXTURE_MIN_FILTER, filterToGL[ texture.minFilter ] );

			if ( texture.compareFunction ) {

				_gl.texParameteri( textureType, _gl.TEXTURE_COMPARE_MODE, _gl.COMPARE_REF_TO_TEXTURE );
				_gl.texParameteri( textureType, _gl.TEXTURE_COMPARE_FUNC, compareToGL[ texture.compareFunction ] );

			}

			if ( extensions.has( 'EXT_texture_filter_anisotropic' ) === true ) {

				if ( texture.magFilter === NearestFilter ) return;
				if ( texture.minFilter !== NearestMipmapLinearFilter && texture.minFilter !== LinearMipmapLinearFilter ) return;
				if ( texture.type === FloatType && extensions.has( 'OES_texture_float_linear' ) === false ) return; // verify extension

				if ( texture.anisotropy > 1 || properties.get( texture ).__currentAnisotropy ) {

					const extension = extensions.get( 'EXT_texture_filter_anisotropic' );
					_gl.texParameterf( textureType, extension.TEXTURE_MAX_ANISOTROPY_EXT, Math.min( texture.anisotropy, capabilities.getMaxAnisotropy() ) );
					properties.get( texture ).__currentAnisotropy = texture.anisotropy;

				}

			}

		}

		function initTexture( textureProperties, texture ) {

			let forceUpload = false;

			if ( textureProperties.__webglInit === undefined ) {

				textureProperties.__webglInit = true;

				texture.addEventListener( 'dispose', onTextureDispose );

			}

			// create Source <-> WebGLTextures mapping if necessary

			const source = texture.source;
			let webglTextures = _sources.get( source );

			if ( webglTextures === undefined ) {

				webglTextures = {};
				_sources.set( source, webglTextures );

			}

			// check if there is already a WebGLTexture object for the given texture parameters

			const textureCacheKey = getTextureCacheKey( texture );

			if ( textureCacheKey !== textureProperties.__cacheKey ) {

				// if not, create a new instance of WebGLTexture

				if ( webglTextures[ textureCacheKey ] === undefined ) {

					// create new entry

					webglTextures[ textureCacheKey ] = {
						texture: _gl.createTexture(),
						usedTimes: 0
					};

					info.memory.textures ++;

					// when a new instance of WebGLTexture was created, a texture upload is required
					// even if the image contents are identical

					forceUpload = true;

				}

				webglTextures[ textureCacheKey ].usedTimes ++;

				// every time the texture cache key changes, it's necessary to check if an instance of
				// WebGLTexture can be deleted in order to avoid a memory leak.

				const webglTexture = webglTextures[ textureProperties.__cacheKey ];

				if ( webglTexture !== undefined ) {

					webglTextures[ textureProperties.__cacheKey ].usedTimes --;

					if ( webglTexture.usedTimes === 0 ) {

						deleteTexture( texture );

					}

				}

				// store references to cache key and WebGLTexture object

				textureProperties.__cacheKey = textureCacheKey;
				textureProperties.__webglTexture = webglTextures[ textureCacheKey ].texture;

			}

			return forceUpload;

		}

		function getRow( index, rowLength, componentStride ) {

			return Math.floor( Math.floor( index / componentStride ) / rowLength );

		}

		function updateTexture( texture, image, glFormat, glType ) {

			const componentStride = 4; // only RGBA supported

			const updateRanges = texture.updateRanges;

			if ( updateRanges.length === 0 ) {

				state.texSubImage2D( _gl.TEXTURE_2D, 0, 0, 0, image.width, image.height, glFormat, glType, image.data );

			} else {

				// Before applying update ranges, we merge any adjacent / overlapping
				// ranges to reduce load on `gl.texSubImage2D`. Empirically, this has led
				// to performance improvements for applications which make heavy use of
				// update ranges. Likely due to GPU command overhead.
				//
				// Note that to reduce garbage collection between frames, we merge the
				// update ranges in-place. This is safe because this method will clear the
				// update ranges once updated.

				updateRanges.sort( ( a, b ) => a.start - b.start );

				// To merge the update ranges in-place, we work from left to right in the
				// existing updateRanges array, merging ranges. This may result in a final
				// array which is smaller than the original. This index tracks the last
				// index representing a merged range, any data after this index can be
				// trimmed once the merge algorithm is completed.
				let mergeIndex = 0;

				for ( let i = 1; i < updateRanges.length; i ++ ) {

					const previousRange = updateRanges[ mergeIndex ];
					const range = updateRanges[ i ];

					// Only merge if in the same row and overlapping/adjacent
					const previousEnd = previousRange.start + previousRange.count;
					const currentRow = getRow( range.start, image.width, componentStride );
					const previousRow = getRow( previousRange.start, image.width, componentStride );

					// We add one here to merge adjacent ranges. This is safe because ranges
					// operate over positive integers.
					if (
						range.start <= previousEnd + 1 &&
						currentRow === previousRow &&
						getRow( range.start + range.count - 1, image.width, componentStride ) === currentRow // ensure range doesn't spill
					) {

						previousRange.count = Math.max(
							previousRange.count,
							range.start + range.count - previousRange.start
						);

					} else {

						++ mergeIndex;
						updateRanges[ mergeIndex ] = range;

					}


				}

				// Trim the array to only contain the merged ranges.
				updateRanges.length = mergeIndex + 1;

				const currentUnpackRowLen = _gl.getParameter( _gl.UNPACK_ROW_LENGTH );
				const currentUnpackSkipPixels = _gl.getParameter( _gl.UNPACK_SKIP_PIXELS );
				const currentUnpackSkipRows = _gl.getParameter( _gl.UNPACK_SKIP_ROWS );

				_gl.pixelStorei( _gl.UNPACK_ROW_LENGTH, image.width );

				for ( let i = 0, l = updateRanges.length; i < l; i ++ ) {

					const range = updateRanges[ i ];

					const pixelStart = Math.floor( range.start / componentStride );
					const pixelCount = Math.ceil( range.count / componentStride );

					const x = pixelStart % image.width;
					const y = Math.floor( pixelStart / image.width );

					// Assumes update ranges refer to contiguous memory
					const width = pixelCount;
					const height = 1;

					_gl.pixelStorei( _gl.UNPACK_SKIP_PIXELS, x );
					_gl.pixelStorei( _gl.UNPACK_SKIP_ROWS, y );

					state.texSubImage2D( _gl.TEXTURE_2D, 0, x, y, width, height, glFormat, glType, image.data );

				}

				texture.clearUpdateRanges();

				_gl.pixelStorei( _gl.UNPACK_ROW_LENGTH, currentUnpackRowLen );
				_gl.pixelStorei( _gl.UNPACK_SKIP_PIXELS, currentUnpackSkipPixels );
				_gl.pixelStorei( _gl.UNPACK_SKIP_ROWS, currentUnpackSkipRows );

			}

		}

		function uploadTexture( textureProperties, texture, slot ) {

			let textureType = _gl.TEXTURE_2D;

			if ( texture.isDataArrayTexture || texture.isCompressedArrayTexture ) textureType = _gl.TEXTURE_2D_ARRAY;
			if ( texture.isData3DTexture ) textureType = _gl.TEXTURE_3D;

			const forceUpload = initTexture( textureProperties, texture );
			const source = texture.source;

			state.bindTexture( textureType, textureProperties.__webglTexture, _gl.TEXTURE0 + slot );

			const sourceProperties = properties.get( source );

			if ( source.version !== sourceProperties.__version || forceUpload === true ) {

				state.activeTexture( _gl.TEXTURE0 + slot );

				const workingPrimaries = ColorManagement.getPrimaries( ColorManagement.workingColorSpace );
				const texturePrimaries = texture.colorSpace === NoColorSpace ? null : ColorManagement.getPrimaries( texture.colorSpace );
				const unpackConversion = texture.colorSpace === NoColorSpace || workingPrimaries === texturePrimaries ? _gl.NONE : _gl.BROWSER_DEFAULT_WEBGL;

				_gl.pixelStorei( _gl.UNPACK_FLIP_Y_WEBGL, texture.flipY );
				_gl.pixelStorei( _gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, texture.premultiplyAlpha );
				_gl.pixelStorei( _gl.UNPACK_ALIGNMENT, texture.unpackAlignment );
				_gl.pixelStorei( _gl.UNPACK_COLORSPACE_CONVERSION_WEBGL, unpackConversion );

				let image = resizeImage( texture.image, false, capabilities.maxTextureSize );
				image = verifyColorSpace( texture, image );

				const glFormat = utils.convert( texture.format, texture.colorSpace );

				const glType = utils.convert( texture.type );
				let glInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.colorSpace, texture.isVideoTexture );

				setTextureParameters( textureType, texture );

				let mipmap;
				const mipmaps = texture.mipmaps;

				const useTexStorage = ( texture.isVideoTexture !== true );
				const allocateMemory = ( sourceProperties.__version === undefined ) || ( forceUpload === true );
				const dataReady = source.dataReady;
				const levels = getMipLevels( texture, image );

				if ( texture.isDepthTexture ) {

					glInternalFormat = getInternalDepthFormat( texture.format === DepthStencilFormat, texture.type );

					//

					if ( allocateMemory ) {

						if ( useTexStorage ) {

							state.texStorage2D( _gl.TEXTURE_2D, 1, glInternalFormat, image.width, image.height );

						} else {

							state.texImage2D( _gl.TEXTURE_2D, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, null );

						}

					}

				} else if ( texture.isDataTexture ) {

					// use manually created mipmaps if available
					// if there are no manual mipmaps
					// set 0 level mipmap and then use GL to generate other mipmap levels

					if ( mipmaps.length > 0 ) {

						if ( useTexStorage && allocateMemory ) {

							state.texStorage2D( _gl.TEXTURE_2D, levels, glInternalFormat, mipmaps[ 0 ].width, mipmaps[ 0 ].height );

						}

						for ( let i = 0, il = mipmaps.length; i < il; i ++ ) {

							mipmap = mipmaps[ i ];

							if ( useTexStorage ) {

								if ( dataReady ) {

									state.texSubImage2D( _gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data );

								}

							} else {

								state.texImage2D( _gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data );

							}

						}

						texture.generateMipmaps = false;

					} else {

						if ( useTexStorage ) {

							if ( allocateMemory ) {

								state.texStorage2D( _gl.TEXTURE_2D, levels, glInternalFormat, image.width, image.height );

							}

							if ( dataReady ) {

								updateTexture( texture, image, glFormat, glType );

							}

						} else {

							state.texImage2D( _gl.TEXTURE_2D, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, image.data );

						}

					}

				} else if ( texture.isCompressedTexture ) {

					if ( texture.isCompressedArrayTexture ) {

						if ( useTexStorage && allocateMemory ) {

							state.texStorage3D( _gl.TEXTURE_2D_ARRAY, levels, glInternalFormat, mipmaps[ 0 ].width, mipmaps[ 0 ].height, image.depth );

						}

						for ( let i = 0, il = mipmaps.length; i < il; i ++ ) {

							mipmap = mipmaps[ i ];

							if ( texture.format !== RGBAFormat ) {

								if ( glFormat !== null ) {

									if ( useTexStorage ) {

										if ( dataReady ) {

											if ( texture.layerUpdates.size > 0 ) {

												const layerByteLength = getByteLength( mipmap.width, mipmap.height, texture.format, texture.type );

												for ( const layerIndex of texture.layerUpdates ) {

													const layerData = mipmap.data.subarray(
														layerIndex * layerByteLength / mipmap.data.BYTES_PER_ELEMENT,
														( layerIndex + 1 ) * layerByteLength / mipmap.data.BYTES_PER_ELEMENT
													);
													state.compressedTexSubImage3D( _gl.TEXTURE_2D_ARRAY, i, 0, 0, layerIndex, mipmap.width, mipmap.height, 1, glFormat, layerData );

												}

												texture.clearLayerUpdates();

											} else {

												state.compressedTexSubImage3D( _gl.TEXTURE_2D_ARRAY, i, 0, 0, 0, mipmap.width, mipmap.height, image.depth, glFormat, mipmap.data );

											}

										}

									} else {

										state.compressedTexImage3D( _gl.TEXTURE_2D_ARRAY, i, glInternalFormat, mipmap.width, mipmap.height, image.depth, 0, mipmap.data, 0, 0 );

									}

								} else {

									console.warn( 'THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .uploadTexture()' );

								}

							} else {

								if ( useTexStorage ) {

									if ( dataReady ) {

										state.texSubImage3D( _gl.TEXTURE_2D_ARRAY, i, 0, 0, 0, mipmap.width, mipmap.height, image.depth, glFormat, glType, mipmap.data );

									}

								} else {

									state.texImage3D( _gl.TEXTURE_2D_ARRAY, i, glInternalFormat, mipmap.width, mipmap.height, image.depth, 0, glFormat, glType, mipmap.data );

								}

							}

						}

					} else {

						if ( useTexStorage && allocateMemory ) {

							state.texStorage2D( _gl.TEXTURE_2D, levels, glInternalFormat, mipmaps[ 0 ].width, mipmaps[ 0 ].height );

						}

						for ( let i = 0, il = mipmaps.length; i < il; i ++ ) {

							mipmap = mipmaps[ i ];

							if ( texture.format !== RGBAFormat ) {

								if ( glFormat !== null ) {

									if ( useTexStorage ) {

										if ( dataReady ) {

											state.compressedTexSubImage2D( _gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, mipmap.data );

										}

									} else {

										state.compressedTexImage2D( _gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, mipmap.data );

									}

								} else {

									console.warn( 'THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .uploadTexture()' );

								}

							} else {

								if ( useTexStorage ) {

									if ( dataReady ) {

										state.texSubImage2D( _gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data );

									}

								} else {

									state.texImage2D( _gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data );

								}

							}

						}

					}

				} else if ( texture.isDataArrayTexture ) {

					if ( useTexStorage ) {

						if ( allocateMemory ) {

							state.texStorage3D( _gl.TEXTURE_2D_ARRAY, levels, glInternalFormat, image.width, image.height, image.depth );

						}

						if ( dataReady ) {

							if ( texture.layerUpdates.size > 0 ) {

								const layerByteLength = getByteLength( image.width, image.height, texture.format, texture.type );

								for ( const layerIndex of texture.layerUpdates ) {

									const layerData = image.data.subarray(
										layerIndex * layerByteLength / image.data.BYTES_PER_ELEMENT,
										( layerIndex + 1 ) * layerByteLength / image.data.BYTES_PER_ELEMENT
									);
									state.texSubImage3D( _gl.TEXTURE_2D_ARRAY, 0, 0, 0, layerIndex, image.width, image.height, 1, glFormat, glType, layerData );

								}

								texture.clearLayerUpdates();

							} else {

								state.texSubImage3D( _gl.TEXTURE_2D_ARRAY, 0, 0, 0, 0, image.width, image.height, image.depth, glFormat, glType, image.data );

							}

						}

					} else {

						state.texImage3D( _gl.TEXTURE_2D_ARRAY, 0, glInternalFormat, image.width, image.height, image.depth, 0, glFormat, glType, image.data );

					}

				} else if ( texture.isData3DTexture ) {

					if ( useTexStorage ) {

						if ( allocateMemory ) {

							state.texStorage3D( _gl.TEXTURE_3D, levels, glInternalFormat, image.width, image.height, image.depth );

						}

						if ( dataReady ) {

							state.texSubImage3D( _gl.TEXTURE_3D, 0, 0, 0, 0, image.width, image.height, image.depth, glFormat, glType, image.data );

						}

					} else {

						state.texImage3D( _gl.TEXTURE_3D, 0, glInternalFormat, image.width, image.height, image.depth, 0, glFormat, glType, image.data );

					}

				} else if ( texture.isFramebufferTexture ) {

					if ( allocateMemory ) {

						if ( useTexStorage ) {

							state.texStorage2D( _gl.TEXTURE_2D, levels, glInternalFormat, image.width, image.height );

						} else {

							let width = image.width, height = image.height;

							for ( let i = 0; i < levels; i ++ ) {

								state.texImage2D( _gl.TEXTURE_2D, i, glInternalFormat, width, height, 0, glFormat, glType, null );

								width >>= 1;
								height >>= 1;

							}

						}

					}

				} else {

					// regular Texture (image, video, canvas)

					// use manually created mipmaps if available
					// if there are no manual mipmaps
					// set 0 level mipmap and then use GL to generate other mipmap levels

					if ( mipmaps.length > 0 ) {

						if ( useTexStorage && allocateMemory ) {

							const dimensions = getDimensions( mipmaps[ 0 ] );

							state.texStorage2D( _gl.TEXTURE_2D, levels, glInternalFormat, dimensions.width, dimensions.height );

						}

						for ( let i = 0, il = mipmaps.length; i < il; i ++ ) {

							mipmap = mipmaps[ i ];

							if ( useTexStorage ) {

								if ( dataReady ) {

									state.texSubImage2D( _gl.TEXTURE_2D, i, 0, 0, glFormat, glType, mipmap );

								}

							} else {

								state.texImage2D( _gl.TEXTURE_2D, i, glInternalFormat, glFormat, glType, mipmap );

							}

						}

						texture.generateMipmaps = false;

					} else {

						if ( useTexStorage ) {

							if ( allocateMemory ) {

								const dimensions = getDimensions( image );

								state.texStorage2D( _gl.TEXTURE_2D, levels, glInternalFormat, dimensions.width, dimensions.height );

							}

							if ( dataReady ) {

								state.texSubImage2D( _gl.TEXTURE_2D, 0, 0, 0, glFormat, glType, image );

							}

						} else {

							state.texImage2D( _gl.TEXTURE_2D, 0, glInternalFormat, glFormat, glType, image );

						}

					}

				}

				if ( textureNeedsGenerateMipmaps( texture ) ) {

					generateMipmap( textureType );

				}

				sourceProperties.__version = source.version;

				if ( texture.onUpdate ) texture.onUpdate( texture );

			}

			textureProperties.__version = texture.version;

		}

		function uploadCubeTexture( textureProperties, texture, slot ) {

			if ( texture.image.length !== 6 ) return;

			const forceUpload = initTexture( textureProperties, texture );
			const source = texture.source;

			state.bindTexture( _gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture, _gl.TEXTURE0 + slot );

			const sourceProperties = properties.get( source );

			if ( source.version !== sourceProperties.__version || forceUpload === true ) {

				state.activeTexture( _gl.TEXTURE0 + slot );

				const workingPrimaries = ColorManagement.getPrimaries( ColorManagement.workingColorSpace );
				const texturePrimaries = texture.colorSpace === NoColorSpace ? null : ColorManagement.getPrimaries( texture.colorSpace );
				const unpackConversion = texture.colorSpace === NoColorSpace || workingPrimaries === texturePrimaries ? _gl.NONE : _gl.BROWSER_DEFAULT_WEBGL;

				_gl.pixelStorei( _gl.UNPACK_FLIP_Y_WEBGL, texture.flipY );
				_gl.pixelStorei( _gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, texture.premultiplyAlpha );
				_gl.pixelStorei( _gl.UNPACK_ALIGNMENT, texture.unpackAlignment );
				_gl.pixelStorei( _gl.UNPACK_COLORSPACE_CONVERSION_WEBGL, unpackConversion );

				const isCompressed = ( texture.isCompressedTexture || texture.image[ 0 ].isCompressedTexture );
				const isDataTexture = ( texture.image[ 0 ] && texture.image[ 0 ].isDataTexture );

				const cubeImage = [];

				for ( let i = 0; i < 6; i ++ ) {

					if ( ! isCompressed && ! isDataTexture ) {

						cubeImage[ i ] = resizeImage( texture.image[ i ], true, capabilities.maxCubemapSize );

					} else {

						cubeImage[ i ] = isDataTexture ? texture.image[ i ].image : texture.image[ i ];

					}

					cubeImage[ i ] = verifyColorSpace( texture, cubeImage[ i ] );

				}

				const image = cubeImage[ 0 ],
					glFormat = utils.convert( texture.format, texture.colorSpace ),
					glType = utils.convert( texture.type ),
					glInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.colorSpace );

				const useTexStorage = ( texture.isVideoTexture !== true );
				const allocateMemory = ( sourceProperties.__version === undefined ) || ( forceUpload === true );
				const dataReady = source.dataReady;
				let levels = getMipLevels( texture, image );

				setTextureParameters( _gl.TEXTURE_CUBE_MAP, texture );

				let mipmaps;

				if ( isCompressed ) {

					if ( useTexStorage && allocateMemory ) {

						state.texStorage2D( _gl.TEXTURE_CUBE_MAP, levels, glInternalFormat, image.width, image.height );

					}

					for ( let i = 0; i < 6; i ++ ) {

						mipmaps = cubeImage[ i ].mipmaps;

						for ( let j = 0; j < mipmaps.length; j ++ ) {

							const mipmap = mipmaps[ j ];

							if ( texture.format !== RGBAFormat ) {

								if ( glFormat !== null ) {

									if ( useTexStorage ) {

										if ( dataReady ) {

											state.compressedTexSubImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, 0, 0, mipmap.width, mipmap.height, glFormat, mipmap.data );

										}

									} else {

										state.compressedTexImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, glInternalFormat, mipmap.width, mipmap.height, 0, mipmap.data );

									}

								} else {

									console.warn( 'THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .setTextureCube()' );

								}

							} else {

								if ( useTexStorage ) {

									if ( dataReady ) {

										state.texSubImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data );

									}

								} else {

									state.texImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data );

								}

							}

						}

					}

				} else {

					mipmaps = texture.mipmaps;

					if ( useTexStorage && allocateMemory ) {

						// TODO: Uniformly handle mipmap definitions
						// Normal textures and compressed cube textures define base level + mips with their mipmap array
						// Uncompressed cube textures use their mipmap array only for mips (no base level)

						if ( mipmaps.length > 0 ) levels ++;

						const dimensions = getDimensions( cubeImage[ 0 ] );

						state.texStorage2D( _gl.TEXTURE_CUBE_MAP, levels, glInternalFormat, dimensions.width, dimensions.height );

					}

					for ( let i = 0; i < 6; i ++ ) {

						if ( isDataTexture ) {

							if ( useTexStorage ) {

								if ( dataReady ) {

									state.texSubImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, 0, 0, cubeImage[ i ].width, cubeImage[ i ].height, glFormat, glType, cubeImage[ i ].data );

								}

							} else {

								state.texImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, glInternalFormat, cubeImage[ i ].width, cubeImage[ i ].height, 0, glFormat, glType, cubeImage[ i ].data );

							}

							for ( let j = 0; j < mipmaps.length; j ++ ) {

								const mipmap = mipmaps[ j ];
								const mipmapImage = mipmap.image[ i ].image;

								if ( useTexStorage ) {

									if ( dataReady ) {

										state.texSubImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, 0, 0, mipmapImage.width, mipmapImage.height, glFormat, glType, mipmapImage.data );

									}

								} else {

									state.texImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, glInternalFormat, mipmapImage.width, mipmapImage.height, 0, glFormat, glType, mipmapImage.data );

								}

							}

						} else {

							if ( useTexStorage ) {

								if ( dataReady ) {

									state.texSubImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, 0, 0, glFormat, glType, cubeImage[ i ] );

								}

							} else {

								state.texImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, glInternalFormat, glFormat, glType, cubeImage[ i ] );

							}

							for ( let j = 0; j < mipmaps.length; j ++ ) {

								const mipmap = mipmaps[ j ];

								if ( useTexStorage ) {

									if ( dataReady ) {

										state.texSubImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, 0, 0, glFormat, glType, mipmap.image[ i ] );

									}

								} else {

									state.texImage2D( _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, glInternalFormat, glFormat, glType, mipmap.image[ i ] );

								}

							}

						}

					}

				}

				if ( textureNeedsGenerateMipmaps( texture ) ) {

					// We assume images for cube map have the same size.
					generateMipmap( _gl.TEXTURE_CUBE_MAP );

				}

				sourceProperties.__version = source.version;

				if ( texture.onUpdate ) texture.onUpdate( texture );

			}

			textureProperties.__version = texture.version;

		}

		// Render targets

		// Setup storage for target texture and bind it to correct framebuffer
		function setupFrameBufferTexture( framebuffer, renderTarget, texture, attachment, textureTarget, level ) {

			const glFormat = utils.convert( texture.format, texture.colorSpace );
			const glType = utils.convert( texture.type );
			const glInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.colorSpace );
			const renderTargetProperties = properties.get( renderTarget );
			const textureProperties = properties.get( texture );

			textureProperties.__renderTarget = renderTarget;

			if ( ! renderTargetProperties.__hasExternalTextures ) {

				const width = Math.max( 1, renderTarget.width >> level );
				const height = Math.max( 1, renderTarget.height >> level );

				if ( textureTarget === _gl.TEXTURE_3D || textureTarget === _gl.TEXTURE_2D_ARRAY ) {

					state.texImage3D( textureTarget, level, glInternalFormat, width, height, renderTarget.depth, 0, glFormat, glType, null );

				} else {

					state.texImage2D( textureTarget, level, glInternalFormat, width, height, 0, glFormat, glType, null );

				}

			}

			state.bindFramebuffer( _gl.FRAMEBUFFER, framebuffer );

			if ( useMultisampledRTT( renderTarget ) ) {

				multisampledRTTExt.framebufferTexture2DMultisampleEXT( _gl.FRAMEBUFFER, attachment, textureTarget, textureProperties.__webglTexture, 0, getRenderTargetSamples( renderTarget ) );

			} else if ( textureTarget === _gl.TEXTURE_2D || ( textureTarget >= _gl.TEXTURE_CUBE_MAP_POSITIVE_X && textureTarget <= _gl.TEXTURE_CUBE_MAP_NEGATIVE_Z ) ) { // see #24753

				_gl.framebufferTexture2D( _gl.FRAMEBUFFER, attachment, textureTarget, textureProperties.__webglTexture, level );

			}

			state.bindFramebuffer( _gl.FRAMEBUFFER, null );

		}

		// Setup storage for internal depth/stencil buffers and bind to correct framebuffer
		function setupRenderBufferStorage( renderbuffer, renderTarget, isMultisample ) {

			_gl.bindRenderbuffer( _gl.RENDERBUFFER, renderbuffer );

			if ( renderTarget.depthBuffer ) {

				// retrieve the depth attachment types
				const depthTexture = renderTarget.depthTexture;
				const depthType = depthTexture && depthTexture.isDepthTexture ? depthTexture.type : null;
				const glInternalFormat = getInternalDepthFormat( renderTarget.stencilBuffer, depthType );
				const glAttachmentType = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;

				// set up the attachment
				const samples = getRenderTargetSamples( renderTarget );
				const isUseMultisampledRTT = useMultisampledRTT( renderTarget );
				if ( isUseMultisampledRTT ) {

					multisampledRTTExt.renderbufferStorageMultisampleEXT( _gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height );

				} else if ( isMultisample ) {

					_gl.renderbufferStorageMultisample( _gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height );

				} else {

					_gl.renderbufferStorage( _gl.RENDERBUFFER, glInternalFormat, renderTarget.width, renderTarget.height );

				}

				_gl.framebufferRenderbuffer( _gl.FRAMEBUFFER, glAttachmentType, _gl.RENDERBUFFER, renderbuffer );

			} else {

				const textures = renderTarget.textures;

				for ( let i = 0; i < textures.length; i ++ ) {

					const texture = textures[ i ];

					const glFormat = utils.convert( texture.format, texture.colorSpace );
					const glType = utils.convert( texture.type );
					const glInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.colorSpace );
					const samples = getRenderTargetSamples( renderTarget );

					if ( isMultisample && useMultisampledRTT( renderTarget ) === false ) {

						_gl.renderbufferStorageMultisample( _gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height );

					} else if ( useMultisampledRTT( renderTarget ) ) {

						multisampledRTTExt.renderbufferStorageMultisampleEXT( _gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height );

					} else {

						_gl.renderbufferStorage( _gl.RENDERBUFFER, glInternalFormat, renderTarget.width, renderTarget.height );

					}

				}

			}

			_gl.bindRenderbuffer( _gl.RENDERBUFFER, null );

		}

		// Setup resources for a Depth Texture for a FBO (needs an extension)
		function setupDepthTexture( framebuffer, renderTarget ) {

			const isCube = ( renderTarget && renderTarget.isWebGLCubeRenderTarget );
			if ( isCube ) throw new Error( 'Depth Texture with cube render targets is not supported' );

			state.bindFramebuffer( _gl.FRAMEBUFFER, framebuffer );

			if ( ! ( renderTarget.depthTexture && renderTarget.depthTexture.isDepthTexture ) ) {

				throw new Error( 'renderTarget.depthTexture must be an instance of THREE.DepthTexture' );

			}

			const textureProperties = properties.get( renderTarget.depthTexture );
			textureProperties.__renderTarget = renderTarget;

			// upload an empty depth texture with framebuffer size
			if ( ! textureProperties.__webglTexture ||
					renderTarget.depthTexture.image.width !== renderTarget.width ||
					renderTarget.depthTexture.image.height !== renderTarget.height ) {

				renderTarget.depthTexture.image.width = renderTarget.width;
				renderTarget.depthTexture.image.height = renderTarget.height;
				renderTarget.depthTexture.needsUpdate = true;

			}

			setTexture2D( renderTarget.depthTexture, 0 );

			const webglDepthTexture = textureProperties.__webglTexture;
			const samples = getRenderTargetSamples( renderTarget );

			if ( renderTarget.depthTexture.format === DepthFormat ) {

				if ( useMultisampledRTT( renderTarget ) ) {

					multisampledRTTExt.framebufferTexture2DMultisampleEXT( _gl.FRAMEBUFFER, _gl.DEPTH_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0, samples );

				} else {

					_gl.framebufferTexture2D( _gl.FRAMEBUFFER, _gl.DEPTH_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0 );

				}

			} else if ( renderTarget.depthTexture.format === DepthStencilFormat ) {

				if ( useMultisampledRTT( renderTarget ) ) {

					multisampledRTTExt.framebufferTexture2DMultisampleEXT( _gl.FRAMEBUFFER, _gl.DEPTH_STENCIL_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0, samples );

				} else {

					_gl.framebufferTexture2D( _gl.FRAMEBUFFER, _gl.DEPTH_STENCIL_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0 );

				}

			} else {

				throw new Error( 'Unknown depthTexture format' );

			}

		}

		// Setup GL resources for a non-texture depth buffer
		function setupDepthRenderbuffer( renderTarget ) {

			const renderTargetProperties = properties.get( renderTarget );
			const isCube = ( renderTarget.isWebGLCubeRenderTarget === true );

			// if the bound depth texture has changed
			if ( renderTargetProperties.__boundDepthTexture !== renderTarget.depthTexture ) {

				// fire the dispose event to get rid of stored state associated with the previously bound depth buffer
				const depthTexture = renderTarget.depthTexture;
				if ( renderTargetProperties.__depthDisposeCallback ) {

					renderTargetProperties.__depthDisposeCallback();

				}

				// set up dispose listeners to track when the currently attached buffer is implicitly unbound
				if ( depthTexture ) {

					const disposeEvent = () => {

						delete renderTargetProperties.__boundDepthTexture;
						delete renderTargetProperties.__depthDisposeCallback;
						depthTexture.removeEventListener( 'dispose', disposeEvent );

					};

					depthTexture.addEventListener( 'dispose', disposeEvent );
					renderTargetProperties.__depthDisposeCallback = disposeEvent;

				}

				renderTargetProperties.__boundDepthTexture = depthTexture;

			}

			if ( renderTarget.depthTexture && ! renderTargetProperties.__autoAllocateDepthBuffer ) {

				if ( isCube ) throw new Error( 'target.depthTexture not supported in Cube render targets' );

				const mipmaps = renderTarget.texture.mipmaps;

				if ( mipmaps && mipmaps.length > 0 ) {

					setupDepthTexture( renderTargetProperties.__webglFramebuffer[ 0 ], renderTarget );

				} else {

					setupDepthTexture( renderTargetProperties.__webglFramebuffer, renderTarget );

				}

			} else {

				if ( isCube ) {

					renderTargetProperties.__webglDepthbuffer = [];

					for ( let i = 0; i < 6; i ++ ) {

						state.bindFramebuffer( _gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer[ i ] );

						if ( renderTargetProperties.__webglDepthbuffer[ i ] === undefined ) {

							renderTargetProperties.__webglDepthbuffer[ i ] = _gl.createRenderbuffer();
							setupRenderBufferStorage( renderTargetProperties.__webglDepthbuffer[ i ], renderTarget, false );

						} else {

							// attach buffer if it's been created already
							const glAttachmentType = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;
							const renderbuffer = renderTargetProperties.__webglDepthbuffer[ i ];
							_gl.bindRenderbuffer( _gl.RENDERBUFFER, renderbuffer );
							_gl.framebufferRenderbuffer( _gl.FRAMEBUFFER, glAttachmentType, _gl.RENDERBUFFER, renderbuffer );

						}

					}

				} else {

					const mipmaps = renderTarget.texture.mipmaps;

					if ( mipmaps && mipmaps.length > 0 ) {

						state.bindFramebuffer( _gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer[ 0 ] );

					} else {

						state.bindFramebuffer( _gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer );

					}

					if ( renderTargetProperties.__webglDepthbuffer === undefined ) {

						renderTargetProperties.__webglDepthbuffer = _gl.createRenderbuffer();
						setupRenderBufferStorage( renderTargetProperties.__webglDepthbuffer, renderTarget, false );

					} else {

						// attach buffer if it's been created already
						const glAttachmentType = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;
						const renderbuffer = renderTargetProperties.__webglDepthbuffer;
						_gl.bindRenderbuffer( _gl.RENDERBUFFER, renderbuffer );
						_gl.framebufferRenderbuffer( _gl.FRAMEBUFFER, glAttachmentType, _gl.RENDERBUFFER, renderbuffer );

					}

				}

			}

			state.bindFramebuffer( _gl.FRAMEBUFFER, null );

		}

		// rebind framebuffer with external textures
		function rebindTextures( renderTarget, colorTexture, depthTexture ) {

			const renderTargetProperties = properties.get( renderTarget );

			if ( colorTexture !== undefined ) {

				setupFrameBufferTexture( renderTargetProperties.__webglFramebuffer, renderTarget, renderTarget.texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, 0 );

			}

			if ( depthTexture !== undefined ) {

				setupDepthRenderbuffer( renderTarget );

			}

		}

		// Set up GL resources for the render target
		function setupRenderTarget( renderTarget ) {

			const texture = renderTarget.texture;

			const renderTargetProperties = properties.get( renderTarget );
			const textureProperties = properties.get( texture );

			renderTarget.addEventListener( 'dispose', onRenderTargetDispose );

			const textures = renderTarget.textures;

			const isCube = ( renderTarget.isWebGLCubeRenderTarget === true );
			const isMultipleRenderTargets = ( textures.length > 1 );

			if ( ! isMultipleRenderTargets ) {

				if ( textureProperties.__webglTexture === undefined ) {

					textureProperties.__webglTexture = _gl.createTexture();

				}

				textureProperties.__version = texture.version;
				info.memory.textures ++;

			}

			// Setup framebuffer

			if ( isCube ) {

				renderTargetProperties.__webglFramebuffer = [];

				for ( let i = 0; i < 6; i ++ ) {

					if ( texture.mipmaps && texture.mipmaps.length > 0 ) {

						renderTargetProperties.__webglFramebuffer[ i ] = [];

						for ( let level = 0; level < texture.mipmaps.length; level ++ ) {

							renderTargetProperties.__webglFramebuffer[ i ][ level ] = _gl.createFramebuffer();

						}

					} else {

						renderTargetProperties.__webglFramebuffer[ i ] = _gl.createFramebuffer();

					}

				}

			} else {

				if ( texture.mipmaps && texture.mipmaps.length > 0 ) {

					renderTargetProperties.__webglFramebuffer = [];

					for ( let level = 0; level < texture.mipmaps.length; level ++ ) {

						renderTargetProperties.__webglFramebuffer[ level ] = _gl.createFramebuffer();

					}

				} else {

					renderTargetProperties.__webglFramebuffer = _gl.createFramebuffer();

				}

				if ( isMultipleRenderTargets ) {

					for ( let i = 0, il = textures.length; i < il; i ++ ) {

						const attachmentProperties = properties.get( textures[ i ] );

						if ( attachmentProperties.__webglTexture === undefined ) {

							attachmentProperties.__webglTexture = _gl.createTexture();

							info.memory.textures ++;

						}

					}

				}

				if ( ( renderTarget.samples > 0 ) && useMultisampledRTT( renderTarget ) === false ) {

					renderTargetProperties.__webglMultisampledFramebuffer = _gl.createFramebuffer();
					renderTargetProperties.__webglColorRenderbuffer = [];

					state.bindFramebuffer( _gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer );

					for ( let i = 0; i < textures.length; i ++ ) {

						const texture = textures[ i ];
						renderTargetProperties.__webglColorRenderbuffer[ i ] = _gl.createRenderbuffer();

						_gl.bindRenderbuffer( _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[ i ] );

						const glFormat = utils.convert( texture.format, texture.colorSpace );
						const glType = utils.convert( texture.type );
						const glInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.colorSpace, renderTarget.isXRRenderTarget === true );
						const samples = getRenderTargetSamples( renderTarget );
						_gl.renderbufferStorageMultisample( _gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height );

						_gl.framebufferRenderbuffer( _gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[ i ] );

					}

					_gl.bindRenderbuffer( _gl.RENDERBUFFER, null );

					if ( renderTarget.depthBuffer ) {

						renderTargetProperties.__webglDepthRenderbuffer = _gl.createRenderbuffer();
						setupRenderBufferStorage( renderTargetProperties.__webglDepthRenderbuffer, renderTarget, true );

					}

					state.bindFramebuffer( _gl.FRAMEBUFFER, null );

				}

			}

			// Setup color buffer

			if ( isCube ) {

				state.bindTexture( _gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture );
				setTextureParameters( _gl.TEXTURE_CUBE_MAP, texture );

				for ( let i = 0; i < 6; i ++ ) {

					if ( texture.mipmaps && texture.mipmaps.length > 0 ) {

						for ( let level = 0; level < texture.mipmaps.length; level ++ ) {

							setupFrameBufferTexture( renderTargetProperties.__webglFramebuffer[ i ][ level ], renderTarget, texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, level );

						}

					} else {

						setupFrameBufferTexture( renderTargetProperties.__webglFramebuffer[ i ], renderTarget, texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0 );

					}

				}

				if ( textureNeedsGenerateMipmaps( texture ) ) {

					generateMipmap( _gl.TEXTURE_CUBE_MAP );

				}

				state.unbindTexture();

			} else if ( isMultipleRenderTargets ) {

				for ( let i = 0, il = textures.length; i < il; i ++ ) {

					const attachment = textures[ i ];
					const attachmentProperties = properties.get( attachment );

					state.bindTexture( _gl.TEXTURE_2D, attachmentProperties.__webglTexture );
					setTextureParameters( _gl.TEXTURE_2D, attachment );
					setupFrameBufferTexture( renderTargetProperties.__webglFramebuffer, renderTarget, attachment, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, 0 );

					if ( textureNeedsGenerateMipmaps( attachment ) ) {

						generateMipmap( _gl.TEXTURE_2D );

					}

				}

				state.unbindTexture();

			} else {

				let glTextureType = _gl.TEXTURE_2D;

				if ( renderTarget.isWebGL3DRenderTarget || renderTarget.isWebGLArrayRenderTarget ) {

					glTextureType = renderTarget.isWebGL3DRenderTarget ? _gl.TEXTURE_3D : _gl.TEXTURE_2D_ARRAY;

				}

				state.bindTexture( glTextureType, textureProperties.__webglTexture );
				setTextureParameters( glTextureType, texture );

				if ( texture.mipmaps && texture.mipmaps.length > 0 ) {

					for ( let level = 0; level < texture.mipmaps.length; level ++ ) {

						setupFrameBufferTexture( renderTargetProperties.__webglFramebuffer[ level ], renderTarget, texture, _gl.COLOR_ATTACHMENT0, glTextureType, level );

					}

				} else {

					setupFrameBufferTexture( renderTargetProperties.__webglFramebuffer, renderTarget, texture, _gl.COLOR_ATTACHMENT0, glTextureType, 0 );

				}

				if ( textureNeedsGenerateMipmaps( texture ) ) {

					generateMipmap( glTextureType );

				}

				state.unbindTexture();

			}

			// Setup depth and stencil buffers

			if ( renderTarget.depthBuffer ) {

				setupDepthRenderbuffer( renderTarget );

			}

		}

		function updateRenderTargetMipmap( renderTarget ) {

			const textures = renderTarget.textures;

			for ( let i = 0, il = textures.length; i < il; i ++ ) {

				const texture = textures[ i ];

				if ( textureNeedsGenerateMipmaps( texture ) ) {

					const targetType = getTargetType( renderTarget );
					const webglTexture = properties.get( texture ).__webglTexture;

					state.bindTexture( targetType, webglTexture );
					generateMipmap( targetType );
					state.unbindTexture();

				}

			}

		}

		const invalidationArrayRead = [];
		const invalidationArrayDraw = [];

		function updateMultisampleRenderTarget( renderTarget ) {

			if ( renderTarget.samples > 0 ) {

				if ( useMultisampledRTT( renderTarget ) === false ) {

					const textures = renderTarget.textures;
					const width = renderTarget.width;
					const height = renderTarget.height;
					let mask = _gl.COLOR_BUFFER_BIT;
					const depthStyle = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;
					const renderTargetProperties = properties.get( renderTarget );
					const isMultipleRenderTargets = ( textures.length > 1 );

					// If MRT we need to remove FBO attachments
					if ( isMultipleRenderTargets ) {

						for ( let i = 0; i < textures.length; i ++ ) {

							state.bindFramebuffer( _gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer );
							_gl.framebufferRenderbuffer( _gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, null );

							state.bindFramebuffer( _gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer );
							_gl.framebufferTexture2D( _gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, null, 0 );

						}

					}

					state.bindFramebuffer( _gl.READ_FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer );

					const mipmaps = renderTarget.texture.mipmaps;

					if ( mipmaps && mipmaps.length > 0 ) {

						state.bindFramebuffer( _gl.DRAW_FRAMEBUFFER, renderTargetProperties.__webglFramebuffer[ 0 ] );

					} else {

						state.bindFramebuffer( _gl.DRAW_FRAMEBUFFER, renderTargetProperties.__webglFramebuffer );

					}

					for ( let i = 0; i < textures.length; i ++ ) {

						if ( renderTarget.resolveDepthBuffer ) {

							if ( renderTarget.depthBuffer ) mask |= _gl.DEPTH_BUFFER_BIT;

							// resolving stencil is slow with a D3D backend. disable it for all transmission render targets (see #27799)

							if ( renderTarget.stencilBuffer && renderTarget.resolveStencilBuffer ) mask |= _gl.STENCIL_BUFFER_BIT;

						}

						if ( isMultipleRenderTargets ) {

							_gl.framebufferRenderbuffer( _gl.READ_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[ i ] );

							const webglTexture = properties.get( textures[ i ] ).__webglTexture;
							_gl.framebufferTexture2D( _gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, webglTexture, 0 );

						}

						_gl.blitFramebuffer( 0, 0, width, height, 0, 0, width, height, mask, _gl.NEAREST );

						if ( supportsInvalidateFramebuffer === true ) {

							invalidationArrayRead.length = 0;
							invalidationArrayDraw.length = 0;

							invalidationArrayRead.push( _gl.COLOR_ATTACHMENT0 + i );

							if ( renderTarget.depthBuffer && renderTarget.resolveDepthBuffer === false ) {

								invalidationArrayRead.push( depthStyle );
								invalidationArrayDraw.push( depthStyle );

								_gl.invalidateFramebuffer( _gl.DRAW_FRAMEBUFFER, invalidationArrayDraw );

							}

							_gl.invalidateFramebuffer( _gl.READ_FRAMEBUFFER, invalidationArrayRead );

						}

					}

					state.bindFramebuffer( _gl.READ_FRAMEBUFFER, null );
					state.bindFramebuffer( _gl.DRAW_FRAMEBUFFER, null );

					// If MRT since pre-blit we removed the FBO we need to reconstruct the attachments
					if ( isMultipleRenderTargets ) {

						for ( let i = 0; i < textures.length; i ++ ) {

							state.bindFramebuffer( _gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer );
							_gl.framebufferRenderbuffer( _gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[ i ] );

							const webglTexture = properties.get( textures[ i ] ).__webglTexture;

							state.bindFramebuffer( _gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer );
							_gl.framebufferTexture2D( _gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, webglTexture, 0 );

						}

					}

					state.bindFramebuffer( _gl.DRAW_FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer );

				} else {

					if ( renderTarget.depthBuffer && renderTarget.resolveDepthBuffer === false && supportsInvalidateFramebuffer ) {

						const depthStyle = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;

						_gl.invalidateFramebuffer( _gl.DRAW_FRAMEBUFFER, [ depthStyle ] );

					}

				}

			}

		}

		function getRenderTargetSamples( renderTarget ) {

			return Math.min( capabilities.maxSamples, renderTarget.samples );

		}

		function useMultisampledRTT( renderTarget ) {

			const renderTargetProperties = properties.get( renderTarget );

			return renderTarget.samples > 0 && extensions.has( 'WEBGL_multisampled_render_to_texture' ) === true && renderTargetProperties.__useRenderToTexture !== false;

		}

		function updateVideoTexture( texture ) {

			const frame = info.render.frame;

			// Check the last frame we updated the VideoTexture

			if ( _videoTextures.get( texture ) !== frame ) {

				_videoTextures.set( texture, frame );
				texture.update();

			}

		}

		function verifyColorSpace( texture, image ) {

			const colorSpace = texture.colorSpace;
			const format = texture.format;
			const type = texture.type;

			if ( texture.isCompressedTexture === true || texture.isVideoTexture === true ) return image;

			if ( colorSpace !== LinearSRGBColorSpace && colorSpace !== NoColorSpace ) {

				// sRGB

				if ( ColorManagement.getTransfer( colorSpace ) === SRGBTransfer ) {

					// in WebGL 2 uncompressed textures can only be sRGB encoded if they have the RGBA8 format

					if ( format !== RGBAFormat || type !== UnsignedByteType ) {

						console.warn( 'THREE.WebGLTextures: sRGB encoded textures have to use RGBAFormat and UnsignedByteType.' );

					}

				} else {

					console.error( 'THREE.WebGLTextures: Unsupported texture color space:', colorSpace );

				}

			}

			return image;

		}

		function getDimensions( image ) {

			if ( typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement ) {

				// if intrinsic data are not available, fallback to width/height

				_imageDimensions.width = image.naturalWidth || image.width;
				_imageDimensions.height = image.naturalHeight || image.height;

			} else if ( typeof VideoFrame !== 'undefined' && image instanceof VideoFrame ) {

				_imageDimensions.width = image.displayWidth;
				_imageDimensions.height = image.displayHeight;

			} else {

				_imageDimensions.width = image.width;
				_imageDimensions.height = image.height;

			}

			return _imageDimensions;

		}

		//

		this.allocateTextureUnit = allocateTextureUnit;
		this.resetTextureUnits = resetTextureUnits;

		this.setTexture2D = setTexture2D;
		this.setTexture2DArray = setTexture2DArray;
		this.setTexture3D = setTexture3D;
		this.setTextureCube = setTextureCube;
		this.rebindTextures = rebindTextures;
		this.setupRenderTarget = setupRenderTarget;
		this.updateRenderTargetMipmap = updateRenderTargetMipmap;
		this.updateMultisampleRenderTarget = updateMultisampleRenderTarget;
		this.setupDepthRenderbuffer = setupDepthRenderbuffer;
		this.setupFrameBufferTexture = setupFrameBufferTexture;
		this.useMultisampledRTT = useMultisampledRTT;

	}

	function WebGLUtils( gl, extensions ) {

		function convert( p, colorSpace = NoColorSpace ) {

			let extension;

			const transfer = ColorManagement.getTransfer( colorSpace );

			if ( p === UnsignedByteType ) return gl.UNSIGNED_BYTE;
			if ( p === UnsignedShort4444Type ) return gl.UNSIGNED_SHORT_4_4_4_4;
			if ( p === UnsignedShort5551Type ) return gl.UNSIGNED_SHORT_5_5_5_1;
			if ( p === UnsignedInt5999Type ) return gl.UNSIGNED_INT_5_9_9_9_REV;

			if ( p === ByteType ) return gl.BYTE;
			if ( p === ShortType ) return gl.SHORT;
			if ( p === UnsignedShortType ) return gl.UNSIGNED_SHORT;
			if ( p === IntType ) return gl.INT;
			if ( p === UnsignedIntType ) return gl.UNSIGNED_INT;
			if ( p === FloatType ) return gl.FLOAT;
			if ( p === HalfFloatType ) return gl.HALF_FLOAT;

			if ( p === AlphaFormat ) return gl.ALPHA;
			if ( p === RGBFormat ) return gl.RGB;
			if ( p === RGBAFormat ) return gl.RGBA;
			if ( p === DepthFormat ) return gl.DEPTH_COMPONENT;
			if ( p === DepthStencilFormat ) return gl.DEPTH_STENCIL;

			// WebGL2 formats.

			if ( p === RedFormat ) return gl.RED;
			if ( p === RedIntegerFormat ) return gl.RED_INTEGER;
			if ( p === RGFormat ) return gl.RG;
			if ( p === RGIntegerFormat ) return gl.RG_INTEGER;
			if ( p === RGBAIntegerFormat ) return gl.RGBA_INTEGER;

			// S3TC

			if ( p === RGB_S3TC_DXT1_Format || p === RGBA_S3TC_DXT1_Format || p === RGBA_S3TC_DXT3_Format || p === RGBA_S3TC_DXT5_Format ) {

				if ( transfer === SRGBTransfer ) {

					extension = extensions.get( 'WEBGL_compressed_texture_s3tc_srgb' );

					if ( extension !== null ) {

						if ( p === RGB_S3TC_DXT1_Format ) return extension.COMPRESSED_SRGB_S3TC_DXT1_EXT;
						if ( p === RGBA_S3TC_DXT1_Format ) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT;
						if ( p === RGBA_S3TC_DXT3_Format ) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT;
						if ( p === RGBA_S3TC_DXT5_Format ) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT;

					} else {

						return null;

					}

				} else {

					extension = extensions.get( 'WEBGL_compressed_texture_s3tc' );

					if ( extension !== null ) {

						if ( p === RGB_S3TC_DXT1_Format ) return extension.COMPRESSED_RGB_S3TC_DXT1_EXT;
						if ( p === RGBA_S3TC_DXT1_Format ) return extension.COMPRESSED_RGBA_S3TC_DXT1_EXT;
						if ( p === RGBA_S3TC_DXT3_Format ) return extension.COMPRESSED_RGBA_S3TC_DXT3_EXT;
						if ( p === RGBA_S3TC_DXT5_Format ) return extension.COMPRESSED_RGBA_S3TC_DXT5_EXT;

					} else {

						return null;

					}

				}

			}

			// PVRTC

			if ( p === RGB_PVRTC_4BPPV1_Format || p === RGB_PVRTC_2BPPV1_Format || p === RGBA_PVRTC_4BPPV1_Format || p === RGBA_PVRTC_2BPPV1_Format ) {

				extension = extensions.get( 'WEBGL_compressed_texture_pvrtc' );

				if ( extension !== null ) {

					if ( p === RGB_PVRTC_4BPPV1_Format ) return extension.COMPRESSED_RGB_PVRTC_4BPPV1_IMG;
					if ( p === RGB_PVRTC_2BPPV1_Format ) return extension.COMPRESSED_RGB_PVRTC_2BPPV1_IMG;
					if ( p === RGBA_PVRTC_4BPPV1_Format ) return extension.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG;
					if ( p === RGBA_PVRTC_2BPPV1_Format ) return extension.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG;

				} else {

					return null;

				}

			}

			// ETC

			if ( p === RGB_ETC1_Format || p === RGB_ETC2_Format || p === RGBA_ETC2_EAC_Format ) {

				extension = extensions.get( 'WEBGL_compressed_texture_etc' );

				if ( extension !== null ) {

					if ( p === RGB_ETC1_Format || p === RGB_ETC2_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ETC2 : extension.COMPRESSED_RGB8_ETC2;
					if ( p === RGBA_ETC2_EAC_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ETC2_EAC : extension.COMPRESSED_RGBA8_ETC2_EAC;

				} else {

					return null;

				}

			}

			// ASTC

			if ( p === RGBA_ASTC_4x4_Format || p === RGBA_ASTC_5x4_Format || p === RGBA_ASTC_5x5_Format ||
				p === RGBA_ASTC_6x5_Format || p === RGBA_ASTC_6x6_Format || p === RGBA_ASTC_8x5_Format ||
				p === RGBA_ASTC_8x6_Format || p === RGBA_ASTC_8x8_Format || p === RGBA_ASTC_10x5_Format ||
				p === RGBA_ASTC_10x6_Format || p === RGBA_ASTC_10x8_Format || p === RGBA_ASTC_10x10_Format ||
				p === RGBA_ASTC_12x10_Format || p === RGBA_ASTC_12x12_Format ) {

				extension = extensions.get( 'WEBGL_compressed_texture_astc' );

				if ( extension !== null ) {

					if ( p === RGBA_ASTC_4x4_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR : extension.COMPRESSED_RGBA_ASTC_4x4_KHR;
					if ( p === RGBA_ASTC_5x4_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR : extension.COMPRESSED_RGBA_ASTC_5x4_KHR;
					if ( p === RGBA_ASTC_5x5_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR : extension.COMPRESSED_RGBA_ASTC_5x5_KHR;
					if ( p === RGBA_ASTC_6x5_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR : extension.COMPRESSED_RGBA_ASTC_6x5_KHR;
					if ( p === RGBA_ASTC_6x6_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR : extension.COMPRESSED_RGBA_ASTC_6x6_KHR;
					if ( p === RGBA_ASTC_8x5_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR : extension.COMPRESSED_RGBA_ASTC_8x5_KHR;
					if ( p === RGBA_ASTC_8x6_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR : extension.COMPRESSED_RGBA_ASTC_8x6_KHR;
					if ( p === RGBA_ASTC_8x8_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR : extension.COMPRESSED_RGBA_ASTC_8x8_KHR;
					if ( p === RGBA_ASTC_10x5_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR : extension.COMPRESSED_RGBA_ASTC_10x5_KHR;
					if ( p === RGBA_ASTC_10x6_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR : extension.COMPRESSED_RGBA_ASTC_10x6_KHR;
					if ( p === RGBA_ASTC_10x8_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR : extension.COMPRESSED_RGBA_ASTC_10x8_KHR;
					if ( p === RGBA_ASTC_10x10_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR : extension.COMPRESSED_RGBA_ASTC_10x10_KHR;
					if ( p === RGBA_ASTC_12x10_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR : extension.COMPRESSED_RGBA_ASTC_12x10_KHR;
					if ( p === RGBA_ASTC_12x12_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR : extension.COMPRESSED_RGBA_ASTC_12x12_KHR;

				} else {

					return null;

				}

			}

			// BPTC

			if ( p === RGBA_BPTC_Format || p === RGB_BPTC_SIGNED_Format || p === RGB_BPTC_UNSIGNED_Format ) {

				extension = extensions.get( 'EXT_texture_compression_bptc' );

				if ( extension !== null ) {

					if ( p === RGBA_BPTC_Format ) return ( transfer === SRGBTransfer ) ? extension.COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT : extension.COMPRESSED_RGBA_BPTC_UNORM_EXT;
					if ( p === RGB_BPTC_SIGNED_Format ) return extension.COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT;
					if ( p === RGB_BPTC_UNSIGNED_Format ) return extension.COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT;

				} else {

					return null;

				}

			}

			// RGTC

			if ( p === RED_RGTC1_Format || p === SIGNED_RED_RGTC1_Format || p === RED_GREEN_RGTC2_Format || p === SIGNED_RED_GREEN_RGTC2_Format ) {

				extension = extensions.get( 'EXT_texture_compression_rgtc' );

				if ( extension !== null ) {

					if ( p === RGBA_BPTC_Format ) return extension.COMPRESSED_RED_RGTC1_EXT;
					if ( p === SIGNED_RED_RGTC1_Format ) return extension.COMPRESSED_SIGNED_RED_RGTC1_EXT;
					if ( p === RED_GREEN_RGTC2_Format ) return extension.COMPRESSED_RED_GREEN_RGTC2_EXT;
					if ( p === SIGNED_RED_GREEN_RGTC2_Format ) return extension.COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT;

				} else {

					return null;

				}

			}

			//

			if ( p === UnsignedInt248Type ) return gl.UNSIGNED_INT_24_8;

			// if "p" can't be resolved, assume the user defines a WebGL constant as a string (fallback/workaround for packed RGB formats)

			return ( gl[ p ] !== undefined ) ? gl[ p ] : null;

		}

		return { convert: convert };

	}

	const _occlusion_vertex = `
void main() {

	gl_Position = vec4( position, 1.0 );

}`;

	const _occlusion_fragment = `
uniform sampler2DArray depthColor;
uniform float depthWidth;
uniform float depthHeight;

void main() {

	vec2 coord = vec2( gl_FragCoord.x / depthWidth, gl_FragCoord.y / depthHeight );

	if ( coord.x >= 1.0 ) {

		gl_FragDepth = texture( depthColor, vec3( coord.x - 1.0, coord.y, 1 ) ).r;

	} else {

		gl_FragDepth = texture( depthColor, vec3( coord.x, coord.y, 0 ) ).r;

	}

}`;

	/**
	 * A XR module that manages the access to the Depth Sensing API.
	 */
	class WebXRDepthSensing {

		/**
		 * Constructs a new depth sensing module.
		 */
		constructor() {

			/**
			 * A texture representing the depth of the user's environment.
			 *
			 * @type {?Texture}
			 */
			this.texture = null;

			/**
			 * A plane mesh for visualizing the depth texture.
			 *
			 * @type {?Mesh}
			 */
			this.mesh = null;

			/**
			 * The depth near value.
			 *
			 * @type {number}
			 */
			this.depthNear = 0;

			/**
			 * The depth near far.
			 *
			 * @type {number}
			 */
			this.depthFar = 0;

		}

		/**
		 * Inits the depth sensing module
		 *
		 * @param {WebGLRenderer} renderer - The renderer.
		 * @param {XRWebGLDepthInformation} depthData - The XR depth data.
		 * @param {XRRenderState} renderState - The XR render state.
		 */
		init( renderer, depthData, renderState ) {

			if ( this.texture === null ) {

				const texture = new Texture();

				const texProps = renderer.properties.get( texture );
				texProps.__webglTexture = depthData.texture;

				if ( ( depthData.depthNear !== renderState.depthNear ) || ( depthData.depthFar !== renderState.depthFar ) ) {

					this.depthNear = depthData.depthNear;
					this.depthFar = depthData.depthFar;

				}

				this.texture = texture;

			}

		}

		/**
		 * Returns a plane mesh that visualizes the depth texture.
		 *
		 * @param {ArrayCamera} cameraXR - The XR camera.
		 * @return {?Mesh} The plane mesh.
		 */
		getMesh( cameraXR ) {

			if ( this.texture !== null ) {

				if ( this.mesh === null ) {

					const viewport = cameraXR.cameras[ 0 ].viewport;
					const material = new ShaderMaterial( {
						vertexShader: _occlusion_vertex,
						fragmentShader: _occlusion_fragment,
						uniforms: {
							depthColor: { value: this.texture },
							depthWidth: { value: viewport.z },
							depthHeight: { value: viewport.w }
						}
					} );

					this.mesh = new Mesh( new PlaneGeometry( 20, 20 ), material );

				}

			}

			return this.mesh;

		}

		/**
		 * Resets the module
		 */
		reset() {

			this.texture = null;
			this.mesh = null;

		}

		/**
		 * Returns a texture representing the depth of the user's environment.
		 *
		 * @return {?Texture} The depth texture.
		 */
		getDepthTexture() {

			return this.texture;

		}

	}

	/**
	 * This class represents an abstraction of the WebXR Device API and is
	 * internally used by {@link WebGLRenderer}. `WebXRManager` also provides a public
	 * interface that allows users to enable/disable XR and perform XR related
	 * tasks like for instance retrieving controllers.
	 *
	 * @augments EventDispatcher
	 * @hideconstructor
	 */
	class WebXRManager extends EventDispatcher {

		/**
		 * Constructs a new WebGL renderer.
		 *
		 * @param {WebGLRenderer} renderer - The renderer.
		 * @param {WebGL2RenderingContext} gl - The rendering context.
		 */
		constructor( renderer, gl ) {

			super();

			const scope = this;

			let session = null;

			let framebufferScaleFactor = 1.0;

			let referenceSpace = null;
			let referenceSpaceType = 'local-floor';
			// Set default foveation to maximum.
			let foveation = 1.0;
			let customReferenceSpace = null;

			let pose = null;
			let glBinding = null;
			let glProjLayer = null;
			let glBaseLayer = null;
			let xrFrame = null;

			const depthSensing = new WebXRDepthSensing();
			const attributes = gl.getContextAttributes();

			let initialRenderTarget = null;
			let newRenderTarget = null;

			const controllers = [];
			const controllerInputSources = [];

			const currentSize = new Vector2();
			let currentPixelRatio = null;

			//

			const cameraL = new PerspectiveCamera();
			cameraL.viewport = new Vector4();

			const cameraR = new PerspectiveCamera();
			cameraR.viewport = new Vector4();

			const cameras = [ cameraL, cameraR ];

			const cameraXR = new ArrayCamera();

			let _currentDepthNear = null;
			let _currentDepthFar = null;

			//

			/**
			 * Whether the manager's XR camera should be automatically updated or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.cameraAutoUpdate = true;

			/**
			 * This flag notifies the renderer to be ready for XR rendering. Set it to `true`
			 * if you are going to use XR in your app.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.enabled = false;

			/**
			 * Whether XR presentation is active or not.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default false
			 */
			this.isPresenting = false;

			/**
			 * Returns a group representing the `target ray` space of the XR controller.
			 * Use this space for visualizing 3D objects that support the user in pointing
			 * tasks like UI interaction.
			 *
			 * @param {number} index - The index of the controller.
			 * @return {Group} A group representing the `target ray` space.
			 */
			this.getController = function ( index ) {

				let controller = controllers[ index ];

				if ( controller === undefined ) {

					controller = new WebXRController();
					controllers[ index ] = controller;

				}

				return controller.getTargetRaySpace();

			};

			/**
			 * Returns a group representing the `grip` space of the XR controller.
			 * Use this space for visualizing 3D objects that support the user in pointing
			 * tasks like UI interaction.
			 *
			 * Note: If you want to show something in the user's hand AND offer a
			 * pointing ray at the same time, you'll want to attached the handheld object
			 * to the group returned by `getControllerGrip()` and the ray to the
			 * group returned by `getController()`. The idea is to have two
			 * different groups in two different coordinate spaces for the same WebXR
			 * controller.
			 *
			 * @param {number} index - The index of the controller.
			 * @return {Group} A group representing the `grip` space.
			 */
			this.getControllerGrip = function ( index ) {

				let controller = controllers[ index ];

				if ( controller === undefined ) {

					controller = new WebXRController();
					controllers[ index ] = controller;

				}

				return controller.getGripSpace();

			};

			/**
			 * Returns a group representing the `hand` space of the XR controller.
			 * Use this space for visualizing 3D objects that support the user in pointing
			 * tasks like UI interaction.
			 *
			 * @param {number} index - The index of the controller.
			 * @return {Group} A group representing the `hand` space.
			 */
			this.getHand = function ( index ) {

				let controller = controllers[ index ];

				if ( controller === undefined ) {

					controller = new WebXRController();
					controllers[ index ] = controller;

				}

				return controller.getHandSpace();

			};

			//

			function onSessionEvent( event ) {

				const controllerIndex = controllerInputSources.indexOf( event.inputSource );

				if ( controllerIndex === -1 ) {

					return;

				}

				const controller = controllers[ controllerIndex ];

				if ( controller !== undefined ) {

					controller.update( event.inputSource, event.frame, customReferenceSpace || referenceSpace );
					controller.dispatchEvent( { type: event.type, data: event.inputSource } );

				}

			}

			function onSessionEnd() {

				session.removeEventListener( 'select', onSessionEvent );
				session.removeEventListener( 'selectstart', onSessionEvent );
				session.removeEventListener( 'selectend', onSessionEvent );
				session.removeEventListener( 'squeeze', onSessionEvent );
				session.removeEventListener( 'squeezestart', onSessionEvent );
				session.removeEventListener( 'squeezeend', onSessionEvent );
				session.removeEventListener( 'end', onSessionEnd );
				session.removeEventListener( 'inputsourceschange', onInputSourcesChange );

				for ( let i = 0; i < controllers.length; i ++ ) {

					const inputSource = controllerInputSources[ i ];

					if ( inputSource === null ) continue;

					controllerInputSources[ i ] = null;

					controllers[ i ].disconnect( inputSource );

				}

				_currentDepthNear = null;
				_currentDepthFar = null;

				depthSensing.reset();

				// restore framebuffer/rendering state

				renderer.setRenderTarget( initialRenderTarget );

				glBaseLayer = null;
				glProjLayer = null;
				glBinding = null;
				session = null;
				newRenderTarget = null;

				//

				animation.stop();

				scope.isPresenting = false;

				renderer.setPixelRatio( currentPixelRatio );
				renderer.setSize( currentSize.width, currentSize.height, false );

				scope.dispatchEvent( { type: 'sessionend' } );

			}

			/**
			 * Sets the framebuffer scale factor.
			 *
			 * This method can not be used during a XR session.
			 *
			 * @param {number} value - The framebuffer scale factor.
			 */
			this.setFramebufferScaleFactor = function ( value ) {

				framebufferScaleFactor = value;

				if ( scope.isPresenting === true ) {

					console.warn( 'THREE.WebXRManager: Cannot change framebuffer scale while presenting.' );

				}

			};

			/**
			 * Sets the reference space type. Can be used to configure a spatial relationship with the user's physical
			 * environment. Depending on how the user moves in 3D space, setting an appropriate reference space can
			 * improve tracking. Default is `local-floor`. Valid values can be found here
			 * https://developer.mozilla.org/en-US/docs/Web/API/XRReferenceSpace#reference_space_types.
			 *
			 * This method can not be used during a XR session.
			 *
			 * @param {string} value - The reference space type.
			 */
			this.setReferenceSpaceType = function ( value ) {

				referenceSpaceType = value;

				if ( scope.isPresenting === true ) {

					console.warn( 'THREE.WebXRManager: Cannot change reference space type while presenting.' );

				}

			};

			/**
			 * Returns the XR reference space.
			 *
			 * @return {XRReferenceSpace} The XR reference space.
			 */
			this.getReferenceSpace = function () {

				return customReferenceSpace || referenceSpace;

			};

			/**
			 * Sets a custom XR reference space.
			 *
			 * @param {XRReferenceSpace} space - The XR reference space.
			 */
			this.setReferenceSpace = function ( space ) {

				customReferenceSpace = space;

			};

			/**
			 * Returns the current base layer.
			 *
			 * @return {?(XRWebGLLayer|XRProjectionLayer)} The XR base layer.
			 */
			this.getBaseLayer = function () {

				return glProjLayer !== null ? glProjLayer : glBaseLayer;

			};

			/**
			 * Returns the current XR binding.
			 *
			 * @return {?XRWebGLBinding} The XR binding.
			 */
			this.getBinding = function () {

				return glBinding;

			};

			/**
			 * Returns the current XR frame.
			 *
			 * @return {?XRFrame} The XR frame. Returns `null` when used outside a XR session.
			 */
			this.getFrame = function () {

				return xrFrame;

			};

			/**
			 * Returns the current XR session.
			 *
			 * @return {?XRSession} The XR session. Returns `null` when used outside a XR session.
			 */
			this.getSession = function () {

				return session;

			};

			/**
			 * After a XR session has been requested usually with one of the `*Button` modules, it
			 * is injected into the renderer with this method. This method triggers the start of
			 * the actual XR rendering.
			 *
			 * @async
			 * @param {XRSession} value - The XR session to set.
			 * @return {Promise} A Promise that resolves when the session has been set.
			 */
			this.setSession = async function ( value ) {

				session = value;

				if ( session !== null ) {

					initialRenderTarget = renderer.getRenderTarget();

					session.addEventListener( 'select', onSessionEvent );
					session.addEventListener( 'selectstart', onSessionEvent );
					session.addEventListener( 'selectend', onSessionEvent );
					session.addEventListener( 'squeeze', onSessionEvent );
					session.addEventListener( 'squeezestart', onSessionEvent );
					session.addEventListener( 'squeezeend', onSessionEvent );
					session.addEventListener( 'end', onSessionEnd );
					session.addEventListener( 'inputsourceschange', onInputSourcesChange );

					if ( attributes.xrCompatible !== true ) {

						await gl.makeXRCompatible();

					}

					currentPixelRatio = renderer.getPixelRatio();
					renderer.getSize( currentSize );

					// Check that the browser implements the necessary APIs to use an
					// XRProjectionLayer rather than an XRWebGLLayer
					const useLayers = typeof XRWebGLBinding !== 'undefined' && 'createProjectionLayer' in XRWebGLBinding.prototype;

					if ( ! useLayers ) {

						const layerInit = {
							antialias: attributes.antialias,
							alpha: true,
							depth: attributes.depth,
							stencil: attributes.stencil,
							framebufferScaleFactor: framebufferScaleFactor
						};

						glBaseLayer = new XRWebGLLayer( session, gl, layerInit );

						session.updateRenderState( { baseLayer: glBaseLayer } );

						renderer.setPixelRatio( 1 );
						renderer.setSize( glBaseLayer.framebufferWidth, glBaseLayer.framebufferHeight, false );

						newRenderTarget = new WebGLRenderTarget(
							glBaseLayer.framebufferWidth,
							glBaseLayer.framebufferHeight,
							{
								format: RGBAFormat,
								type: UnsignedByteType,
								colorSpace: renderer.outputColorSpace,
								stencilBuffer: attributes.stencil,
								resolveDepthBuffer: ( glBaseLayer.ignoreDepthValues === false ),
								resolveStencilBuffer: ( glBaseLayer.ignoreDepthValues === false )

							}
						);

					} else {

						let depthFormat = null;
						let depthType = null;
						let glDepthFormat = null;

						if ( attributes.depth ) {

							glDepthFormat = attributes.stencil ? gl.DEPTH24_STENCIL8 : gl.DEPTH_COMPONENT24;
							depthFormat = attributes.stencil ? DepthStencilFormat : DepthFormat;
							depthType = attributes.stencil ? UnsignedInt248Type : UnsignedIntType;

						}

						const projectionlayerInit = {
							colorFormat: gl.RGBA8,
							depthFormat: glDepthFormat,
							scaleFactor: framebufferScaleFactor
						};

						glBinding = new XRWebGLBinding( session, gl );

						glProjLayer = glBinding.createProjectionLayer( projectionlayerInit );

						session.updateRenderState( { layers: [ glProjLayer ] } );

						renderer.setPixelRatio( 1 );
						renderer.setSize( glProjLayer.textureWidth, glProjLayer.textureHeight, false );

						newRenderTarget = new WebGLRenderTarget(
							glProjLayer.textureWidth,
							glProjLayer.textureHeight,
							{
								format: RGBAFormat,
								type: UnsignedByteType,
								depthTexture: new DepthTexture( glProjLayer.textureWidth, glProjLayer.textureHeight, depthType, undefined, undefined, undefined, undefined, undefined, undefined, depthFormat ),
								stencilBuffer: attributes.stencil,
								colorSpace: renderer.outputColorSpace,
								samples: attributes.antialias ? 4 : 0,
								resolveDepthBuffer: ( glProjLayer.ignoreDepthValues === false ),
								resolveStencilBuffer: ( glProjLayer.ignoreDepthValues === false )
							} );

					}

					newRenderTarget.isXRRenderTarget = true; // TODO Remove this when possible, see #23278

					this.setFoveation( foveation );

					customReferenceSpace = null;
					referenceSpace = await session.requestReferenceSpace( referenceSpaceType );

					animation.setContext( session );
					animation.start();

					scope.isPresenting = true;

					scope.dispatchEvent( { type: 'sessionstart' } );

				}

			};

			/**
			 * Returns the environment blend mode from the current XR session.
			 *
			 * @return {'opaque'|'additive'|'alpha-blend'|undefined} The environment blend mode. Returns `undefined` when used outside of a XR session.
			 */
			this.getEnvironmentBlendMode = function () {

				if ( session !== null ) {

					return session.environmentBlendMode;

				}

			};

			/**
			 * Returns the current depth texture computed via depth sensing.
			 *
			 * @return {?Texture} The depth texture.
			 */
			this.getDepthTexture = function () {

				return depthSensing.getDepthTexture();

			};

			function onInputSourcesChange( event ) {

				// Notify disconnected

				for ( let i = 0; i < event.removed.length; i ++ ) {

					const inputSource = event.removed[ i ];
					const index = controllerInputSources.indexOf( inputSource );

					if ( index >= 0 ) {

						controllerInputSources[ index ] = null;
						controllers[ index ].disconnect( inputSource );

					}

				}

				// Notify connected

				for ( let i = 0; i < event.added.length; i ++ ) {

					const inputSource = event.added[ i ];

					let controllerIndex = controllerInputSources.indexOf( inputSource );

					if ( controllerIndex === -1 ) {

						// Assign input source a controller that currently has no input source

						for ( let i = 0; i < controllers.length; i ++ ) {

							if ( i >= controllerInputSources.length ) {

								controllerInputSources.push( inputSource );
								controllerIndex = i;
								break;

							} else if ( controllerInputSources[ i ] === null ) {

								controllerInputSources[ i ] = inputSource;
								controllerIndex = i;
								break;

							}

						}

						// If all controllers do currently receive input we ignore new ones

						if ( controllerIndex === -1 ) break;

					}

					const controller = controllers[ controllerIndex ];

					if ( controller ) {

						controller.connect( inputSource );

					}

				}

			}

			//

			const cameraLPos = new Vector3();
			const cameraRPos = new Vector3();

			/**
			 * Assumes 2 cameras that are parallel and share an X-axis, and that
			 * the cameras' projection and world matrices have already been set.
			 * And that near and far planes are identical for both cameras.
			 * Visualization of this technique: https://computergraphics.stackexchange.com/a/4765
			 *
			 * @param {ArrayCamera} camera - The camera to update.
			 * @param {PerspectiveCamera} cameraL - The left camera.
			 * @param {PerspectiveCamera} cameraR - The right camera.
			 */
			function setProjectionFromUnion( camera, cameraL, cameraR ) {

				cameraLPos.setFromMatrixPosition( cameraL.matrixWorld );
				cameraRPos.setFromMatrixPosition( cameraR.matrixWorld );

				const ipd = cameraLPos.distanceTo( cameraRPos );

				const projL = cameraL.projectionMatrix.elements;
				const projR = cameraR.projectionMatrix.elements;

				// VR systems will have identical far and near planes, and
				// most likely identical top and bottom frustum extents.
				// Use the left camera for these values.
				const near = projL[ 14 ] / ( projL[ 10 ] - 1 );
				const far = projL[ 14 ] / ( projL[ 10 ] + 1 );
				const topFov = ( projL[ 9 ] + 1 ) / projL[ 5 ];
				const bottomFov = ( projL[ 9 ] - 1 ) / projL[ 5 ];

				const leftFov = ( projL[ 8 ] - 1 ) / projL[ 0 ];
				const rightFov = ( projR[ 8 ] + 1 ) / projR[ 0 ];
				const left = near * leftFov;
				const right = near * rightFov;

				// Calculate the new camera's position offset from the
				// left camera. xOffset should be roughly half `ipd`.
				const zOffset = ipd / ( - leftFov + rightFov );
				const xOffset = zOffset * - leftFov;

				// TODO: Better way to apply this offset?
				cameraL.matrixWorld.decompose( camera.position, camera.quaternion, camera.scale );
				camera.translateX( xOffset );
				camera.translateZ( zOffset );
				camera.matrixWorld.compose( camera.position, camera.quaternion, camera.scale );
				camera.matrixWorldInverse.copy( camera.matrixWorld ).invert();

				// Check if the projection uses an infinite far plane.
				if ( projL[ 10 ] === -1 ) {

					// Use the projection matrix from the left eye.
					// The camera offset is sufficient to include the view volumes
					// of both eyes (assuming symmetric projections).
					camera.projectionMatrix.copy( cameraL.projectionMatrix );
					camera.projectionMatrixInverse.copy( cameraL.projectionMatrixInverse );

				} else {

					// Find the union of the frustum values of the cameras and scale
					// the values so that the near plane's position does not change in world space,
					// although must now be relative to the new union camera.
					const near2 = near + zOffset;
					const far2 = far + zOffset;
					const left2 = left - xOffset;
					const right2 = right + ( ipd - xOffset );
					const top2 = topFov * far / far2 * near2;
					const bottom2 = bottomFov * far / far2 * near2;

					camera.projectionMatrix.makePerspective( left2, right2, top2, bottom2, near2, far2 );
					camera.projectionMatrixInverse.copy( camera.projectionMatrix ).invert();

				}

			}

			function updateCamera( camera, parent ) {

				if ( parent === null ) {

					camera.matrixWorld.copy( camera.matrix );

				} else {

					camera.matrixWorld.multiplyMatrices( parent.matrixWorld, camera.matrix );

				}

				camera.matrixWorldInverse.copy( camera.matrixWorld ).invert();

			}

			/**
			 * Updates the state of the XR camera. Use this method on app level if you
			 * set cameraAutoUpdate` to `false`. The method requires the non-XR
			 * camera of the scene as a parameter. The passed in camera's transformation
			 * is automatically adjusted to the position of the XR camera when calling
			 * this method.
			 *
			 * @param {Camera} camera - The camera.
			 */
			this.updateCamera = function ( camera ) {

				if ( session === null ) return;

				let depthNear = camera.near;
				let depthFar = camera.far;

				if ( depthSensing.texture !== null ) {

					if ( depthSensing.depthNear > 0 ) depthNear = depthSensing.depthNear;
					if ( depthSensing.depthFar > 0 ) depthFar = depthSensing.depthFar;

				}

				cameraXR.near = cameraR.near = cameraL.near = depthNear;
				cameraXR.far = cameraR.far = cameraL.far = depthFar;

				if ( _currentDepthNear !== cameraXR.near || _currentDepthFar !== cameraXR.far ) {

					// Note that the new renderState won't apply until the next frame. See #18320

					session.updateRenderState( {
						depthNear: cameraXR.near,
						depthFar: cameraXR.far
					} );

					_currentDepthNear = cameraXR.near;
					_currentDepthFar = cameraXR.far;

				}

				cameraL.layers.mask = camera.layers.mask | 0b010;
				cameraR.layers.mask = camera.layers.mask | 0b100;
				cameraXR.layers.mask = cameraL.layers.mask | cameraR.layers.mask;

				const parent = camera.parent;
				const cameras = cameraXR.cameras;

				updateCamera( cameraXR, parent );

				for ( let i = 0; i < cameras.length; i ++ ) {

					updateCamera( cameras[ i ], parent );

				}

				// update projection matrix for proper view frustum culling

				if ( cameras.length === 2 ) {

					setProjectionFromUnion( cameraXR, cameraL, cameraR );

				} else {

					// assume single camera setup (AR)

					cameraXR.projectionMatrix.copy( cameraL.projectionMatrix );

				}

				// update user camera and its children

				updateUserCamera( camera, cameraXR, parent );

			};

			function updateUserCamera( camera, cameraXR, parent ) {

				if ( parent === null ) {

					camera.matrix.copy( cameraXR.matrixWorld );

				} else {

					camera.matrix.copy( parent.matrixWorld );
					camera.matrix.invert();
					camera.matrix.multiply( cameraXR.matrixWorld );

				}

				camera.matrix.decompose( camera.position, camera.quaternion, camera.scale );
				camera.updateMatrixWorld( true );

				camera.projectionMatrix.copy( cameraXR.projectionMatrix );
				camera.projectionMatrixInverse.copy( cameraXR.projectionMatrixInverse );

				if ( camera.isPerspectiveCamera ) {

					camera.fov = RAD2DEG * 2 * Math.atan( 1 / camera.projectionMatrix.elements[ 5 ] );
					camera.zoom = 1;

				}

			}

			/**
			 * Returns an instance of {@link ArrayCamera} which represents the XR camera
			 * of the active XR session. For each view it holds a separate camera object.
			 *
			 * The camera's `fov` is currently not used and does not reflect the fov of
			 * the XR camera. If you need the fov on app level, you have to compute in
			 * manually from the XR camera's projection matrices.
			 *
			 * @return {ArrayCamera} The XR camera.
			 */
			this.getCamera = function () {

				return cameraXR;

			};

			/**
			 * Returns the amount of foveation used by the XR compositor for the projection layer.
			 *
			 * @return {number} The amount of foveation.
			 */
			this.getFoveation = function () {

				if ( glProjLayer === null && glBaseLayer === null ) {

					return undefined;

				}

				return foveation;

			};

			/**
			 * Sets the foveation value.
			 *
			 * @param {number} value - A number in the range `[0,1]` where `0` means no foveation (full resolution)
			 * and `1` means maximum foveation (the edges render at lower resolution).
			 */
			this.setFoveation = function ( value ) {

				// 0 = no foveation = full resolution
				// 1 = maximum foveation = the edges render at lower resolution

				foveation = value;

				if ( glProjLayer !== null ) {

					glProjLayer.fixedFoveation = value;

				}

				if ( glBaseLayer !== null && glBaseLayer.fixedFoveation !== undefined ) {

					glBaseLayer.fixedFoveation = value;

				}

			};

			/**
			 * Returns `true` if depth sensing is supported.
			 *
			 * @return {boolean} Whether depth sensing is supported or not.
			 */
			this.hasDepthSensing = function () {

				return depthSensing.texture !== null;

			};

			/**
			 * Returns the depth sensing mesh.
			 *
			 * @return {Mesh} The depth sensing mesh.
			 */
			this.getDepthSensingMesh = function () {

				return depthSensing.getMesh( cameraXR );

			};

			// Animation Loop

			let onAnimationFrameCallback = null;

			function onAnimationFrame( time, frame ) {

				pose = frame.getViewerPose( customReferenceSpace || referenceSpace );
				xrFrame = frame;

				if ( pose !== null ) {

					const views = pose.views;

					if ( glBaseLayer !== null ) {

						renderer.setRenderTargetFramebuffer( newRenderTarget, glBaseLayer.framebuffer );
						renderer.setRenderTarget( newRenderTarget );

					}

					let cameraXRNeedsUpdate = false;

					// check if it's necessary to rebuild cameraXR's camera list

					if ( views.length !== cameraXR.cameras.length ) {

						cameraXR.cameras.length = 0;
						cameraXRNeedsUpdate = true;

					}

					for ( let i = 0; i < views.length; i ++ ) {

						const view = views[ i ];

						let viewport = null;

						if ( glBaseLayer !== null ) {

							viewport = glBaseLayer.getViewport( view );

						} else {

							const glSubImage = glBinding.getViewSubImage( glProjLayer, view );
							viewport = glSubImage.viewport;

							// For side-by-side projection, we only produce a single texture for both eyes.
							if ( i === 0 ) {

								renderer.setRenderTargetTextures(
									newRenderTarget,
									glSubImage.colorTexture,
									glSubImage.depthStencilTexture );

								renderer.setRenderTarget( newRenderTarget );

							}

						}

						let camera = cameras[ i ];

						if ( camera === undefined ) {

							camera = new PerspectiveCamera();
							camera.layers.enable( i );
							camera.viewport = new Vector4();
							cameras[ i ] = camera;

						}

						camera.matrix.fromArray( view.transform.matrix );
						camera.matrix.decompose( camera.position, camera.quaternion, camera.scale );
						camera.projectionMatrix.fromArray( view.projectionMatrix );
						camera.projectionMatrixInverse.copy( camera.projectionMatrix ).invert();
						camera.viewport.set( viewport.x, viewport.y, viewport.width, viewport.height );

						if ( i === 0 ) {

							cameraXR.matrix.copy( camera.matrix );
							cameraXR.matrix.decompose( cameraXR.position, cameraXR.quaternion, cameraXR.scale );

						}

						if ( cameraXRNeedsUpdate === true ) {

							cameraXR.cameras.push( camera );

						}

					}

					//

					const enabledFeatures = session.enabledFeatures;
					const gpuDepthSensingEnabled = enabledFeatures &&
						enabledFeatures.includes( 'depth-sensing' ) &&
						session.depthUsage == 'gpu-optimized';

					if ( gpuDepthSensingEnabled && glBinding ) {

						const depthData = glBinding.getDepthInformation( views[ 0 ] );

						if ( depthData && depthData.isValid && depthData.texture ) {

							depthSensing.init( renderer, depthData, session.renderState );

						}

					}

				}

				//

				for ( let i = 0; i < controllers.length; i ++ ) {

					const inputSource = controllerInputSources[ i ];
					const controller = controllers[ i ];

					if ( inputSource !== null && controller !== undefined ) {

						controller.update( inputSource, frame, customReferenceSpace || referenceSpace );

					}

				}

				if ( onAnimationFrameCallback ) onAnimationFrameCallback( time, frame );

				if ( frame.detectedPlanes ) {

					scope.dispatchEvent( { type: 'planesdetected', data: frame } );

				}

				xrFrame = null;

			}

			const animation = new WebGLAnimation();

			animation.setAnimationLoop( onAnimationFrame );

			this.setAnimationLoop = function ( callback ) {

				onAnimationFrameCallback = callback;

			};

			this.dispose = function () {};

		}

	}

	const _e1 = /*@__PURE__*/ new Euler();
	const _m1$3 = /*@__PURE__*/ new Matrix4();

	function WebGLMaterials( renderer, properties ) {

		function refreshTransformUniform( map, uniform ) {

			if ( map.matrixAutoUpdate === true ) {

				map.updateMatrix();

			}

			uniform.value.copy( map.matrix );

		}

		function refreshFogUniforms( uniforms, fog ) {

			fog.color.getRGB( uniforms.fogColor.value, getUnlitUniformColorSpace( renderer ) );

			if ( fog.isFog ) {

				uniforms.fogNear.value = fog.near;
				uniforms.fogFar.value = fog.far;

			} else if ( fog.isFogExp2 ) {

				uniforms.fogDensity.value = fog.density;

			}

		}

		function refreshMaterialUniforms( uniforms, material, pixelRatio, height, transmissionRenderTarget ) {

			if ( material.isMeshBasicMaterial ) {

				refreshUniformsCommon( uniforms, material );

			} else if ( material.isMeshLambertMaterial ) {

				refreshUniformsCommon( uniforms, material );

			} else if ( material.isMeshToonMaterial ) {

				refreshUniformsCommon( uniforms, material );
				refreshUniformsToon( uniforms, material );

			} else if ( material.isMeshPhongMaterial ) {

				refreshUniformsCommon( uniforms, material );
				refreshUniformsPhong( uniforms, material );

			} else if ( material.isMeshStandardMaterial ) {

				refreshUniformsCommon( uniforms, material );
				refreshUniformsStandard( uniforms, material );

				if ( material.isMeshPhysicalMaterial ) {

					refreshUniformsPhysical( uniforms, material, transmissionRenderTarget );

				}

			} else if ( material.isMeshMatcapMaterial ) {

				refreshUniformsCommon( uniforms, material );
				refreshUniformsMatcap( uniforms, material );

			} else if ( material.isMeshDepthMaterial ) {

				refreshUniformsCommon( uniforms, material );

			} else if ( material.isMeshDistanceMaterial ) {

				refreshUniformsCommon( uniforms, material );
				refreshUniformsDistance( uniforms, material );

			} else if ( material.isMeshNormalMaterial ) {

				refreshUniformsCommon( uniforms, material );

			} else if ( material.isLineBasicMaterial ) {

				refreshUniformsLine( uniforms, material );

				if ( material.isLineDashedMaterial ) {

					refreshUniformsDash( uniforms, material );

				}

			} else if ( material.isPointsMaterial ) {

				refreshUniformsPoints( uniforms, material, pixelRatio, height );

			} else if ( material.isSpriteMaterial ) {

				refreshUniformsSprites( uniforms, material );

			} else if ( material.isShadowMaterial ) {

				uniforms.color.value.copy( material.color );
				uniforms.opacity.value = material.opacity;

			} else if ( material.isShaderMaterial ) {

				material.uniformsNeedUpdate = false; // #15581

			}

		}

		function refreshUniformsCommon( uniforms, material ) {

			uniforms.opacity.value = material.opacity;

			if ( material.color ) {

				uniforms.diffuse.value.copy( material.color );

			}

			if ( material.emissive ) {

				uniforms.emissive.value.copy( material.emissive ).multiplyScalar( material.emissiveIntensity );

			}

			if ( material.map ) {

				uniforms.map.value = material.map;

				refreshTransformUniform( material.map, uniforms.mapTransform );

			}

			if ( material.alphaMap ) {

				uniforms.alphaMap.value = material.alphaMap;

				refreshTransformUniform( material.alphaMap, uniforms.alphaMapTransform );

			}

			if ( material.bumpMap ) {

				uniforms.bumpMap.value = material.bumpMap;

				refreshTransformUniform( material.bumpMap, uniforms.bumpMapTransform );

				uniforms.bumpScale.value = material.bumpScale;

				if ( material.side === BackSide ) {

					uniforms.bumpScale.value *= -1;

				}

			}

			if ( material.normalMap ) {

				uniforms.normalMap.value = material.normalMap;

				refreshTransformUniform( material.normalMap, uniforms.normalMapTransform );

				uniforms.normalScale.value.copy( material.normalScale );

				if ( material.side === BackSide ) {

					uniforms.normalScale.value.negate();

				}

			}

			if ( material.displacementMap ) {

				uniforms.displacementMap.value = material.displacementMap;

				refreshTransformUniform( material.displacementMap, uniforms.displacementMapTransform );

				uniforms.displacementScale.value = material.displacementScale;
				uniforms.displacementBias.value = material.displacementBias;

			}

			if ( material.emissiveMap ) {

				uniforms.emissiveMap.value = material.emissiveMap;

				refreshTransformUniform( material.emissiveMap, uniforms.emissiveMapTransform );

			}

			if ( material.specularMap ) {

				uniforms.specularMap.value = material.specularMap;

				refreshTransformUniform( material.specularMap, uniforms.specularMapTransform );

			}

			if ( material.alphaTest > 0 ) {

				uniforms.alphaTest.value = material.alphaTest;

			}

			const materialProperties = properties.get( material );

			const envMap = materialProperties.envMap;
			const envMapRotation = materialProperties.envMapRotation;

			if ( envMap ) {

				uniforms.envMap.value = envMap;

				_e1.copy( envMapRotation );

				// accommodate left-handed frame
				_e1.x *= -1; _e1.y *= -1; _e1.z *= -1;

				if ( envMap.isCubeTexture && envMap.isRenderTargetTexture === false ) {

					// environment maps which are not cube render targets or PMREMs follow a different convention
					_e1.y *= -1;
					_e1.z *= -1;

				}

				uniforms.envMapRotation.value.setFromMatrix4( _m1$3.makeRotationFromEuler( _e1 ) );

				uniforms.flipEnvMap.value = ( envMap.isCubeTexture && envMap.isRenderTargetTexture === false ) ? -1 : 1;

				uniforms.reflectivity.value = material.reflectivity;
				uniforms.ior.value = material.ior;
				uniforms.refractionRatio.value = material.refractionRatio;

			}

			if ( material.lightMap ) {

				uniforms.lightMap.value = material.lightMap;
				uniforms.lightMapIntensity.value = material.lightMapIntensity;

				refreshTransformUniform( material.lightMap, uniforms.lightMapTransform );

			}

			if ( material.aoMap ) {

				uniforms.aoMap.value = material.aoMap;
				uniforms.aoMapIntensity.value = material.aoMapIntensity;

				refreshTransformUniform( material.aoMap, uniforms.aoMapTransform );

			}

		}

		function refreshUniformsLine( uniforms, material ) {

			uniforms.diffuse.value.copy( material.color );
			uniforms.opacity.value = material.opacity;

			if ( material.map ) {

				uniforms.map.value = material.map;

				refreshTransformUniform( material.map, uniforms.mapTransform );

			}

		}

		function refreshUniformsDash( uniforms, material ) {

			uniforms.dashSize.value = material.dashSize;
			uniforms.totalSize.value = material.dashSize + material.gapSize;
			uniforms.scale.value = material.scale;

		}

		function refreshUniformsPoints( uniforms, material, pixelRatio, height ) {

			uniforms.diffuse.value.copy( material.color );
			uniforms.opacity.value = material.opacity;
			uniforms.size.value = material.size * pixelRatio;
			uniforms.scale.value = height * 0.5;

			if ( material.map ) {

				uniforms.map.value = material.map;

				refreshTransformUniform( material.map, uniforms.uvTransform );

			}

			if ( material.alphaMap ) {

				uniforms.alphaMap.value = material.alphaMap;

				refreshTransformUniform( material.alphaMap, uniforms.alphaMapTransform );

			}

			if ( material.alphaTest > 0 ) {

				uniforms.alphaTest.value = material.alphaTest;

			}

		}

		function refreshUniformsSprites( uniforms, material ) {

			uniforms.diffuse.value.copy( material.color );
			uniforms.opacity.value = material.opacity;
			uniforms.rotation.value = material.rotation;

			if ( material.map ) {

				uniforms.map.value = material.map;

				refreshTransformUniform( material.map, uniforms.mapTransform );

			}

			if ( material.alphaMap ) {

				uniforms.alphaMap.value = material.alphaMap;

				refreshTransformUniform( material.alphaMap, uniforms.alphaMapTransform );

			}

			if ( material.alphaTest > 0 ) {

				uniforms.alphaTest.value = material.alphaTest;

			}

		}

		function refreshUniformsPhong( uniforms, material ) {

			uniforms.specular.value.copy( material.specular );
			uniforms.shininess.value = Math.max( material.shininess, 1e-4 ); // to prevent pow( 0.0, 0.0 )

		}

		function refreshUniformsToon( uniforms, material ) {

			if ( material.gradientMap ) {

				uniforms.gradientMap.value = material.gradientMap;

			}

		}

		function refreshUniformsStandard( uniforms, material ) {

			uniforms.metalness.value = material.metalness;

			if ( material.metalnessMap ) {

				uniforms.metalnessMap.value = material.metalnessMap;

				refreshTransformUniform( material.metalnessMap, uniforms.metalnessMapTransform );

			}

			uniforms.roughness.value = material.roughness;

			if ( material.roughnessMap ) {

				uniforms.roughnessMap.value = material.roughnessMap;

				refreshTransformUniform( material.roughnessMap, uniforms.roughnessMapTransform );

			}

			if ( material.envMap ) {

				//uniforms.envMap.value = material.envMap; // part of uniforms common

				uniforms.envMapIntensity.value = material.envMapIntensity;

			}

		}

		function refreshUniformsPhysical( uniforms, material, transmissionRenderTarget ) {

			uniforms.ior.value = material.ior; // also part of uniforms common

			if ( material.sheen > 0 ) {

				uniforms.sheenColor.value.copy( material.sheenColor ).multiplyScalar( material.sheen );

				uniforms.sheenRoughness.value = material.sheenRoughness;

				if ( material.sheenColorMap ) {

					uniforms.sheenColorMap.value = material.sheenColorMap;

					refreshTransformUniform( material.sheenColorMap, uniforms.sheenColorMapTransform );

				}

				if ( material.sheenRoughnessMap ) {

					uniforms.sheenRoughnessMap.value = material.sheenRoughnessMap;

					refreshTransformUniform( material.sheenRoughnessMap, uniforms.sheenRoughnessMapTransform );

				}

			}

			if ( material.clearcoat > 0 ) {

				uniforms.clearcoat.value = material.clearcoat;
				uniforms.clearcoatRoughness.value = material.clearcoatRoughness;

				if ( material.clearcoatMap ) {

					uniforms.clearcoatMap.value = material.clearcoatMap;

					refreshTransformUniform( material.clearcoatMap, uniforms.clearcoatMapTransform );

				}

				if ( material.clearcoatRoughnessMap ) {

					uniforms.clearcoatRoughnessMap.value = material.clearcoatRoughnessMap;

					refreshTransformUniform( material.clearcoatRoughnessMap, uniforms.clearcoatRoughnessMapTransform );

				}

				if ( material.clearcoatNormalMap ) {

					uniforms.clearcoatNormalMap.value = material.clearcoatNormalMap;

					refreshTransformUniform( material.clearcoatNormalMap, uniforms.clearcoatNormalMapTransform );

					uniforms.clearcoatNormalScale.value.copy( material.clearcoatNormalScale );

					if ( material.side === BackSide ) {

						uniforms.clearcoatNormalScale.value.negate();

					}

				}

			}

			if ( material.dispersion > 0 ) {

				uniforms.dispersion.value = material.dispersion;

			}

			if ( material.iridescence > 0 ) {

				uniforms.iridescence.value = material.iridescence;
				uniforms.iridescenceIOR.value = material.iridescenceIOR;
				uniforms.iridescenceThicknessMinimum.value = material.iridescenceThicknessRange[ 0 ];
				uniforms.iridescenceThicknessMaximum.value = material.iridescenceThicknessRange[ 1 ];

				if ( material.iridescenceMap ) {

					uniforms.iridescenceMap.value = material.iridescenceMap;

					refreshTransformUniform( material.iridescenceMap, uniforms.iridescenceMapTransform );

				}

				if ( material.iridescenceThicknessMap ) {

					uniforms.iridescenceThicknessMap.value = material.iridescenceThicknessMap;

					refreshTransformUniform( material.iridescenceThicknessMap, uniforms.iridescenceThicknessMapTransform );

				}

			}

			if ( material.transmission > 0 ) {

				uniforms.transmission.value = material.transmission;
				uniforms.transmissionSamplerMap.value = transmissionRenderTarget.texture;
				uniforms.transmissionSamplerSize.value.set( transmissionRenderTarget.width, transmissionRenderTarget.height );

				if ( material.transmissionMap ) {

					uniforms.transmissionMap.value = material.transmissionMap;

					refreshTransformUniform( material.transmissionMap, uniforms.transmissionMapTransform );

				}

				uniforms.thickness.value = material.thickness;

				if ( material.thicknessMap ) {

					uniforms.thicknessMap.value = material.thicknessMap;

					refreshTransformUniform( material.thicknessMap, uniforms.thicknessMapTransform );

				}

				uniforms.attenuationDistance.value = material.attenuationDistance;
				uniforms.attenuationColor.value.copy( material.attenuationColor );

			}

			if ( material.anisotropy > 0 ) {

				uniforms.anisotropyVector.value.set( material.anisotropy * Math.cos( material.anisotropyRotation ), material.anisotropy * Math.sin( material.anisotropyRotation ) );

				if ( material.anisotropyMap ) {

					uniforms.anisotropyMap.value = material.anisotropyMap;

					refreshTransformUniform( material.anisotropyMap, uniforms.anisotropyMapTransform );

				}

			}

			uniforms.specularIntensity.value = material.specularIntensity;
			uniforms.specularColor.value.copy( material.specularColor );

			if ( material.specularColorMap ) {

				uniforms.specularColorMap.value = material.specularColorMap;

				refreshTransformUniform( material.specularColorMap, uniforms.specularColorMapTransform );

			}

			if ( material.specularIntensityMap ) {

				uniforms.specularIntensityMap.value = material.specularIntensityMap;

				refreshTransformUniform( material.specularIntensityMap, uniforms.specularIntensityMapTransform );

			}

		}

		function refreshUniformsMatcap( uniforms, material ) {

			if ( material.matcap ) {

				uniforms.matcap.value = material.matcap;

			}

		}

		function refreshUniformsDistance( uniforms, material ) {

			const light = properties.get( material ).light;

			uniforms.referencePosition.value.setFromMatrixPosition( light.matrixWorld );
			uniforms.nearDistance.value = light.shadow.camera.near;
			uniforms.farDistance.value = light.shadow.camera.far;

		}

		return {
			refreshFogUniforms: refreshFogUniforms,
			refreshMaterialUniforms: refreshMaterialUniforms
		};

	}

	function WebGLUniformsGroups( gl, info, capabilities, state ) {

		let buffers = {};
		let updateList = {};
		let allocatedBindingPoints = [];

		const maxBindingPoints = gl.getParameter( gl.MAX_UNIFORM_BUFFER_BINDINGS ); // binding points are global whereas block indices are per shader program

		function bind( uniformsGroup, program ) {

			const webglProgram = program.program;
			state.uniformBlockBinding( uniformsGroup, webglProgram );

		}

		function update( uniformsGroup, program ) {

			let buffer = buffers[ uniformsGroup.id ];

			if ( buffer === undefined ) {

				prepareUniformsGroup( uniformsGroup );

				buffer = createBuffer( uniformsGroup );
				buffers[ uniformsGroup.id ] = buffer;

				uniformsGroup.addEventListener( 'dispose', onUniformsGroupsDispose );

			}

			// ensure to update the binding points/block indices mapping for this program

			const webglProgram = program.program;
			state.updateUBOMapping( uniformsGroup, webglProgram );

			// update UBO once per frame

			const frame = info.render.frame;

			if ( updateList[ uniformsGroup.id ] !== frame ) {

				updateBufferData( uniformsGroup );

				updateList[ uniformsGroup.id ] = frame;

			}

		}

		function createBuffer( uniformsGroup ) {

			// the setup of an UBO is independent of a particular shader program but global

			const bindingPointIndex = allocateBindingPointIndex();
			uniformsGroup.__bindingPointIndex = bindingPointIndex;

			const buffer = gl.createBuffer();
			const size = uniformsGroup.__size;
			const usage = uniformsGroup.usage;

			gl.bindBuffer( gl.UNIFORM_BUFFER, buffer );
			gl.bufferData( gl.UNIFORM_BUFFER, size, usage );
			gl.bindBuffer( gl.UNIFORM_BUFFER, null );
			gl.bindBufferBase( gl.UNIFORM_BUFFER, bindingPointIndex, buffer );

			return buffer;

		}

		function allocateBindingPointIndex() {

			for ( let i = 0; i < maxBindingPoints; i ++ ) {

				if ( allocatedBindingPoints.indexOf( i ) === -1 ) {

					allocatedBindingPoints.push( i );
					return i;

				}

			}

			console.error( 'THREE.WebGLRenderer: Maximum number of simultaneously usable uniforms groups reached.' );

			return 0;

		}

		function updateBufferData( uniformsGroup ) {

			const buffer = buffers[ uniformsGroup.id ];
			const uniforms = uniformsGroup.uniforms;
			const cache = uniformsGroup.__cache;

			gl.bindBuffer( gl.UNIFORM_BUFFER, buffer );

			for ( let i = 0, il = uniforms.length; i < il; i ++ ) {

				const uniformArray = Array.isArray( uniforms[ i ] ) ? uniforms[ i ] : [ uniforms[ i ] ];

				for ( let j = 0, jl = uniformArray.length; j < jl; j ++ ) {

					const uniform = uniformArray[ j ];

					if ( hasUniformChanged( uniform, i, j, cache ) === true ) {

						const offset = uniform.__offset;

						const values = Array.isArray( uniform.value ) ? uniform.value : [ uniform.value ];

						let arrayOffset = 0;

						for ( let k = 0; k < values.length; k ++ ) {

							const value = values[ k ];

							const info = getUniformSize( value );

							// TODO add integer and struct support
							if ( typeof value === 'number' || typeof value === 'boolean' ) {

								uniform.__data[ 0 ] = value;
								gl.bufferSubData( gl.UNIFORM_BUFFER, offset + arrayOffset, uniform.__data );

							} else if ( value.isMatrix3 ) {

								// manually converting 3x3 to 3x4

								uniform.__data[ 0 ] = value.elements[ 0 ];
								uniform.__data[ 1 ] = value.elements[ 1 ];
								uniform.__data[ 2 ] = value.elements[ 2 ];
								uniform.__data[ 3 ] = 0;
								uniform.__data[ 4 ] = value.elements[ 3 ];
								uniform.__data[ 5 ] = value.elements[ 4 ];
								uniform.__data[ 6 ] = value.elements[ 5 ];
								uniform.__data[ 7 ] = 0;
								uniform.__data[ 8 ] = value.elements[ 6 ];
								uniform.__data[ 9 ] = value.elements[ 7 ];
								uniform.__data[ 10 ] = value.elements[ 8 ];
								uniform.__data[ 11 ] = 0;

							} else {

								value.toArray( uniform.__data, arrayOffset );

								arrayOffset += info.storage / Float32Array.BYTES_PER_ELEMENT;

							}

						}

						gl.bufferSubData( gl.UNIFORM_BUFFER, offset, uniform.__data );

					}

				}

			}

			gl.bindBuffer( gl.UNIFORM_BUFFER, null );

		}

		function hasUniformChanged( uniform, index, indexArray, cache ) {

			const value = uniform.value;
			const indexString = index + '_' + indexArray;

			if ( cache[ indexString ] === undefined ) {

				// cache entry does not exist so far

				if ( typeof value === 'number' || typeof value === 'boolean' ) {

					cache[ indexString ] = value;

				} else {

					cache[ indexString ] = value.clone();

				}

				return true;

			} else {

				const cachedObject = cache[ indexString ];

				// compare current value with cached entry

				if ( typeof value === 'number' || typeof value === 'boolean' ) {

					if ( cachedObject !== value ) {

						cache[ indexString ] = value;
						return true;

					}

				} else {

					if ( cachedObject.equals( value ) === false ) {

						cachedObject.copy( value );
						return true;

					}

				}

			}

			return false;

		}

		function prepareUniformsGroup( uniformsGroup ) {

			// determine total buffer size according to the STD140 layout
			// Hint: STD140 is the only supported layout in WebGL 2

			const uniforms = uniformsGroup.uniforms;

			let offset = 0; // global buffer offset in bytes
			const chunkSize = 16; // size of a chunk in bytes

			for ( let i = 0, l = uniforms.length; i < l; i ++ ) {

				const uniformArray = Array.isArray( uniforms[ i ] ) ? uniforms[ i ] : [ uniforms[ i ] ];

				for ( let j = 0, jl = uniformArray.length; j < jl; j ++ ) {

					const uniform = uniformArray[ j ];

					const values = Array.isArray( uniform.value ) ? uniform.value : [ uniform.value ];

					for ( let k = 0, kl = values.length; k < kl; k ++ ) {

						const value = values[ k ];

						const info = getUniformSize( value );

						const chunkOffset = offset % chunkSize; // offset in the current chunk
						const chunkPadding = chunkOffset % info.boundary; // required padding to match boundary
						const chunkStart = chunkOffset + chunkPadding; // the start position in the current chunk for the data

						offset += chunkPadding;

						// Check for chunk overflow
						if ( chunkStart !== 0 && ( chunkSize - chunkStart ) < info.storage ) {

							// Add padding and adjust offset
							offset += ( chunkSize - chunkStart );

						}

						// the following two properties will be used for partial buffer updates
						uniform.__data = new Float32Array( info.storage / Float32Array.BYTES_PER_ELEMENT );
						uniform.__offset = offset;

						// Update the global offset
						offset += info.storage;

					}

				}

			}

			// ensure correct final padding

			const chunkOffset = offset % chunkSize;

			if ( chunkOffset > 0 ) offset += ( chunkSize - chunkOffset );

			//

			uniformsGroup.__size = offset;
			uniformsGroup.__cache = {};

			return this;

		}

		function getUniformSize( value ) {

			const info = {
				boundary: 0, // bytes
				storage: 0 // bytes
			};

			// determine sizes according to STD140

			if ( typeof value === 'number' || typeof value === 'boolean' ) {

				// float/int/bool

				info.boundary = 4;
				info.storage = 4;

			} else if ( value.isVector2 ) {

				// vec2

				info.boundary = 8;
				info.storage = 8;

			} else if ( value.isVector3 || value.isColor ) {

				// vec3

				info.boundary = 16;
				info.storage = 12; // evil: vec3 must start on a 16-byte boundary but it only consumes 12 bytes

			} else if ( value.isVector4 ) {

				// vec4

				info.boundary = 16;
				info.storage = 16;

			} else if ( value.isMatrix3 ) {

				// mat3 (in STD140 a 3x3 matrix is represented as 3x4)

				info.boundary = 48;
				info.storage = 48;

			} else if ( value.isMatrix4 ) {

				// mat4

				info.boundary = 64;
				info.storage = 64;

			} else if ( value.isTexture ) {

				console.warn( 'THREE.WebGLRenderer: Texture samplers can not be part of an uniforms group.' );

			} else {

				console.warn( 'THREE.WebGLRenderer: Unsupported uniform value type.', value );

			}

			return info;

		}

		function onUniformsGroupsDispose( event ) {

			const uniformsGroup = event.target;

			uniformsGroup.removeEventListener( 'dispose', onUniformsGroupsDispose );

			const index = allocatedBindingPoints.indexOf( uniformsGroup.__bindingPointIndex );
			allocatedBindingPoints.splice( index, 1 );

			gl.deleteBuffer( buffers[ uniformsGroup.id ] );

			delete buffers[ uniformsGroup.id ];
			delete updateList[ uniformsGroup.id ];

		}

		function dispose() {

			for ( const id in buffers ) {

				gl.deleteBuffer( buffers[ id ] );

			}

			allocatedBindingPoints = [];
			buffers = {};
			updateList = {};

		}

		return {

			bind: bind,
			update: update,

			dispose: dispose

		};

	}

	/**
	 * This renderer uses WebGL 2 to display scenes.
	 *
	 * WebGL 1 is not supported since `r163`.
	 */
	class WebGLRenderer {

		/**
		 * Constructs a new WebGL renderer.
		 *
		 * @param {WebGLRenderer~Options} [parameters] - The configuration parameter.
		 */
		constructor( parameters = {} ) {

			const {
				canvas = createCanvasElement(),
				context = null,
				depth = true,
				stencil = false,
				alpha = false,
				antialias = false,
				premultipliedAlpha = true,
				preserveDrawingBuffer = false,
				powerPreference = 'default',
				failIfMajorPerformanceCaveat = false,
				reverseDepthBuffer = false,
			} = parameters;

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isWebGLRenderer = true;

			let _alpha;

			if ( context !== null ) {

				if ( typeof WebGLRenderingContext !== 'undefined' && context instanceof WebGLRenderingContext ) {

					throw new Error( 'THREE.WebGLRenderer: WebGL 1 is not supported since r163.' );

				}

				_alpha = context.getContextAttributes().alpha;

			} else {

				_alpha = alpha;

			}

			const uintClearColor = new Uint32Array( 4 );
			const intClearColor = new Int32Array( 4 );

			let currentRenderList = null;
			let currentRenderState = null;

			// render() can be called from within a callback triggered by another render.
			// We track this so that the nested render call gets its list and state isolated from the parent render call.

			const renderListStack = [];
			const renderStateStack = [];

			// public properties

			/**
			 * A canvas where the renderer draws its output.This is automatically created by the renderer
			 * in the constructor (if not provided already); you just need to add it to your page like so:
			 * ```js
			 * document.body.appendChild( renderer.domElement );
			 * ```
			 *
			 * @type {DOMElement}
			 */
			this.domElement = canvas;

			/**
			 * A object with debug configuration settings.
			 *
			 * - `checkShaderErrors`: If it is `true`, defines whether material shader programs are
			 * checked for errors during compilation and linkage process. It may be useful to disable
			 * this check in production for performance gain. It is strongly recommended to keep these
			 * checks enabled during development. If the shader does not compile and link - it will not
			 * work and associated material will not render.
			 * - `onShaderError(gl, program, glVertexShader,glFragmentShader)`: A callback function that
			 * can be used for custom error reporting. The callback receives the WebGL context, an instance
			 * of WebGLProgram as well two instances of WebGLShader representing the vertex and fragment shader.
			 * Assigning a custom function disables the default error reporting.
			 *
			 * @type {Object}
			 */
			this.debug = {

				/**
				 * Enables error checking and reporting when shader programs are being compiled.
				 * @type {boolean}
				 */
				checkShaderErrors: true,
				/**
				 * Callback for custom error reporting.
				 * @type {?Function}
				 */
				onShaderError: null
			};

			// clearing

			/**
			 * Whether the renderer should automatically clear its output before rendering a frame or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.autoClear = true;

			/**
			 * If {@link WebGLRenderer#autoClear} set to `true`, whether the renderer should clear
			 * the color buffer or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.autoClearColor = true;

			/**
			 * If {@link WebGLRenderer#autoClear} set to `true`, whether the renderer should clear
			 * the depth buffer or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.autoClearDepth = true;

			/**
			 * If {@link WebGLRenderer#autoClear} set to `true`, whether the renderer should clear
			 * the stencil buffer or not.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.autoClearStencil = true;

			// scene graph

			/**
			 * Whether the renderer should sort objects or not.
			 *
			 * Note: Sorting is used to attempt to properly render objects that have some
			 * degree of transparency. By definition, sorting objects may not work in all
			 * cases. Depending on the needs of application, it may be necessary to turn
			 * off sorting and use other methods to deal with transparency rendering e.g.
			 * manually determining each object's rendering order.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.sortObjects = true;

			// user-defined clipping

			/**
			 * User-defined clipping planes specified in world space. These planes apply globally.
			 * Points in space whose dot product with the plane is negative are cut away.
			 *
			 * @type {Array<Plane>}
			 */
			this.clippingPlanes = [];

			/**
			 * Whether the renderer respects object-level clipping planes or not.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.localClippingEnabled = false;

			// tone mapping

			/**
			 * The tone mapping technique of the renderer.
			 *
			 * @type {(NoToneMapping|LinearToneMapping|ReinhardToneMapping|CineonToneMapping|ACESFilmicToneMapping|CustomToneMapping|AgXToneMapping|NeutralToneMapping)}
			 * @default NoToneMapping
			 */
			this.toneMapping = NoToneMapping;

			/**
			 * Exposure level of tone mapping.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.toneMappingExposure = 1.0;

			// transmission

			/**
			 * The normalized resolution scale for the transmission render target, measured in percentage
			 * of viewport dimensions. Lowering this value can result in significant performance improvements
			 * when using {@link MeshPhysicalMaterial#transmission}.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.transmissionResolutionScale = 1.0;

			// internal properties

			const _this = this;

			let _isContextLost = false;

			// internal state cache

			this._outputColorSpace = SRGBColorSpace;

			let _currentActiveCubeFace = 0;
			let _currentActiveMipmapLevel = 0;
			let _currentRenderTarget = null;
			let _currentMaterialId = -1;

			let _currentCamera = null;

			const _currentViewport = new Vector4();
			const _currentScissor = new Vector4();
			let _currentScissorTest = null;

			const _currentClearColor = new Color( 0x000000 );
			let _currentClearAlpha = 0;

			//

			let _width = canvas.width;
			let _height = canvas.height;

			let _pixelRatio = 1;
			let _opaqueSort = null;
			let _transparentSort = null;

			const _viewport = new Vector4( 0, 0, _width, _height );
			const _scissor = new Vector4( 0, 0, _width, _height );
			let _scissorTest = false;

			// frustum

			const _frustum = new Frustum();

			// clipping

			let _clippingEnabled = false;
			let _localClippingEnabled = false;

			// camera matrices cache

			const _currentProjectionMatrix = new Matrix4();
			const _projScreenMatrix = new Matrix4();

			const _vector3 = new Vector3();

			const _vector4 = new Vector4();

			const _emptyScene = { background: null, fog: null, environment: null, overrideMaterial: null, isScene: true };

			let _renderBackground = false;

			function getTargetPixelRatio() {

				return _currentRenderTarget === null ? _pixelRatio : 1;

			}

			// initialize

			let _gl = context;

			function getContext( contextName, contextAttributes ) {

				return canvas.getContext( contextName, contextAttributes );

			}

			try {

				const contextAttributes = {
					alpha: true,
					depth,
					stencil,
					antialias,
					premultipliedAlpha,
					preserveDrawingBuffer,
					powerPreference,
					failIfMajorPerformanceCaveat,
				};

				// OffscreenCanvas does not have setAttribute, see #22811
				if ( 'setAttribute' in canvas ) canvas.setAttribute( 'data-engine', `three.js r${REVISION}` );

				// event listeners must be registered before WebGL context is created, see #12753
				canvas.addEventListener( 'webglcontextlost', onContextLost, false );
				canvas.addEventListener( 'webglcontextrestored', onContextRestore, false );
				canvas.addEventListener( 'webglcontextcreationerror', onContextCreationError, false );

				if ( _gl === null ) {

					const contextName = 'webgl2';

					_gl = getContext( contextName, contextAttributes );

					if ( _gl === null ) {

						if ( getContext( contextName ) ) {

							throw new Error( 'Error creating WebGL context with your selected attributes.' );

						} else {

							throw new Error( 'Error creating WebGL context.' );

						}

					}

				}

			} catch ( error ) {

				console.error( 'THREE.WebGLRenderer: ' + error.message );
				throw error;

			}

			let extensions, capabilities, state, info;
			let properties, textures, cubemaps, cubeuvmaps, attributes, geometries, objects;
			let programCache, materials, renderLists, renderStates, clipping, shadowMap;

			let background, morphtargets, bufferRenderer, indexedBufferRenderer;

			let utils, bindingStates, uniformsGroups;

			function initGLContext() {

				extensions = new WebGLExtensions( _gl );
				extensions.init();

				utils = new WebGLUtils( _gl, extensions );

				capabilities = new WebGLCapabilities( _gl, extensions, parameters, utils );

				state = new WebGLState( _gl, extensions );

				if ( capabilities.reverseDepthBuffer && reverseDepthBuffer ) {

					state.buffers.depth.setReversed( true );

				}

				info = new WebGLInfo( _gl );
				properties = new WebGLProperties();
				textures = new WebGLTextures( _gl, extensions, state, properties, capabilities, utils, info );
				cubemaps = new WebGLCubeMaps( _this );
				cubeuvmaps = new WebGLCubeUVMaps( _this );
				attributes = new WebGLAttributes( _gl );
				bindingStates = new WebGLBindingStates( _gl, attributes );
				geometries = new WebGLGeometries( _gl, attributes, info, bindingStates );
				objects = new WebGLObjects( _gl, geometries, attributes, info );
				morphtargets = new WebGLMorphtargets( _gl, capabilities, textures );
				clipping = new WebGLClipping( properties );
				programCache = new WebGLPrograms( _this, cubemaps, cubeuvmaps, extensions, capabilities, bindingStates, clipping );
				materials = new WebGLMaterials( _this, properties );
				renderLists = new WebGLRenderLists();
				renderStates = new WebGLRenderStates( extensions );
				background = new WebGLBackground( _this, cubemaps, cubeuvmaps, state, objects, _alpha, premultipliedAlpha );
				shadowMap = new WebGLShadowMap( _this, objects, capabilities );
				uniformsGroups = new WebGLUniformsGroups( _gl, info, capabilities, state );

				bufferRenderer = new WebGLBufferRenderer( _gl, extensions, info );
				indexedBufferRenderer = new WebGLIndexedBufferRenderer( _gl, extensions, info );

				info.programs = programCache.programs;

				/**
				 * Holds details about the capabilities of the current rendering context.
				 *
				 * @name WebGLRenderer#capabilities
				 * @type {WebGLRenderer~Capabilities}
				 */
				_this.capabilities = capabilities;

				/**
				 * Provides methods for retrieving and testing WebGL extensions.
				 *
				 * - `get(extensionName:string)`: Used to check whether a WebGL extension is supported
				 * and return the extension object if available.
				 * - `has(extensionName:string)`: returns `true` if the extension is supported.
				 *
				 * @name WebGLRenderer#extensions
				 * @type {Object}
				 */
				_this.extensions = extensions;

				/**
				 * Used to track properties of other objects like native WebGL objects.
				 *
				 * @name WebGLRenderer#properties
				 * @type {Object}
				 */
				_this.properties = properties;

				/**
				 * Manages the render lists of the renderer.
				 *
				 * @name WebGLRenderer#renderLists
				 * @type {Object}
				 */
				_this.renderLists = renderLists;



				/**
				 * Interface for managing shadows.
				 *
				 * @name WebGLRenderer#shadowMap
				 * @type {WebGLRenderer~ShadowMap}
				 */
				_this.shadowMap = shadowMap;

				/**
				 * Interface for managing the WebGL state.
				 *
				 * @name WebGLRenderer#state
				 * @type {Object}
				 */
				_this.state = state;

				/**
				 * Holds a series of statistical information about the GPU memory
				 * and the rendering process. Useful for debugging and monitoring.
				 *
				 * By default these data are reset at each render call but when having
				 * multiple render passes per frame (e.g. when using post processing) it can
				 * be preferred to reset with a custom pattern. First, set `autoReset` to
				 * `false`.
				 * ```js
				 * renderer.info.autoReset = false;
				 * ```
				 * Call `reset()` whenever you have finished to render a single frame.
				 * ```js
				 * renderer.info.reset();
				 * ```
				 *
				 * @name WebGLRenderer#info
				 * @type {WebGLRenderer~Info}
				 */
				_this.info = info;

			}

			initGLContext();

			// xr

			const xr = new WebXRManager( _this, _gl );

			/**
			 * A reference to the XR manager.
			 *
			 * @type {WebXRManager}
			 */
			this.xr = xr;

			/**
			 * Returns the rendering context.
			 *
			 * @return {WebGL2RenderingContext} The rendering context.
			 */
			this.getContext = function () {

				return _gl;

			};

			/**
			 * Returns the rendering context attributes.
			 *
			 * @return {WebGLContextAttributes} The rendering context attributes.
			 */
			this.getContextAttributes = function () {

				return _gl.getContextAttributes();

			};

			/**
			 * Simulates a loss of the WebGL context. This requires support for the `WEBGL_lose_context` extension.
			 */
			this.forceContextLoss = function () {

				const extension = extensions.get( 'WEBGL_lose_context' );
				if ( extension ) extension.loseContext();

			};

			/**
			 * Simulates a restore of the WebGL context. This requires support for the `WEBGL_lose_context` extension.
			 */
			this.forceContextRestore = function () {

				const extension = extensions.get( 'WEBGL_lose_context' );
				if ( extension ) extension.restoreContext();

			};

			/**
			 * Returns the pixel ratio.
			 *
			 * @return {number} The pixel ratio.
			 */
			this.getPixelRatio = function () {

				return _pixelRatio;

			};

			/**
			 * Sets the given pixel ratio and resizes the canvas if necessary.
			 *
			 * @param {number} value - The pixel ratio.
			 */
			this.setPixelRatio = function ( value ) {

				if ( value === undefined ) return;

				_pixelRatio = value;

				this.setSize( _width, _height, false );

			};

			/**
			 * Returns the renderer's size in logical pixels. This method does not honor the pixel ratio.
			 *
			 * @param {Vector2} target - The method writes the result in this target object.
			 * @return {Vector2} The renderer's size in logical pixels.
			 */
			this.getSize = function ( target ) {

				return target.set( _width, _height );

			};

			/**
			 * Resizes the output canvas to (width, height) with device pixel ratio taken
			 * into account, and also sets the viewport to fit that size, starting in (0,
			 * 0). Setting `updateStyle` to false prevents any style changes to the output canvas.
			 *
			 * @param {number} width - The width in logical pixels.
			 * @param {number} height - The height in logical pixels.
			 * @param {boolean} [updateStyle=true] - Whether to update the `style` attribute of the canvas or not.
			 */
			this.setSize = function ( width, height, updateStyle = true ) {

				if ( xr.isPresenting ) {

					console.warn( 'THREE.WebGLRenderer: Can\'t change size while VR device is presenting.' );
					return;

				}

				_width = width;
				_height = height;

				canvas.width = Math.floor( width * _pixelRatio );
				canvas.height = Math.floor( height * _pixelRatio );

				if ( updateStyle === true ) {

					canvas.style.width = width + 'px';
					canvas.style.height = height + 'px';

				}

				this.setViewport( 0, 0, width, height );

			};

			/**
			 * Returns the drawing buffer size in physical pixels. This method honors the pixel ratio.
			 *
			 * @param {Vector2} target - The method writes the result in this target object.
			 * @return {Vector2} The drawing buffer size.
			 */
			this.getDrawingBufferSize = function ( target ) {

				return target.set( _width * _pixelRatio, _height * _pixelRatio ).floor();

			};

			/**
			 * This method allows to define the drawing buffer size by specifying
			 * width, height and pixel ratio all at once. The size of the drawing
			 * buffer is computed with this formula:
			 * ```js
			 * size.x = width * pixelRatio;
			 * size.y = height * pixelRatio;
			 * ```
			 *
			 * @param {number} width - The width in logical pixels.
			 * @param {number} height - The height in logical pixels.
			 * @param {number} pixelRatio - The pixel ratio.
			 */
			this.setDrawingBufferSize = function ( width, height, pixelRatio ) {

				_width = width;
				_height = height;

				_pixelRatio = pixelRatio;

				canvas.width = Math.floor( width * pixelRatio );
				canvas.height = Math.floor( height * pixelRatio );

				this.setViewport( 0, 0, width, height );

			};

			/**
			 * Returns the current viewport definition.
			 *
			 * @param {Vector2} target - The method writes the result in this target object.
			 * @return {Vector2} The current viewport definition.
			 */
			this.getCurrentViewport = function ( target ) {

				return target.copy( _currentViewport );

			};

			/**
			 * Returns the viewport definition.
			 *
			 * @param {Vector4} target - The method writes the result in this target object.
			 * @return {Vector4} The viewport definition.
			 */
			this.getViewport = function ( target ) {

				return target.copy( _viewport );

			};

			/**
			 * Sets the viewport to render from `(x, y)` to `(x + width, y + height)`.
			 *
			 * @param {number | Vector4} x - The horizontal coordinate for the lower left corner of the viewport origin in logical pixel unit.
			 * Or alternatively a four-component vector specifying all the parameters of the viewport.
			 * @param {number} y - The vertical coordinate for the lower left corner of the viewport origin  in logical pixel unit.
			 * @param {number} width - The width of the viewport in logical pixel unit.
			 * @param {number} height - The height of the viewport in logical pixel unit.
			 */
			this.setViewport = function ( x, y, width, height ) {

				if ( x.isVector4 ) {

					_viewport.set( x.x, x.y, x.z, x.w );

				} else {

					_viewport.set( x, y, width, height );

				}

				state.viewport( _currentViewport.copy( _viewport ).multiplyScalar( _pixelRatio ).round() );

			};

			/**
			 * Returns the scissor region.
			 *
			 * @param {Vector4} target - The method writes the result in this target object.
			 * @return {Vector4} The scissor region.
			 */
			this.getScissor = function ( target ) {

				return target.copy( _scissor );

			};

			/**
			 * Sets the scissor region to render from `(x, y)` to `(x + width, y + height)`.
			 *
			 * @param {number | Vector4} x - The horizontal coordinate for the lower left corner of the scissor region origin in logical pixel unit.
			 * Or alternatively a four-component vector specifying all the parameters of the scissor region.
			 * @param {number} y - The vertical coordinate for the lower left corner of the scissor region origin  in logical pixel unit.
			 * @param {number} width - The width of the scissor region in logical pixel unit.
			 * @param {number} height - The height of the scissor region in logical pixel unit.
			 */
			this.setScissor = function ( x, y, width, height ) {

				if ( x.isVector4 ) {

					_scissor.set( x.x, x.y, x.z, x.w );

				} else {

					_scissor.set( x, y, width, height );

				}

				state.scissor( _currentScissor.copy( _scissor ).multiplyScalar( _pixelRatio ).round() );

			};

			/**
			 * Returns `true` if the scissor test is enabled.
			 *
			 * @return {boolean} Whether the scissor test is enabled or not.
			 */
			this.getScissorTest = function () {

				return _scissorTest;

			};

			/**
			 * Enable or disable the scissor test. When this is enabled, only the pixels
			 * within the defined scissor area will be affected by further renderer
			 * actions.
			 *
			 * @param {boolean} boolean - Whether the scissor test is enabled or not.
			 */
			this.setScissorTest = function ( boolean ) {

				state.setScissorTest( _scissorTest = boolean );

			};

			/**
			 * Sets a custom opaque sort function for the render lists. Pass `null`
			 * to use the default `painterSortStable` function.
			 *
			 * @param {?Function} method - The opaque sort function.
			 */
			this.setOpaqueSort = function ( method ) {

				_opaqueSort = method;

			};

			/**
			 * Sets a custom transparent sort function for the render lists. Pass `null`
			 * to use the default `reversePainterSortStable` function.
			 *
			 * @param {?Function} method - The opaque sort function.
			 */
			this.setTransparentSort = function ( method ) {

				_transparentSort = method;

			};

			// Clearing

			/**
			 * Returns the clear color.
			 *
			 * @param {Color} target - The method writes the result in this target object.
			 * @return {Color} The clear color.
			 */
			this.getClearColor = function ( target ) {

				return target.copy( background.getClearColor() );

			};

			/**
			 * Sets the clear color and alpha.
			 *
			 * @param {Color} color - The clear color.
			 * @param {number} [alpha=1] - The clear alpha.
			 */
			this.setClearColor = function () {

				background.setClearColor( ...arguments );

			};

			/**
			 * Returns the clear alpha. Ranges within `[0,1]`.
			 *
			 * @return {number} The clear alpha.
			 */
			this.getClearAlpha = function () {

				return background.getClearAlpha();

			};

			/**
			 * Sets the clear alpha.
			 *
			 * @param {number} alpha - The clear alpha.
			 */
			this.setClearAlpha = function () {

				background.setClearAlpha( ...arguments );

			};

			/**
			 * Tells the renderer to clear its color, depth or stencil drawing buffer(s).
			 * This method initializes the buffers to the current clear color values.
			 *
			 * @param {boolean} [color=true] - Whether the color buffer should be cleared or not.
			 * @param {boolean} [depth=true] - Whether the depth buffer should be cleared or not.
			 * @param {boolean} [stencil=true] - Whether the stencil buffer should be cleared or not.
			 */
			this.clear = function ( color = true, depth = true, stencil = true ) {

				let bits = 0;

				if ( color ) {

					// check if we're trying to clear an integer target
					let isIntegerFormat = false;
					if ( _currentRenderTarget !== null ) {

						const targetFormat = _currentRenderTarget.texture.format;
						isIntegerFormat = targetFormat === RGBAIntegerFormat ||
							targetFormat === RGIntegerFormat ||
							targetFormat === RedIntegerFormat;

					}

					// use the appropriate clear functions to clear the target if it's a signed
					// or unsigned integer target
					if ( isIntegerFormat ) {

						const targetType = _currentRenderTarget.texture.type;
						const isUnsignedType = targetType === UnsignedByteType ||
							targetType === UnsignedIntType ||
							targetType === UnsignedShortType ||
							targetType === UnsignedInt248Type ||
							targetType === UnsignedShort4444Type ||
							targetType === UnsignedShort5551Type;

						const clearColor = background.getClearColor();
						const a = background.getClearAlpha();
						const r = clearColor.r;
						const g = clearColor.g;
						const b = clearColor.b;

						if ( isUnsignedType ) {

							uintClearColor[ 0 ] = r;
							uintClearColor[ 1 ] = g;
							uintClearColor[ 2 ] = b;
							uintClearColor[ 3 ] = a;
							_gl.clearBufferuiv( _gl.COLOR, 0, uintClearColor );

						} else {

							intClearColor[ 0 ] = r;
							intClearColor[ 1 ] = g;
							intClearColor[ 2 ] = b;
							intClearColor[ 3 ] = a;
							_gl.clearBufferiv( _gl.COLOR, 0, intClearColor );

						}

					} else {

						bits |= _gl.COLOR_BUFFER_BIT;

					}

				}

				if ( depth ) {

					bits |= _gl.DEPTH_BUFFER_BIT;

				}

				if ( stencil ) {

					bits |= _gl.STENCIL_BUFFER_BIT;
					this.state.buffers.stencil.setMask( 0xffffffff );

				}

				_gl.clear( bits );

			};

			/**
			 * Clears the color buffer. Equivalent to calling `renderer.clear( true, false, false )`.
			 */
			this.clearColor = function () {

				this.clear( true, false, false );

			};

			/**
			 * Clears the depth buffer. Equivalent to calling `renderer.clear( false, true, false )`.
			 */
			this.clearDepth = function () {

				this.clear( false, true, false );

			};

			/**
			 * Clears the stencil buffer. Equivalent to calling `renderer.clear( false, false, true )`.
			 */
			this.clearStencil = function () {

				this.clear( false, false, true );

			};

			/**
			 * Frees the GPU-related resources allocated by this instance. Call this
			 * method whenever this instance is no longer used in your app.
			 */
			this.dispose = function () {

				canvas.removeEventListener( 'webglcontextlost', onContextLost, false );
				canvas.removeEventListener( 'webglcontextrestored', onContextRestore, false );
				canvas.removeEventListener( 'webglcontextcreationerror', onContextCreationError, false );

				background.dispose();
				renderLists.dispose();
				renderStates.dispose();
				properties.dispose();
				cubemaps.dispose();
				cubeuvmaps.dispose();
				objects.dispose();
				bindingStates.dispose();
				uniformsGroups.dispose();
				programCache.dispose();

				xr.dispose();

				xr.removeEventListener( 'sessionstart', onXRSessionStart );
				xr.removeEventListener( 'sessionend', onXRSessionEnd );

				animation.stop();

			};

			// Events

			function onContextLost( event ) {

				event.preventDefault();

				console.log( 'THREE.WebGLRenderer: Context Lost.' );

				_isContextLost = true;

			}

			function onContextRestore( /* event */ ) {

				console.log( 'THREE.WebGLRenderer: Context Restored.' );

				_isContextLost = false;

				const infoAutoReset = info.autoReset;
				const shadowMapEnabled = shadowMap.enabled;
				const shadowMapAutoUpdate = shadowMap.autoUpdate;
				const shadowMapNeedsUpdate = shadowMap.needsUpdate;
				const shadowMapType = shadowMap.type;

				initGLContext();

				info.autoReset = infoAutoReset;
				shadowMap.enabled = shadowMapEnabled;
				shadowMap.autoUpdate = shadowMapAutoUpdate;
				shadowMap.needsUpdate = shadowMapNeedsUpdate;
				shadowMap.type = shadowMapType;

			}

			function onContextCreationError( event ) {

				console.error( 'THREE.WebGLRenderer: A WebGL context could not be created. Reason: ', event.statusMessage );

			}

			function onMaterialDispose( event ) {

				const material = event.target;

				material.removeEventListener( 'dispose', onMaterialDispose );

				deallocateMaterial( material );

			}

			// Buffer deallocation

			function deallocateMaterial( material ) {

				releaseMaterialProgramReferences( material );

				properties.remove( material );

			}


			function releaseMaterialProgramReferences( material ) {

				const programs = properties.get( material ).programs;

				if ( programs !== undefined ) {

					programs.forEach( function ( program ) {

						programCache.releaseProgram( program );

					} );

					if ( material.isShaderMaterial ) {

						programCache.releaseShaderCache( material );

					}

				}

			}

			// Buffer rendering

			this.renderBufferDirect = function ( camera, scene, geometry, material, object, group ) {

				if ( scene === null ) scene = _emptyScene; // renderBufferDirect second parameter used to be fog (could be null)

				const frontFaceCW = ( object.isMesh && object.matrixWorld.determinant() < 0 );

				const program = setProgram( camera, scene, geometry, material, object );

				state.setMaterial( material, frontFaceCW );

				//

				let index = geometry.index;
				let rangeFactor = 1;

				if ( material.wireframe === true ) {

					index = geometries.getWireframeAttribute( geometry );

					if ( index === undefined ) return;

					rangeFactor = 2;

				}

				//

				const drawRange = geometry.drawRange;
				const position = geometry.attributes.position;

				let drawStart = drawRange.start * rangeFactor;
				let drawEnd = ( drawRange.start + drawRange.count ) * rangeFactor;

				if ( group !== null ) {

					drawStart = Math.max( drawStart, group.start * rangeFactor );
					drawEnd = Math.min( drawEnd, ( group.start + group.count ) * rangeFactor );

				}

				if ( index !== null ) {

					drawStart = Math.max( drawStart, 0 );
					drawEnd = Math.min( drawEnd, index.count );

				} else if ( position !== undefined && position !== null ) {

					drawStart = Math.max( drawStart, 0 );
					drawEnd = Math.min( drawEnd, position.count );

				}

				const drawCount = drawEnd - drawStart;

				if ( drawCount < 0 || drawCount === Infinity ) return;

				//

				bindingStates.setup( object, material, program, geometry, index );

				let attribute;
				let renderer = bufferRenderer;

				if ( index !== null ) {

					attribute = attributes.get( index );

					renderer = indexedBufferRenderer;
					renderer.setIndex( attribute );

				}

				//

				if ( object.isMesh ) {

					if ( material.wireframe === true ) {

						state.setLineWidth( material.wireframeLinewidth * getTargetPixelRatio() );
						renderer.setMode( _gl.LINES );

					} else {

						renderer.setMode( _gl.TRIANGLES );

					}

				} else if ( object.isLine ) {

					let lineWidth = material.linewidth;

					if ( lineWidth === undefined ) lineWidth = 1; // Not using Line*Material

					state.setLineWidth( lineWidth * getTargetPixelRatio() );

					if ( object.isLineSegments ) {

						renderer.setMode( _gl.LINES );

					} else if ( object.isLineLoop ) {

						renderer.setMode( _gl.LINE_LOOP );

					} else {

						renderer.setMode( _gl.LINE_STRIP );

					}

				} else if ( object.isPoints ) {

					renderer.setMode( _gl.POINTS );

				} else if ( object.isSprite ) {

					renderer.setMode( _gl.TRIANGLES );

				}

				if ( object.isBatchedMesh ) {

					if ( object._multiDrawInstances !== null ) {

						// @deprecated, r174
						warnOnce( 'THREE.WebGLRenderer: renderMultiDrawInstances has been deprecated and will be removed in r184. Append to renderMultiDraw arguments and use indirection.' );
						renderer.renderMultiDrawInstances( object._multiDrawStarts, object._multiDrawCounts, object._multiDrawCount, object._multiDrawInstances );

					} else {

						if ( ! extensions.get( 'WEBGL_multi_draw' ) ) {

							const starts = object._multiDrawStarts;
							const counts = object._multiDrawCounts;
							const drawCount = object._multiDrawCount;
							const bytesPerElement = index ? attributes.get( index ).bytesPerElement : 1;
							const uniforms = properties.get( material ).currentProgram.getUniforms();
							for ( let i = 0; i < drawCount; i ++ ) {

								uniforms.setValue( _gl, '_gl_DrawID', i );
								renderer.render( starts[ i ] / bytesPerElement, counts[ i ] );

							}

						} else {

							renderer.renderMultiDraw( object._multiDrawStarts, object._multiDrawCounts, object._multiDrawCount );

						}

					}

				} else if ( object.isInstancedMesh ) {

					renderer.renderInstances( drawStart, drawCount, object.count );

				} else if ( geometry.isInstancedBufferGeometry ) {

					const maxInstanceCount = geometry._maxInstanceCount !== undefined ? geometry._maxInstanceCount : Infinity;
					const instanceCount = Math.min( geometry.instanceCount, maxInstanceCount );

					renderer.renderInstances( drawStart, drawCount, instanceCount );

				} else {

					renderer.render( drawStart, drawCount );

				}

			};

			// Compile

			function prepareMaterial( material, scene, object ) {

				if ( material.transparent === true && material.side === DoubleSide && material.forceSinglePass === false ) {

					material.side = BackSide;
					material.needsUpdate = true;
					getProgram( material, scene, object );

					material.side = FrontSide;
					material.needsUpdate = true;
					getProgram( material, scene, object );

					material.side = DoubleSide;

				} else {

					getProgram( material, scene, object );

				}

			}

			/**
			 * Compiles all materials in the scene with the camera. This is useful to precompile shaders
			 * before the first rendering. If you want to add a 3D object to an existing scene, use the third
			 * optional parameter for applying the target scene.
			 *
			 * Note that the (target) scene's lighting and environment must be configured before calling this method.
			 *
			 * @param {Object3D} scene - The scene or another type of 3D object to precompile.
			 * @param {Camera} camera - The camera.
			 * @param {?Scene} [targetScene=null] - The target scene.
			 * @return {Set<Material>} The precompiled materials.
			 */
			this.compile = function ( scene, camera, targetScene = null ) {

				if ( targetScene === null ) targetScene = scene;

				currentRenderState = renderStates.get( targetScene );
				currentRenderState.init( camera );

				renderStateStack.push( currentRenderState );

				// gather lights from both the target scene and the new object that will be added to the scene.

				targetScene.traverseVisible( function ( object ) {

					if ( object.isLight && object.layers.test( camera.layers ) ) {

						currentRenderState.pushLight( object );

						if ( object.castShadow ) {

							currentRenderState.pushShadow( object );

						}

					}

				} );

				if ( scene !== targetScene ) {

					scene.traverseVisible( function ( object ) {

						if ( object.isLight && object.layers.test( camera.layers ) ) {

							currentRenderState.pushLight( object );

							if ( object.castShadow ) {

								currentRenderState.pushShadow( object );

							}

						}

					} );

				}

				currentRenderState.setupLights();

				// Only initialize materials in the new scene, not the targetScene.

				const materials = new Set();

				scene.traverse( function ( object ) {

					if ( ! ( object.isMesh || object.isPoints || object.isLine || object.isSprite ) ) {

						return;

					}

					const material = object.material;

					if ( material ) {

						if ( Array.isArray( material ) ) {

							for ( let i = 0; i < material.length; i ++ ) {

								const material2 = material[ i ];

								prepareMaterial( material2, targetScene, object );
								materials.add( material2 );

							}

						} else {

							prepareMaterial( material, targetScene, object );
							materials.add( material );

						}

					}

				} );

				currentRenderState = renderStateStack.pop();

				return materials;

			};

			// compileAsync

			/**
			 * Asynchronous version of {@link WebGLRenderer#compile}.
			 *
			 * This method makes use of the `KHR_parallel_shader_compile` WebGL extension. Hence,
			 * it is recommended to use this version of `compile()` whenever possible.
			 *
			 * @async
			 * @param {Object3D} scene - The scene or another type of 3D object to precompile.
			 * @param {Camera} camera - The camera.
			 * @param {?Scene} [targetScene=null] - The target scene.
			 * @return {Promise} A Promise that resolves when the given scene can be rendered without unnecessary stalling due to shader compilation.
			 */
			this.compileAsync = function ( scene, camera, targetScene = null ) {

				const materials = this.compile( scene, camera, targetScene );

				// Wait for all the materials in the new object to indicate that they're
				// ready to be used before resolving the promise.

				return new Promise( ( resolve ) => {

					function checkMaterialsReady() {

						materials.forEach( function ( material ) {

							const materialProperties = properties.get( material );
							const program = materialProperties.currentProgram;

							if ( program.isReady() ) {

								// remove any programs that report they're ready to use from the list
								materials.delete( material );

							}

						} );

						// once the list of compiling materials is empty, call the callback

						if ( materials.size === 0 ) {

							resolve( scene );
							return;

						}

						// if some materials are still not ready, wait a bit and check again

						setTimeout( checkMaterialsReady, 10 );

					}

					if ( extensions.get( 'KHR_parallel_shader_compile' ) !== null ) {

						// If we can check the compilation status of the materials without
						// blocking then do so right away.

						checkMaterialsReady();

					} else {

						// Otherwise start by waiting a bit to give the materials we just
						// initialized a chance to finish.

						setTimeout( checkMaterialsReady, 10 );

					}

				} );

			};

			// Animation Loop

			let onAnimationFrameCallback = null;

			function onAnimationFrame( time ) {

				if ( onAnimationFrameCallback ) onAnimationFrameCallback( time );

			}

			function onXRSessionStart() {

				animation.stop();

			}

			function onXRSessionEnd() {

				animation.start();

			}

			const animation = new WebGLAnimation();
			animation.setAnimationLoop( onAnimationFrame );

			if ( typeof self !== 'undefined' ) animation.setContext( self );

			this.setAnimationLoop = function ( callback ) {

				onAnimationFrameCallback = callback;
				xr.setAnimationLoop( callback );

				( callback === null ) ? animation.stop() : animation.start();

			};

			xr.addEventListener( 'sessionstart', onXRSessionStart );
			xr.addEventListener( 'sessionend', onXRSessionEnd );

			// Rendering

			/**
			 * Renders the given scene (or other type of 3D object) using the given camera.
			 *
			 * The render is done to a previously specified render target set by calling {@link WebGLRenderer#setRenderTarget}
			 * or to the canvas as usual.
			 *
			 * By default render buffers are cleared before rendering but you can prevent
			 * this by setting the property `autoClear` to `false`. If you want to prevent
			 * only certain buffers being cleared you can `autoClearColor`, `autoClearDepth`
			 * or `autoClearStencil` to `false`. To force a clear, use {@link WebGLRenderer#clear}.
			 *
			 * @param {Object3D} scene - The scene to render.
			 * @param {Camera} camera - The camera.
			 */
			this.render = function ( scene, camera ) {

				if ( camera !== undefined && camera.isCamera !== true ) {

					console.error( 'THREE.WebGLRenderer.render: camera is not an instance of THREE.Camera.' );
					return;

				}

				if ( _isContextLost === true ) return;

				// update scene graph

				if ( scene.matrixWorldAutoUpdate === true ) scene.updateMatrixWorld();

				// update camera matrices and frustum

				if ( camera.parent === null && camera.matrixWorldAutoUpdate === true ) camera.updateMatrixWorld();

				if ( xr.enabled === true && xr.isPresenting === true ) {

					if ( xr.cameraAutoUpdate === true ) xr.updateCamera( camera );

					camera = xr.getCamera(); // use XR camera for rendering

				}

				//
				if ( scene.isScene === true ) scene.onBeforeRender( _this, scene, camera, _currentRenderTarget );

				currentRenderState = renderStates.get( scene, renderStateStack.length );
				currentRenderState.init( camera );

				renderStateStack.push( currentRenderState );

				_projScreenMatrix.multiplyMatrices( camera.projectionMatrix, camera.matrixWorldInverse );
				_frustum.setFromProjectionMatrix( _projScreenMatrix );

				_localClippingEnabled = this.localClippingEnabled;
				_clippingEnabled = clipping.init( this.clippingPlanes, _localClippingEnabled );

				currentRenderList = renderLists.get( scene, renderListStack.length );
				currentRenderList.init();

				renderListStack.push( currentRenderList );

				if ( xr.enabled === true && xr.isPresenting === true ) {

					const depthSensingMesh = _this.xr.getDepthSensingMesh();

					if ( depthSensingMesh !== null ) {

						projectObject( depthSensingMesh, camera, - Infinity, _this.sortObjects );

					}

				}

				projectObject( scene, camera, 0, _this.sortObjects );

				currentRenderList.finish();

				if ( _this.sortObjects === true ) {

					currentRenderList.sort( _opaqueSort, _transparentSort );

				}

				_renderBackground = xr.enabled === false || xr.isPresenting === false || xr.hasDepthSensing() === false;
				if ( _renderBackground ) {

					background.addToRenderList( currentRenderList, scene );

				}

				//

				this.info.render.frame ++;

				if ( _clippingEnabled === true ) clipping.beginShadows();

				const shadowsArray = currentRenderState.state.shadowsArray;

				shadowMap.render( shadowsArray, scene, camera );

				if ( _clippingEnabled === true ) clipping.endShadows();

				//

				if ( this.info.autoReset === true ) this.info.reset();

				// render scene

				const opaqueObjects = currentRenderList.opaque;
				const transmissiveObjects = currentRenderList.transmissive;

				currentRenderState.setupLights();

				if ( camera.isArrayCamera ) {

					const cameras = camera.cameras;

					if ( transmissiveObjects.length > 0 ) {

						for ( let i = 0, l = cameras.length; i < l; i ++ ) {

							const camera2 = cameras[ i ];

							renderTransmissionPass( opaqueObjects, transmissiveObjects, scene, camera2 );

						}

					}

					if ( _renderBackground ) background.render( scene );

					for ( let i = 0, l = cameras.length; i < l; i ++ ) {

						const camera2 = cameras[ i ];

						renderScene( currentRenderList, scene, camera2, camera2.viewport );

					}

				} else {

					if ( transmissiveObjects.length > 0 ) renderTransmissionPass( opaqueObjects, transmissiveObjects, scene, camera );

					if ( _renderBackground ) background.render( scene );

					renderScene( currentRenderList, scene, camera );

				}

				//

				if ( _currentRenderTarget !== null && _currentActiveMipmapLevel === 0 ) {

					// resolve multisample renderbuffers to a single-sample texture if necessary

					textures.updateMultisampleRenderTarget( _currentRenderTarget );

					// Generate mipmap if we're using any kind of mipmap filtering

					textures.updateRenderTargetMipmap( _currentRenderTarget );

				}

				//

				if ( scene.isScene === true ) scene.onAfterRender( _this, scene, camera );

				// _gl.finish();

				bindingStates.resetDefaultState();
				_currentMaterialId = -1;
				_currentCamera = null;

				renderStateStack.pop();

				if ( renderStateStack.length > 0 ) {

					currentRenderState = renderStateStack[ renderStateStack.length - 1 ];

					if ( _clippingEnabled === true ) clipping.setGlobalState( _this.clippingPlanes, currentRenderState.state.camera );

				} else {

					currentRenderState = null;

				}

				renderListStack.pop();

				if ( renderListStack.length > 0 ) {

					currentRenderList = renderListStack[ renderListStack.length - 1 ];

				} else {

					currentRenderList = null;

				}

			};

			function projectObject( object, camera, groupOrder, sortObjects ) {

				if ( object.visible === false ) return;

				const visible = object.layers.test( camera.layers );

				if ( visible ) {

					if ( object.isGroup ) {

						groupOrder = object.renderOrder;

					} else if ( object.isLOD ) {

						if ( object.autoUpdate === true ) object.update( camera );

					} else if ( object.isLight ) {

						currentRenderState.pushLight( object );

						if ( object.castShadow ) {

							currentRenderState.pushShadow( object );

						}

					} else if ( object.isSprite ) {

						if ( ! object.frustumCulled || _frustum.intersectsSprite( object ) ) {

							if ( sortObjects ) {

								_vector4.setFromMatrixPosition( object.matrixWorld )
									.applyMatrix4( _projScreenMatrix );

							}

							const geometry = objects.update( object );
							const material = object.material;

							if ( material.visible ) {

								currentRenderList.push( object, geometry, material, groupOrder, _vector4.z, null );

							}

						}

					} else if ( object.isMesh || object.isLine || object.isPoints ) {

						if ( ! object.frustumCulled || _frustum.intersectsObject( object ) ) {

							const geometry = objects.update( object );
							const material = object.material;

							if ( sortObjects ) {

								if ( object.boundingSphere !== undefined ) {

									if ( object.boundingSphere === null ) object.computeBoundingSphere();
									_vector4.copy( object.boundingSphere.center );

								} else {

									if ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();
									_vector4.copy( geometry.boundingSphere.center );

								}

								_vector4
									.applyMatrix4( object.matrixWorld )
									.applyMatrix4( _projScreenMatrix );

							}

							if ( Array.isArray( material ) ) {

								const groups = geometry.groups;

								for ( let i = 0, l = groups.length; i < l; i ++ ) {

									const group = groups[ i ];
									const groupMaterial = material[ group.materialIndex ];

									if ( groupMaterial && groupMaterial.visible ) {

										currentRenderList.push( object, geometry, groupMaterial, groupOrder, _vector4.z, group );

									}

								}

							} else if ( material.visible ) {

								currentRenderList.push( object, geometry, material, groupOrder, _vector4.z, null );

							}

						}

					}

				}

				const children = object.children;

				for ( let i = 0, l = children.length; i < l; i ++ ) {

					projectObject( children[ i ], camera, groupOrder, sortObjects );

				}

			}

			function renderScene( currentRenderList, scene, camera, viewport ) {

				const opaqueObjects = currentRenderList.opaque;
				const transmissiveObjects = currentRenderList.transmissive;
				const transparentObjects = currentRenderList.transparent;

				currentRenderState.setupLightsView( camera );

				if ( _clippingEnabled === true ) clipping.setGlobalState( _this.clippingPlanes, camera );

				if ( viewport ) state.viewport( _currentViewport.copy( viewport ) );

				if ( opaqueObjects.length > 0 ) renderObjects( opaqueObjects, scene, camera );
				if ( transmissiveObjects.length > 0 ) renderObjects( transmissiveObjects, scene, camera );
				if ( transparentObjects.length > 0 ) renderObjects( transparentObjects, scene, camera );

				// Ensure depth buffer writing is enabled so it can be cleared on next render

				state.buffers.depth.setTest( true );
				state.buffers.depth.setMask( true );
				state.buffers.color.setMask( true );

				state.setPolygonOffset( false );

			}

			function renderTransmissionPass( opaqueObjects, transmissiveObjects, scene, camera ) {

				const overrideMaterial = scene.isScene === true ? scene.overrideMaterial : null;

				if ( overrideMaterial !== null ) {

					return;

				}

				if ( currentRenderState.state.transmissionRenderTarget[ camera.id ] === undefined ) {

					currentRenderState.state.transmissionRenderTarget[ camera.id ] = new WebGLRenderTarget( 1, 1, {
						generateMipmaps: true,
						type: ( extensions.has( 'EXT_color_buffer_half_float' ) || extensions.has( 'EXT_color_buffer_float' ) ) ? HalfFloatType : UnsignedByteType,
						minFilter: LinearMipmapLinearFilter,
						samples: 4,
						stencilBuffer: stencil,
						resolveDepthBuffer: false,
						resolveStencilBuffer: false,
						colorSpace: ColorManagement.workingColorSpace,
					} );

					// debug

					/*
					const geometry = new PlaneGeometry();
					const material = new MeshBasicMaterial( { map: _transmissionRenderTarget.texture } );

					const mesh = new Mesh( geometry, material );
					scene.add( mesh );
					*/

				}

				const transmissionRenderTarget = currentRenderState.state.transmissionRenderTarget[ camera.id ];

				const activeViewport = camera.viewport || _currentViewport;
				transmissionRenderTarget.setSize( activeViewport.z * _this.transmissionResolutionScale, activeViewport.w * _this.transmissionResolutionScale );

				//

				const currentRenderTarget = _this.getRenderTarget();
				_this.setRenderTarget( transmissionRenderTarget );

				_this.getClearColor( _currentClearColor );
				_currentClearAlpha = _this.getClearAlpha();
				if ( _currentClearAlpha < 1 ) _this.setClearColor( 0xffffff, 0.5 );

				_this.clear();

				if ( _renderBackground ) background.render( scene );

				// Turn off the features which can affect the frag color for opaque objects pass.
				// Otherwise they are applied twice in opaque objects pass and transmission objects pass.
				const currentToneMapping = _this.toneMapping;
				_this.toneMapping = NoToneMapping;

				// Remove viewport from camera to avoid nested render calls resetting viewport to it (e.g Reflector).
				// Transmission render pass requires viewport to match the transmissionRenderTarget.
				const currentCameraViewport = camera.viewport;
				if ( camera.viewport !== undefined ) camera.viewport = undefined;

				currentRenderState.setupLightsView( camera );

				if ( _clippingEnabled === true ) clipping.setGlobalState( _this.clippingPlanes, camera );

				renderObjects( opaqueObjects, scene, camera );

				textures.updateMultisampleRenderTarget( transmissionRenderTarget );
				textures.updateRenderTargetMipmap( transmissionRenderTarget );

				if ( extensions.has( 'WEBGL_multisampled_render_to_texture' ) === false ) { // see #28131

					let renderTargetNeedsUpdate = false;

					for ( let i = 0, l = transmissiveObjects.length; i < l; i ++ ) {

						const renderItem = transmissiveObjects[ i ];

						const object = renderItem.object;
						const geometry = renderItem.geometry;
						const material = renderItem.material;
						const group = renderItem.group;

						if ( material.side === DoubleSide && object.layers.test( camera.layers ) ) {

							const currentSide = material.side;

							material.side = BackSide;
							material.needsUpdate = true;

							renderObject( object, scene, camera, geometry, material, group );

							material.side = currentSide;
							material.needsUpdate = true;

							renderTargetNeedsUpdate = true;

						}

					}

					if ( renderTargetNeedsUpdate === true ) {

						textures.updateMultisampleRenderTarget( transmissionRenderTarget );
						textures.updateRenderTargetMipmap( transmissionRenderTarget );

					}

				}

				_this.setRenderTarget( currentRenderTarget );

				_this.setClearColor( _currentClearColor, _currentClearAlpha );

				if ( currentCameraViewport !== undefined ) camera.viewport = currentCameraViewport;

				_this.toneMapping = currentToneMapping;

			}

			function renderObjects( renderList, scene, camera ) {

				const overrideMaterial = scene.isScene === true ? scene.overrideMaterial : null;

				for ( let i = 0, l = renderList.length; i < l; i ++ ) {

					const renderItem = renderList[ i ];

					const object = renderItem.object;
					const geometry = renderItem.geometry;
					const group = renderItem.group;
					let material = renderItem.material;

					if ( material.allowOverride === true && overrideMaterial !== null ) {

						material = overrideMaterial;

					}

					if ( object.layers.test( camera.layers ) ) {

						renderObject( object, scene, camera, geometry, material, group );

					}

				}

			}

			function renderObject( object, scene, camera, geometry, material, group ) {

				object.onBeforeRender( _this, scene, camera, geometry, material, group );

				object.modelViewMatrix.multiplyMatrices( camera.matrixWorldInverse, object.matrixWorld );
				object.normalMatrix.getNormalMatrix( object.modelViewMatrix );

				material.onBeforeRender( _this, scene, camera, geometry, object, group );

				if ( material.transparent === true && material.side === DoubleSide && material.forceSinglePass === false ) {

					material.side = BackSide;
					material.needsUpdate = true;
					_this.renderBufferDirect( camera, scene, geometry, material, object, group );

					material.side = FrontSide;
					material.needsUpdate = true;
					_this.renderBufferDirect( camera, scene, geometry, material, object, group );

					material.side = DoubleSide;

				} else {

					_this.renderBufferDirect( camera, scene, geometry, material, object, group );

				}

				object.onAfterRender( _this, scene, camera, geometry, material, group );

			}

			function getProgram( material, scene, object ) {

				if ( scene.isScene !== true ) scene = _emptyScene; // scene could be a Mesh, Line, Points, ...

				const materialProperties = properties.get( material );

				const lights = currentRenderState.state.lights;
				const shadowsArray = currentRenderState.state.shadowsArray;

				const lightsStateVersion = lights.state.version;

				const parameters = programCache.getParameters( material, lights.state, shadowsArray, scene, object );
				const programCacheKey = programCache.getProgramCacheKey( parameters );

				let programs = materialProperties.programs;

				// always update environment and fog - changing these trigger an getProgram call, but it's possible that the program doesn't change

				materialProperties.environment = material.isMeshStandardMaterial ? scene.environment : null;
				materialProperties.fog = scene.fog;
				materialProperties.envMap = ( material.isMeshStandardMaterial ? cubeuvmaps : cubemaps ).get( material.envMap || materialProperties.environment );
				materialProperties.envMapRotation = ( materialProperties.environment !== null && material.envMap === null ) ? scene.environmentRotation : material.envMapRotation;

				if ( programs === undefined ) {

					// new material

					material.addEventListener( 'dispose', onMaterialDispose );

					programs = new Map();
					materialProperties.programs = programs;

				}

				let program = programs.get( programCacheKey );

				if ( program !== undefined ) {

					// early out if program and light state is identical

					if ( materialProperties.currentProgram === program && materialProperties.lightsStateVersion === lightsStateVersion ) {

						updateCommonMaterialProperties( material, parameters );

						return program;

					}

				} else {

					parameters.uniforms = programCache.getUniforms( material );

					material.onBeforeCompile( parameters, _this );

					program = programCache.acquireProgram( parameters, programCacheKey );
					programs.set( programCacheKey, program );

					materialProperties.uniforms = parameters.uniforms;

				}

				const uniforms = materialProperties.uniforms;

				if ( ( ! material.isShaderMaterial && ! material.isRawShaderMaterial ) || material.clipping === true ) {

					uniforms.clippingPlanes = clipping.uniform;

				}

				updateCommonMaterialProperties( material, parameters );

				// store the light setup it was created for

				materialProperties.needsLights = materialNeedsLights( material );
				materialProperties.lightsStateVersion = lightsStateVersion;

				if ( materialProperties.needsLights ) {

					// wire up the material to this renderer's lighting state

					uniforms.ambientLightColor.value = lights.state.ambient;
					uniforms.lightProbe.value = lights.state.probe;
					uniforms.directionalLights.value = lights.state.directional;
					uniforms.directionalLightShadows.value = lights.state.directionalShadow;
					uniforms.spotLights.value = lights.state.spot;
					uniforms.spotLightShadows.value = lights.state.spotShadow;
					uniforms.rectAreaLights.value = lights.state.rectArea;
					uniforms.ltc_1.value = lights.state.rectAreaLTC1;
					uniforms.ltc_2.value = lights.state.rectAreaLTC2;
					uniforms.pointLights.value = lights.state.point;
					uniforms.pointLightShadows.value = lights.state.pointShadow;
					uniforms.hemisphereLights.value = lights.state.hemi;

					uniforms.directionalShadowMap.value = lights.state.directionalShadowMap;
					uniforms.directionalShadowMatrix.value = lights.state.directionalShadowMatrix;
					uniforms.spotShadowMap.value = lights.state.spotShadowMap;
					uniforms.spotLightMatrix.value = lights.state.spotLightMatrix;
					uniforms.spotLightMap.value = lights.state.spotLightMap;
					uniforms.pointShadowMap.value = lights.state.pointShadowMap;
					uniforms.pointShadowMatrix.value = lights.state.pointShadowMatrix;
					// TODO (abelnation): add area lights shadow info to uniforms

				}

				materialProperties.currentProgram = program;
				materialProperties.uniformsList = null;

				return program;

			}

			function getUniformList( materialProperties ) {

				if ( materialProperties.uniformsList === null ) {

					const progUniforms = materialProperties.currentProgram.getUniforms();
					materialProperties.uniformsList = WebGLUniforms.seqWithValue( progUniforms.seq, materialProperties.uniforms );

				}

				return materialProperties.uniformsList;

			}

			function updateCommonMaterialProperties( material, parameters ) {

				const materialProperties = properties.get( material );

				materialProperties.outputColorSpace = parameters.outputColorSpace;
				materialProperties.batching = parameters.batching;
				materialProperties.batchingColor = parameters.batchingColor;
				materialProperties.instancing = parameters.instancing;
				materialProperties.instancingColor = parameters.instancingColor;
				materialProperties.instancingMorph = parameters.instancingMorph;
				materialProperties.skinning = parameters.skinning;
				materialProperties.morphTargets = parameters.morphTargets;
				materialProperties.morphNormals = parameters.morphNormals;
				materialProperties.morphColors = parameters.morphColors;
				materialProperties.morphTargetsCount = parameters.morphTargetsCount;
				materialProperties.numClippingPlanes = parameters.numClippingPlanes;
				materialProperties.numIntersection = parameters.numClipIntersection;
				materialProperties.vertexAlphas = parameters.vertexAlphas;
				materialProperties.vertexTangents = parameters.vertexTangents;
				materialProperties.toneMapping = parameters.toneMapping;

			}

			function setProgram( camera, scene, geometry, material, object ) {

				if ( scene.isScene !== true ) scene = _emptyScene; // scene could be a Mesh, Line, Points, ...

				textures.resetTextureUnits();

				const fog = scene.fog;
				const environment = material.isMeshStandardMaterial ? scene.environment : null;
				const colorSpace = ( _currentRenderTarget === null ) ? _this.outputColorSpace : ( _currentRenderTarget.isXRRenderTarget === true ? _currentRenderTarget.texture.colorSpace : LinearSRGBColorSpace );
				const envMap = ( material.isMeshStandardMaterial ? cubeuvmaps : cubemaps ).get( material.envMap || environment );
				const vertexAlphas = material.vertexColors === true && !! geometry.attributes.color && geometry.attributes.color.itemSize === 4;
				const vertexTangents = !! geometry.attributes.tangent && ( !! material.normalMap || material.anisotropy > 0 );
				const morphTargets = !! geometry.morphAttributes.position;
				const morphNormals = !! geometry.morphAttributes.normal;
				const morphColors = !! geometry.morphAttributes.color;

				let toneMapping = NoToneMapping;

				if ( material.toneMapped ) {

					if ( _currentRenderTarget === null || _currentRenderTarget.isXRRenderTarget === true ) {

						toneMapping = _this.toneMapping;

					}

				}

				const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;
				const morphTargetsCount = ( morphAttribute !== undefined ) ? morphAttribute.length : 0;

				const materialProperties = properties.get( material );
				const lights = currentRenderState.state.lights;

				if ( _clippingEnabled === true ) {

					if ( _localClippingEnabled === true || camera !== _currentCamera ) {

						const useCache =
							camera === _currentCamera &&
							material.id === _currentMaterialId;

						// we might want to call this function with some ClippingGroup
						// object instead of the material, once it becomes feasible
						// (#8465, #8379)
						clipping.setState( material, camera, useCache );

					}

				}

				//

				let needsProgramChange = false;

				if ( material.version === materialProperties.__version ) {

					if ( materialProperties.needsLights && ( materialProperties.lightsStateVersion !== lights.state.version ) ) {

						needsProgramChange = true;

					} else if ( materialProperties.outputColorSpace !== colorSpace ) {

						needsProgramChange = true;

					} else if ( object.isBatchedMesh && materialProperties.batching === false ) {

						needsProgramChange = true;

					} else if ( ! object.isBatchedMesh && materialProperties.batching === true ) {

						needsProgramChange = true;

					} else if ( object.isBatchedMesh && materialProperties.batchingColor === true && object.colorTexture === null ) {

						needsProgramChange = true;

					} else if ( object.isBatchedMesh && materialProperties.batchingColor === false && object.colorTexture !== null ) {

						needsProgramChange = true;

					} else if ( object.isInstancedMesh && materialProperties.instancing === false ) {

						needsProgramChange = true;

					} else if ( ! object.isInstancedMesh && materialProperties.instancing === true ) {

						needsProgramChange = true;

					} else if ( object.isSkinnedMesh && materialProperties.skinning === false ) {

						needsProgramChange = true;

					} else if ( ! object.isSkinnedMesh && materialProperties.skinning === true ) {

						needsProgramChange = true;

					} else if ( object.isInstancedMesh && materialProperties.instancingColor === true && object.instanceColor === null ) {

						needsProgramChange = true;

					} else if ( object.isInstancedMesh && materialProperties.instancingColor === false && object.instanceColor !== null ) {

						needsProgramChange = true;

					} else if ( object.isInstancedMesh && materialProperties.instancingMorph === true && object.morphTexture === null ) {

						needsProgramChange = true;

					} else if ( object.isInstancedMesh && materialProperties.instancingMorph === false && object.morphTexture !== null ) {

						needsProgramChange = true;

					} else if ( materialProperties.envMap !== envMap ) {

						needsProgramChange = true;

					} else if ( material.fog === true && materialProperties.fog !== fog ) {

						needsProgramChange = true;

					} else if ( materialProperties.numClippingPlanes !== undefined &&
						( materialProperties.numClippingPlanes !== clipping.numPlanes ||
						materialProperties.numIntersection !== clipping.numIntersection ) ) {

						needsProgramChange = true;

					} else if ( materialProperties.vertexAlphas !== vertexAlphas ) {

						needsProgramChange = true;

					} else if ( materialProperties.vertexTangents !== vertexTangents ) {

						needsProgramChange = true;

					} else if ( materialProperties.morphTargets !== morphTargets ) {

						needsProgramChange = true;

					} else if ( materialProperties.morphNormals !== morphNormals ) {

						needsProgramChange = true;

					} else if ( materialProperties.morphColors !== morphColors ) {

						needsProgramChange = true;

					} else if ( materialProperties.toneMapping !== toneMapping ) {

						needsProgramChange = true;

					} else if ( materialProperties.morphTargetsCount !== morphTargetsCount ) {

						needsProgramChange = true;

					}

				} else {

					needsProgramChange = true;
					materialProperties.__version = material.version;

				}

				//

				let program = materialProperties.currentProgram;

				if ( needsProgramChange === true ) {

					program = getProgram( material, scene, object );

				}

				let refreshProgram = false;
				let refreshMaterial = false;
				let refreshLights = false;

				const p_uniforms = program.getUniforms(),
					m_uniforms = materialProperties.uniforms;

				if ( state.useProgram( program.program ) ) {

					refreshProgram = true;
					refreshMaterial = true;
					refreshLights = true;

				}

				if ( material.id !== _currentMaterialId ) {

					_currentMaterialId = material.id;

					refreshMaterial = true;

				}

				if ( refreshProgram || _currentCamera !== camera ) {

					// common camera uniforms

					const reverseDepthBuffer = state.buffers.depth.getReversed();

					if ( reverseDepthBuffer ) {

						_currentProjectionMatrix.copy( camera.projectionMatrix );

						toNormalizedProjectionMatrix( _currentProjectionMatrix );
						toReversedProjectionMatrix( _currentProjectionMatrix );

						p_uniforms.setValue( _gl, 'projectionMatrix', _currentProjectionMatrix );

					} else {

						p_uniforms.setValue( _gl, 'projectionMatrix', camera.projectionMatrix );

					}

					p_uniforms.setValue( _gl, 'viewMatrix', camera.matrixWorldInverse );

					const uCamPos = p_uniforms.map.cameraPosition;

					if ( uCamPos !== undefined ) {

						uCamPos.setValue( _gl, _vector3.setFromMatrixPosition( camera.matrixWorld ) );

					}

					if ( capabilities.logarithmicDepthBuffer ) {

						p_uniforms.setValue( _gl, 'logDepthBufFC',
							2.0 / ( Math.log( camera.far + 1.0 ) / Math.LN2 ) );

					}

					// consider moving isOrthographic to UniformLib and WebGLMaterials, see https://github.com/mrdoob/three.js/pull/26467#issuecomment-1645185067

					if ( material.isMeshPhongMaterial ||
						material.isMeshToonMaterial ||
						material.isMeshLambertMaterial ||
						material.isMeshBasicMaterial ||
						material.isMeshStandardMaterial ||
						material.isShaderMaterial ) {

						p_uniforms.setValue( _gl, 'isOrthographic', camera.isOrthographicCamera === true );

					}

					if ( _currentCamera !== camera ) {

						_currentCamera = camera;

						// lighting uniforms depend on the camera so enforce an update
						// now, in case this material supports lights - or later, when
						// the next material that does gets activated:

						refreshMaterial = true;		// set to true on material change
						refreshLights = true;		// remains set until update done

					}

				}

				// skinning and morph target uniforms must be set even if material didn't change
				// auto-setting of texture unit for bone and morph texture must go before other textures
				// otherwise textures used for skinning and morphing can take over texture units reserved for other material textures

				if ( object.isSkinnedMesh ) {

					p_uniforms.setOptional( _gl, object, 'bindMatrix' );
					p_uniforms.setOptional( _gl, object, 'bindMatrixInverse' );

					const skeleton = object.skeleton;

					if ( skeleton ) {

						if ( skeleton.boneTexture === null ) skeleton.computeBoneTexture();

						p_uniforms.setValue( _gl, 'boneTexture', skeleton.boneTexture, textures );

					}

				}

				if ( object.isBatchedMesh ) {

					p_uniforms.setOptional( _gl, object, 'batchingTexture' );
					p_uniforms.setValue( _gl, 'batchingTexture', object._matricesTexture, textures );

					p_uniforms.setOptional( _gl, object, 'batchingIdTexture' );
					p_uniforms.setValue( _gl, 'batchingIdTexture', object._indirectTexture, textures );

					p_uniforms.setOptional( _gl, object, 'batchingColorTexture' );
					if ( object._colorsTexture !== null ) {

						p_uniforms.setValue( _gl, 'batchingColorTexture', object._colorsTexture, textures );

					}

				}

				const morphAttributes = geometry.morphAttributes;

				if ( morphAttributes.position !== undefined || morphAttributes.normal !== undefined || ( morphAttributes.color !== undefined ) ) {

					morphtargets.update( object, geometry, program );

				}

				if ( refreshMaterial || materialProperties.receiveShadow !== object.receiveShadow ) {

					materialProperties.receiveShadow = object.receiveShadow;
					p_uniforms.setValue( _gl, 'receiveShadow', object.receiveShadow );

				}

				// https://github.com/mrdoob/three.js/pull/24467#issuecomment-1209031512

				if ( material.isMeshGouraudMaterial && material.envMap !== null ) {

					m_uniforms.envMap.value = envMap;

					m_uniforms.flipEnvMap.value = ( envMap.isCubeTexture && envMap.isRenderTargetTexture === false ) ? -1 : 1;

				}

				if ( material.isMeshStandardMaterial && material.envMap === null && scene.environment !== null ) {

					m_uniforms.envMapIntensity.value = scene.environmentIntensity;

				}

				if ( refreshMaterial ) {

					p_uniforms.setValue( _gl, 'toneMappingExposure', _this.toneMappingExposure );

					if ( materialProperties.needsLights ) {

						// the current material requires lighting info

						// note: all lighting uniforms are always set correctly
						// they simply reference the renderer's state for their
						// values
						//
						// use the current material's .needsUpdate flags to set
						// the GL state when required

						markUniformsLightsNeedsUpdate( m_uniforms, refreshLights );

					}

					// refresh uniforms common to several materials

					if ( fog && material.fog === true ) {

						materials.refreshFogUniforms( m_uniforms, fog );

					}

					materials.refreshMaterialUniforms( m_uniforms, material, _pixelRatio, _height, currentRenderState.state.transmissionRenderTarget[ camera.id ] );

					WebGLUniforms.upload( _gl, getUniformList( materialProperties ), m_uniforms, textures );

				}

				if ( material.isShaderMaterial && material.uniformsNeedUpdate === true ) {

					WebGLUniforms.upload( _gl, getUniformList( materialProperties ), m_uniforms, textures );
					material.uniformsNeedUpdate = false;

				}

				if ( material.isSpriteMaterial ) {

					p_uniforms.setValue( _gl, 'center', object.center );

				}

				// common matrices

				p_uniforms.setValue( _gl, 'modelViewMatrix', object.modelViewMatrix );
				p_uniforms.setValue( _gl, 'normalMatrix', object.normalMatrix );
				p_uniforms.setValue( _gl, 'modelMatrix', object.matrixWorld );

				// UBOs

				if ( material.isShaderMaterial || material.isRawShaderMaterial ) {

					const groups = material.uniformsGroups;

					for ( let i = 0, l = groups.length; i < l; i ++ ) {

						const group = groups[ i ];

						uniformsGroups.update( group, program );
						uniformsGroups.bind( group, program );

					}

				}

				return program;

			}

			// If uniforms are marked as clean, they don't need to be loaded to the GPU.

			function markUniformsLightsNeedsUpdate( uniforms, value ) {

				uniforms.ambientLightColor.needsUpdate = value;
				uniforms.lightProbe.needsUpdate = value;

				uniforms.directionalLights.needsUpdate = value;
				uniforms.directionalLightShadows.needsUpdate = value;
				uniforms.pointLights.needsUpdate = value;
				uniforms.pointLightShadows.needsUpdate = value;
				uniforms.spotLights.needsUpdate = value;
				uniforms.spotLightShadows.needsUpdate = value;
				uniforms.rectAreaLights.needsUpdate = value;
				uniforms.hemisphereLights.needsUpdate = value;

			}

			function materialNeedsLights( material ) {

				return material.isMeshLambertMaterial || material.isMeshToonMaterial || material.isMeshPhongMaterial ||
					material.isMeshStandardMaterial || material.isShadowMaterial ||
					( material.isShaderMaterial && material.lights === true );

			}

			/**
			 * Returns the active cube face.
			 *
			 * @return {number} The active cube face.
			 */
			this.getActiveCubeFace = function () {

				return _currentActiveCubeFace;

			};

			/**
			 * Returns the active mipmap level.
			 *
			 * @return {number} The active mipmap level.
			 */
			this.getActiveMipmapLevel = function () {

				return _currentActiveMipmapLevel;

			};

			/**
			 * Returns the active render target.
			 *
			 * @return {?WebGLRenderTarget} The active render target. Returns `null` if no render target
			 * is currently set.
			 */
			this.getRenderTarget = function () {

				return _currentRenderTarget;

			};

			this.setRenderTargetTextures = function ( renderTarget, colorTexture, depthTexture ) {

				const renderTargetProperties = properties.get( renderTarget );

				renderTargetProperties.__autoAllocateDepthBuffer = renderTarget.resolveDepthBuffer === false;
				if ( renderTargetProperties.__autoAllocateDepthBuffer === false ) {

					// The multisample_render_to_texture extension doesn't work properly if there
					// are midframe flushes and an external depth buffer. Disable use of the extension.
					renderTargetProperties.__useRenderToTexture = false;

				}

				properties.get( renderTarget.texture ).__webglTexture = colorTexture;
				properties.get( renderTarget.depthTexture ).__webglTexture = renderTargetProperties.__autoAllocateDepthBuffer ? undefined : depthTexture;

				renderTargetProperties.__hasExternalTextures = true;

			};

			this.setRenderTargetFramebuffer = function ( renderTarget, defaultFramebuffer ) {

				const renderTargetProperties = properties.get( renderTarget );
				renderTargetProperties.__webglFramebuffer = defaultFramebuffer;
				renderTargetProperties.__useDefaultFramebuffer = defaultFramebuffer === undefined;

			};

			const _scratchFrameBuffer = _gl.createFramebuffer();

			/**
			 * Sets the active rendertarget.
			 *
			 * @param {?WebGLRenderTarget} renderTarget - The render target to set. When `null` is given,
			 * the canvas is set as the active render target instead.
			 * @param {number} [activeCubeFace=0] - The active cube face when using a cube render target.
			 * Indicates the z layer to render in to when using 3D or array render targets.
			 * @param {number} [activeMipmapLevel=0] - The active mipmap level.
			 */
			this.setRenderTarget = function ( renderTarget, activeCubeFace = 0, activeMipmapLevel = 0 ) {

				_currentRenderTarget = renderTarget;
				_currentActiveCubeFace = activeCubeFace;
				_currentActiveMipmapLevel = activeMipmapLevel;

				let useDefaultFramebuffer = true;
				let framebuffer = null;
				let isCube = false;
				let isRenderTarget3D = false;

				if ( renderTarget ) {

					const renderTargetProperties = properties.get( renderTarget );

					if ( renderTargetProperties.__useDefaultFramebuffer !== undefined ) {

						// We need to make sure to rebind the framebuffer.
						state.bindFramebuffer( _gl.FRAMEBUFFER, null );
						useDefaultFramebuffer = false;

					} else if ( renderTargetProperties.__webglFramebuffer === undefined ) {

						textures.setupRenderTarget( renderTarget );

					} else if ( renderTargetProperties.__hasExternalTextures ) {

						// Color and depth texture must be rebound in order for the swapchain to update.
						textures.rebindTextures( renderTarget, properties.get( renderTarget.texture ).__webglTexture, properties.get( renderTarget.depthTexture ).__webglTexture );

					} else if ( renderTarget.depthBuffer ) {

						// check if the depth texture is already bound to the frame buffer and that it's been initialized
						const depthTexture = renderTarget.depthTexture;
						if ( renderTargetProperties.__boundDepthTexture !== depthTexture ) {

							// check if the depth texture is compatible
							if (
								depthTexture !== null &&
								properties.has( depthTexture ) &&
								( renderTarget.width !== depthTexture.image.width || renderTarget.height !== depthTexture.image.height )
							) {

								throw new Error( 'WebGLRenderTarget: Attached DepthTexture is initialized to the incorrect size.' );

							}

							// Swap the depth buffer to the currently attached one
							textures.setupDepthRenderbuffer( renderTarget );

						}

					}

					const texture = renderTarget.texture;

					if ( texture.isData3DTexture || texture.isDataArrayTexture || texture.isCompressedArrayTexture ) {

						isRenderTarget3D = true;

					}

					const __webglFramebuffer = properties.get( renderTarget ).__webglFramebuffer;

					if ( renderTarget.isWebGLCubeRenderTarget ) {

						if ( Array.isArray( __webglFramebuffer[ activeCubeFace ] ) ) {

							framebuffer = __webglFramebuffer[ activeCubeFace ][ activeMipmapLevel ];

						} else {

							framebuffer = __webglFramebuffer[ activeCubeFace ];

						}

						isCube = true;

					} else if ( ( renderTarget.samples > 0 ) && textures.useMultisampledRTT( renderTarget ) === false ) {

						framebuffer = properties.get( renderTarget ).__webglMultisampledFramebuffer;

					} else {

						if ( Array.isArray( __webglFramebuffer ) ) {

							framebuffer = __webglFramebuffer[ activeMipmapLevel ];

						} else {

							framebuffer = __webglFramebuffer;

						}

					}

					_currentViewport.copy( renderTarget.viewport );
					_currentScissor.copy( renderTarget.scissor );
					_currentScissorTest = renderTarget.scissorTest;

				} else {

					_currentViewport.copy( _viewport ).multiplyScalar( _pixelRatio ).floor();
					_currentScissor.copy( _scissor ).multiplyScalar( _pixelRatio ).floor();
					_currentScissorTest = _scissorTest;

				}

				// Use a scratch frame buffer if rendering to a mip level to avoid depth buffers
				// being bound that are different sizes.
				if ( activeMipmapLevel !== 0 ) {

					framebuffer = _scratchFrameBuffer;

				}

				const framebufferBound = state.bindFramebuffer( _gl.FRAMEBUFFER, framebuffer );

				if ( framebufferBound && useDefaultFramebuffer ) {

					state.drawBuffers( renderTarget, framebuffer );

				}

				state.viewport( _currentViewport );
				state.scissor( _currentScissor );
				state.setScissorTest( _currentScissorTest );

				if ( isCube ) {

					const textureProperties = properties.get( renderTarget.texture );
					_gl.framebufferTexture2D( _gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + activeCubeFace, textureProperties.__webglTexture, activeMipmapLevel );

				} else if ( isRenderTarget3D ) {

					const textureProperties = properties.get( renderTarget.texture );
					const layer = activeCubeFace;
					_gl.framebufferTextureLayer( _gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, textureProperties.__webglTexture, activeMipmapLevel, layer );

				} else if ( renderTarget !== null && activeMipmapLevel !== 0 ) {

					// Only bind the frame buffer if we are using a scratch frame buffer to render to a mipmap.
					// If we rebind the texture when using a multi sample buffer then an error about inconsistent samples will be thrown.
					const textureProperties = properties.get( renderTarget.texture );
					_gl.framebufferTexture2D( _gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, textureProperties.__webglTexture, activeMipmapLevel );

				}

				_currentMaterialId = -1; // reset current material to ensure correct uniform bindings

			};

			/**
			 * Reads the pixel data from the given render target into the given buffer.
			 *
			 * @param {WebGLRenderTarget} renderTarget - The render target to read from.
			 * @param {number} x - The `x` coordinate of the copy region's origin.
			 * @param {number} y - The `y` coordinate of the copy region's origin.
			 * @param {number} width - The width of the copy region.
			 * @param {number} height - The height of the copy region.
			 * @param {TypedArray} buffer - The result buffer.
			 * @param {number} [activeCubeFaceIndex] - The active cube face index.
			 * @param {number} [textureIndex=0] - The texture index of an MRT render target.
			 */
			this.readRenderTargetPixels = function ( renderTarget, x, y, width, height, buffer, activeCubeFaceIndex, textureIndex = 0 ) {

				if ( ! ( renderTarget && renderTarget.isWebGLRenderTarget ) ) {

					console.error( 'THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.' );
					return;

				}

				let framebuffer = properties.get( renderTarget ).__webglFramebuffer;

				if ( renderTarget.isWebGLCubeRenderTarget && activeCubeFaceIndex !== undefined ) {

					framebuffer = framebuffer[ activeCubeFaceIndex ];

				}

				if ( framebuffer ) {

					state.bindFramebuffer( _gl.FRAMEBUFFER, framebuffer );

					try {

						const texture = renderTarget.textures[ textureIndex ];
						const textureFormat = texture.format;
						const textureType = texture.type;

						if ( ! capabilities.textureFormatReadable( textureFormat ) ) {

							console.error( 'THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in RGBA or implementation defined format.' );
							return;

						}

						if ( ! capabilities.textureTypeReadable( textureType ) ) {

							console.error( 'THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in UnsignedByteType or implementation defined type.' );
							return;

						}

						// the following if statement ensures valid read requests (no out-of-bounds pixels, see #8604)

						if ( ( x >= 0 && x <= ( renderTarget.width - width ) ) && ( y >= 0 && y <= ( renderTarget.height - height ) ) ) {

							// when using MRT, select the corect color buffer for the subsequent read command

							if ( renderTarget.textures.length > 1 ) _gl.readBuffer( _gl.COLOR_ATTACHMENT0 + textureIndex );

							_gl.readPixels( x, y, width, height, utils.convert( textureFormat ), utils.convert( textureType ), buffer );

						}

					} finally {

						// restore framebuffer of current render target if necessary

						const framebuffer = ( _currentRenderTarget !== null ) ? properties.get( _currentRenderTarget ).__webglFramebuffer : null;
						state.bindFramebuffer( _gl.FRAMEBUFFER, framebuffer );

					}

				}

			};

			/**
			 * Asynchronous, non-blocking version of {@link WebGLRenderer#readRenderTargetPixels}.
			 *
			 * It is recommended to use this version of `readRenderTargetPixels()` whenever possible.
			 *
			 * @async
			 * @param {WebGLRenderTarget} renderTarget - The render target to read from.
			 * @param {number} x - The `x` coordinate of the copy region's origin.
			 * @param {number} y - The `y` coordinate of the copy region's origin.
			 * @param {number} width - The width of the copy region.
			 * @param {number} height - The height of the copy region.
			 * @param {TypedArray} buffer - The result buffer.
			 * @param {number} [activeCubeFaceIndex] - The active cube face index.
			 * @param {number} [textureIndex=0] - The texture index of an MRT render target.
			 * @return {Promise<TypedArray>} A Promise that resolves when the read has been finished. The resolve provides the read data as a typed array.
			 */
			this.readRenderTargetPixelsAsync = async function ( renderTarget, x, y, width, height, buffer, activeCubeFaceIndex, textureIndex = 0 ) {

				if ( ! ( renderTarget && renderTarget.isWebGLRenderTarget ) ) {

					throw new Error( 'THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.' );

				}

				let framebuffer = properties.get( renderTarget ).__webglFramebuffer;
				if ( renderTarget.isWebGLCubeRenderTarget && activeCubeFaceIndex !== undefined ) {

					framebuffer = framebuffer[ activeCubeFaceIndex ];

				}

				if ( framebuffer ) {

					// the following if statement ensures valid read requests (no out-of-bounds pixels, see #8604)
					if ( ( x >= 0 && x <= ( renderTarget.width - width ) ) && ( y >= 0 && y <= ( renderTarget.height - height ) ) ) {

						// set the active frame buffer to the one we want to read
						state.bindFramebuffer( _gl.FRAMEBUFFER, framebuffer );

						const texture = renderTarget.textures[ textureIndex ];
						const textureFormat = texture.format;
						const textureType = texture.type;

						if ( ! capabilities.textureFormatReadable( textureFormat ) ) {

							throw new Error( 'THREE.WebGLRenderer.readRenderTargetPixelsAsync: renderTarget is not in RGBA or implementation defined format.' );

						}

						if ( ! capabilities.textureTypeReadable( textureType ) ) {

							throw new Error( 'THREE.WebGLRenderer.readRenderTargetPixelsAsync: renderTarget is not in UnsignedByteType or implementation defined type.' );

						}

						const glBuffer = _gl.createBuffer();
						_gl.bindBuffer( _gl.PIXEL_PACK_BUFFER, glBuffer );
						_gl.bufferData( _gl.PIXEL_PACK_BUFFER, buffer.byteLength, _gl.STREAM_READ );

						// when using MRT, select the corect color buffer for the subsequent read command

						if ( renderTarget.textures.length > 1 ) _gl.readBuffer( _gl.COLOR_ATTACHMENT0 + textureIndex );

						_gl.readPixels( x, y, width, height, utils.convert( textureFormat ), utils.convert( textureType ), 0 );

						// reset the frame buffer to the currently set buffer before waiting
						const currFramebuffer = _currentRenderTarget !== null ? properties.get( _currentRenderTarget ).__webglFramebuffer : null;
						state.bindFramebuffer( _gl.FRAMEBUFFER, currFramebuffer );

						// check if the commands have finished every 8 ms
						const sync = _gl.fenceSync( _gl.SYNC_GPU_COMMANDS_COMPLETE, 0 );

						_gl.flush();

						await probeAsync( _gl, sync, 4 );

						// read the data and delete the buffer
						_gl.bindBuffer( _gl.PIXEL_PACK_BUFFER, glBuffer );
						_gl.getBufferSubData( _gl.PIXEL_PACK_BUFFER, 0, buffer );
						_gl.deleteBuffer( glBuffer );
						_gl.deleteSync( sync );

						return buffer;

					} else {

						throw new Error( 'THREE.WebGLRenderer.readRenderTargetPixelsAsync: requested read bounds are out of range.' );

					}

				}

			};

			/**
			 * Copies pixels from the current bound framebuffer into the given texture.
			 *
			 * @param {FramebufferTexture} texture - The texture.
			 * @param {?Vector2} [position=null] - The start position of the copy operation.
			 * @param {number} [level=0] - The mip level. The default represents the base mip.
			 */
			this.copyFramebufferToTexture = function ( texture, position = null, level = 0 ) {

				const levelScale = Math.pow( 2, - level );
				const width = Math.floor( texture.image.width * levelScale );
				const height = Math.floor( texture.image.height * levelScale );

				const x = position !== null ? position.x : 0;
				const y = position !== null ? position.y : 0;

				textures.setTexture2D( texture, 0 );

				_gl.copyTexSubImage2D( _gl.TEXTURE_2D, level, 0, 0, x, y, width, height );

				state.unbindTexture();

			};

			const _srcFramebuffer = _gl.createFramebuffer();
			const _dstFramebuffer = _gl.createFramebuffer();

			/**
			 * Copies data of the given source texture into a destination texture.
			 *
			 * When using render target textures as `srcTexture` and `dstTexture`, you must make sure both render targets are initialized
			 * {@link WebGLRenderer#initRenderTarget}.
			 *
			 * @param {Texture} srcTexture - The source texture.
			 * @param {Texture} dstTexture - The destination texture.
			 * @param {?(Box2|Box3)} [srcRegion=null] - A bounding box which describes the source region. Can be two or three-dimensional.
			 * @param {?(Vector2|Vector3)} [dstPosition=null] - A vector that represents the origin of the destination region. Can be two or three-dimensional.
			 * @param {number} [srcLevel=0] - The source mipmap level to copy.
			 * @param {?number} [dstLevel=null] - The destination mipmap level.
			 */
			this.copyTextureToTexture = function ( srcTexture, dstTexture, srcRegion = null, dstPosition = null, srcLevel = 0, dstLevel = null ) {

				// support the previous signature with just a single dst mipmap level
				if ( dstLevel === null ) {

					if ( srcLevel !== 0 ) {

						// @deprecated, r171
						warnOnce( 'WebGLRenderer: copyTextureToTexture function signature has changed to support src and dst mipmap levels.' );
						dstLevel = srcLevel;
						srcLevel = 0;

					} else {

						dstLevel = 0;

					}

				}

				// gather the necessary dimensions to copy
				let width, height, depth, minX, minY, minZ;
				let dstX, dstY, dstZ;
				const image = srcTexture.isCompressedTexture ? srcTexture.mipmaps[ dstLevel ] : srcTexture.image;
				if ( srcRegion !== null ) {

					width = srcRegion.max.x - srcRegion.min.x;
					height = srcRegion.max.y - srcRegion.min.y;
					depth = srcRegion.isBox3 ? srcRegion.max.z - srcRegion.min.z : 1;
					minX = srcRegion.min.x;
					minY = srcRegion.min.y;
					minZ = srcRegion.isBox3 ? srcRegion.min.z : 0;

				} else {

					const levelScale = Math.pow( 2, - srcLevel );
					width = Math.floor( image.width * levelScale );
					height = Math.floor( image.height * levelScale );
					if ( srcTexture.isDataArrayTexture ) {

						depth = image.depth;

					} else if ( srcTexture.isData3DTexture ) {

						depth = Math.floor( image.depth * levelScale );

					} else {

						depth = 1;

					}

					minX = 0;
					minY = 0;
					minZ = 0;

				}

				if ( dstPosition !== null ) {

					dstX = dstPosition.x;
					dstY = dstPosition.y;
					dstZ = dstPosition.z;

				} else {

					dstX = 0;
					dstY = 0;
					dstZ = 0;

				}

				// Set up the destination target
				const glFormat = utils.convert( dstTexture.format );
				const glType = utils.convert( dstTexture.type );
				let glTarget;

				if ( dstTexture.isData3DTexture ) {

					textures.setTexture3D( dstTexture, 0 );
					glTarget = _gl.TEXTURE_3D;

				} else if ( dstTexture.isDataArrayTexture || dstTexture.isCompressedArrayTexture ) {

					textures.setTexture2DArray( dstTexture, 0 );
					glTarget = _gl.TEXTURE_2D_ARRAY;

				} else {

					textures.setTexture2D( dstTexture, 0 );
					glTarget = _gl.TEXTURE_2D;

				}

				_gl.pixelStorei( _gl.UNPACK_FLIP_Y_WEBGL, dstTexture.flipY );
				_gl.pixelStorei( _gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, dstTexture.premultiplyAlpha );
				_gl.pixelStorei( _gl.UNPACK_ALIGNMENT, dstTexture.unpackAlignment );

				// used for copying data from cpu
				const currentUnpackRowLen = _gl.getParameter( _gl.UNPACK_ROW_LENGTH );
				const currentUnpackImageHeight = _gl.getParameter( _gl.UNPACK_IMAGE_HEIGHT );
				const currentUnpackSkipPixels = _gl.getParameter( _gl.UNPACK_SKIP_PIXELS );
				const currentUnpackSkipRows = _gl.getParameter( _gl.UNPACK_SKIP_ROWS );
				const currentUnpackSkipImages = _gl.getParameter( _gl.UNPACK_SKIP_IMAGES );

				_gl.pixelStorei( _gl.UNPACK_ROW_LENGTH, image.width );
				_gl.pixelStorei( _gl.UNPACK_IMAGE_HEIGHT, image.height );
				_gl.pixelStorei( _gl.UNPACK_SKIP_PIXELS, minX );
				_gl.pixelStorei( _gl.UNPACK_SKIP_ROWS, minY );
				_gl.pixelStorei( _gl.UNPACK_SKIP_IMAGES, minZ );

				// set up the src texture
				const isSrc3D = srcTexture.isDataArrayTexture || srcTexture.isData3DTexture;
				const isDst3D = dstTexture.isDataArrayTexture || dstTexture.isData3DTexture;
				if ( srcTexture.isDepthTexture ) {

					const srcTextureProperties = properties.get( srcTexture );
					const dstTextureProperties = properties.get( dstTexture );
					const srcRenderTargetProperties = properties.get( srcTextureProperties.__renderTarget );
					const dstRenderTargetProperties = properties.get( dstTextureProperties.__renderTarget );
					state.bindFramebuffer( _gl.READ_FRAMEBUFFER, srcRenderTargetProperties.__webglFramebuffer );
					state.bindFramebuffer( _gl.DRAW_FRAMEBUFFER, dstRenderTargetProperties.__webglFramebuffer );

					for ( let i = 0; i < depth; i ++ ) {

						// if the source or destination are a 3d target then a layer needs to be bound
						if ( isSrc3D ) {

							_gl.framebufferTextureLayer( _gl.READ_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, properties.get( srcTexture ).__webglTexture, srcLevel, minZ + i );
							_gl.framebufferTextureLayer( _gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, properties.get( dstTexture ).__webglTexture, dstLevel, dstZ + i );

						}

						_gl.blitFramebuffer( minX, minY, width, height, dstX, dstY, width, height, _gl.DEPTH_BUFFER_BIT, _gl.NEAREST );

					}

					state.bindFramebuffer( _gl.READ_FRAMEBUFFER, null );
					state.bindFramebuffer( _gl.DRAW_FRAMEBUFFER, null );

				} else if ( srcLevel !== 0 || srcTexture.isRenderTargetTexture || properties.has( srcTexture ) ) {

					// get the appropriate frame buffers
					const srcTextureProperties = properties.get( srcTexture );
					const dstTextureProperties = properties.get( dstTexture );

					// bind the frame buffer targets
					state.bindFramebuffer( _gl.READ_FRAMEBUFFER, _srcFramebuffer );
					state.bindFramebuffer( _gl.DRAW_FRAMEBUFFER, _dstFramebuffer );

					for ( let i = 0; i < depth; i ++ ) {

						// assign the correct layers and mip maps to the frame buffers
						if ( isSrc3D ) {

							_gl.framebufferTextureLayer( _gl.READ_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, srcTextureProperties.__webglTexture, srcLevel, minZ + i );

						} else {

							_gl.framebufferTexture2D( _gl.READ_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, srcTextureProperties.__webglTexture, srcLevel );

						}

						if ( isDst3D ) {

							_gl.framebufferTextureLayer( _gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, dstTextureProperties.__webglTexture, dstLevel, dstZ + i );

						} else {

							_gl.framebufferTexture2D( _gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, dstTextureProperties.__webglTexture, dstLevel );

						}

						// copy the data using the fastest function that can achieve the copy
						if ( srcLevel !== 0 ) {

							_gl.blitFramebuffer( minX, minY, width, height, dstX, dstY, width, height, _gl.COLOR_BUFFER_BIT, _gl.NEAREST );

						} else if ( isDst3D ) {

							_gl.copyTexSubImage3D( glTarget, dstLevel, dstX, dstY, dstZ + i, minX, minY, width, height );

						} else {

							_gl.copyTexSubImage2D( glTarget, dstLevel, dstX, dstY, minX, minY, width, height );

						}

					}

					// unbind read, draw buffers
					state.bindFramebuffer( _gl.READ_FRAMEBUFFER, null );
					state.bindFramebuffer( _gl.DRAW_FRAMEBUFFER, null );

				} else {

					if ( isDst3D ) {

						// copy data into the 3d texture
						if ( srcTexture.isDataTexture || srcTexture.isData3DTexture ) {

							_gl.texSubImage3D( glTarget, dstLevel, dstX, dstY, dstZ, width, height, depth, glFormat, glType, image.data );

						} else if ( dstTexture.isCompressedArrayTexture ) {

							_gl.compressedTexSubImage3D( glTarget, dstLevel, dstX, dstY, dstZ, width, height, depth, glFormat, image.data );

						} else {

							_gl.texSubImage3D( glTarget, dstLevel, dstX, dstY, dstZ, width, height, depth, glFormat, glType, image );

						}

					} else {

						// copy data into the 2d texture
						if ( srcTexture.isDataTexture ) {

							_gl.texSubImage2D( _gl.TEXTURE_2D, dstLevel, dstX, dstY, width, height, glFormat, glType, image.data );

						} else if ( srcTexture.isCompressedTexture ) {

							_gl.compressedTexSubImage2D( _gl.TEXTURE_2D, dstLevel, dstX, dstY, image.width, image.height, glFormat, image.data );

						} else {

							_gl.texSubImage2D( _gl.TEXTURE_2D, dstLevel, dstX, dstY, width, height, glFormat, glType, image );

						}

					}

				}

				// reset values
				_gl.pixelStorei( _gl.UNPACK_ROW_LENGTH, currentUnpackRowLen );
				_gl.pixelStorei( _gl.UNPACK_IMAGE_HEIGHT, currentUnpackImageHeight );
				_gl.pixelStorei( _gl.UNPACK_SKIP_PIXELS, currentUnpackSkipPixels );
				_gl.pixelStorei( _gl.UNPACK_SKIP_ROWS, currentUnpackSkipRows );
				_gl.pixelStorei( _gl.UNPACK_SKIP_IMAGES, currentUnpackSkipImages );

				// Generate mipmaps only when copying level 0
				if ( dstLevel === 0 && dstTexture.generateMipmaps ) {

					_gl.generateMipmap( glTarget );

				}

				state.unbindTexture();

			};

			this.copyTextureToTexture3D = function ( srcTexture, dstTexture, srcRegion = null, dstPosition = null, level = 0 ) {

				// @deprecated, r170
				warnOnce( 'WebGLRenderer: copyTextureToTexture3D function has been deprecated. Use "copyTextureToTexture" instead.' );

				return this.copyTextureToTexture( srcTexture, dstTexture, srcRegion, dstPosition, level );

			};

			/**
			 * Initializes the given WebGLRenderTarget memory. Useful for initializing a render target so data
			 * can be copied into it using {@link WebGLRenderer#copyTextureToTexture} before it has been
			 * rendered to.
			 *
			 * @param {WebGLRenderTarget} target - The render target.
			 */
			this.initRenderTarget = function ( target ) {

				if ( properties.get( target ).__webglFramebuffer === undefined ) {

					textures.setupRenderTarget( target );

				}

			};

			/**
			 * Initializes the given texture. Useful for preloading a texture rather than waiting until first
			 * render (which can cause noticeable lags due to decode and GPU upload overhead).
			 *
			 * @param {Texture} texture - The texture.
			 */
			this.initTexture = function ( texture ) {

				if ( texture.isCubeTexture ) {

					textures.setTextureCube( texture, 0 );

				} else if ( texture.isData3DTexture ) {

					textures.setTexture3D( texture, 0 );

				} else if ( texture.isDataArrayTexture || texture.isCompressedArrayTexture ) {

					textures.setTexture2DArray( texture, 0 );

				} else {

					textures.setTexture2D( texture, 0 );

				}

				state.unbindTexture();

			};

			/**
			 * Can be used to reset the internal WebGL state. This method is mostly
			 * relevant for applications which share a single WebGL context across
			 * multiple WebGL libraries.
			 */
			this.resetState = function () {

				_currentActiveCubeFace = 0;
				_currentActiveMipmapLevel = 0;
				_currentRenderTarget = null;

				state.reset();
				bindingStates.reset();

			};

			if ( typeof __THREE_DEVTOOLS__ !== 'undefined' ) {

				__THREE_DEVTOOLS__.dispatchEvent( new CustomEvent( 'observe', { detail: this } ) );

			}

		}

		/**
		 * Defines the coordinate system of the renderer.
		 *
		 * In `WebGLRenderer`, the value is always `WebGLCoordinateSystem`.
		 *
		 * @type {WebGLCoordinateSystem|WebGPUCoordinateSystem}
		 * @default WebGLCoordinateSystem
		 * @readonly
		 */
		get coordinateSystem() {

			return WebGLCoordinateSystem;

		}

		/**
		 * Defines the output color space of the renderer.
		 *
		 * @type {SRGBColorSpace|LinearSRGBColorSpace}
		 * @default SRGBColorSpace
		 */
		get outputColorSpace() {

			return this._outputColorSpace;

		}

		set outputColorSpace( colorSpace ) {

			this._outputColorSpace = colorSpace;

			const gl = this.getContext();
			gl.drawingBufferColorSpace = ColorManagement._getDrawingBufferColorSpace( colorSpace );
			gl.unpackColorSpace = ColorManagement._getUnpackColorSpace();

		}

	}

	/**
	 * A utility class for creating a button that allows to initiate
	 * immersive VR sessions based on WebXR. The button can be created
	 * with a factory method and then appended ot the website's DOM.
	 *
	 * ```js
	 * document.body.appendChild( VRButton.createButton( renderer ) );
	 * ```
	 *
	 * @hideconstructor
	 * @three_import import { VRButton } from 'three/addons/webxr/VRButton.js';
	 */
	class VRButton {

		/**
		 * Constructs a new VR button.
		 *
		 * @param {WebGLRenderer|WebGPURenderer} renderer - The renderer.
		 * @param {XRSessionInit} [sessionInit] - The a configuration object for the AR session.
		 * @return {HTMLElement} The button or an error message if `immersive-ar` isn't supported.
		 */
		static createButton( renderer, sessionInit = {} ) {

			const button = document.createElement( 'button' );

			function showEnterVR( /*device*/ ) {

				let currentSession = null;

				async function onSessionStarted( session ) {

					session.addEventListener( 'end', onSessionEnded );

					await renderer.xr.setSession( session );
					button.textContent = 'EXIT VR';

					currentSession = session;

				}

				function onSessionEnded( /*event*/ ) {

					currentSession.removeEventListener( 'end', onSessionEnded );

					button.textContent = 'ENTER VR';

					currentSession = null;

				}

				//

				button.style.display = '';

				button.style.cursor = 'pointer';
				button.style.left = 'calc(50% - 50px)';
				button.style.width = '100px';

				button.textContent = 'ENTER VR';

				// WebXR's requestReferenceSpace only works if the corresponding feature
				// was requested at session creation time. For simplicity, just ask for
				// the interesting ones as optional features, but be aware that the
				// requestReferenceSpace call will fail if it turns out to be unavailable.
				// ('local' is always available for immersive sessions and doesn't need to
				// be requested separately.)

				const sessionOptions = {
					...sessionInit,
					optionalFeatures: [
						'local-floor',
						'bounded-floor',
						'layers',
						...( sessionInit.optionalFeatures || [] )
					],
				};

				button.onmouseenter = function () {

					button.style.opacity = '1.0';

				};

				button.onmouseleave = function () {

					button.style.opacity = '0.5';

				};

				button.onclick = function () {

					if ( currentSession === null ) {

						navigator.xr.requestSession( 'immersive-vr', sessionOptions ).then( onSessionStarted );

					} else {

						currentSession.end();

						if ( navigator.xr.offerSession !== undefined ) {

							navigator.xr.offerSession( 'immersive-vr', sessionOptions )
								.then( onSessionStarted )
								.catch( ( err ) => {

									console.warn( err );

								} );

						}

					}

				};

				if ( navigator.xr.offerSession !== undefined ) {

					navigator.xr.offerSession( 'immersive-vr', sessionOptions )
						.then( onSessionStarted )
						.catch( ( err ) => {

							console.warn( err );

						} );

				}

			}

			function disableButton() {

				button.style.display = '';

				button.style.cursor = 'auto';
				button.style.left = 'calc(50% - 75px)';
				button.style.width = '150px';

				button.onmouseenter = null;
				button.onmouseleave = null;

				button.onclick = null;

			}

			function showWebXRNotFound() {

				disableButton();

				button.textContent = 'VR NOT SUPPORTED';

			}

			function showVRNotAllowed( exception ) {

				disableButton();

				console.warn( 'Exception when trying to call xr.isSessionSupported', exception );

				button.textContent = 'VR NOT ALLOWED';

			}

			function stylizeElement( element ) {

				element.style.position = 'absolute';
				element.style.bottom = '20px';
				element.style.padding = '12px 6px';
				element.style.border = '1px solid #fff';
				element.style.borderRadius = '4px';
				element.style.background = 'rgba(0,0,0,0.1)';
				element.style.color = '#fff';
				element.style.font = 'normal 13px sans-serif';
				element.style.textAlign = 'center';
				element.style.opacity = '0.5';
				element.style.outline = 'none';
				element.style.zIndex = '999';

			}

			if ( 'xr' in navigator ) {

				button.id = 'VRButton';
				button.style.display = 'none';

				stylizeElement( button );

				navigator.xr.isSessionSupported( 'immersive-vr' ).then( function ( supported ) {

					supported ? showEnterVR() : showWebXRNotFound();

					if ( supported && VRButton.xrSessionIsGranted ) {

						button.click();

					}

				} ).catch( showVRNotAllowed );

				return button;

			} else {

				const message = document.createElement( 'a' );

				if ( window.isSecureContext === false ) {

					message.href = document.location.href.replace( /^http:/, 'https:' );
					message.innerHTML = 'WEBXR NEEDS HTTPS'; // TODO Improve message

				} else {

					message.href = 'https://immersiveweb.dev/';
					message.innerHTML = 'WEBXR NOT AVAILABLE';

				}

				message.style.left = 'calc(50% - 90px)';
				message.style.width = '180px';
				message.style.textDecoration = 'none';

				stylizeElement( message );

				return message;

			}

		}

		/**
		 * Registers a `sessiongranted` event listener. When a session is granted, the {@link VRButton#xrSessionIsGranted}
		 * flag will evaluate to `true`. This method is automatically called by the module itself so there
		 * should be no need to use it on app level.
		 */
		static registerSessionGrantedListener() {

			if ( typeof navigator !== 'undefined' && 'xr' in navigator ) {

				// WebXRViewer (based on Firefox) has a bug where addEventListener
				// throws a silent exception and aborts execution entirely.
				if ( /WebXRViewer\//i.test( navigator.userAgent ) ) return;

				navigator.xr.addEventListener( 'sessiongranted', () => {

					VRButton.xrSessionIsGranted = true;

				} );

			}

		}

	}

	/**
	 * Whether a XR session has been granted or not.
	 *
	 * @static
	 * @type {boolean}
	 * @default false
	 */
	VRButton.xrSessionIsGranted = false;
	VRButton.registerSessionGrantedListener();

	// tweenable styles

	const _tweens_ = Symbol('tweens');
	const _host_ = Symbol.for('host');

	const OBJECT = 'object';
	const NUMBER = 'number';

	class Style {
	    constructor(props, host) {
	        Object.assign(this, props);
	        this[_tweens_] = {};
	        this[_host_] = host;

	        this.changed = true;

	    }

	    get host() {
	        return this[_host_]
	    }

	    get transition() {
	        return this.host.transition
	    }

	    isAnimated(name, value) {
	        if (this._transitionsDisabled) {
	            return false
	        }
	        if (this[name] === undefined) {
	            return false
	        }
	        if (typeof value !== NUMBER) {
	            return false
	        }
	        return true
	    }

	    disableTransitions() {
	        this._transitionsDisabled = true;
	    }
	    enableTransitions() {
	        this._transitionsDisabled = false;
	    }

	    set(name, value) {
	        if (this[name] === value) {
	            return true
	        }

	        if (this.isAnimated(name, value)) {
	            return this.setAnimated(name, value)
	        } else {
	            if (typeof value === OBJECT) {
	                console.error("setting object props", name, this[name]);
	                if (typeof this[name] !== OBJECT) { this[name] = new Style(value, this.host); }
	                for (let key in Object.keys(value)) {
	                    this[name].set(key, value[key]);
	                }
	                return;
	            }
	        }

	        this[name] = value;
	        this.changed = true;
	    }

	    updateTweenProps(t, trans) {
	        //console.log("UPDATE TWEEN", this.host.transition, trans, trans.duration * 1000, trans.delay * 1000);

	        t.easing(trans.ease || TWEEN.Easing.Linear.None);
	        t.delay(trans.delay * 1000);
	        //t.to(t._to, trans.duration * 1000)
	        t.duration(trans.duration * 1000);
	    }

	    createTween(trans, obj) {
	        var t = new TWEEN.Tween(obj);
	        t._to = {};
	        t.to(t._to, trans.duration * 1000);
	        t.onUpdate(() => {
	            this.changed = name;
	        });
	        t.onComplete(() => {
	            //console.error(t, 'tween completed', this);
	        });

	        return t
	    }

	    getTween(name, trans, obj) {
	        if (!this[_tweens_][name]) {
	            this[_tweens_][name] = this.createTween(trans, obj);
	        }
	        var t = this[_tweens_][name];
	        this.updateTweenProps(t, trans);
	        return t
	    }

	    setAnimated(name, value, obj, tid) {

	        //console.log('NAME VALUE: ', name, value);

	        if (!obj) { obj = this; }

	        if (obj[name] === undefined) {
	            obj[name] = 0;
	        }
	        var t, trans;

	        if (this.transition[name]) {
	            trans = this.transition[name];
	            t = this.getTween(name, trans, obj);
	        } else if (this.transition.all) {
	            trans = this.transition.all;
	            t = this.getTween('all', trans, obj);
	        }

	        if (t) {
	            t.stop();
	            t._to[name] = value;
	            t.start();
	        } else {
	            obj[name] = value;
	        }


	        //console.log("set animated", name, value, obj[name], t);

	    }


	}

	function Bezier(x1, y1, x2, y2, epsilon){

		var curveX = function(t){
			var v = 1 - t;
			return 3 * v * v * t * x1 + 3 * v * t * t * x2 + t * t * t;
		};

		var curveY = function(t){
			var v = 1 - t;
			return 3 * v * v * t * y1 + 3 * v * t * t * y2 + t * t * t;
		};

		var derivativeCurveX = function(t){
			var v = 1 - t;
			return 3 * (2 * (t - 1) * t + v * v) * x1 + 3 * (- t * t * t + 2 * v * t) * x2;
		};

		return function(t){

			var x = t, t0, t1, t2, x2, d2, i;

			// First try a few iterations of Newton's method -- normally very fast.
			for (t2 = x, i = 0; i < 8; i++){
				x2 = curveX(t2) - x;
				if (Math.abs(x2) < epsilon) return curveY(t2)
				d2 = derivativeCurveX(t2);
				if (Math.abs(d2) < 1e-6) break
				t2 = t2 - x2 / d2;
			}

			t0 = 0;
			t1 = 1;
			t2 = x;

			if (t2 < t0) return curveY(t0);
			if (t2 > t1) return curveY(t1);

			// Fallback to the bisection method for reliability.
			while (t0 < t1){
				x2 = curveX(t2);
				if (Math.abs(x2 - x) < epsilon) return curveY(t2);
				if (x > x2) t0 = t2;
				else t1 = t2;
				t2 = (t1 - t0) * 0.5 + t0;
			}

			// Failure
			return curveY(t2);

		};

	}

	/**
	 * Returns a new geometry with vertices for which all similar vertex attributes (within tolerance) are merged.
	 *
	 * @param {BufferGeometry} geometry - The geometry to merge vertices for.
	 * @param {number} [tolerance=1e-4] - The tolerance value.
	 * @return {BufferGeometry} - The new geometry with merged vertices.
	 */
	function mergeVertices( geometry, tolerance = 1e-4 ) {

		tolerance = Math.max( tolerance, Number.EPSILON );

		// Generate an index buffer if the geometry doesn't have one, or optimize it
		// if it's already available.
		const hashToIndex = {};
		const indices = geometry.getIndex();
		const positions = geometry.getAttribute( 'position' );
		const vertexCount = indices ? indices.count : positions.count;

		// next value for triangle indices
		let nextIndex = 0;

		// attributes and new attribute arrays
		const attributeNames = Object.keys( geometry.attributes );
		const tmpAttributes = {};
		const tmpMorphAttributes = {};
		const newIndices = [];
		const getters = [ 'getX', 'getY', 'getZ', 'getW' ];
		const setters = [ 'setX', 'setY', 'setZ', 'setW' ];

		// Initialize the arrays, allocating space conservatively. Extra
		// space will be trimmed in the last step.
		for ( let i = 0, l = attributeNames.length; i < l; i ++ ) {

			const name = attributeNames[ i ];
			const attr = geometry.attributes[ name ];

			tmpAttributes[ name ] = new attr.constructor(
				new attr.array.constructor( attr.count * attr.itemSize ),
				attr.itemSize,
				attr.normalized
			);

			const morphAttributes = geometry.morphAttributes[ name ];
			if ( morphAttributes ) {

				if ( ! tmpMorphAttributes[ name ] ) tmpMorphAttributes[ name ] = [];
				morphAttributes.forEach( ( morphAttr, i ) => {

					const array = new morphAttr.array.constructor( morphAttr.count * morphAttr.itemSize );
					tmpMorphAttributes[ name ][ i ] = new morphAttr.constructor( array, morphAttr.itemSize, morphAttr.normalized );

				} );

			}

		}

		// convert the error tolerance to an amount of decimal places to truncate to
		const halfTolerance = tolerance * 0.5;
		const exponent = Math.log10( 1 / tolerance );
		const hashMultiplier = Math.pow( 10, exponent );
		const hashAdditive = halfTolerance * hashMultiplier;
		for ( let i = 0; i < vertexCount; i ++ ) {

			const index = indices ? indices.getX( i ) : i;

			// Generate a hash for the vertex attributes at the current index 'i'
			let hash = '';
			for ( let j = 0, l = attributeNames.length; j < l; j ++ ) {

				const name = attributeNames[ j ];
				const attribute = geometry.getAttribute( name );
				const itemSize = attribute.itemSize;

				for ( let k = 0; k < itemSize; k ++ ) {

					// double tilde truncates the decimal value
					hash += `${ ~ ~ ( attribute[ getters[ k ] ]( index ) * hashMultiplier + hashAdditive ) },`;

				}

			}

			// Add another reference to the vertex if it's already
			// used by another index
			if ( hash in hashToIndex ) {

				newIndices.push( hashToIndex[ hash ] );

			} else {

				// copy data to the new index in the temporary attributes
				for ( let j = 0, l = attributeNames.length; j < l; j ++ ) {

					const name = attributeNames[ j ];
					const attribute = geometry.getAttribute( name );
					const morphAttributes = geometry.morphAttributes[ name ];
					const itemSize = attribute.itemSize;
					const newArray = tmpAttributes[ name ];
					const newMorphArrays = tmpMorphAttributes[ name ];

					for ( let k = 0; k < itemSize; k ++ ) {

						const getterFunc = getters[ k ];
						const setterFunc = setters[ k ];
						newArray[ setterFunc ]( nextIndex, attribute[ getterFunc ]( index ) );

						if ( morphAttributes ) {

							for ( let m = 0, ml = morphAttributes.length; m < ml; m ++ ) {

								newMorphArrays[ m ][ setterFunc ]( nextIndex, morphAttributes[ m ][ getterFunc ]( index ) );

							}

						}

					}

				}

				hashToIndex[ hash ] = nextIndex;
				newIndices.push( nextIndex );
				nextIndex ++;

			}

		}

		// generate result BufferGeometry
		const result = geometry.clone();
		for ( const name in geometry.attributes ) {

			const tmpAttribute = tmpAttributes[ name ];

			result.setAttribute( name, new tmpAttribute.constructor(
				tmpAttribute.array.slice( 0, nextIndex * tmpAttribute.itemSize ),
				tmpAttribute.itemSize,
				tmpAttribute.normalized,
			) );

			if ( ! ( name in tmpMorphAttributes ) ) continue;

			for ( let j = 0; j < tmpMorphAttributes[ name ].length; j ++ ) {

				const tmpMorphAttribute = tmpMorphAttributes[ name ][ j ];

				result.morphAttributes[ name ][ j ] = new tmpMorphAttribute.constructor(
					tmpMorphAttribute.array.slice( 0, nextIndex * tmpMorphAttribute.itemSize ),
					tmpMorphAttribute.itemSize,
					tmpMorphAttribute.normalized,
				);

			}

		}

		// indices

		result.setIndex( newIndices );

		return result;

	}

	/**
	 * Returns a new indexed geometry based on `TrianglesDrawMode` draw mode.
	 * This mode corresponds to the `gl.TRIANGLES` primitive in WebGL.
	 *
	 * @param {BufferGeometry} geometry - The geometry to convert.
	 * @param {number} drawMode - The current draw mode.
	 * @return {BufferGeometry} The new geometry using `TrianglesDrawMode`.
	 */
	function toTrianglesDrawMode( geometry, drawMode ) {

		if ( drawMode === TrianglesDrawMode ) {

			console.warn( 'THREE.BufferGeometryUtils.toTrianglesDrawMode(): Geometry already defined as triangles.' );
			return geometry;

		}

		if ( drawMode === TriangleFanDrawMode || drawMode === TriangleStripDrawMode ) {

			let index = geometry.getIndex();

			// generate index if not present

			if ( index === null ) {

				const indices = [];

				const position = geometry.getAttribute( 'position' );

				if ( position !== undefined ) {

					for ( let i = 0; i < position.count; i ++ ) {

						indices.push( i );

					}

					geometry.setIndex( indices );
					index = geometry.getIndex();

				} else {

					console.error( 'THREE.BufferGeometryUtils.toTrianglesDrawMode(): Undefined position attribute. Processing not possible.' );
					return geometry;

				}

			}

			//

			const numberOfTriangles = index.count - 2;
			const newIndices = [];

			if ( drawMode === TriangleFanDrawMode ) {

				// gl.TRIANGLE_FAN

				for ( let i = 1; i <= numberOfTriangles; i ++ ) {

					newIndices.push( index.getX( 0 ) );
					newIndices.push( index.getX( i ) );
					newIndices.push( index.getX( i + 1 ) );

				}

			} else {

				// gl.TRIANGLE_STRIP

				for ( let i = 0; i < numberOfTriangles; i ++ ) {

					if ( i % 2 === 0 ) {

						newIndices.push( index.getX( i ) );
						newIndices.push( index.getX( i + 1 ) );
						newIndices.push( index.getX( i + 2 ) );

					} else {

						newIndices.push( index.getX( i + 2 ) );
						newIndices.push( index.getX( i + 1 ) );
						newIndices.push( index.getX( i ) );

					}

				}

			}

			if ( ( newIndices.length / 3 ) !== numberOfTriangles ) {

				console.error( 'THREE.BufferGeometryUtils.toTrianglesDrawMode(): Unable to generate correct amount of triangles.' );

			}

			// build final geometry

			const newGeometry = geometry.clone();
			newGeometry.setIndex( newIndices );
			newGeometry.clearGroups();

			return newGeometry;

		} else {

			console.error( 'THREE.BufferGeometryUtils.toTrianglesDrawMode(): Unknown draw mode:', drawMode );
			return geometry;

		}

	}

	/**
	 * A loader for the glTF 2.0 format.
	 *
	 * [glTF]{@link https://www.khronos.org/gltf/} (GL Transmission Format) is an [open format specification]{@link https://github.com/KhronosGroup/glTF/tree/main/specification/2.0}
	 * for efficient delivery and loading of 3D content. Assets may be provided either in JSON (.gltf) or binary (.glb)
	 * format. External files store textures (.jpg, .png) and additional binary data (.bin). A glTF asset may deliver
	 * one or more scenes, including meshes, materials, textures, skins, skeletons, morph targets, animations, lights,
	 * and/or cameras.
	 *
	 * `GLTFLoader` uses {@link ImageBitmapLoader} whenever possible. Be advised that image bitmaps are not
	 * automatically GC-collected when they are no longer referenced, and they require special handling during
	 * the disposal process.
	 *
	 * `GLTFLoader` supports the following glTF 2.0 extensions:
	 * - KHR_draco_mesh_compression
	 * - KHR_materials_clearcoat
	 * - KHR_materials_dispersion
	 * - KHR_materials_ior
	 * - KHR_materials_specular
	 * - KHR_materials_transmission
	 * - KHR_materials_iridescence
	 * - KHR_materials_unlit
	 * - KHR_materials_volume
	 * - KHR_mesh_quantization
	 * - KHR_lights_punctual
	 * - KHR_texture_basisu
	 * - KHR_texture_transform
	 * - EXT_texture_webp
	 * - EXT_meshopt_compression
	 * - EXT_mesh_gpu_instancing
	 *
	 * The following glTF 2.0 extension is supported by an external user plugin:
	 * - [KHR_materials_variants]{@link https://github.com/takahirox/three-gltf-extensions}
	 * - [MSFT_texture_dds]{@link https://github.com/takahirox/three-gltf-extensions}
	 *
	 * ```js
	 * const loader = new GLTFLoader();
	 *
	 * // Optional: Provide a DRACOLoader instance to decode compressed mesh data
	 * const dracoLoader = new DRACOLoader();
	 * dracoLoader.setDecoderPath( '/examples/jsm/libs/draco/' );
	 * loader.setDRACOLoader( dracoLoader );
	 *
	 * const gltf = await loader.loadAsync( 'models/gltf/duck/duck.gltf' );
	 * scene.add( gltf.scene );
	 * ```
	 *
	 * @augments Loader
	 * @three_import import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
	 */
	class GLTFLoader extends Loader {

		/**
		 * Constructs a new glTF loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			super( manager );

			this.dracoLoader = null;
			this.ktx2Loader = null;
			this.meshoptDecoder = null;

			this.pluginCallbacks = [];

			this.register( function ( parser ) {

				return new GLTFMaterialsClearcoatExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsDispersionExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFTextureBasisUExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFTextureWebPExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFTextureAVIFExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsSheenExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsTransmissionExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsVolumeExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsIorExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsEmissiveStrengthExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsSpecularExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsIridescenceExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsAnisotropyExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMaterialsBumpExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFLightsExtension( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMeshoptCompression( parser );

			} );

			this.register( function ( parser ) {

				return new GLTFMeshGpuInstancing( parser );

			} );

		}

		/**
		 * Starts loading from the given URL and passes the loaded glTF asset
		 * to the `onLoad()` callback.
		 *
		 * @param {string} url - The path/URL of the file to be loaded. This can also be a data URI.
		 * @param {function(GLTFLoader~LoadObject)} onLoad - Executed when the loading process has been finished.
		 * @param {onProgressCallback} onProgress - Executed while the loading is in progress.
		 * @param {onErrorCallback} onError - Executed when errors occur.
		 */
		load( url, onLoad, onProgress, onError ) {

			const scope = this;

			let resourcePath;

			if ( this.resourcePath !== '' ) {

				resourcePath = this.resourcePath;

			} else if ( this.path !== '' ) {

				// If a base path is set, resources will be relative paths from that plus the relative path of the gltf file
				// Example  path = 'https://my-cnd-server.com/', url = 'assets/models/model.gltf'
				// resourcePath = 'https://my-cnd-server.com/assets/models/'
				// referenced resource 'model.bin' will be loaded from 'https://my-cnd-server.com/assets/models/model.bin'
				// referenced resource '../textures/texture.png' will be loaded from 'https://my-cnd-server.com/assets/textures/texture.png'
				const relativeUrl = LoaderUtils.extractUrlBase( url );
				resourcePath = LoaderUtils.resolveURL( relativeUrl, this.path );

			} else {

				resourcePath = LoaderUtils.extractUrlBase( url );

			}

			// Tells the LoadingManager to track an extra item, which resolves after
			// the model is fully loaded. This means the count of items loaded will
			// be incorrect, but ensures manager.onLoad() does not fire early.
			this.manager.itemStart( url );

			const _onError = function ( e ) {

				if ( onError ) {

					onError( e );

				} else {

					console.error( e );

				}

				scope.manager.itemError( url );
				scope.manager.itemEnd( url );

			};

			const loader = new FileLoader( this.manager );

			loader.setPath( this.path );
			loader.setResponseType( 'arraybuffer' );
			loader.setRequestHeader( this.requestHeader );
			loader.setWithCredentials( this.withCredentials );

			loader.load( url, function ( data ) {

				try {

					scope.parse( data, resourcePath, function ( gltf ) {

						onLoad( gltf );

						scope.manager.itemEnd( url );

					}, _onError );

				} catch ( e ) {

					_onError( e );

				}

			}, onProgress, _onError );

		}

		/**
		 * Sets the given Draco loader to this loader. Required for decoding assets
		 * compressed with the `KHR_draco_mesh_compression` extension.
		 *
		 * @param {DRACOLoader} dracoLoader - The Draco loader to set.
		 * @return {GLTFLoader} A reference to this loader.
		 */
		setDRACOLoader( dracoLoader ) {

			this.dracoLoader = dracoLoader;
			return this;

		}

		/**
		 * Sets the given KTX2 loader to this loader. Required for loading KTX2
		 * compressed textures.
		 *
		 * @param {KTX2Loader} ktx2Loader - The KTX2 loader to set.
		 * @return {GLTFLoader} A reference to this loader.
		 */
		setKTX2Loader( ktx2Loader ) {

			this.ktx2Loader = ktx2Loader;
			return this;

		}

		/**
		 * Sets the given meshopt decoder. Required for decoding assets
		 * compressed with the `EXT_meshopt_compression` extension.
		 *
		 * @param {Object} meshoptDecoder - The meshopt decoder to set.
		 * @return {GLTFLoader} A reference to this loader.
		 */
		setMeshoptDecoder( meshoptDecoder ) {

			this.meshoptDecoder = meshoptDecoder;
			return this;

		}

		/**
		 * Registers a plugin callback. This API is internally used to implement the various
		 * glTF extensions but can also used by third-party code to add additional logic
		 * to the loader.
		 *
		 * @param {function(parser:GLTFParser)} callback - The callback function to register.
		 * @return {GLTFLoader} A reference to this loader.
		 */
		register( callback ) {

			if ( this.pluginCallbacks.indexOf( callback ) === - 1 ) {

				this.pluginCallbacks.push( callback );

			}

			return this;

		}

		/**
		 * Unregisters a plugin callback.
		 *
		 * @param {Function} callback - The callback function to unregister.
		 * @return {GLTFLoader} A reference to this loader.
		 */
		unregister( callback ) {

			if ( this.pluginCallbacks.indexOf( callback ) !== - 1 ) {

				this.pluginCallbacks.splice( this.pluginCallbacks.indexOf( callback ), 1 );

			}

			return this;

		}

		/**
		 * Parses the given FBX data and returns the resulting group.
		 *
		 * @param {string|ArrayBuffer} data - The raw glTF data.
		 * @param {string} path - The URL base path.
		 * @param {function(GLTFLoader~LoadObject)} onLoad - Executed when the loading process has been finished.
		 * @param {onErrorCallback} onError - Executed when errors occur.
		 */
		parse( data, path, onLoad, onError ) {

			let json;
			const extensions = {};
			const plugins = {};
			const textDecoder = new TextDecoder();

			if ( typeof data === 'string' ) {

				json = JSON.parse( data );

			} else if ( data instanceof ArrayBuffer ) {

				const magic = textDecoder.decode( new Uint8Array( data, 0, 4 ) );

				if ( magic === BINARY_EXTENSION_HEADER_MAGIC ) {

					try {

						extensions[ EXTENSIONS.KHR_BINARY_GLTF ] = new GLTFBinaryExtension( data );

					} catch ( error ) {

						if ( onError ) onError( error );
						return;

					}

					json = JSON.parse( extensions[ EXTENSIONS.KHR_BINARY_GLTF ].content );

				} else {

					json = JSON.parse( textDecoder.decode( data ) );

				}

			} else {

				json = data;

			}

			if ( json.asset === undefined || json.asset.version[ 0 ] < 2 ) {

				if ( onError ) onError( new Error( 'THREE.GLTFLoader: Unsupported asset. glTF versions >=2.0 are supported.' ) );
				return;

			}

			const parser = new GLTFParser( json, {

				path: path || this.resourcePath || '',
				crossOrigin: this.crossOrigin,
				requestHeader: this.requestHeader,
				manager: this.manager,
				ktx2Loader: this.ktx2Loader,
				meshoptDecoder: this.meshoptDecoder

			} );

			parser.fileLoader.setRequestHeader( this.requestHeader );

			for ( let i = 0; i < this.pluginCallbacks.length; i ++ ) {

				const plugin = this.pluginCallbacks[ i ]( parser );

				if ( ! plugin.name ) console.error( 'THREE.GLTFLoader: Invalid plugin found: missing name' );

				plugins[ plugin.name ] = plugin;

				// Workaround to avoid determining as unknown extension
				// in addUnknownExtensionsToUserData().
				// Remove this workaround if we move all the existing
				// extension handlers to plugin system
				extensions[ plugin.name ] = true;

			}

			if ( json.extensionsUsed ) {

				for ( let i = 0; i < json.extensionsUsed.length; ++ i ) {

					const extensionName = json.extensionsUsed[ i ];
					const extensionsRequired = json.extensionsRequired || [];

					switch ( extensionName ) {

						case EXTENSIONS.KHR_MATERIALS_UNLIT:
							extensions[ extensionName ] = new GLTFMaterialsUnlitExtension();
							break;

						case EXTENSIONS.KHR_DRACO_MESH_COMPRESSION:
							extensions[ extensionName ] = new GLTFDracoMeshCompressionExtension( json, this.dracoLoader );
							break;

						case EXTENSIONS.KHR_TEXTURE_TRANSFORM:
							extensions[ extensionName ] = new GLTFTextureTransformExtension();
							break;

						case EXTENSIONS.KHR_MESH_QUANTIZATION:
							extensions[ extensionName ] = new GLTFMeshQuantizationExtension();
							break;

						default:

							if ( extensionsRequired.indexOf( extensionName ) >= 0 && plugins[ extensionName ] === undefined ) {

								console.warn( 'THREE.GLTFLoader: Unknown extension "' + extensionName + '".' );

							}

					}

				}

			}

			parser.setExtensions( extensions );
			parser.setPlugins( plugins );
			parser.parse( onLoad, onError );

		}

		/**
		 * Async version of {@link GLTFLoader#parse}.
		 *
		 * @async
		 * @param {string|ArrayBuffer} data - The raw glTF data.
		 * @param {string} path - The URL base path.
		 * @return {Promise<GLTFLoader~LoadObject>} A Promise that resolves with the loaded glTF when the parsing has been finished.
		 */
		parseAsync( data, path ) {

			const scope = this;

			return new Promise( function ( resolve, reject ) {

				scope.parse( data, path, resolve, reject );

			} );

		}

	}

	/* GLTFREGISTRY */

	function GLTFRegistry() {

		let objects = {};

		return	{

			get: function ( key ) {

				return objects[ key ];

			},

			add: function ( key, object ) {

				objects[ key ] = object;

			},

			remove: function ( key ) {

				delete objects[ key ];

			},

			removeAll: function () {

				objects = {};

			}

		};

	}

	/*********************************/
	/********** EXTENSIONS ***********/
	/*********************************/

	const EXTENSIONS = {
		KHR_BINARY_GLTF: 'KHR_binary_glTF',
		KHR_DRACO_MESH_COMPRESSION: 'KHR_draco_mesh_compression',
		KHR_LIGHTS_PUNCTUAL: 'KHR_lights_punctual',
		KHR_MATERIALS_CLEARCOAT: 'KHR_materials_clearcoat',
		KHR_MATERIALS_DISPERSION: 'KHR_materials_dispersion',
		KHR_MATERIALS_IOR: 'KHR_materials_ior',
		KHR_MATERIALS_SHEEN: 'KHR_materials_sheen',
		KHR_MATERIALS_SPECULAR: 'KHR_materials_specular',
		KHR_MATERIALS_TRANSMISSION: 'KHR_materials_transmission',
		KHR_MATERIALS_IRIDESCENCE: 'KHR_materials_iridescence',
		KHR_MATERIALS_ANISOTROPY: 'KHR_materials_anisotropy',
		KHR_MATERIALS_UNLIT: 'KHR_materials_unlit',
		KHR_MATERIALS_VOLUME: 'KHR_materials_volume',
		KHR_TEXTURE_BASISU: 'KHR_texture_basisu',
		KHR_TEXTURE_TRANSFORM: 'KHR_texture_transform',
		KHR_MESH_QUANTIZATION: 'KHR_mesh_quantization',
		KHR_MATERIALS_EMISSIVE_STRENGTH: 'KHR_materials_emissive_strength',
		EXT_MATERIALS_BUMP: 'EXT_materials_bump',
		EXT_TEXTURE_WEBP: 'EXT_texture_webp',
		EXT_TEXTURE_AVIF: 'EXT_texture_avif',
		EXT_MESHOPT_COMPRESSION: 'EXT_meshopt_compression',
		EXT_MESH_GPU_INSTANCING: 'EXT_mesh_gpu_instancing'
	};

	/**
	 * Punctual Lights Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_lights_punctual
	 *
	 * @private
	 */
	class GLTFLightsExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_LIGHTS_PUNCTUAL;

			// Object3D instance caches
			this.cache = { refs: {}, uses: {} };

		}

		_markDefs() {

			const parser = this.parser;
			const nodeDefs = this.parser.json.nodes || [];

			for ( let nodeIndex = 0, nodeLength = nodeDefs.length; nodeIndex < nodeLength; nodeIndex ++ ) {

				const nodeDef = nodeDefs[ nodeIndex ];

				if ( nodeDef.extensions
						&& nodeDef.extensions[ this.name ]
						&& nodeDef.extensions[ this.name ].light !== undefined ) {

					parser._addNodeRef( this.cache, nodeDef.extensions[ this.name ].light );

				}

			}

		}

		_loadLight( lightIndex ) {

			const parser = this.parser;
			const cacheKey = 'light:' + lightIndex;
			let dependency = parser.cache.get( cacheKey );

			if ( dependency ) return dependency;

			const json = parser.json;
			const extensions = ( json.extensions && json.extensions[ this.name ] ) || {};
			const lightDefs = extensions.lights || [];
			const lightDef = lightDefs[ lightIndex ];
			let lightNode;

			const color = new Color( 0xffffff );

			if ( lightDef.color !== undefined ) color.setRGB( lightDef.color[ 0 ], lightDef.color[ 1 ], lightDef.color[ 2 ], LinearSRGBColorSpace );

			const range = lightDef.range !== undefined ? lightDef.range : 0;

			switch ( lightDef.type ) {

				case 'directional':
					lightNode = new DirectionalLight( color );
					lightNode.target.position.set( 0, 0, - 1 );
					lightNode.add( lightNode.target );
					break;

				case 'point':
					lightNode = new PointLight( color );
					lightNode.distance = range;
					break;

				case 'spot':
					lightNode = new SpotLight( color );
					lightNode.distance = range;
					// Handle spotlight properties.
					lightDef.spot = lightDef.spot || {};
					lightDef.spot.innerConeAngle = lightDef.spot.innerConeAngle !== undefined ? lightDef.spot.innerConeAngle : 0;
					lightDef.spot.outerConeAngle = lightDef.spot.outerConeAngle !== undefined ? lightDef.spot.outerConeAngle : Math.PI / 4.0;
					lightNode.angle = lightDef.spot.outerConeAngle;
					lightNode.penumbra = 1.0 - lightDef.spot.innerConeAngle / lightDef.spot.outerConeAngle;
					lightNode.target.position.set( 0, 0, - 1 );
					lightNode.add( lightNode.target );
					break;

				default:
					throw new Error( 'THREE.GLTFLoader: Unexpected light type: ' + lightDef.type );

			}

			// Some lights (e.g. spot) default to a position other than the origin. Reset the position
			// here, because node-level parsing will only override position if explicitly specified.
			lightNode.position.set( 0, 0, 0 );

			assignExtrasToUserData( lightNode, lightDef );

			if ( lightDef.intensity !== undefined ) lightNode.intensity = lightDef.intensity;

			lightNode.name = parser.createUniqueName( lightDef.name || ( 'light_' + lightIndex ) );

			dependency = Promise.resolve( lightNode );

			parser.cache.add( cacheKey, dependency );

			return dependency;

		}

		getDependency( type, index ) {

			if ( type !== 'light' ) return;

			return this._loadLight( index );

		}

		createNodeAttachment( nodeIndex ) {

			const self = this;
			const parser = this.parser;
			const json = parser.json;
			const nodeDef = json.nodes[ nodeIndex ];
			const lightDef = ( nodeDef.extensions && nodeDef.extensions[ this.name ] ) || {};
			const lightIndex = lightDef.light;

			if ( lightIndex === undefined ) return null;

			return this._loadLight( lightIndex ).then( function ( light ) {

				return parser._getNodeRef( self.cache, lightIndex, light );

			} );

		}

	}

	/**
	 * Unlit Materials Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_unlit
	 *
	 * @private
	 */
	class GLTFMaterialsUnlitExtension {

		constructor() {

			this.name = EXTENSIONS.KHR_MATERIALS_UNLIT;

		}

		getMaterialType() {

			return MeshBasicMaterial;

		}

		extendParams( materialParams, materialDef, parser ) {

			const pending = [];

			materialParams.color = new Color( 1.0, 1.0, 1.0 );
			materialParams.opacity = 1.0;

			const metallicRoughness = materialDef.pbrMetallicRoughness;

			if ( metallicRoughness ) {

				if ( Array.isArray( metallicRoughness.baseColorFactor ) ) {

					const array = metallicRoughness.baseColorFactor;

					materialParams.color.setRGB( array[ 0 ], array[ 1 ], array[ 2 ], LinearSRGBColorSpace );
					materialParams.opacity = array[ 3 ];

				}

				if ( metallicRoughness.baseColorTexture !== undefined ) {

					pending.push( parser.assignTexture( materialParams, 'map', metallicRoughness.baseColorTexture, SRGBColorSpace ) );

				}

			}

			return Promise.all( pending );

		}

	}

	/**
	 * Materials Emissive Strength Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/blob/5768b3ce0ef32bc39cdf1bef10b948586635ead3/extensions/2.0/Khronos/KHR_materials_emissive_strength/README.md
	 *
	 * @private
	 */
	class GLTFMaterialsEmissiveStrengthExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_EMISSIVE_STRENGTH;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const emissiveStrength = materialDef.extensions[ this.name ].emissiveStrength;

			if ( emissiveStrength !== undefined ) {

				materialParams.emissiveIntensity = emissiveStrength;

			}

			return Promise.resolve();

		}

	}

	/**
	 * Clearcoat Materials Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_clearcoat
	 *
	 * @private
	 */
	class GLTFMaterialsClearcoatExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_CLEARCOAT;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const pending = [];

			const extension = materialDef.extensions[ this.name ];

			if ( extension.clearcoatFactor !== undefined ) {

				materialParams.clearcoat = extension.clearcoatFactor;

			}

			if ( extension.clearcoatTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'clearcoatMap', extension.clearcoatTexture ) );

			}

			if ( extension.clearcoatRoughnessFactor !== undefined ) {

				materialParams.clearcoatRoughness = extension.clearcoatRoughnessFactor;

			}

			if ( extension.clearcoatRoughnessTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'clearcoatRoughnessMap', extension.clearcoatRoughnessTexture ) );

			}

			if ( extension.clearcoatNormalTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'clearcoatNormalMap', extension.clearcoatNormalTexture ) );

				if ( extension.clearcoatNormalTexture.scale !== undefined ) {

					const scale = extension.clearcoatNormalTexture.scale;

					materialParams.clearcoatNormalScale = new Vector2( scale, scale );

				}

			}

			return Promise.all( pending );

		}

	}

	/**
	 * Materials dispersion Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_dispersion
	 *
	 * @private
	 */
	class GLTFMaterialsDispersionExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_DISPERSION;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const extension = materialDef.extensions[ this.name ];

			materialParams.dispersion = extension.dispersion !== undefined ? extension.dispersion : 0;

			return Promise.resolve();

		}

	}

	/**
	 * Iridescence Materials Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_iridescence
	 *
	 * @private
	 */
	class GLTFMaterialsIridescenceExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_IRIDESCENCE;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const pending = [];

			const extension = materialDef.extensions[ this.name ];

			if ( extension.iridescenceFactor !== undefined ) {

				materialParams.iridescence = extension.iridescenceFactor;

			}

			if ( extension.iridescenceTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'iridescenceMap', extension.iridescenceTexture ) );

			}

			if ( extension.iridescenceIor !== undefined ) {

				materialParams.iridescenceIOR = extension.iridescenceIor;

			}

			if ( materialParams.iridescenceThicknessRange === undefined ) {

				materialParams.iridescenceThicknessRange = [ 100, 400 ];

			}

			if ( extension.iridescenceThicknessMinimum !== undefined ) {

				materialParams.iridescenceThicknessRange[ 0 ] = extension.iridescenceThicknessMinimum;

			}

			if ( extension.iridescenceThicknessMaximum !== undefined ) {

				materialParams.iridescenceThicknessRange[ 1 ] = extension.iridescenceThicknessMaximum;

			}

			if ( extension.iridescenceThicknessTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'iridescenceThicknessMap', extension.iridescenceThicknessTexture ) );

			}

			return Promise.all( pending );

		}

	}

	/**
	 * Sheen Materials Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_sheen
	 *
	 * @private
	 */
	class GLTFMaterialsSheenExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_SHEEN;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const pending = [];

			materialParams.sheenColor = new Color( 0, 0, 0 );
			materialParams.sheenRoughness = 0;
			materialParams.sheen = 1;

			const extension = materialDef.extensions[ this.name ];

			if ( extension.sheenColorFactor !== undefined ) {

				const colorFactor = extension.sheenColorFactor;
				materialParams.sheenColor.setRGB( colorFactor[ 0 ], colorFactor[ 1 ], colorFactor[ 2 ], LinearSRGBColorSpace );

			}

			if ( extension.sheenRoughnessFactor !== undefined ) {

				materialParams.sheenRoughness = extension.sheenRoughnessFactor;

			}

			if ( extension.sheenColorTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'sheenColorMap', extension.sheenColorTexture, SRGBColorSpace ) );

			}

			if ( extension.sheenRoughnessTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'sheenRoughnessMap', extension.sheenRoughnessTexture ) );

			}

			return Promise.all( pending );

		}

	}

	/**
	 * Transmission Materials Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_transmission
	 * Draft: https://github.com/KhronosGroup/glTF/pull/1698
	 *
	 * @private
	 */
	class GLTFMaterialsTransmissionExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_TRANSMISSION;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const pending = [];

			const extension = materialDef.extensions[ this.name ];

			if ( extension.transmissionFactor !== undefined ) {

				materialParams.transmission = extension.transmissionFactor;

			}

			if ( extension.transmissionTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'transmissionMap', extension.transmissionTexture ) );

			}

			return Promise.all( pending );

		}

	}

	/**
	 * Materials Volume Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_volume
	 *
	 * @private
	 */
	class GLTFMaterialsVolumeExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_VOLUME;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const pending = [];

			const extension = materialDef.extensions[ this.name ];

			materialParams.thickness = extension.thicknessFactor !== undefined ? extension.thicknessFactor : 0;

			if ( extension.thicknessTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'thicknessMap', extension.thicknessTexture ) );

			}

			materialParams.attenuationDistance = extension.attenuationDistance || Infinity;

			const colorArray = extension.attenuationColor || [ 1, 1, 1 ];
			materialParams.attenuationColor = new Color().setRGB( colorArray[ 0 ], colorArray[ 1 ], colorArray[ 2 ], LinearSRGBColorSpace );

			return Promise.all( pending );

		}

	}

	/**
	 * Materials ior Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_ior
	 *
	 * @private
	 */
	class GLTFMaterialsIorExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_IOR;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const extension = materialDef.extensions[ this.name ];

			materialParams.ior = extension.ior !== undefined ? extension.ior : 1.5;

			return Promise.resolve();

		}

	}

	/**
	 * Materials specular Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_specular
	 *
	 * @private
	 */
	class GLTFMaterialsSpecularExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_SPECULAR;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const pending = [];

			const extension = materialDef.extensions[ this.name ];

			materialParams.specularIntensity = extension.specularFactor !== undefined ? extension.specularFactor : 1.0;

			if ( extension.specularTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'specularIntensityMap', extension.specularTexture ) );

			}

			const colorArray = extension.specularColorFactor || [ 1, 1, 1 ];
			materialParams.specularColor = new Color().setRGB( colorArray[ 0 ], colorArray[ 1 ], colorArray[ 2 ], LinearSRGBColorSpace );

			if ( extension.specularColorTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'specularColorMap', extension.specularColorTexture, SRGBColorSpace ) );

			}

			return Promise.all( pending );

		}

	}


	/**
	 * Materials bump Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/EXT_materials_bump
	 *
	 * @private
	 */
	class GLTFMaterialsBumpExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.EXT_MATERIALS_BUMP;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const pending = [];

			const extension = materialDef.extensions[ this.name ];

			materialParams.bumpScale = extension.bumpFactor !== undefined ? extension.bumpFactor : 1.0;

			if ( extension.bumpTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'bumpMap', extension.bumpTexture ) );

			}

			return Promise.all( pending );

		}

	}

	/**
	 * Materials anisotropy Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_anisotropy
	 *
	 * @private
	 */
	class GLTFMaterialsAnisotropyExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_MATERIALS_ANISOTROPY;

		}

		getMaterialType( materialIndex ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;

			return MeshPhysicalMaterial;

		}

		extendMaterialParams( materialIndex, materialParams ) {

			const parser = this.parser;
			const materialDef = parser.json.materials[ materialIndex ];

			if ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {

				return Promise.resolve();

			}

			const pending = [];

			const extension = materialDef.extensions[ this.name ];

			if ( extension.anisotropyStrength !== undefined ) {

				materialParams.anisotropy = extension.anisotropyStrength;

			}

			if ( extension.anisotropyRotation !== undefined ) {

				materialParams.anisotropyRotation = extension.anisotropyRotation;

			}

			if ( extension.anisotropyTexture !== undefined ) {

				pending.push( parser.assignTexture( materialParams, 'anisotropyMap', extension.anisotropyTexture ) );

			}

			return Promise.all( pending );

		}

	}

	/**
	 * BasisU Texture Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_texture_basisu
	 *
	 * @private
	 */
	class GLTFTextureBasisUExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.KHR_TEXTURE_BASISU;

		}

		loadTexture( textureIndex ) {

			const parser = this.parser;
			const json = parser.json;

			const textureDef = json.textures[ textureIndex ];

			if ( ! textureDef.extensions || ! textureDef.extensions[ this.name ] ) {

				return null;

			}

			const extension = textureDef.extensions[ this.name ];
			const loader = parser.options.ktx2Loader;

			if ( ! loader ) {

				if ( json.extensionsRequired && json.extensionsRequired.indexOf( this.name ) >= 0 ) {

					throw new Error( 'THREE.GLTFLoader: setKTX2Loader must be called before loading KTX2 textures' );

				} else {

					// Assumes that the extension is optional and that a fallback texture is present
					return null;

				}

			}

			return parser.loadTextureImage( textureIndex, extension.source, loader );

		}

	}

	/**
	 * WebP Texture Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_texture_webp
	 *
	 * @private
	 */
	class GLTFTextureWebPExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.EXT_TEXTURE_WEBP;

		}

		loadTexture( textureIndex ) {

			const name = this.name;
			const parser = this.parser;
			const json = parser.json;

			const textureDef = json.textures[ textureIndex ];

			if ( ! textureDef.extensions || ! textureDef.extensions[ name ] ) {

				return null;

			}

			const extension = textureDef.extensions[ name ];
			const source = json.images[ extension.source ];

			let loader = parser.textureLoader;
			if ( source.uri ) {

				const handler = parser.options.manager.getHandler( source.uri );
				if ( handler !== null ) loader = handler;

			}

			return parser.loadTextureImage( textureIndex, extension.source, loader );

		}

	}

	/**
	 * AVIF Texture Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_texture_avif
	 *
	 * @private
	 */
	class GLTFTextureAVIFExtension {

		constructor( parser ) {

			this.parser = parser;
			this.name = EXTENSIONS.EXT_TEXTURE_AVIF;

		}

		loadTexture( textureIndex ) {

			const name = this.name;
			const parser = this.parser;
			const json = parser.json;

			const textureDef = json.textures[ textureIndex ];

			if ( ! textureDef.extensions || ! textureDef.extensions[ name ] ) {

				return null;

			}

			const extension = textureDef.extensions[ name ];
			const source = json.images[ extension.source ];

			let loader = parser.textureLoader;
			if ( source.uri ) {

				const handler = parser.options.manager.getHandler( source.uri );
				if ( handler !== null ) loader = handler;

			}

			return parser.loadTextureImage( textureIndex, extension.source, loader );

		}

	}

	/**
	 * meshopt BufferView Compression Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_meshopt_compression
	 *
	 * @private
	 */
	class GLTFMeshoptCompression {

		constructor( parser ) {

			this.name = EXTENSIONS.EXT_MESHOPT_COMPRESSION;
			this.parser = parser;

		}

		loadBufferView( index ) {

			const json = this.parser.json;
			const bufferView = json.bufferViews[ index ];

			if ( bufferView.extensions && bufferView.extensions[ this.name ] ) {

				const extensionDef = bufferView.extensions[ this.name ];

				const buffer = this.parser.getDependency( 'buffer', extensionDef.buffer );
				const decoder = this.parser.options.meshoptDecoder;

				if ( ! decoder || ! decoder.supported ) {

					if ( json.extensionsRequired && json.extensionsRequired.indexOf( this.name ) >= 0 ) {

						throw new Error( 'THREE.GLTFLoader: setMeshoptDecoder must be called before loading compressed files' );

					} else {

						// Assumes that the extension is optional and that fallback buffer data is present
						return null;

					}

				}

				return buffer.then( function ( res ) {

					const byteOffset = extensionDef.byteOffset || 0;
					const byteLength = extensionDef.byteLength || 0;

					const count = extensionDef.count;
					const stride = extensionDef.byteStride;

					const source = new Uint8Array( res, byteOffset, byteLength );

					if ( decoder.decodeGltfBufferAsync ) {

						return decoder.decodeGltfBufferAsync( count, stride, source, extensionDef.mode, extensionDef.filter ).then( function ( res ) {

							return res.buffer;

						} );

					} else {

						// Support for MeshoptDecoder 0.18 or earlier, without decodeGltfBufferAsync
						return decoder.ready.then( function () {

							const result = new ArrayBuffer( count * stride );
							decoder.decodeGltfBuffer( new Uint8Array( result ), count, stride, source, extensionDef.mode, extensionDef.filter );
							return result;

						} );

					}

				} );

			} else {

				return null;

			}

		}

	}

	/**
	 * GPU Instancing Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_mesh_gpu_instancing
	 *
	 * @private
	 */
	class GLTFMeshGpuInstancing {

		constructor( parser ) {

			this.name = EXTENSIONS.EXT_MESH_GPU_INSTANCING;
			this.parser = parser;

		}

		createNodeMesh( nodeIndex ) {

			const json = this.parser.json;
			const nodeDef = json.nodes[ nodeIndex ];

			if ( ! nodeDef.extensions || ! nodeDef.extensions[ this.name ] ||
				nodeDef.mesh === undefined ) {

				return null;

			}

			const meshDef = json.meshes[ nodeDef.mesh ];

			// No Points or Lines + Instancing support yet

			for ( const primitive of meshDef.primitives ) {

				if ( primitive.mode !== WEBGL_CONSTANTS.TRIANGLES &&
					 primitive.mode !== WEBGL_CONSTANTS.TRIANGLE_STRIP &&
					 primitive.mode !== WEBGL_CONSTANTS.TRIANGLE_FAN &&
					 primitive.mode !== undefined ) {

					return null;

				}

			}

			const extensionDef = nodeDef.extensions[ this.name ];
			const attributesDef = extensionDef.attributes;

			// @TODO: Can we support InstancedMesh + SkinnedMesh?

			const pending = [];
			const attributes = {};

			for ( const key in attributesDef ) {

				pending.push( this.parser.getDependency( 'accessor', attributesDef[ key ] ).then( accessor => {

					attributes[ key ] = accessor;
					return attributes[ key ];

				} ) );

			}

			if ( pending.length < 1 ) {

				return null;

			}

			pending.push( this.parser.createNodeMesh( nodeIndex ) );

			return Promise.all( pending ).then( results => {

				const nodeObject = results.pop();
				const meshes = nodeObject.isGroup ? nodeObject.children : [ nodeObject ];
				const count = results[ 0 ].count; // All attribute counts should be same
				const instancedMeshes = [];

				for ( const mesh of meshes ) {

					// Temporal variables
					const m = new Matrix4();
					const p = new Vector3();
					const q = new Quaternion();
					const s = new Vector3( 1, 1, 1 );

					const instancedMesh = new InstancedMesh( mesh.geometry, mesh.material, count );

					for ( let i = 0; i < count; i ++ ) {

						if ( attributes.TRANSLATION ) {

							p.fromBufferAttribute( attributes.TRANSLATION, i );

						}

						if ( attributes.ROTATION ) {

							q.fromBufferAttribute( attributes.ROTATION, i );

						}

						if ( attributes.SCALE ) {

							s.fromBufferAttribute( attributes.SCALE, i );

						}

						instancedMesh.setMatrixAt( i, m.compose( p, q, s ) );

					}

					// Add instance attributes to the geometry, excluding TRS.
					for ( const attributeName in attributes ) {

						if ( attributeName === '_COLOR_0' ) {

							const attr = attributes[ attributeName ];
							instancedMesh.instanceColor = new InstancedBufferAttribute( attr.array, attr.itemSize, attr.normalized );

						} else if ( attributeName !== 'TRANSLATION' &&
							 attributeName !== 'ROTATION' &&
							 attributeName !== 'SCALE' ) {

							mesh.geometry.setAttribute( attributeName, attributes[ attributeName ] );

						}

					}

					// Just in case
					Object3D.prototype.copy.call( instancedMesh, mesh );

					this.parser.assignFinalMaterial( instancedMesh );

					instancedMeshes.push( instancedMesh );

				}

				if ( nodeObject.isGroup ) {

					nodeObject.clear();

					nodeObject.add( ... instancedMeshes );

					return nodeObject;

				}

				return instancedMeshes[ 0 ];

			} );

		}

	}

	/* BINARY EXTENSION */
	const BINARY_EXTENSION_HEADER_MAGIC = 'glTF';
	const BINARY_EXTENSION_HEADER_LENGTH = 12;
	const BINARY_EXTENSION_CHUNK_TYPES = { JSON: 0x4E4F534A, BIN: 0x004E4942 };

	class GLTFBinaryExtension {

		constructor( data ) {

			this.name = EXTENSIONS.KHR_BINARY_GLTF;
			this.content = null;
			this.body = null;

			const headerView = new DataView( data, 0, BINARY_EXTENSION_HEADER_LENGTH );
			const textDecoder = new TextDecoder();

			this.header = {
				magic: textDecoder.decode( new Uint8Array( data.slice( 0, 4 ) ) ),
				version: headerView.getUint32( 4, true ),
				length: headerView.getUint32( 8, true )
			};

			if ( this.header.magic !== BINARY_EXTENSION_HEADER_MAGIC ) {

				throw new Error( 'THREE.GLTFLoader: Unsupported glTF-Binary header.' );

			} else if ( this.header.version < 2.0 ) {

				throw new Error( 'THREE.GLTFLoader: Legacy binary file detected.' );

			}

			const chunkContentsLength = this.header.length - BINARY_EXTENSION_HEADER_LENGTH;
			const chunkView = new DataView( data, BINARY_EXTENSION_HEADER_LENGTH );
			let chunkIndex = 0;

			while ( chunkIndex < chunkContentsLength ) {

				const chunkLength = chunkView.getUint32( chunkIndex, true );
				chunkIndex += 4;

				const chunkType = chunkView.getUint32( chunkIndex, true );
				chunkIndex += 4;

				if ( chunkType === BINARY_EXTENSION_CHUNK_TYPES.JSON ) {

					const contentArray = new Uint8Array( data, BINARY_EXTENSION_HEADER_LENGTH + chunkIndex, chunkLength );
					this.content = textDecoder.decode( contentArray );

				} else if ( chunkType === BINARY_EXTENSION_CHUNK_TYPES.BIN ) {

					const byteOffset = BINARY_EXTENSION_HEADER_LENGTH + chunkIndex;
					this.body = data.slice( byteOffset, byteOffset + chunkLength );

				}

				// Clients must ignore chunks with unknown types.

				chunkIndex += chunkLength;

			}

			if ( this.content === null ) {

				throw new Error( 'THREE.GLTFLoader: JSON content not found.' );

			}

		}

	}

	/**
	 * DRACO Mesh Compression Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression
	 *
	 * @private
	 */
	class GLTFDracoMeshCompressionExtension {

		constructor( json, dracoLoader ) {

			if ( ! dracoLoader ) {

				throw new Error( 'THREE.GLTFLoader: No DRACOLoader instance provided.' );

			}

			this.name = EXTENSIONS.KHR_DRACO_MESH_COMPRESSION;
			this.json = json;
			this.dracoLoader = dracoLoader;
			this.dracoLoader.preload();

		}

		decodePrimitive( primitive, parser ) {

			const json = this.json;
			const dracoLoader = this.dracoLoader;
			const bufferViewIndex = primitive.extensions[ this.name ].bufferView;
			const gltfAttributeMap = primitive.extensions[ this.name ].attributes;
			const threeAttributeMap = {};
			const attributeNormalizedMap = {};
			const attributeTypeMap = {};

			for ( const attributeName in gltfAttributeMap ) {

				const threeAttributeName = ATTRIBUTES[ attributeName ] || attributeName.toLowerCase();

				threeAttributeMap[ threeAttributeName ] = gltfAttributeMap[ attributeName ];

			}

			for ( const attributeName in primitive.attributes ) {

				const threeAttributeName = ATTRIBUTES[ attributeName ] || attributeName.toLowerCase();

				if ( gltfAttributeMap[ attributeName ] !== undefined ) {

					const accessorDef = json.accessors[ primitive.attributes[ attributeName ] ];
					const componentType = WEBGL_COMPONENT_TYPES[ accessorDef.componentType ];

					attributeTypeMap[ threeAttributeName ] = componentType.name;
					attributeNormalizedMap[ threeAttributeName ] = accessorDef.normalized === true;

				}

			}

			return parser.getDependency( 'bufferView', bufferViewIndex ).then( function ( bufferView ) {

				return new Promise( function ( resolve, reject ) {

					dracoLoader.decodeDracoFile( bufferView, function ( geometry ) {

						for ( const attributeName in geometry.attributes ) {

							const attribute = geometry.attributes[ attributeName ];
							const normalized = attributeNormalizedMap[ attributeName ];

							if ( normalized !== undefined ) attribute.normalized = normalized;

						}

						resolve( geometry );

					}, threeAttributeMap, attributeTypeMap, LinearSRGBColorSpace, reject );

				} );

			} );

		}

	}

	/**
	 * Texture Transform Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_texture_transform
	 *
	 * @private
	 */
	class GLTFTextureTransformExtension {

		constructor() {

			this.name = EXTENSIONS.KHR_TEXTURE_TRANSFORM;

		}

		extendTexture( texture, transform ) {

			if ( ( transform.texCoord === undefined || transform.texCoord === texture.channel )
				&& transform.offset === undefined
				&& transform.rotation === undefined
				&& transform.scale === undefined ) {

				// See https://github.com/mrdoob/three.js/issues/21819.
				return texture;

			}

			texture = texture.clone();

			if ( transform.texCoord !== undefined ) {

				texture.channel = transform.texCoord;

			}

			if ( transform.offset !== undefined ) {

				texture.offset.fromArray( transform.offset );

			}

			if ( transform.rotation !== undefined ) {

				texture.rotation = transform.rotation;

			}

			if ( transform.scale !== undefined ) {

				texture.repeat.fromArray( transform.scale );

			}

			texture.needsUpdate = true;

			return texture;

		}

	}

	/**
	 * Mesh Quantization Extension
	 *
	 * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_mesh_quantization
	 *
	 * @private
	 */
	class GLTFMeshQuantizationExtension {

		constructor() {

			this.name = EXTENSIONS.KHR_MESH_QUANTIZATION;

		}

	}

	/*********************************/
	/********** INTERPOLATION ********/
	/*********************************/

	// Spline Interpolation
	// Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#appendix-c-spline-interpolation
	class GLTFCubicSplineInterpolant extends Interpolant {

		constructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {

			super( parameterPositions, sampleValues, sampleSize, resultBuffer );

		}

		copySampleValue_( index ) {

			// Copies a sample value to the result buffer. See description of glTF
			// CUBICSPLINE values layout in interpolate_() function below.

			const result = this.resultBuffer,
				values = this.sampleValues,
				valueSize = this.valueSize,
				offset = index * valueSize * 3 + valueSize;

			for ( let i = 0; i !== valueSize; i ++ ) {

				result[ i ] = values[ offset + i ];

			}

			return result;

		}

		interpolate_( i1, t0, t, t1 ) {

			const result = this.resultBuffer;
			const values = this.sampleValues;
			const stride = this.valueSize;

			const stride2 = stride * 2;
			const stride3 = stride * 3;

			const td = t1 - t0;

			const p = ( t - t0 ) / td;
			const pp = p * p;
			const ppp = pp * p;

			const offset1 = i1 * stride3;
			const offset0 = offset1 - stride3;

			const s2 = - 2 * ppp + 3 * pp;
			const s3 = ppp - pp;
			const s0 = 1 - s2;
			const s1 = s3 - pp + p;

			// Layout of keyframe output values for CUBICSPLINE animations:
			//   [ inTangent_1, splineVertex_1, outTangent_1, inTangent_2, splineVertex_2, ... ]
			for ( let i = 0; i !== stride; i ++ ) {

				const p0 = values[ offset0 + i + stride ]; // splineVertex_k
				const m0 = values[ offset0 + i + stride2 ] * td; // outTangent_k * (t_k+1 - t_k)
				const p1 = values[ offset1 + i + stride ]; // splineVertex_k+1
				const m1 = values[ offset1 + i ] * td; // inTangent_k+1 * (t_k+1 - t_k)

				result[ i ] = s0 * p0 + s1 * m0 + s2 * p1 + s3 * m1;

			}

			return result;

		}

	}

	const _quaternion = new Quaternion();

	class GLTFCubicSplineQuaternionInterpolant extends GLTFCubicSplineInterpolant {

		interpolate_( i1, t0, t, t1 ) {

			const result = super.interpolate_( i1, t0, t, t1 );

			_quaternion.fromArray( result ).normalize().toArray( result );

			return result;

		}

	}


	/*********************************/
	/********** INTERNALS ************/
	/*********************************/

	/* CONSTANTS */

	const WEBGL_CONSTANTS = {
		FLOAT: 5126,
		//FLOAT_MAT2: 35674,
		FLOAT_MAT3: 35675,
		FLOAT_MAT4: 35676,
		FLOAT_VEC2: 35664,
		FLOAT_VEC3: 35665,
		FLOAT_VEC4: 35666,
		LINEAR: 9729,
		REPEAT: 10497,
		SAMPLER_2D: 35678,
		POINTS: 0,
		LINES: 1,
		LINE_LOOP: 2,
		LINE_STRIP: 3,
		TRIANGLES: 4,
		TRIANGLE_STRIP: 5,
		TRIANGLE_FAN: 6,
		UNSIGNED_BYTE: 5121,
		UNSIGNED_SHORT: 5123
	};

	const WEBGL_COMPONENT_TYPES = {
		5120: Int8Array,
		5121: Uint8Array,
		5122: Int16Array,
		5123: Uint16Array,
		5125: Uint32Array,
		5126: Float32Array
	};

	const WEBGL_FILTERS = {
		9728: NearestFilter,
		9729: LinearFilter,
		9984: NearestMipmapNearestFilter,
		9985: LinearMipmapNearestFilter,
		9986: NearestMipmapLinearFilter,
		9987: LinearMipmapLinearFilter
	};

	const WEBGL_WRAPPINGS = {
		33071: ClampToEdgeWrapping,
		33648: MirroredRepeatWrapping,
		10497: RepeatWrapping
	};

	const WEBGL_TYPE_SIZES = {
		'SCALAR': 1,
		'VEC2': 2,
		'VEC3': 3,
		'VEC4': 4,
		'MAT2': 4,
		'MAT3': 9,
		'MAT4': 16
	};

	const ATTRIBUTES = {
		POSITION: 'position',
		NORMAL: 'normal',
		TANGENT: 'tangent',
		TEXCOORD_0: 'uv',
		TEXCOORD_1: 'uv1',
		TEXCOORD_2: 'uv2',
		TEXCOORD_3: 'uv3',
		COLOR_0: 'color',
		WEIGHTS_0: 'skinWeight',
		JOINTS_0: 'skinIndex',
	};

	const PATH_PROPERTIES = {
		scale: 'scale',
		translation: 'position',
		rotation: 'quaternion',
		weights: 'morphTargetInfluences'
	};

	const INTERPOLATION = {
		CUBICSPLINE: undefined, // We use a custom interpolant (GLTFCubicSplineInterpolation) for CUBICSPLINE tracks. Each
			                        // keyframe track will be initialized with a default interpolation type, then modified.
		LINEAR: InterpolateLinear,
		STEP: InterpolateDiscrete
	};

	const ALPHA_MODES = {
		OPAQUE: 'OPAQUE',
		MASK: 'MASK',
		BLEND: 'BLEND'
	};

	/**
	 * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#default-material
	 *
	 * @private
	 * @param {Object<string, Material>} cache
	 * @return {Material}
	 */
	function createDefaultMaterial( cache ) {

		if ( cache[ 'DefaultMaterial' ] === undefined ) {

			cache[ 'DefaultMaterial' ] = new MeshStandardMaterial( {
				color: 0xFFFFFF,
				emissive: 0x000000,
				metalness: 1,
				roughness: 1,
				transparent: false,
				depthTest: true,
				side: FrontSide
			} );

		}

		return cache[ 'DefaultMaterial' ];

	}

	function addUnknownExtensionsToUserData( knownExtensions, object, objectDef ) {

		// Add unknown glTF extensions to an object's userData.

		for ( const name in objectDef.extensions ) {

			if ( knownExtensions[ name ] === undefined ) {

				object.userData.gltfExtensions = object.userData.gltfExtensions || {};
				object.userData.gltfExtensions[ name ] = objectDef.extensions[ name ];

			}

		}

	}

	/**
	 *
	 * @private
	 * @param {Object3D|Material|BufferGeometry|Object} object
	 * @param {GLTF.definition} gltfDef
	 */
	function assignExtrasToUserData( object, gltfDef ) {

		if ( gltfDef.extras !== undefined ) {

			if ( typeof gltfDef.extras === 'object' ) {

				Object.assign( object.userData, gltfDef.extras );

			} else {

				console.warn( 'THREE.GLTFLoader: Ignoring primitive type .extras, ' + gltfDef.extras );

			}

		}

	}

	/**
	 * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#morph-targets
	 *
	 * @private
	 * @param {BufferGeometry} geometry
	 * @param {Array<GLTF.Target>} targets
	 * @param {GLTFParser} parser
	 * @return {Promise<BufferGeometry>}
	 */
	function addMorphTargets( geometry, targets, parser ) {

		let hasMorphPosition = false;
		let hasMorphNormal = false;
		let hasMorphColor = false;

		for ( let i = 0, il = targets.length; i < il; i ++ ) {

			const target = targets[ i ];

			if ( target.POSITION !== undefined ) hasMorphPosition = true;
			if ( target.NORMAL !== undefined ) hasMorphNormal = true;
			if ( target.COLOR_0 !== undefined ) hasMorphColor = true;

			if ( hasMorphPosition && hasMorphNormal && hasMorphColor ) break;

		}

		if ( ! hasMorphPosition && ! hasMorphNormal && ! hasMorphColor ) return Promise.resolve( geometry );

		const pendingPositionAccessors = [];
		const pendingNormalAccessors = [];
		const pendingColorAccessors = [];

		for ( let i = 0, il = targets.length; i < il; i ++ ) {

			const target = targets[ i ];

			if ( hasMorphPosition ) {

				const pendingAccessor = target.POSITION !== undefined
					? parser.getDependency( 'accessor', target.POSITION )
					: geometry.attributes.position;

				pendingPositionAccessors.push( pendingAccessor );

			}

			if ( hasMorphNormal ) {

				const pendingAccessor = target.NORMAL !== undefined
					? parser.getDependency( 'accessor', target.NORMAL )
					: geometry.attributes.normal;

				pendingNormalAccessors.push( pendingAccessor );

			}

			if ( hasMorphColor ) {

				const pendingAccessor = target.COLOR_0 !== undefined
					? parser.getDependency( 'accessor', target.COLOR_0 )
					: geometry.attributes.color;

				pendingColorAccessors.push( pendingAccessor );

			}

		}

		return Promise.all( [
			Promise.all( pendingPositionAccessors ),
			Promise.all( pendingNormalAccessors ),
			Promise.all( pendingColorAccessors )
		] ).then( function ( accessors ) {

			const morphPositions = accessors[ 0 ];
			const morphNormals = accessors[ 1 ];
			const morphColors = accessors[ 2 ];

			if ( hasMorphPosition ) geometry.morphAttributes.position = morphPositions;
			if ( hasMorphNormal ) geometry.morphAttributes.normal = morphNormals;
			if ( hasMorphColor ) geometry.morphAttributes.color = morphColors;
			geometry.morphTargetsRelative = true;

			return geometry;

		} );

	}

	/**
	 *
	 * @private
	 * @param {Mesh} mesh
	 * @param {GLTF.Mesh} meshDef
	 */
	function updateMorphTargets( mesh, meshDef ) {

		mesh.updateMorphTargets();

		if ( meshDef.weights !== undefined ) {

			for ( let i = 0, il = meshDef.weights.length; i < il; i ++ ) {

				mesh.morphTargetInfluences[ i ] = meshDef.weights[ i ];

			}

		}

		// .extras has user-defined data, so check that .extras.targetNames is an array.
		if ( meshDef.extras && Array.isArray( meshDef.extras.targetNames ) ) {

			const targetNames = meshDef.extras.targetNames;

			if ( mesh.morphTargetInfluences.length === targetNames.length ) {

				mesh.morphTargetDictionary = {};

				for ( let i = 0, il = targetNames.length; i < il; i ++ ) {

					mesh.morphTargetDictionary[ targetNames[ i ] ] = i;

				}

			} else {

				console.warn( 'THREE.GLTFLoader: Invalid extras.targetNames length. Ignoring names.' );

			}

		}

	}

	function createPrimitiveKey( primitiveDef ) {

		let geometryKey;

		const dracoExtension = primitiveDef.extensions && primitiveDef.extensions[ EXTENSIONS.KHR_DRACO_MESH_COMPRESSION ];

		if ( dracoExtension ) {

			geometryKey = 'draco:' + dracoExtension.bufferView
					+ ':' + dracoExtension.indices
					+ ':' + createAttributesKey( dracoExtension.attributes );

		} else {

			geometryKey = primitiveDef.indices + ':' + createAttributesKey( primitiveDef.attributes ) + ':' + primitiveDef.mode;

		}

		if ( primitiveDef.targets !== undefined ) {

			for ( let i = 0, il = primitiveDef.targets.length; i < il; i ++ ) {

				geometryKey += ':' + createAttributesKey( primitiveDef.targets[ i ] );

			}

		}

		return geometryKey;

	}

	function createAttributesKey( attributes ) {

		let attributesKey = '';

		const keys = Object.keys( attributes ).sort();

		for ( let i = 0, il = keys.length; i < il; i ++ ) {

			attributesKey += keys[ i ] + ':' + attributes[ keys[ i ] ] + ';';

		}

		return attributesKey;

	}

	function getNormalizedComponentScale( constructor ) {

		// Reference:
		// https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_mesh_quantization#encoding-quantized-data

		switch ( constructor ) {

			case Int8Array:
				return 1 / 127;

			case Uint8Array:
				return 1 / 255;

			case Int16Array:
				return 1 / 32767;

			case Uint16Array:
				return 1 / 65535;

			default:
				throw new Error( 'THREE.GLTFLoader: Unsupported normalized accessor component type.' );

		}

	}

	function getImageURIMimeType( uri ) {

		if ( uri.search( /\.jpe?g($|\?)/i ) > 0 || uri.search( /^data\:image\/jpeg/ ) === 0 ) return 'image/jpeg';
		if ( uri.search( /\.webp($|\?)/i ) > 0 || uri.search( /^data\:image\/webp/ ) === 0 ) return 'image/webp';
		if ( uri.search( /\.ktx2($|\?)/i ) > 0 || uri.search( /^data\:image\/ktx2/ ) === 0 ) return 'image/ktx2';

		return 'image/png';

	}

	const _identityMatrix$1 = new Matrix4();

	/* GLTF PARSER */

	class GLTFParser {

		constructor( json = {}, options = {} ) {

			this.json = json;
			this.extensions = {};
			this.plugins = {};
			this.options = options;

			// loader object cache
			this.cache = new GLTFRegistry();

			// associations between Three.js objects and glTF elements
			this.associations = new Map();

			// BufferGeometry caching
			this.primitiveCache = {};

			// Node cache
			this.nodeCache = {};

			// Object3D instance caches
			this.meshCache = { refs: {}, uses: {} };
			this.cameraCache = { refs: {}, uses: {} };
			this.lightCache = { refs: {}, uses: {} };

			this.sourceCache = {};
			this.textureCache = {};

			// Track node names, to ensure no duplicates
			this.nodeNamesUsed = {};

			// Use an ImageBitmapLoader if imageBitmaps are supported. Moves much of the
			// expensive work of uploading a texture to the GPU off the main thread.

			let isSafari = false;
			let safariVersion = - 1;
			let isFirefox = false;
			let firefoxVersion = - 1;

			if ( typeof navigator !== 'undefined' ) {

				const userAgent = navigator.userAgent;

				isSafari = /^((?!chrome|android).)*safari/i.test( userAgent ) === true;
				const safariMatch = userAgent.match( /Version\/(\d+)/ );
				safariVersion = isSafari && safariMatch ? parseInt( safariMatch[ 1 ], 10 ) : - 1;

				isFirefox = userAgent.indexOf( 'Firefox' ) > - 1;
				firefoxVersion = isFirefox ? userAgent.match( /Firefox\/([0-9]+)\./ )[ 1 ] : - 1;

			}

			if ( typeof createImageBitmap === 'undefined' || ( isSafari && safariVersion < 17 ) || ( isFirefox && firefoxVersion < 98 ) ) {

				this.textureLoader = new TextureLoader( this.options.manager );

			} else {

				this.textureLoader = new ImageBitmapLoader( this.options.manager );

			}

			this.textureLoader.setCrossOrigin( this.options.crossOrigin );
			this.textureLoader.setRequestHeader( this.options.requestHeader );

			this.fileLoader = new FileLoader( this.options.manager );
			this.fileLoader.setResponseType( 'arraybuffer' );

			if ( this.options.crossOrigin === 'use-credentials' ) {

				this.fileLoader.setWithCredentials( true );

			}

		}

		setExtensions( extensions ) {

			this.extensions = extensions;

		}

		setPlugins( plugins ) {

			this.plugins = plugins;

		}

		parse( onLoad, onError ) {

			const parser = this;
			const json = this.json;
			const extensions = this.extensions;

			// Clear the loader cache
			this.cache.removeAll();
			this.nodeCache = {};

			// Mark the special nodes/meshes in json for efficient parse
			this._invokeAll( function ( ext ) {

				return ext._markDefs && ext._markDefs();

			} );

			Promise.all( this._invokeAll( function ( ext ) {

				return ext.beforeRoot && ext.beforeRoot();

			} ) ).then( function () {

				return Promise.all( [

					parser.getDependencies( 'scene' ),
					parser.getDependencies( 'animation' ),
					parser.getDependencies( 'camera' ),

				] );

			} ).then( function ( dependencies ) {

				const result = {
					scene: dependencies[ 0 ][ json.scene || 0 ],
					scenes: dependencies[ 0 ],
					animations: dependencies[ 1 ],
					cameras: dependencies[ 2 ],
					asset: json.asset,
					parser: parser,
					userData: {}
				};

				addUnknownExtensionsToUserData( extensions, result, json );

				assignExtrasToUserData( result, json );

				return Promise.all( parser._invokeAll( function ( ext ) {

					return ext.afterRoot && ext.afterRoot( result );

				} ) ).then( function () {

					for ( const scene of result.scenes ) {

						scene.updateMatrixWorld();

					}

					onLoad( result );

				} );

			} ).catch( onError );

		}

		/**
		 * Marks the special nodes/meshes in json for efficient parse.
		 *
		 * @private
		 */
		_markDefs() {

			const nodeDefs = this.json.nodes || [];
			const skinDefs = this.json.skins || [];
			const meshDefs = this.json.meshes || [];

			// Nothing in the node definition indicates whether it is a Bone or an
			// Object3D. Use the skins' joint references to mark bones.
			for ( let skinIndex = 0, skinLength = skinDefs.length; skinIndex < skinLength; skinIndex ++ ) {

				const joints = skinDefs[ skinIndex ].joints;

				for ( let i = 0, il = joints.length; i < il; i ++ ) {

					nodeDefs[ joints[ i ] ].isBone = true;

				}

			}

			// Iterate over all nodes, marking references to shared resources,
			// as well as skeleton joints.
			for ( let nodeIndex = 0, nodeLength = nodeDefs.length; nodeIndex < nodeLength; nodeIndex ++ ) {

				const nodeDef = nodeDefs[ nodeIndex ];

				if ( nodeDef.mesh !== undefined ) {

					this._addNodeRef( this.meshCache, nodeDef.mesh );

					// Nothing in the mesh definition indicates whether it is
					// a SkinnedMesh or Mesh. Use the node's mesh reference
					// to mark SkinnedMesh if node has skin.
					if ( nodeDef.skin !== undefined ) {

						meshDefs[ nodeDef.mesh ].isSkinnedMesh = true;

					}

				}

				if ( nodeDef.camera !== undefined ) {

					this._addNodeRef( this.cameraCache, nodeDef.camera );

				}

			}

		}

		/**
		 * Counts references to shared node / Object3D resources. These resources
		 * can be reused, or "instantiated", at multiple nodes in the scene
		 * hierarchy. Mesh, Camera, and Light instances are instantiated and must
		 * be marked. Non-scenegraph resources (like Materials, Geometries, and
		 * Textures) can be reused directly and are not marked here.
		 *
		 * Example: CesiumMilkTruck sample model reuses "Wheel" meshes.
		 *
		 * @private
		 * @param {Object} cache
		 * @param {Object3D} index
		 */
		_addNodeRef( cache, index ) {

			if ( index === undefined ) return;

			if ( cache.refs[ index ] === undefined ) {

				cache.refs[ index ] = cache.uses[ index ] = 0;

			}

			cache.refs[ index ] ++;

		}

		/**
		 * Returns a reference to a shared resource, cloning it if necessary.
		 *
		 * @private
		 * @param {Object} cache
		 * @param {number} index
		 * @param {Object} object
		 * @return {Object}
		 */
		_getNodeRef( cache, index, object ) {

			if ( cache.refs[ index ] <= 1 ) return object;

			const ref = object.clone();

			// Propagates mappings to the cloned object, prevents mappings on the
			// original object from being lost.
			const updateMappings = ( original, clone ) => {

				const mappings = this.associations.get( original );
				if ( mappings != null ) {

					this.associations.set( clone, mappings );

				}

				for ( const [ i, child ] of original.children.entries() ) {

					updateMappings( child, clone.children[ i ] );

				}

			};

			updateMappings( object, ref );

			ref.name += '_instance_' + ( cache.uses[ index ] ++ );

			return ref;

		}

		_invokeOne( func ) {

			const extensions = Object.values( this.plugins );
			extensions.push( this );

			for ( let i = 0; i < extensions.length; i ++ ) {

				const result = func( extensions[ i ] );

				if ( result ) return result;

			}

			return null;

		}

		_invokeAll( func ) {

			const extensions = Object.values( this.plugins );
			extensions.unshift( this );

			const pending = [];

			for ( let i = 0; i < extensions.length; i ++ ) {

				const result = func( extensions[ i ] );

				if ( result ) pending.push( result );

			}

			return pending;

		}

		/**
		 * Requests the specified dependency asynchronously, with caching.
		 *
		 * @private
		 * @param {string} type
		 * @param {number} index
		 * @return {Promise<Object3D|Material|THREE.Texture|AnimationClip|ArrayBuffer|Object>}
		 */
		getDependency( type, index ) {

			const cacheKey = type + ':' + index;
			let dependency = this.cache.get( cacheKey );

			if ( ! dependency ) {

				switch ( type ) {

					case 'scene':
						dependency = this.loadScene( index );
						break;

					case 'node':
						dependency = this._invokeOne( function ( ext ) {

							return ext.loadNode && ext.loadNode( index );

						} );
						break;

					case 'mesh':
						dependency = this._invokeOne( function ( ext ) {

							return ext.loadMesh && ext.loadMesh( index );

						} );
						break;

					case 'accessor':
						dependency = this.loadAccessor( index );
						break;

					case 'bufferView':
						dependency = this._invokeOne( function ( ext ) {

							return ext.loadBufferView && ext.loadBufferView( index );

						} );
						break;

					case 'buffer':
						dependency = this.loadBuffer( index );
						break;

					case 'material':
						dependency = this._invokeOne( function ( ext ) {

							return ext.loadMaterial && ext.loadMaterial( index );

						} );
						break;

					case 'texture':
						dependency = this._invokeOne( function ( ext ) {

							return ext.loadTexture && ext.loadTexture( index );

						} );
						break;

					case 'skin':
						dependency = this.loadSkin( index );
						break;

					case 'animation':
						dependency = this._invokeOne( function ( ext ) {

							return ext.loadAnimation && ext.loadAnimation( index );

						} );
						break;

					case 'camera':
						dependency = this.loadCamera( index );
						break;

					default:
						dependency = this._invokeOne( function ( ext ) {

							return ext != this && ext.getDependency && ext.getDependency( type, index );

						} );

						if ( ! dependency ) {

							throw new Error( 'Unknown type: ' + type );

						}

						break;

				}

				this.cache.add( cacheKey, dependency );

			}

			return dependency;

		}

		/**
		 * Requests all dependencies of the specified type asynchronously, with caching.
		 *
		 * @private
		 * @param {string} type
		 * @return {Promise<Array<Object>>}
		 */
		getDependencies( type ) {

			let dependencies = this.cache.get( type );

			if ( ! dependencies ) {

				const parser = this;
				const defs = this.json[ type + ( type === 'mesh' ? 'es' : 's' ) ] || [];

				dependencies = Promise.all( defs.map( function ( def, index ) {

					return parser.getDependency( type, index );

				} ) );

				this.cache.add( type, dependencies );

			}

			return dependencies;

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#buffers-and-buffer-views
		 *
		 * @private
		 * @param {number} bufferIndex
		 * @return {Promise<ArrayBuffer>}
		 */
		loadBuffer( bufferIndex ) {

			const bufferDef = this.json.buffers[ bufferIndex ];
			const loader = this.fileLoader;

			if ( bufferDef.type && bufferDef.type !== 'arraybuffer' ) {

				throw new Error( 'THREE.GLTFLoader: ' + bufferDef.type + ' buffer type is not supported.' );

			}

			// If present, GLB container is required to be the first buffer.
			if ( bufferDef.uri === undefined && bufferIndex === 0 ) {

				return Promise.resolve( this.extensions[ EXTENSIONS.KHR_BINARY_GLTF ].body );

			}

			const options = this.options;

			return new Promise( function ( resolve, reject ) {

				loader.load( LoaderUtils.resolveURL( bufferDef.uri, options.path ), resolve, undefined, function () {

					reject( new Error( 'THREE.GLTFLoader: Failed to load buffer "' + bufferDef.uri + '".' ) );

				} );

			} );

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#buffers-and-buffer-views
		 *
		 * @private
		 * @param {number} bufferViewIndex
		 * @return {Promise<ArrayBuffer>}
		 */
		loadBufferView( bufferViewIndex ) {

			const bufferViewDef = this.json.bufferViews[ bufferViewIndex ];

			return this.getDependency( 'buffer', bufferViewDef.buffer ).then( function ( buffer ) {

				const byteLength = bufferViewDef.byteLength || 0;
				const byteOffset = bufferViewDef.byteOffset || 0;
				return buffer.slice( byteOffset, byteOffset + byteLength );

			} );

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#accessors
		 *
		 * @private
		 * @param {number} accessorIndex
		 * @return {Promise<BufferAttribute|InterleavedBufferAttribute>}
		 */
		loadAccessor( accessorIndex ) {

			const parser = this;
			const json = this.json;

			const accessorDef = this.json.accessors[ accessorIndex ];

			if ( accessorDef.bufferView === undefined && accessorDef.sparse === undefined ) {

				const itemSize = WEBGL_TYPE_SIZES[ accessorDef.type ];
				const TypedArray = WEBGL_COMPONENT_TYPES[ accessorDef.componentType ];
				const normalized = accessorDef.normalized === true;

				const array = new TypedArray( accessorDef.count * itemSize );
				return Promise.resolve( new BufferAttribute( array, itemSize, normalized ) );

			}

			const pendingBufferViews = [];

			if ( accessorDef.bufferView !== undefined ) {

				pendingBufferViews.push( this.getDependency( 'bufferView', accessorDef.bufferView ) );

			} else {

				pendingBufferViews.push( null );

			}

			if ( accessorDef.sparse !== undefined ) {

				pendingBufferViews.push( this.getDependency( 'bufferView', accessorDef.sparse.indices.bufferView ) );
				pendingBufferViews.push( this.getDependency( 'bufferView', accessorDef.sparse.values.bufferView ) );

			}

			return Promise.all( pendingBufferViews ).then( function ( bufferViews ) {

				const bufferView = bufferViews[ 0 ];

				const itemSize = WEBGL_TYPE_SIZES[ accessorDef.type ];
				const TypedArray = WEBGL_COMPONENT_TYPES[ accessorDef.componentType ];

				// For VEC3: itemSize is 3, elementBytes is 4, itemBytes is 12.
				const elementBytes = TypedArray.BYTES_PER_ELEMENT;
				const itemBytes = elementBytes * itemSize;
				const byteOffset = accessorDef.byteOffset || 0;
				const byteStride = accessorDef.bufferView !== undefined ? json.bufferViews[ accessorDef.bufferView ].byteStride : undefined;
				const normalized = accessorDef.normalized === true;
				let array, bufferAttribute;

				// The buffer is not interleaved if the stride is the item size in bytes.
				if ( byteStride && byteStride !== itemBytes ) {

					// Each "slice" of the buffer, as defined by 'count' elements of 'byteStride' bytes, gets its own InterleavedBuffer
					// This makes sure that IBA.count reflects accessor.count properly
					const ibSlice = Math.floor( byteOffset / byteStride );
					const ibCacheKey = 'InterleavedBuffer:' + accessorDef.bufferView + ':' + accessorDef.componentType + ':' + ibSlice + ':' + accessorDef.count;
					let ib = parser.cache.get( ibCacheKey );

					if ( ! ib ) {

						array = new TypedArray( bufferView, ibSlice * byteStride, accessorDef.count * byteStride / elementBytes );

						// Integer parameters to IB/IBA are in array elements, not bytes.
						ib = new InterleavedBuffer( array, byteStride / elementBytes );

						parser.cache.add( ibCacheKey, ib );

					}

					bufferAttribute = new InterleavedBufferAttribute( ib, itemSize, ( byteOffset % byteStride ) / elementBytes, normalized );

				} else {

					if ( bufferView === null ) {

						array = new TypedArray( accessorDef.count * itemSize );

					} else {

						array = new TypedArray( bufferView, byteOffset, accessorDef.count * itemSize );

					}

					bufferAttribute = new BufferAttribute( array, itemSize, normalized );

				}

				// https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#sparse-accessors
				if ( accessorDef.sparse !== undefined ) {

					const itemSizeIndices = WEBGL_TYPE_SIZES.SCALAR;
					const TypedArrayIndices = WEBGL_COMPONENT_TYPES[ accessorDef.sparse.indices.componentType ];

					const byteOffsetIndices = accessorDef.sparse.indices.byteOffset || 0;
					const byteOffsetValues = accessorDef.sparse.values.byteOffset || 0;

					const sparseIndices = new TypedArrayIndices( bufferViews[ 1 ], byteOffsetIndices, accessorDef.sparse.count * itemSizeIndices );
					const sparseValues = new TypedArray( bufferViews[ 2 ], byteOffsetValues, accessorDef.sparse.count * itemSize );

					if ( bufferView !== null ) {

						// Avoid modifying the original ArrayBuffer, if the bufferView wasn't initialized with zeroes.
						bufferAttribute = new BufferAttribute( bufferAttribute.array.slice(), bufferAttribute.itemSize, bufferAttribute.normalized );

					}

					// Ignore normalized since we copy from sparse
					bufferAttribute.normalized = false;

					for ( let i = 0, il = sparseIndices.length; i < il; i ++ ) {

						const index = sparseIndices[ i ];

						bufferAttribute.setX( index, sparseValues[ i * itemSize ] );
						if ( itemSize >= 2 ) bufferAttribute.setY( index, sparseValues[ i * itemSize + 1 ] );
						if ( itemSize >= 3 ) bufferAttribute.setZ( index, sparseValues[ i * itemSize + 2 ] );
						if ( itemSize >= 4 ) bufferAttribute.setW( index, sparseValues[ i * itemSize + 3 ] );
						if ( itemSize >= 5 ) throw new Error( 'THREE.GLTFLoader: Unsupported itemSize in sparse BufferAttribute.' );

					}

					bufferAttribute.normalized = normalized;

				}

				return bufferAttribute;

			} );

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#textures
		 *
		 * @private
		 * @param {number} textureIndex
		 * @return {Promise<THREE.Texture|null>}
		 */
		loadTexture( textureIndex ) {

			const json = this.json;
			const options = this.options;
			const textureDef = json.textures[ textureIndex ];
			const sourceIndex = textureDef.source;
			const sourceDef = json.images[ sourceIndex ];

			let loader = this.textureLoader;

			if ( sourceDef.uri ) {

				const handler = options.manager.getHandler( sourceDef.uri );
				if ( handler !== null ) loader = handler;

			}

			return this.loadTextureImage( textureIndex, sourceIndex, loader );

		}

		loadTextureImage( textureIndex, sourceIndex, loader ) {

			const parser = this;
			const json = this.json;

			const textureDef = json.textures[ textureIndex ];
			const sourceDef = json.images[ sourceIndex ];

			const cacheKey = ( sourceDef.uri || sourceDef.bufferView ) + ':' + textureDef.sampler;

			if ( this.textureCache[ cacheKey ] ) {

				// See https://github.com/mrdoob/three.js/issues/21559.
				return this.textureCache[ cacheKey ];

			}

			const promise = this.loadImageSource( sourceIndex, loader ).then( function ( texture ) {

				texture.flipY = false;

				texture.name = textureDef.name || sourceDef.name || '';

				if ( texture.name === '' && typeof sourceDef.uri === 'string' && sourceDef.uri.startsWith( 'data:image/' ) === false ) {

					texture.name = sourceDef.uri;

				}

				const samplers = json.samplers || {};
				const sampler = samplers[ textureDef.sampler ] || {};

				texture.magFilter = WEBGL_FILTERS[ sampler.magFilter ] || LinearFilter;
				texture.minFilter = WEBGL_FILTERS[ sampler.minFilter ] || LinearMipmapLinearFilter;
				texture.wrapS = WEBGL_WRAPPINGS[ sampler.wrapS ] || RepeatWrapping;
				texture.wrapT = WEBGL_WRAPPINGS[ sampler.wrapT ] || RepeatWrapping;
				texture.generateMipmaps = ! texture.isCompressedTexture && texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter;

				parser.associations.set( texture, { textures: textureIndex } );

				return texture;

			} ).catch( function () {

				return null;

			} );

			this.textureCache[ cacheKey ] = promise;

			return promise;

		}

		loadImageSource( sourceIndex, loader ) {

			const parser = this;
			const json = this.json;
			const options = this.options;

			if ( this.sourceCache[ sourceIndex ] !== undefined ) {

				return this.sourceCache[ sourceIndex ].then( ( texture ) => texture.clone() );

			}

			const sourceDef = json.images[ sourceIndex ];

			const URL = self.URL || self.webkitURL;

			let sourceURI = sourceDef.uri || '';
			let isObjectURL = false;

			if ( sourceDef.bufferView !== undefined ) {

				// Load binary image data from bufferView, if provided.

				sourceURI = parser.getDependency( 'bufferView', sourceDef.bufferView ).then( function ( bufferView ) {

					isObjectURL = true;
					const blob = new Blob( [ bufferView ], { type: sourceDef.mimeType } );
					sourceURI = URL.createObjectURL( blob );
					return sourceURI;

				} );

			} else if ( sourceDef.uri === undefined ) {

				throw new Error( 'THREE.GLTFLoader: Image ' + sourceIndex + ' is missing URI and bufferView' );

			}

			const promise = Promise.resolve( sourceURI ).then( function ( sourceURI ) {

				return new Promise( function ( resolve, reject ) {

					let onLoad = resolve;

					if ( loader.isImageBitmapLoader === true ) {

						onLoad = function ( imageBitmap ) {

							const texture = new Texture( imageBitmap );
							texture.needsUpdate = true;

							resolve( texture );

						};

					}

					loader.load( LoaderUtils.resolveURL( sourceURI, options.path ), onLoad, undefined, reject );

				} );

			} ).then( function ( texture ) {

				// Clean up resources and configure Texture.

				if ( isObjectURL === true ) {

					URL.revokeObjectURL( sourceURI );

				}

				assignExtrasToUserData( texture, sourceDef );

				texture.userData.mimeType = sourceDef.mimeType || getImageURIMimeType( sourceDef.uri );

				return texture;

			} ).catch( function ( error ) {

				console.error( 'THREE.GLTFLoader: Couldn\'t load texture', sourceURI );
				throw error;

			} );

			this.sourceCache[ sourceIndex ] = promise;
			return promise;

		}

		/**
		 * Asynchronously assigns a texture to the given material parameters.
		 *
		 * @private
		 * @param {Object} materialParams
		 * @param {string} mapName
		 * @param {Object} mapDef
		 * @param {string} [colorSpace]
		 * @return {Promise<Texture>}
		 */
		assignTexture( materialParams, mapName, mapDef, colorSpace ) {

			const parser = this;

			return this.getDependency( 'texture', mapDef.index ).then( function ( texture ) {

				if ( ! texture ) return null;

				if ( mapDef.texCoord !== undefined && mapDef.texCoord > 0 ) {

					texture = texture.clone();
					texture.channel = mapDef.texCoord;

				}

				if ( parser.extensions[ EXTENSIONS.KHR_TEXTURE_TRANSFORM ] ) {

					const transform = mapDef.extensions !== undefined ? mapDef.extensions[ EXTENSIONS.KHR_TEXTURE_TRANSFORM ] : undefined;

					if ( transform ) {

						const gltfReference = parser.associations.get( texture );
						texture = parser.extensions[ EXTENSIONS.KHR_TEXTURE_TRANSFORM ].extendTexture( texture, transform );
						parser.associations.set( texture, gltfReference );

					}

				}

				if ( colorSpace !== undefined ) {

					texture.colorSpace = colorSpace;

				}

				materialParams[ mapName ] = texture;

				return texture;

			} );

		}

		/**
		 * Assigns final material to a Mesh, Line, or Points instance. The instance
		 * already has a material (generated from the glTF material options alone)
		 * but reuse of the same glTF material may require multiple threejs materials
		 * to accommodate different primitive types, defines, etc. New materials will
		 * be created if necessary, and reused from a cache.
		 *
		 * @private
		 * @param {Object3D} mesh Mesh, Line, or Points instance.
		 */
		assignFinalMaterial( mesh ) {

			const geometry = mesh.geometry;
			let material = mesh.material;

			const useDerivativeTangents = geometry.attributes.tangent === undefined;
			const useVertexColors = geometry.attributes.color !== undefined;
			const useFlatShading = geometry.attributes.normal === undefined;

			if ( mesh.isPoints ) {

				const cacheKey = 'PointsMaterial:' + material.uuid;

				let pointsMaterial = this.cache.get( cacheKey );

				if ( ! pointsMaterial ) {

					pointsMaterial = new PointsMaterial();
					Material.prototype.copy.call( pointsMaterial, material );
					pointsMaterial.color.copy( material.color );
					pointsMaterial.map = material.map;
					pointsMaterial.sizeAttenuation = false; // glTF spec says points should be 1px

					this.cache.add( cacheKey, pointsMaterial );

				}

				material = pointsMaterial;

			} else if ( mesh.isLine ) {

				const cacheKey = 'LineBasicMaterial:' + material.uuid;

				let lineMaterial = this.cache.get( cacheKey );

				if ( ! lineMaterial ) {

					lineMaterial = new LineBasicMaterial();
					Material.prototype.copy.call( lineMaterial, material );
					lineMaterial.color.copy( material.color );
					lineMaterial.map = material.map;

					this.cache.add( cacheKey, lineMaterial );

				}

				material = lineMaterial;

			}

			// Clone the material if it will be modified
			if ( useDerivativeTangents || useVertexColors || useFlatShading ) {

				let cacheKey = 'ClonedMaterial:' + material.uuid + ':';

				if ( useDerivativeTangents ) cacheKey += 'derivative-tangents:';
				if ( useVertexColors ) cacheKey += 'vertex-colors:';
				if ( useFlatShading ) cacheKey += 'flat-shading:';

				let cachedMaterial = this.cache.get( cacheKey );

				if ( ! cachedMaterial ) {

					cachedMaterial = material.clone();

					if ( useVertexColors ) cachedMaterial.vertexColors = true;
					if ( useFlatShading ) cachedMaterial.flatShading = true;

					if ( useDerivativeTangents ) {

						// https://github.com/mrdoob/three.js/issues/11438#issuecomment-507003995
						if ( cachedMaterial.normalScale ) cachedMaterial.normalScale.y *= - 1;
						if ( cachedMaterial.clearcoatNormalScale ) cachedMaterial.clearcoatNormalScale.y *= - 1;

					}

					this.cache.add( cacheKey, cachedMaterial );

					this.associations.set( cachedMaterial, this.associations.get( material ) );

				}

				material = cachedMaterial;

			}

			mesh.material = material;

		}

		getMaterialType( /* materialIndex */ ) {

			return MeshStandardMaterial;

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#materials
		 *
		 * @private
		 * @param {number} materialIndex
		 * @return {Promise<Material>}
		 */
		loadMaterial( materialIndex ) {

			const parser = this;
			const json = this.json;
			const extensions = this.extensions;
			const materialDef = json.materials[ materialIndex ];

			let materialType;
			const materialParams = {};
			const materialExtensions = materialDef.extensions || {};

			const pending = [];

			if ( materialExtensions[ EXTENSIONS.KHR_MATERIALS_UNLIT ] ) {

				const kmuExtension = extensions[ EXTENSIONS.KHR_MATERIALS_UNLIT ];
				materialType = kmuExtension.getMaterialType();
				pending.push( kmuExtension.extendParams( materialParams, materialDef, parser ) );

			} else {

				// Specification:
				// https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#metallic-roughness-material

				const metallicRoughness = materialDef.pbrMetallicRoughness || {};

				materialParams.color = new Color( 1.0, 1.0, 1.0 );
				materialParams.opacity = 1.0;

				if ( Array.isArray( metallicRoughness.baseColorFactor ) ) {

					const array = metallicRoughness.baseColorFactor;

					materialParams.color.setRGB( array[ 0 ], array[ 1 ], array[ 2 ], LinearSRGBColorSpace );
					materialParams.opacity = array[ 3 ];

				}

				if ( metallicRoughness.baseColorTexture !== undefined ) {

					pending.push( parser.assignTexture( materialParams, 'map', metallicRoughness.baseColorTexture, SRGBColorSpace ) );

				}

				materialParams.metalness = metallicRoughness.metallicFactor !== undefined ? metallicRoughness.metallicFactor : 1.0;
				materialParams.roughness = metallicRoughness.roughnessFactor !== undefined ? metallicRoughness.roughnessFactor : 1.0;

				if ( metallicRoughness.metallicRoughnessTexture !== undefined ) {

					pending.push( parser.assignTexture( materialParams, 'metalnessMap', metallicRoughness.metallicRoughnessTexture ) );
					pending.push( parser.assignTexture( materialParams, 'roughnessMap', metallicRoughness.metallicRoughnessTexture ) );

				}

				materialType = this._invokeOne( function ( ext ) {

					return ext.getMaterialType && ext.getMaterialType( materialIndex );

				} );

				pending.push( Promise.all( this._invokeAll( function ( ext ) {

					return ext.extendMaterialParams && ext.extendMaterialParams( materialIndex, materialParams );

				} ) ) );

			}

			if ( materialDef.doubleSided === true ) {

				materialParams.side = DoubleSide;

			}

			const alphaMode = materialDef.alphaMode || ALPHA_MODES.OPAQUE;

			if ( alphaMode === ALPHA_MODES.BLEND ) {

				materialParams.transparent = true;

				// See: https://github.com/mrdoob/three.js/issues/17706
				materialParams.depthWrite = false;

			} else {

				materialParams.transparent = false;

				if ( alphaMode === ALPHA_MODES.MASK ) {

					materialParams.alphaTest = materialDef.alphaCutoff !== undefined ? materialDef.alphaCutoff : 0.5;

				}

			}

			if ( materialDef.normalTexture !== undefined && materialType !== MeshBasicMaterial ) {

				pending.push( parser.assignTexture( materialParams, 'normalMap', materialDef.normalTexture ) );

				materialParams.normalScale = new Vector2( 1, 1 );

				if ( materialDef.normalTexture.scale !== undefined ) {

					const scale = materialDef.normalTexture.scale;

					materialParams.normalScale.set( scale, scale );

				}

			}

			if ( materialDef.occlusionTexture !== undefined && materialType !== MeshBasicMaterial ) {

				pending.push( parser.assignTexture( materialParams, 'aoMap', materialDef.occlusionTexture ) );

				if ( materialDef.occlusionTexture.strength !== undefined ) {

					materialParams.aoMapIntensity = materialDef.occlusionTexture.strength;

				}

			}

			if ( materialDef.emissiveFactor !== undefined && materialType !== MeshBasicMaterial ) {

				const emissiveFactor = materialDef.emissiveFactor;
				materialParams.emissive = new Color().setRGB( emissiveFactor[ 0 ], emissiveFactor[ 1 ], emissiveFactor[ 2 ], LinearSRGBColorSpace );

			}

			if ( materialDef.emissiveTexture !== undefined && materialType !== MeshBasicMaterial ) {

				pending.push( parser.assignTexture( materialParams, 'emissiveMap', materialDef.emissiveTexture, SRGBColorSpace ) );

			}

			return Promise.all( pending ).then( function () {

				const material = new materialType( materialParams );

				if ( materialDef.name ) material.name = materialDef.name;

				assignExtrasToUserData( material, materialDef );

				parser.associations.set( material, { materials: materialIndex } );

				if ( materialDef.extensions ) addUnknownExtensionsToUserData( extensions, material, materialDef );

				return material;

			} );

		}

		/**
		 * When Object3D instances are targeted by animation, they need unique names.
		 *
		 * @private
		 * @param {string} originalName
		 * @return {string}
		 */
		createUniqueName( originalName ) {

			const sanitizedName = PropertyBinding.sanitizeNodeName( originalName || '' );

			if ( sanitizedName in this.nodeNamesUsed ) {

				return sanitizedName + '_' + ( ++ this.nodeNamesUsed[ sanitizedName ] );

			} else {

				this.nodeNamesUsed[ sanitizedName ] = 0;

				return sanitizedName;

			}

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#geometry
		 *
		 * Creates BufferGeometries from primitives.
		 *
		 * @private
		 * @param {Array<GLTF.Primitive>} primitives
		 * @return {Promise<Array<BufferGeometry>>}
		 */
		loadGeometries( primitives ) {

			const parser = this;
			const extensions = this.extensions;
			const cache = this.primitiveCache;

			function createDracoPrimitive( primitive ) {

				return extensions[ EXTENSIONS.KHR_DRACO_MESH_COMPRESSION ]
					.decodePrimitive( primitive, parser )
					.then( function ( geometry ) {

						return addPrimitiveAttributes( geometry, primitive, parser );

					} );

			}

			const pending = [];

			for ( let i = 0, il = primitives.length; i < il; i ++ ) {

				const primitive = primitives[ i ];
				const cacheKey = createPrimitiveKey( primitive );

				// See if we've already created this geometry
				const cached = cache[ cacheKey ];

				if ( cached ) {

					// Use the cached geometry if it exists
					pending.push( cached.promise );

				} else {

					let geometryPromise;

					if ( primitive.extensions && primitive.extensions[ EXTENSIONS.KHR_DRACO_MESH_COMPRESSION ] ) {

						// Use DRACO geometry if available
						geometryPromise = createDracoPrimitive( primitive );

					} else {

						// Otherwise create a new geometry
						geometryPromise = addPrimitiveAttributes( new BufferGeometry(), primitive, parser );

					}

					// Cache this geometry
					cache[ cacheKey ] = { primitive: primitive, promise: geometryPromise };

					pending.push( geometryPromise );

				}

			}

			return Promise.all( pending );

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#meshes
		 *
		 * @private
		 * @param {number} meshIndex
		 * @return {Promise<Group|Mesh|SkinnedMesh|Line|Points>}
		 */
		loadMesh( meshIndex ) {

			const parser = this;
			const json = this.json;
			const extensions = this.extensions;

			const meshDef = json.meshes[ meshIndex ];
			const primitives = meshDef.primitives;

			const pending = [];

			for ( let i = 0, il = primitives.length; i < il; i ++ ) {

				const material = primitives[ i ].material === undefined
					? createDefaultMaterial( this.cache )
					: this.getDependency( 'material', primitives[ i ].material );

				pending.push( material );

			}

			pending.push( parser.loadGeometries( primitives ) );

			return Promise.all( pending ).then( function ( results ) {

				const materials = results.slice( 0, results.length - 1 );
				const geometries = results[ results.length - 1 ];

				const meshes = [];

				for ( let i = 0, il = geometries.length; i < il; i ++ ) {

					const geometry = geometries[ i ];
					const primitive = primitives[ i ];

					// 1. create Mesh

					let mesh;

					const material = materials[ i ];

					if ( primitive.mode === WEBGL_CONSTANTS.TRIANGLES ||
							primitive.mode === WEBGL_CONSTANTS.TRIANGLE_STRIP ||
							primitive.mode === WEBGL_CONSTANTS.TRIANGLE_FAN ||
							primitive.mode === undefined ) {

						// .isSkinnedMesh isn't in glTF spec. See ._markDefs()
						mesh = meshDef.isSkinnedMesh === true
							? new SkinnedMesh( geometry, material )
							: new Mesh( geometry, material );

						if ( mesh.isSkinnedMesh === true ) {

							// normalize skin weights to fix malformed assets (see #15319)
							mesh.normalizeSkinWeights();

						}

						if ( primitive.mode === WEBGL_CONSTANTS.TRIANGLE_STRIP ) {

							mesh.geometry = toTrianglesDrawMode( mesh.geometry, TriangleStripDrawMode );

						} else if ( primitive.mode === WEBGL_CONSTANTS.TRIANGLE_FAN ) {

							mesh.geometry = toTrianglesDrawMode( mesh.geometry, TriangleFanDrawMode );

						}

					} else if ( primitive.mode === WEBGL_CONSTANTS.LINES ) {

						mesh = new LineSegments( geometry, material );

					} else if ( primitive.mode === WEBGL_CONSTANTS.LINE_STRIP ) {

						mesh = new Line( geometry, material );

					} else if ( primitive.mode === WEBGL_CONSTANTS.LINE_LOOP ) {

						mesh = new LineLoop( geometry, material );

					} else if ( primitive.mode === WEBGL_CONSTANTS.POINTS ) {

						mesh = new Points( geometry, material );

					} else {

						throw new Error( 'THREE.GLTFLoader: Primitive mode unsupported: ' + primitive.mode );

					}

					if ( Object.keys( mesh.geometry.morphAttributes ).length > 0 ) {

						updateMorphTargets( mesh, meshDef );

					}

					mesh.name = parser.createUniqueName( meshDef.name || ( 'mesh_' + meshIndex ) );

					assignExtrasToUserData( mesh, meshDef );

					if ( primitive.extensions ) addUnknownExtensionsToUserData( extensions, mesh, primitive );

					parser.assignFinalMaterial( mesh );

					meshes.push( mesh );

				}

				for ( let i = 0, il = meshes.length; i < il; i ++ ) {

					parser.associations.set( meshes[ i ], {
						meshes: meshIndex,
						primitives: i
					} );

				}

				if ( meshes.length === 1 ) {

					if ( meshDef.extensions ) addUnknownExtensionsToUserData( extensions, meshes[ 0 ], meshDef );

					return meshes[ 0 ];

				}

				const group = new Group$1();

				if ( meshDef.extensions ) addUnknownExtensionsToUserData( extensions, group, meshDef );

				parser.associations.set( group, { meshes: meshIndex } );

				for ( let i = 0, il = meshes.length; i < il; i ++ ) {

					group.add( meshes[ i ] );

				}

				return group;

			} );

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#cameras
		 *
		 * @private
		 * @param {number} cameraIndex
		 * @return {Promise<THREE.Camera>}
		 */
		loadCamera( cameraIndex ) {

			let camera;
			const cameraDef = this.json.cameras[ cameraIndex ];
			const params = cameraDef[ cameraDef.type ];

			if ( ! params ) {

				console.warn( 'THREE.GLTFLoader: Missing camera parameters.' );
				return;

			}

			if ( cameraDef.type === 'perspective' ) {

				camera = new PerspectiveCamera( MathUtils.radToDeg( params.yfov ), params.aspectRatio || 1, params.znear || 1, params.zfar || 2e6 );

			} else if ( cameraDef.type === 'orthographic' ) {

				camera = new OrthographicCamera( - params.xmag, params.xmag, params.ymag, - params.ymag, params.znear, params.zfar );

			}

			if ( cameraDef.name ) camera.name = this.createUniqueName( cameraDef.name );

			assignExtrasToUserData( camera, cameraDef );

			return Promise.resolve( camera );

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#skins
		 *
		 * @private
		 * @param {number} skinIndex
		 * @return {Promise<Skeleton>}
		 */
		loadSkin( skinIndex ) {

			const skinDef = this.json.skins[ skinIndex ];

			const pending = [];

			for ( let i = 0, il = skinDef.joints.length; i < il; i ++ ) {

				pending.push( this._loadNodeShallow( skinDef.joints[ i ] ) );

			}

			if ( skinDef.inverseBindMatrices !== undefined ) {

				pending.push( this.getDependency( 'accessor', skinDef.inverseBindMatrices ) );

			} else {

				pending.push( null );

			}

			return Promise.all( pending ).then( function ( results ) {

				const inverseBindMatrices = results.pop();
				const jointNodes = results;

				// Note that bones (joint nodes) may or may not be in the
				// scene graph at this time.

				const bones = [];
				const boneInverses = [];

				for ( let i = 0, il = jointNodes.length; i < il; i ++ ) {

					const jointNode = jointNodes[ i ];

					if ( jointNode ) {

						bones.push( jointNode );

						const mat = new Matrix4();

						if ( inverseBindMatrices !== null ) {

							mat.fromArray( inverseBindMatrices.array, i * 16 );

						}

						boneInverses.push( mat );

					} else {

						console.warn( 'THREE.GLTFLoader: Joint "%s" could not be found.', skinDef.joints[ i ] );

					}

				}

				return new Skeleton( bones, boneInverses );

			} );

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#animations
		 *
		 * @private
		 * @param {number} animationIndex
		 * @return {Promise<AnimationClip>}
		 */
		loadAnimation( animationIndex ) {

			const json = this.json;
			const parser = this;

			const animationDef = json.animations[ animationIndex ];
			const animationName = animationDef.name ? animationDef.name : 'animation_' + animationIndex;

			const pendingNodes = [];
			const pendingInputAccessors = [];
			const pendingOutputAccessors = [];
			const pendingSamplers = [];
			const pendingTargets = [];

			for ( let i = 0, il = animationDef.channels.length; i < il; i ++ ) {

				const channel = animationDef.channels[ i ];
				const sampler = animationDef.samplers[ channel.sampler ];
				const target = channel.target;
				const name = target.node;
				const input = animationDef.parameters !== undefined ? animationDef.parameters[ sampler.input ] : sampler.input;
				const output = animationDef.parameters !== undefined ? animationDef.parameters[ sampler.output ] : sampler.output;

				if ( target.node === undefined ) continue;

				pendingNodes.push( this.getDependency( 'node', name ) );
				pendingInputAccessors.push( this.getDependency( 'accessor', input ) );
				pendingOutputAccessors.push( this.getDependency( 'accessor', output ) );
				pendingSamplers.push( sampler );
				pendingTargets.push( target );

			}

			return Promise.all( [

				Promise.all( pendingNodes ),
				Promise.all( pendingInputAccessors ),
				Promise.all( pendingOutputAccessors ),
				Promise.all( pendingSamplers ),
				Promise.all( pendingTargets )

			] ).then( function ( dependencies ) {

				const nodes = dependencies[ 0 ];
				const inputAccessors = dependencies[ 1 ];
				const outputAccessors = dependencies[ 2 ];
				const samplers = dependencies[ 3 ];
				const targets = dependencies[ 4 ];

				const tracks = [];

				for ( let i = 0, il = nodes.length; i < il; i ++ ) {

					const node = nodes[ i ];
					const inputAccessor = inputAccessors[ i ];
					const outputAccessor = outputAccessors[ i ];
					const sampler = samplers[ i ];
					const target = targets[ i ];

					if ( node === undefined ) continue;

					if ( node.updateMatrix ) {

						node.updateMatrix();

					}

					const createdTracks = parser._createAnimationTracks( node, inputAccessor, outputAccessor, sampler, target );

					if ( createdTracks ) {

						for ( let k = 0; k < createdTracks.length; k ++ ) {

							tracks.push( createdTracks[ k ] );

						}

					}

				}

				return new AnimationClip( animationName, undefined, tracks );

			} );

		}

		createNodeMesh( nodeIndex ) {

			const json = this.json;
			const parser = this;
			const nodeDef = json.nodes[ nodeIndex ];

			if ( nodeDef.mesh === undefined ) return null;

			return parser.getDependency( 'mesh', nodeDef.mesh ).then( function ( mesh ) {

				const node = parser._getNodeRef( parser.meshCache, nodeDef.mesh, mesh );

				// if weights are provided on the node, override weights on the mesh.
				if ( nodeDef.weights !== undefined ) {

					node.traverse( function ( o ) {

						if ( ! o.isMesh ) return;

						for ( let i = 0, il = nodeDef.weights.length; i < il; i ++ ) {

							o.morphTargetInfluences[ i ] = nodeDef.weights[ i ];

						}

					} );

				}

				return node;

			} );

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#nodes-and-hierarchy
		 *
		 * @private
		 * @param {number} nodeIndex
		 * @return {Promise<Object3D>}
		 */
		loadNode( nodeIndex ) {

			const json = this.json;
			const parser = this;

			const nodeDef = json.nodes[ nodeIndex ];

			const nodePending = parser._loadNodeShallow( nodeIndex );

			const childPending = [];
			const childrenDef = nodeDef.children || [];

			for ( let i = 0, il = childrenDef.length; i < il; i ++ ) {

				childPending.push( parser.getDependency( 'node', childrenDef[ i ] ) );

			}

			const skeletonPending = nodeDef.skin === undefined
				? Promise.resolve( null )
				: parser.getDependency( 'skin', nodeDef.skin );

			return Promise.all( [
				nodePending,
				Promise.all( childPending ),
				skeletonPending
			] ).then( function ( results ) {

				const node = results[ 0 ];
				const children = results[ 1 ];
				const skeleton = results[ 2 ];

				if ( skeleton !== null ) {

					// This full traverse should be fine because
					// child glTF nodes have not been added to this node yet.
					node.traverse( function ( mesh ) {

						if ( ! mesh.isSkinnedMesh ) return;

						mesh.bind( skeleton, _identityMatrix$1 );

					} );

				}

				for ( let i = 0, il = children.length; i < il; i ++ ) {

					node.add( children[ i ] );

				}

				return node;

			} );

		}

		// ._loadNodeShallow() parses a single node.
		// skin and child nodes are created and added in .loadNode() (no '_' prefix).
		_loadNodeShallow( nodeIndex ) {

			const json = this.json;
			const extensions = this.extensions;
			const parser = this;

			// This method is called from .loadNode() and .loadSkin().
			// Cache a node to avoid duplication.

			if ( this.nodeCache[ nodeIndex ] !== undefined ) {

				return this.nodeCache[ nodeIndex ];

			}

			const nodeDef = json.nodes[ nodeIndex ];

			// reserve node's name before its dependencies, so the root has the intended name.
			const nodeName = nodeDef.name ? parser.createUniqueName( nodeDef.name ) : '';

			const pending = [];

			const meshPromise = parser._invokeOne( function ( ext ) {

				return ext.createNodeMesh && ext.createNodeMesh( nodeIndex );

			} );

			if ( meshPromise ) {

				pending.push( meshPromise );

			}

			if ( nodeDef.camera !== undefined ) {

				pending.push( parser.getDependency( 'camera', nodeDef.camera ).then( function ( camera ) {

					return parser._getNodeRef( parser.cameraCache, nodeDef.camera, camera );

				} ) );

			}

			parser._invokeAll( function ( ext ) {

				return ext.createNodeAttachment && ext.createNodeAttachment( nodeIndex );

			} ).forEach( function ( promise ) {

				pending.push( promise );

			} );

			this.nodeCache[ nodeIndex ] = Promise.all( pending ).then( function ( objects ) {

				let node;

				// .isBone isn't in glTF spec. See ._markDefs
				if ( nodeDef.isBone === true ) {

					node = new Bone();

				} else if ( objects.length > 1 ) {

					node = new Group$1();

				} else if ( objects.length === 1 ) {

					node = objects[ 0 ];

				} else {

					node = new Object3D();

				}

				if ( node !== objects[ 0 ] ) {

					for ( let i = 0, il = objects.length; i < il; i ++ ) {

						node.add( objects[ i ] );

					}

				}

				if ( nodeDef.name ) {

					node.userData.name = nodeDef.name;
					node.name = nodeName;

				}

				assignExtrasToUserData( node, nodeDef );

				if ( nodeDef.extensions ) addUnknownExtensionsToUserData( extensions, node, nodeDef );

				if ( nodeDef.matrix !== undefined ) {

					const matrix = new Matrix4();
					matrix.fromArray( nodeDef.matrix );
					node.applyMatrix4( matrix );

				} else {

					if ( nodeDef.translation !== undefined ) {

						node.position.fromArray( nodeDef.translation );

					}

					if ( nodeDef.rotation !== undefined ) {

						node.quaternion.fromArray( nodeDef.rotation );

					}

					if ( nodeDef.scale !== undefined ) {

						node.scale.fromArray( nodeDef.scale );

					}

				}

				if ( ! parser.associations.has( node ) ) {

					parser.associations.set( node, {} );

				} else if ( nodeDef.mesh !== undefined && parser.meshCache.refs[ nodeDef.mesh ] > 1 ) {

					const mapping = parser.associations.get( node );
					parser.associations.set( node, { ...mapping } );

				}

				parser.associations.get( node ).nodes = nodeIndex;

				return node;

			} );

			return this.nodeCache[ nodeIndex ];

		}

		/**
		 * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#scenes
		 *
		 * @private
		 * @param {number} sceneIndex
		 * @return {Promise<Group>}
		 */
		loadScene( sceneIndex ) {

			const extensions = this.extensions;
			const sceneDef = this.json.scenes[ sceneIndex ];
			const parser = this;

			// Loader returns Group, not Scene.
			// See: https://github.com/mrdoob/three.js/issues/18342#issuecomment-578981172
			const scene = new Group$1();
			if ( sceneDef.name ) scene.name = parser.createUniqueName( sceneDef.name );

			assignExtrasToUserData( scene, sceneDef );

			if ( sceneDef.extensions ) addUnknownExtensionsToUserData( extensions, scene, sceneDef );

			const nodeIds = sceneDef.nodes || [];

			const pending = [];

			for ( let i = 0, il = nodeIds.length; i < il; i ++ ) {

				pending.push( parser.getDependency( 'node', nodeIds[ i ] ) );

			}

			return Promise.all( pending ).then( function ( nodes ) {

				for ( let i = 0, il = nodes.length; i < il; i ++ ) {

					scene.add( nodes[ i ] );

				}

				// Removes dangling associations, associations that reference a node that
				// didn't make it into the scene.
				const reduceAssociations = ( node ) => {

					const reducedAssociations = new Map();

					for ( const [ key, value ] of parser.associations ) {

						if ( key instanceof Material || key instanceof Texture ) {

							reducedAssociations.set( key, value );

						}

					}

					node.traverse( ( node ) => {

						const mappings = parser.associations.get( node );

						if ( mappings != null ) {

							reducedAssociations.set( node, mappings );

						}

					} );

					return reducedAssociations;

				};

				parser.associations = reduceAssociations( scene );

				return scene;

			} );

		}

		_createAnimationTracks( node, inputAccessor, outputAccessor, sampler, target ) {

			const tracks = [];

			const targetName = node.name ? node.name : node.uuid;
			const targetNames = [];

			if ( PATH_PROPERTIES[ target.path ] === PATH_PROPERTIES.weights ) {

				node.traverse( function ( object ) {

					if ( object.morphTargetInfluences ) {

						targetNames.push( object.name ? object.name : object.uuid );

					}

				} );

			} else {

				targetNames.push( targetName );

			}

			let TypedKeyframeTrack;

			switch ( PATH_PROPERTIES[ target.path ] ) {

				case PATH_PROPERTIES.weights:

					TypedKeyframeTrack = NumberKeyframeTrack;
					break;

				case PATH_PROPERTIES.rotation:

					TypedKeyframeTrack = QuaternionKeyframeTrack;
					break;

				case PATH_PROPERTIES.translation:
				case PATH_PROPERTIES.scale:

					TypedKeyframeTrack = VectorKeyframeTrack;
					break;

				default:

					switch ( outputAccessor.itemSize ) {

						case 1:
							TypedKeyframeTrack = NumberKeyframeTrack;
							break;
						case 2:
						case 3:
						default:
							TypedKeyframeTrack = VectorKeyframeTrack;
							break;

					}

					break;

			}

			const interpolation = sampler.interpolation !== undefined ? INTERPOLATION[ sampler.interpolation ] : InterpolateLinear;


			const outputArray = this._getArrayFromAccessor( outputAccessor );

			for ( let j = 0, jl = targetNames.length; j < jl; j ++ ) {

				const track = new TypedKeyframeTrack(
					targetNames[ j ] + '.' + PATH_PROPERTIES[ target.path ],
					inputAccessor.array,
					outputArray,
					interpolation
				);

				// Override interpolation with custom factory method.
				if ( sampler.interpolation === 'CUBICSPLINE' ) {

					this._createCubicSplineTrackInterpolant( track );

				}

				tracks.push( track );

			}

			return tracks;

		}

		_getArrayFromAccessor( accessor ) {

			let outputArray = accessor.array;

			if ( accessor.normalized ) {

				const scale = getNormalizedComponentScale( outputArray.constructor );
				const scaled = new Float32Array( outputArray.length );

				for ( let j = 0, jl = outputArray.length; j < jl; j ++ ) {

					scaled[ j ] = outputArray[ j ] * scale;

				}

				outputArray = scaled;

			}

			return outputArray;

		}

		_createCubicSplineTrackInterpolant( track ) {

			track.createInterpolant = function InterpolantFactoryMethodGLTFCubicSpline( result ) {

				// A CUBICSPLINE keyframe in glTF has three output values for each input value,
				// representing inTangent, splineVertex, and outTangent. As a result, track.getValueSize()
				// must be divided by three to get the interpolant's sampleSize argument.

				const interpolantType = ( this instanceof QuaternionKeyframeTrack ) ? GLTFCubicSplineQuaternionInterpolant : GLTFCubicSplineInterpolant;

				return new interpolantType( this.times, this.values, this.getValueSize() / 3, result );

			};

			// Mark as CUBICSPLINE. `track.getInterpolation()` doesn't support custom interpolants.
			track.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline = true;

		}

	}

	/**
	 *
	 * @private
	 * @param {BufferGeometry} geometry
	 * @param {GLTF.Primitive} primitiveDef
	 * @param {GLTFParser} parser
	 */
	function computeBounds( geometry, primitiveDef, parser ) {

		const attributes = primitiveDef.attributes;

		const box = new Box3();

		if ( attributes.POSITION !== undefined ) {

			const accessor = parser.json.accessors[ attributes.POSITION ];

			const min = accessor.min;
			const max = accessor.max;

			// glTF requires 'min' and 'max', but VRM (which extends glTF) currently ignores that requirement.

			if ( min !== undefined && max !== undefined ) {

				box.set(
					new Vector3( min[ 0 ], min[ 1 ], min[ 2 ] ),
					new Vector3( max[ 0 ], max[ 1 ], max[ 2 ] )
				);

				if ( accessor.normalized ) {

					const boxScale = getNormalizedComponentScale( WEBGL_COMPONENT_TYPES[ accessor.componentType ] );
					box.min.multiplyScalar( boxScale );
					box.max.multiplyScalar( boxScale );

				}

			} else {

				console.warn( 'THREE.GLTFLoader: Missing min/max properties for accessor POSITION.' );

				return;

			}

		} else {

			return;

		}

		const targets = primitiveDef.targets;

		if ( targets !== undefined ) {

			const maxDisplacement = new Vector3();
			const vector = new Vector3();

			for ( let i = 0, il = targets.length; i < il; i ++ ) {

				const target = targets[ i ];

				if ( target.POSITION !== undefined ) {

					const accessor = parser.json.accessors[ target.POSITION ];
					const min = accessor.min;
					const max = accessor.max;

					// glTF requires 'min' and 'max', but VRM (which extends glTF) currently ignores that requirement.

					if ( min !== undefined && max !== undefined ) {

						// we need to get max of absolute components because target weight is [-1,1]
						vector.setX( Math.max( Math.abs( min[ 0 ] ), Math.abs( max[ 0 ] ) ) );
						vector.setY( Math.max( Math.abs( min[ 1 ] ), Math.abs( max[ 1 ] ) ) );
						vector.setZ( Math.max( Math.abs( min[ 2 ] ), Math.abs( max[ 2 ] ) ) );


						if ( accessor.normalized ) {

							const boxScale = getNormalizedComponentScale( WEBGL_COMPONENT_TYPES[ accessor.componentType ] );
							vector.multiplyScalar( boxScale );

						}

						// Note: this assumes that the sum of all weights is at most 1. This isn't quite correct - it's more conservative
						// to assume that each target can have a max weight of 1. However, for some use cases - notably, when morph targets
						// are used to implement key-frame animations and as such only two are active at a time - this results in very large
						// boxes. So for now we make a box that's sometimes a touch too small but is hopefully mostly of reasonable size.
						maxDisplacement.max( vector );

					} else {

						console.warn( 'THREE.GLTFLoader: Missing min/max properties for accessor POSITION.' );

					}

				}

			}

			// As per comment above this box isn't conservative, but has a reasonable size for a very large number of morph targets.
			box.expandByVector( maxDisplacement );

		}

		geometry.boundingBox = box;

		const sphere = new Sphere();

		box.getCenter( sphere.center );
		sphere.radius = box.min.distanceTo( box.max ) / 2;

		geometry.boundingSphere = sphere;

	}

	/**
	 *
	 * @private
	 * @param {BufferGeometry} geometry
	 * @param {GLTF.Primitive} primitiveDef
	 * @param {GLTFParser} parser
	 * @return {Promise<BufferGeometry>}
	 */
	function addPrimitiveAttributes( geometry, primitiveDef, parser ) {

		const attributes = primitiveDef.attributes;

		const pending = [];

		function assignAttributeAccessor( accessorIndex, attributeName ) {

			return parser.getDependency( 'accessor', accessorIndex )
				.then( function ( accessor ) {

					geometry.setAttribute( attributeName, accessor );

				} );

		}

		for ( const gltfAttributeName in attributes ) {

			const threeAttributeName = ATTRIBUTES[ gltfAttributeName ] || gltfAttributeName.toLowerCase();

			// Skip attributes already provided by e.g. Draco extension.
			if ( threeAttributeName in geometry.attributes ) continue;

			pending.push( assignAttributeAccessor( attributes[ gltfAttributeName ], threeAttributeName ) );

		}

		if ( primitiveDef.indices !== undefined && ! geometry.index ) {

			const accessor = parser.getDependency( 'accessor', primitiveDef.indices ).then( function ( accessor ) {

				geometry.setIndex( accessor );

			} );

			pending.push( accessor );

		}

		if ( ColorManagement.workingColorSpace !== LinearSRGBColorSpace && 'COLOR_0' in attributes ) {

			console.warn( `THREE.GLTFLoader: Converting vertex colors from "srgb-linear" to "${ColorManagement.workingColorSpace}" not supported.` );

		}

		assignExtrasToUserData( geometry, primitiveDef );

		computeBounds( geometry, primitiveDef, parser );

		return Promise.all( pending ).then( function () {

			return primitiveDef.targets !== undefined
				? addMorphTargets( geometry, primitiveDef.targets, parser )
				: geometry;

		} );

	}

	const _raycaster = new Raycaster();

	const _tempVector = new Vector3();
	const _tempVector2 = new Vector3();
	const _tempQuaternion = new Quaternion();
	const _unit = {
		X: new Vector3( 1, 0, 0 ),
		Y: new Vector3( 0, 1, 0 ),
		Z: new Vector3( 0, 0, 1 )
	};

	/**
	 * Fires if any type of change (object or property change) is performed. Property changes
	 * are separate events you can add event listeners to. The event type is "propertyname-changed".
	 *
	 * @event TransformControls#change
	 * @type {Object}
	 */
	const _changeEvent = { type: 'change' };

	/**
	 * Fires if a pointer (mouse/touch) becomes active.
	 *
	 * @event TransformControls#mouseDown
	 * @type {Object}
	 */
	const _mouseDownEvent = { type: 'mouseDown', mode: null };

	/**
	 * Fires if a pointer (mouse/touch) is no longer active.
	 *
	 * @event TransformControls#mouseUp
	 * @type {Object}
	 */
	const _mouseUpEvent = { type: 'mouseUp', mode: null };

	/**
	 * Fires if the controlled 3D object is changed.
	 *
	 * @event TransformControls#objectChange
	 * @type {Object}
	 */
	const _objectChangeEvent = { type: 'objectChange' };

	/**
	 * This class can be used to transform objects in 3D space by adapting a similar interaction model
	 * of DCC tools like Blender. Unlike other controls, it is not intended to transform the scene's camera.
	 *
	 * `TransformControls` expects that its attached 3D object is part of the scene graph.
	 *
	 * @augments Controls
	 * @three_import import { TransformControls } from 'three/addons/controls/TransformControls.js';
	 */
	class TransformControls extends Controls {

		/**
		 * Constructs a new controls instance.
		 *
		 * @param {Camera} camera - The camera of the rendered scene.
		 * @param {?HTMLDOMElement} domElement - The HTML element used for event listeners.
		 */
		constructor( camera, domElement = null ) {

			super( undefined, domElement );

			const root = new TransformControlsRoot( this );
			this._root = root;

			const gizmo = new TransformControlsGizmo();
			this._gizmo = gizmo;
			root.add( gizmo );

			const plane = new TransformControlsPlane();
			this._plane = plane;
			root.add( plane );

			const scope = this;

			// Defined getter, setter and store for a property
			function defineProperty( propName, defaultValue ) {

				let propValue = defaultValue;

				Object.defineProperty( scope, propName, {

					get: function () {

						return propValue !== undefined ? propValue : defaultValue;

					},

					set: function ( value ) {

						if ( propValue !== value ) {

							propValue = value;
							plane[ propName ] = value;
							gizmo[ propName ] = value;

							scope.dispatchEvent( { type: propName + '-changed', value: value } );
							scope.dispatchEvent( _changeEvent );

						}

					}

				} );

				scope[ propName ] = defaultValue;
				plane[ propName ] = defaultValue;
				gizmo[ propName ] = defaultValue;

			}

			// Define properties with getters/setter
			// Setting the defined property will automatically trigger change event
			// Defined properties are passed down to gizmo and plane

			/**
			 * The camera of the rendered scene.
			 *
			 * @name TransformControls#camera
			 * @type {Camera}
			 */
			defineProperty( 'camera', camera );
			defineProperty( 'object', undefined );
			defineProperty( 'enabled', true );

			/**
			 * The current transformation axis.
			 *
			 * @name TransformControls#axis
			 * @type {string}
			 */
			defineProperty( 'axis', null );

			/**
			 * The current transformation axis.
			 *
			 * @name TransformControls#mode
			 * @type {('translate'|'rotate'|'scale')}
			 * @default 'translate'
			 */
			defineProperty( 'mode', 'translate' );

			/**
			 * By default, 3D objects are continuously translated. If you set this property to a numeric
			 * value (world units), you can define in which steps the 3D object should be translated.
			 *
			 * @name TransformControls#translationSnap
			 * @type {?number}
			 * @default null
			 */
			defineProperty( 'translationSnap', null );

			/**
			 * By default, 3D objects are continuously rotated. If you set this property to a numeric
			 * value (radians), you can define in which steps the 3D object should be rotated.
			 *
			 * @name TransformControls#rotationSnap
			 * @type {?number}
			 * @default null
			 */
			defineProperty( 'rotationSnap', null );

			/**
			 * By default, 3D objects are continuously scaled. If you set this property to a numeric
			 * value, you can define in which steps the 3D object should be scaled.
			 *
			 * @name TransformControls#scaleSnap
			 * @type {?number}
			 * @default null
			 */
			defineProperty( 'scaleSnap', null );

			/**
			 * Defines in which coordinate space transformations should be performed.
			 *
			 * @name TransformControls#space
			 * @type {('world'|'local')}
			 * @default 'world'
			 */
			defineProperty( 'space', 'world' );

			/**
			 * The size of the helper UI (axes/planes).
			 *
			 * @name TransformControls#size
			 * @type {number}
			 * @default 1
			 */
			defineProperty( 'size', 1 );

			/**
			 * Whether dragging is currently performed or not.
			 *
			 * @name TransformControls#dragging
			 * @type {boolean}
			 * @readonly
			 * @default false
			 */
			defineProperty( 'dragging', false );

			/**
			 * Whether the x-axis helper should be visible or not.
			 *
			 * @name TransformControls#showX
			 * @type {boolean}
			 * @default true
			 */
			defineProperty( 'showX', true );

			/**
			 * Whether the y-axis helper should be visible or not.
			 *
			 * @name TransformControls#showY
			 * @type {boolean}
			 * @default true
			 */
			defineProperty( 'showY', true );

			/**
			 * Whether the z-axis helper should be visible or not.
			 *
			 * @name TransformControls#showZ
			 * @type {boolean}
			 * @default true
			 */
			defineProperty( 'showZ', true );

			/**
			 * The minimum allowed X position during translation.
			 *
			 * @name TransformControls#minX
			 * @type {number}
			 * @default -Infinity
			 */
			defineProperty( 'minX', - Infinity );

			/**
			 * The maximum allowed X position during translation.
			 *
			 * @name TransformControls#maxX
			 * @type {number}
			 * @default Infinity
			 */
			defineProperty( 'maxX', Infinity );

			/**
			 * The minimum allowed y position during translation.
			 *
			 * @name TransformControls#minY
			 * @type {number}
			 * @default -Infinity
			 */
			defineProperty( 'minY', - Infinity );

			/**
			 * The maximum allowed Y position during translation.
			 *
			 * @name TransformControls#maxY
			 * @type {number}
			 * @default Infinity
			 */
			defineProperty( 'maxY', Infinity );

			/**
			 * The minimum allowed z position during translation.
			 *
			 * @name TransformControls#minZ
			 * @type {number}
			 * @default -Infinity
			 */
			defineProperty( 'minZ', - Infinity );

			/**
			 * The maximum allowed Z position during translation.
			 *
			 * @name TransformControls#maxZ
			 * @type {number}
			 * @default Infinity
			 */
			defineProperty( 'maxZ', Infinity );

			// Reusable utility variables

			const worldPosition = new Vector3();
			const worldPositionStart = new Vector3();
			const worldQuaternion = new Quaternion();
			const worldQuaternionStart = new Quaternion();
			const cameraPosition = new Vector3();
			const cameraQuaternion = new Quaternion();
			const pointStart = new Vector3();
			const pointEnd = new Vector3();
			const rotationAxis = new Vector3();
			const rotationAngle = 0;
			const eye = new Vector3();

			// TODO: remove properties unused in plane and gizmo

			defineProperty( 'worldPosition', worldPosition );
			defineProperty( 'worldPositionStart', worldPositionStart );
			defineProperty( 'worldQuaternion', worldQuaternion );
			defineProperty( 'worldQuaternionStart', worldQuaternionStart );
			defineProperty( 'cameraPosition', cameraPosition );
			defineProperty( 'cameraQuaternion', cameraQuaternion );
			defineProperty( 'pointStart', pointStart );
			defineProperty( 'pointEnd', pointEnd );
			defineProperty( 'rotationAxis', rotationAxis );
			defineProperty( 'rotationAngle', rotationAngle );
			defineProperty( 'eye', eye );

			this._offset = new Vector3();
			this._startNorm = new Vector3();
			this._endNorm = new Vector3();
			this._cameraScale = new Vector3();

			this._parentPosition = new Vector3();
			this._parentQuaternion = new Quaternion();
			this._parentQuaternionInv = new Quaternion();
			this._parentScale = new Vector3();

			this._worldScaleStart = new Vector3();
			this._worldQuaternionInv = new Quaternion();
			this._worldScale = new Vector3();

			this._positionStart = new Vector3();
			this._quaternionStart = new Quaternion();
			this._scaleStart = new Vector3();

			this._getPointer = getPointer.bind( this );
			this._onPointerDown = onPointerDown.bind( this );
			this._onPointerHover = onPointerHover.bind( this );
			this._onPointerMove = onPointerMove.bind( this );
			this._onPointerUp = onPointerUp.bind( this );

			if ( domElement !== null ) {

				this.connect( domElement );

			}

		}

		connect( element ) {

			super.connect( element );

			this.domElement.addEventListener( 'pointerdown', this._onPointerDown );
			this.domElement.addEventListener( 'pointermove', this._onPointerHover );
			this.domElement.addEventListener( 'pointerup', this._onPointerUp );

			this.domElement.style.touchAction = 'none'; // disable touch scroll

		}

		disconnect() {

			this.domElement.removeEventListener( 'pointerdown', this._onPointerDown );
			this.domElement.removeEventListener( 'pointermove', this._onPointerHover );
			this.domElement.removeEventListener( 'pointermove', this._onPointerMove );
			this.domElement.removeEventListener( 'pointerup', this._onPointerUp );

			this.domElement.style.touchAction = 'auto';

		}

		/**
		 * Returns the visual representation of the controls. Add the helper to your scene to
		 * visually transform the attached  3D object.
		 *
		 * @return {TransformControlsRoot} The helper.
		 */
		getHelper() {

			return this._root;

		}

		pointerHover( pointer ) {

			if ( this.object === undefined || this.dragging === true ) return;

			if ( pointer !== null ) _raycaster.setFromCamera( pointer, this.camera );

			const intersect = intersectObjectWithRay( this._gizmo.picker[ this.mode ], _raycaster );

			if ( intersect ) {

				this.axis = intersect.object.name;

			} else {

				this.axis = null;

			}

		}

		pointerDown( pointer ) {

			if ( this.object === undefined || this.dragging === true || ( pointer != null && pointer.button !== 0 ) ) return;

			if ( this.axis !== null ) {

				if ( pointer !== null ) _raycaster.setFromCamera( pointer, this.camera );

				const planeIntersect = intersectObjectWithRay( this._plane, _raycaster, true );

				if ( planeIntersect ) {

					this.object.updateMatrixWorld();
					this.object.parent.updateMatrixWorld();

					this._positionStart.copy( this.object.position );
					this._quaternionStart.copy( this.object.quaternion );
					this._scaleStart.copy( this.object.scale );

					this.object.matrixWorld.decompose( this.worldPositionStart, this.worldQuaternionStart, this._worldScaleStart );

					this.pointStart.copy( planeIntersect.point ).sub( this.worldPositionStart );

				}

				this.dragging = true;
				_mouseDownEvent.mode = this.mode;
				this.dispatchEvent( _mouseDownEvent );

			}

		}

		pointerMove( pointer ) {

			const axis = this.axis;
			const mode = this.mode;
			const object = this.object;
			let space = this.space;

			if ( mode === 'scale' ) {

				space = 'local';

			} else if ( axis === 'E' || axis === 'XYZE' || axis === 'XYZ' ) {

				space = 'world';

			}

			if ( object === undefined || axis === null || this.dragging === false || ( pointer !== null && pointer.button !== - 1 ) ) return;

			if ( pointer !== null ) _raycaster.setFromCamera( pointer, this.camera );

			const planeIntersect = intersectObjectWithRay( this._plane, _raycaster, true );

			if ( ! planeIntersect ) return;

			this.pointEnd.copy( planeIntersect.point ).sub( this.worldPositionStart );

			if ( mode === 'translate' ) {

				// Apply translate

				this._offset.copy( this.pointEnd ).sub( this.pointStart );

				if ( space === 'local' && axis !== 'XYZ' ) {

					this._offset.applyQuaternion( this._worldQuaternionInv );

				}

				if ( axis.indexOf( 'X' ) === - 1 ) this._offset.x = 0;
				if ( axis.indexOf( 'Y' ) === - 1 ) this._offset.y = 0;
				if ( axis.indexOf( 'Z' ) === - 1 ) this._offset.z = 0;

				if ( space === 'local' && axis !== 'XYZ' ) {

					this._offset.applyQuaternion( this._quaternionStart ).divide( this._parentScale );

				} else {

					this._offset.applyQuaternion( this._parentQuaternionInv ).divide( this._parentScale );

				}

				object.position.copy( this._offset ).add( this._positionStart );

				// Apply translation snap

				if ( this.translationSnap ) {

					if ( space === 'local' ) {

						object.position.applyQuaternion( _tempQuaternion.copy( this._quaternionStart ).invert() );

						if ( axis.search( 'X' ) !== - 1 ) {

							object.position.x = Math.round( object.position.x / this.translationSnap ) * this.translationSnap;

						}

						if ( axis.search( 'Y' ) !== - 1 ) {

							object.position.y = Math.round( object.position.y / this.translationSnap ) * this.translationSnap;

						}

						if ( axis.search( 'Z' ) !== - 1 ) {

							object.position.z = Math.round( object.position.z / this.translationSnap ) * this.translationSnap;

						}

						object.position.applyQuaternion( this._quaternionStart );

					}

					if ( space === 'world' ) {

						if ( object.parent ) {

							object.position.add( _tempVector.setFromMatrixPosition( object.parent.matrixWorld ) );

						}

						if ( axis.search( 'X' ) !== - 1 ) {

							object.position.x = Math.round( object.position.x / this.translationSnap ) * this.translationSnap;

						}

						if ( axis.search( 'Y' ) !== - 1 ) {

							object.position.y = Math.round( object.position.y / this.translationSnap ) * this.translationSnap;

						}

						if ( axis.search( 'Z' ) !== - 1 ) {

							object.position.z = Math.round( object.position.z / this.translationSnap ) * this.translationSnap;

						}

						if ( object.parent ) {

							object.position.sub( _tempVector.setFromMatrixPosition( object.parent.matrixWorld ) );

						}

					}

				}

				object.position.x = Math.max( this.minX, Math.min( this.maxX, object.position.x ) );
				object.position.y = Math.max( this.minY, Math.min( this.maxY, object.position.y ) );
				object.position.z = Math.max( this.minZ, Math.min( this.maxZ, object.position.z ) );

			} else if ( mode === 'scale' ) {

				if ( axis.search( 'XYZ' ) !== - 1 ) {

					let d = this.pointEnd.length() / this.pointStart.length();

					if ( this.pointEnd.dot( this.pointStart ) < 0 ) d *= - 1;

					_tempVector2.set( d, d, d );

				} else {

					_tempVector.copy( this.pointStart );
					_tempVector2.copy( this.pointEnd );

					_tempVector.applyQuaternion( this._worldQuaternionInv );
					_tempVector2.applyQuaternion( this._worldQuaternionInv );

					_tempVector2.divide( _tempVector );

					if ( axis.search( 'X' ) === - 1 ) {

						_tempVector2.x = 1;

					}

					if ( axis.search( 'Y' ) === - 1 ) {

						_tempVector2.y = 1;

					}

					if ( axis.search( 'Z' ) === - 1 ) {

						_tempVector2.z = 1;

					}

				}

				// Apply scale

				object.scale.copy( this._scaleStart ).multiply( _tempVector2 );

				if ( this.scaleSnap ) {

					if ( axis.search( 'X' ) !== - 1 ) {

						object.scale.x = Math.round( object.scale.x / this.scaleSnap ) * this.scaleSnap || this.scaleSnap;

					}

					if ( axis.search( 'Y' ) !== - 1 ) {

						object.scale.y = Math.round( object.scale.y / this.scaleSnap ) * this.scaleSnap || this.scaleSnap;

					}

					if ( axis.search( 'Z' ) !== - 1 ) {

						object.scale.z = Math.round( object.scale.z / this.scaleSnap ) * this.scaleSnap || this.scaleSnap;

					}

				}

			} else if ( mode === 'rotate' ) {

				this._offset.copy( this.pointEnd ).sub( this.pointStart );

				const ROTATION_SPEED = 20 / this.worldPosition.distanceTo( _tempVector.setFromMatrixPosition( this.camera.matrixWorld ) );

				let _inPlaneRotation = false;

				if ( axis === 'XYZE' ) {

					this.rotationAxis.copy( this._offset ).cross( this.eye ).normalize();
					this.rotationAngle = this._offset.dot( _tempVector.copy( this.rotationAxis ).cross( this.eye ) ) * ROTATION_SPEED;

				} else if ( axis === 'X' || axis === 'Y' || axis === 'Z' ) {

					this.rotationAxis.copy( _unit[ axis ] );

					_tempVector.copy( _unit[ axis ] );

					if ( space === 'local' ) {

						_tempVector.applyQuaternion( this.worldQuaternion );

					}

					_tempVector.cross( this.eye );

					// When _tempVector is 0 after cross with this.eye the vectors are parallel and should use in-plane rotation logic.
					if ( _tempVector.length() === 0 ) {

						_inPlaneRotation = true;

					} else {

						this.rotationAngle = this._offset.dot( _tempVector.normalize() ) * ROTATION_SPEED;

					}


				}

				if ( axis === 'E' || _inPlaneRotation ) {

					this.rotationAxis.copy( this.eye );
					this.rotationAngle = this.pointEnd.angleTo( this.pointStart );

					this._startNorm.copy( this.pointStart ).normalize();
					this._endNorm.copy( this.pointEnd ).normalize();

					this.rotationAngle *= ( this._endNorm.cross( this._startNorm ).dot( this.eye ) < 0 ? 1 : - 1 );

				}

				// Apply rotation snap

				if ( this.rotationSnap ) this.rotationAngle = Math.round( this.rotationAngle / this.rotationSnap ) * this.rotationSnap;

				// Apply rotate
				if ( space === 'local' && axis !== 'E' && axis !== 'XYZE' ) {

					object.quaternion.copy( this._quaternionStart );
					object.quaternion.multiply( _tempQuaternion.setFromAxisAngle( this.rotationAxis, this.rotationAngle ) ).normalize();

				} else {

					this.rotationAxis.applyQuaternion( this._parentQuaternionInv );
					object.quaternion.copy( _tempQuaternion.setFromAxisAngle( this.rotationAxis, this.rotationAngle ) );
					object.quaternion.multiply( this._quaternionStart ).normalize();

				}

			}

			this.dispatchEvent( _changeEvent );
			this.dispatchEvent( _objectChangeEvent );

		}

		pointerUp( pointer ) {

			if ( pointer !== null && pointer.button !== 0 ) return;

			if ( this.dragging && ( this.axis !== null ) ) {

				_mouseUpEvent.mode = this.mode;
				this.dispatchEvent( _mouseUpEvent );

			}

			this.dragging = false;
			this.axis = null;

		}

		dispose() {

			this.disconnect();

			this._root.dispose();

		}

		/**
		 * Sets the 3D object that should be transformed and ensures the controls UI is visible.
		 *
		 * @param {Object3D} object -  The 3D object that should be transformed.
		 * @return {TransformControls} A reference to this controls.
		 */
		attach( object ) {

			this.object = object;
			this._root.visible = true;

			return this;

		}

		/**
		 * Removes the current 3D object from the controls and makes the helper UI invisible.
		 *
		 * @return {TransformControls} A reference to this controls.
		 */
		detach() {

			this.object = undefined;
			this.axis = null;

			this._root.visible = false;

			return this;

		}

		/**
		 * Resets the object's position, rotation and scale to when the current transform began.
		 */
		reset() {

			if ( ! this.enabled ) return;

			if ( this.dragging ) {

				this.object.position.copy( this._positionStart );
				this.object.quaternion.copy( this._quaternionStart );
				this.object.scale.copy( this._scaleStart );

				this.dispatchEvent( _changeEvent );
				this.dispatchEvent( _objectChangeEvent );

				this.pointStart.copy( this.pointEnd );

			}

		}

		/**
		 * Returns the raycaster that is used for user interaction. This object is shared between all
		 * instances of `TransformControls`.
		 *
		 * @returns {Raycaster} The internal raycaster.
		 */
		getRaycaster() {

			return _raycaster;

		}

		/**
		 * Returns the transformation mode.
		 *
		 * @returns {'translate'|'rotate'|'scale'} The transformation mode.
		 */
		getMode() {

			return this.mode;

		}

		/**
		 * Sets the given transformation mode.
		 *
		 * @param {'translate'|'rotate'|'scale'} mode - The transformation mode to set.
		 */
		setMode( mode ) {

			this.mode = mode;

		}

		/**
		 * Sets the translation snap.
		 *
		 * @param {?number} translationSnap - The translation snap to set.
		 */
		setTranslationSnap( translationSnap ) {

			this.translationSnap = translationSnap;

		}

		/**
		 * Sets the rotation snap.
		 *
		 * @param {?number} rotationSnap - The rotation snap to set.
		 */
		setRotationSnap( rotationSnap ) {

			this.rotationSnap = rotationSnap;

		}

		/**
		 * Sets the scale snap.
		 *
		 * @param {?number} scaleSnap - The scale snap to set.
		 */
		setScaleSnap( scaleSnap ) {

			this.scaleSnap = scaleSnap;

		}

		/**
		 * Sets the size of the helper UI.
		 *
		 * @param {number} size - The size to set.
		 */
		setSize( size ) {

			this.size = size;

		}

		/**
		 * Sets the coordinate space in which transformations are applied.
		 *
		 * @param {'world'|'local'} space - The space to set.
		 */
		setSpace( space ) {

			this.space = space;

		}

	}

	// mouse / touch event handlers

	function getPointer( event ) {

		if ( this.domElement.ownerDocument.pointerLockElement ) {

			return {
				x: 0,
				y: 0,
				button: event.button
			};

		} else {

			const rect = this.domElement.getBoundingClientRect();

			return {
				x: ( event.clientX - rect.left ) / rect.width * 2 - 1,
				y: - ( event.clientY - rect.top ) / rect.height * 2 + 1,
				button: event.button
			};

		}

	}

	function onPointerHover( event ) {

		if ( ! this.enabled ) return;

		switch ( event.pointerType ) {

			case 'mouse':
			case 'pen':
				this.pointerHover( this._getPointer( event ) );
				break;

		}

	}

	function onPointerDown( event ) {

		if ( ! this.enabled ) return;

		if ( ! document.pointerLockElement ) {

			this.domElement.setPointerCapture( event.pointerId );

		}

		this.domElement.addEventListener( 'pointermove', this._onPointerMove );

		this.pointerHover( this._getPointer( event ) );
		this.pointerDown( this._getPointer( event ) );

	}

	function onPointerMove( event ) {

		if ( ! this.enabled ) return;

		this.pointerMove( this._getPointer( event ) );

	}

	function onPointerUp( event ) {

		if ( ! this.enabled ) return;

		this.domElement.releasePointerCapture( event.pointerId );

		this.domElement.removeEventListener( 'pointermove', this._onPointerMove );

		this.pointerUp( this._getPointer( event ) );

	}

	function intersectObjectWithRay( object, raycaster, includeInvisible ) {

		const allIntersections = raycaster.intersectObject( object, true );

		for ( let i = 0; i < allIntersections.length; i ++ ) {

			if ( allIntersections[ i ].object.visible || includeInvisible ) {

				return allIntersections[ i ];

			}

		}

		return false;

	}

	//

	// Reusable utility variables

	const _tempEuler = new Euler();
	const _alignVector = new Vector3( 0, 1, 0 );
	const _zeroVector = new Vector3( 0, 0, 0 );
	const _lookAtMatrix = new Matrix4();
	const _tempQuaternion2 = new Quaternion();
	const _identityQuaternion = new Quaternion();
	const _dirVector = new Vector3();
	const _tempMatrix = new Matrix4();

	const _unitX = new Vector3( 1, 0, 0 );
	const _unitY = new Vector3( 0, 1, 0 );
	const _unitZ = new Vector3( 0, 0, 1 );

	const _v1 = new Vector3();
	const _v2 = new Vector3();
	const _v3 = new Vector3();

	class TransformControlsRoot extends Object3D {

		constructor( controls ) {

			super();

			this.isTransformControlsRoot = true;

			this.controls = controls;
			this.visible = false;

		}

		// updateMatrixWorld updates key transformation variables
		updateMatrixWorld( force ) {

			const controls = this.controls;

			if ( controls.object !== undefined ) {

				controls.object.updateMatrixWorld();

				if ( controls.object.parent === null ) {

					console.error( 'TransformControls: The attached 3D object must be a part of the scene graph.' );

				} else {

					controls.object.parent.matrixWorld.decompose( controls._parentPosition, controls._parentQuaternion, controls._parentScale );

				}

				controls.object.matrixWorld.decompose( controls.worldPosition, controls.worldQuaternion, controls._worldScale );

				controls._parentQuaternionInv.copy( controls._parentQuaternion ).invert();
				controls._worldQuaternionInv.copy( controls.worldQuaternion ).invert();

			}

			controls.camera.updateMatrixWorld();
			controls.camera.matrixWorld.decompose( controls.cameraPosition, controls.cameraQuaternion, controls._cameraScale );

			if ( controls.camera.isOrthographicCamera ) {

				controls.camera.getWorldDirection( controls.eye ).negate();

			} else {

				controls.eye.copy( controls.cameraPosition ).sub( controls.worldPosition ).normalize();

			}

			super.updateMatrixWorld( force );

		}

		dispose() {

			this.traverse( function ( child ) {

				if ( child.geometry ) child.geometry.dispose();
				if ( child.material ) child.material.dispose();

			} );

		}

	}

	class TransformControlsGizmo extends Object3D {

		constructor() {

			super();

			this.isTransformControlsGizmo = true;

			this.type = 'TransformControlsGizmo';

			// shared materials

			const gizmoMaterial = new MeshBasicMaterial( {
				depthTest: false,
				depthWrite: false,
				fog: false,
				toneMapped: false,
				transparent: true
			} );

			const gizmoLineMaterial = new LineBasicMaterial( {
				depthTest: false,
				depthWrite: false,
				fog: false,
				toneMapped: false,
				transparent: true
			} );

			// Make unique material for each axis/color

			const matInvisible = gizmoMaterial.clone();
			matInvisible.opacity = 0.15;

			const matHelper = gizmoLineMaterial.clone();
			matHelper.opacity = 0.5;

			const matRed = gizmoMaterial.clone();
			matRed.color.setHex( 0xff0000 );

			const matGreen = gizmoMaterial.clone();
			matGreen.color.setHex( 0x00ff00 );

			const matBlue = gizmoMaterial.clone();
			matBlue.color.setHex( 0x0000ff );

			const matRedTransparent = gizmoMaterial.clone();
			matRedTransparent.color.setHex( 0xff0000 );
			matRedTransparent.opacity = 0.5;

			const matGreenTransparent = gizmoMaterial.clone();
			matGreenTransparent.color.setHex( 0x00ff00 );
			matGreenTransparent.opacity = 0.5;

			const matBlueTransparent = gizmoMaterial.clone();
			matBlueTransparent.color.setHex( 0x0000ff );
			matBlueTransparent.opacity = 0.5;

			const matWhiteTransparent = gizmoMaterial.clone();
			matWhiteTransparent.opacity = 0.25;

			const matYellowTransparent = gizmoMaterial.clone();
			matYellowTransparent.color.setHex( 0xffff00 );
			matYellowTransparent.opacity = 0.25;

			const matYellow = gizmoMaterial.clone();
			matYellow.color.setHex( 0xffff00 );

			const matGray = gizmoMaterial.clone();
			matGray.color.setHex( 0x787878 );

			// reusable geometry

			const arrowGeometry = new CylinderGeometry( 0, 0.04, 0.1, 12 );
			arrowGeometry.translate( 0, 0.05, 0 );

			const scaleHandleGeometry = new BoxGeometry( 0.08, 0.08, 0.08 );
			scaleHandleGeometry.translate( 0, 0.04, 0 );

			const lineGeometry = new BufferGeometry();
			lineGeometry.setAttribute( 'position', new Float32BufferAttribute( [ 0, 0, 0,	1, 0, 0 ], 3 ) );

			const lineGeometry2 = new CylinderGeometry( 0.0075, 0.0075, 0.5, 3 );
			lineGeometry2.translate( 0, 0.25, 0 );

			function CircleGeometry( radius, arc ) {

				const geometry = new TorusGeometry( radius, 0.0075, 3, 64, arc * Math.PI * 2 );
				geometry.rotateY( Math.PI / 2 );
				geometry.rotateX( Math.PI / 2 );
				return geometry;

			}

			// Special geometry for transform helper. If scaled with position vector it spans from [0,0,0] to position

			function TranslateHelperGeometry() {

				const geometry = new BufferGeometry();

				geometry.setAttribute( 'position', new Float32BufferAttribute( [ 0, 0, 0, 1, 1, 1 ], 3 ) );

				return geometry;

			}

			// Gizmo definitions - custom hierarchy definitions for setupGizmo() function

			const gizmoTranslate = {
				X: [
					[ new Mesh( arrowGeometry, matRed ), [ 0.5, 0, 0 ], [ 0, 0, - Math.PI / 2 ]],
					[ new Mesh( arrowGeometry, matRed ), [ - 0.5, 0, 0 ], [ 0, 0, Math.PI / 2 ]],
					[ new Mesh( lineGeometry2, matRed ), [ 0, 0, 0 ], [ 0, 0, - Math.PI / 2 ]]
				],
				Y: [
					[ new Mesh( arrowGeometry, matGreen ), [ 0, 0.5, 0 ]],
					[ new Mesh( arrowGeometry, matGreen ), [ 0, - 0.5, 0 ], [ Math.PI, 0, 0 ]],
					[ new Mesh( lineGeometry2, matGreen ) ]
				],
				Z: [
					[ new Mesh( arrowGeometry, matBlue ), [ 0, 0, 0.5 ], [ Math.PI / 2, 0, 0 ]],
					[ new Mesh( arrowGeometry, matBlue ), [ 0, 0, - 0.5 ], [ - Math.PI / 2, 0, 0 ]],
					[ new Mesh( lineGeometry2, matBlue ), null, [ Math.PI / 2, 0, 0 ]]
				],
				XYZ: [
					[ new Mesh( new OctahedronGeometry( 0.1, 0 ), matWhiteTransparent.clone() ), [ 0, 0, 0 ]]
				],
				XY: [
					[ new Mesh( new BoxGeometry( 0.15, 0.15, 0.01 ), matBlueTransparent.clone() ), [ 0.15, 0.15, 0 ]]
				],
				YZ: [
					[ new Mesh( new BoxGeometry( 0.15, 0.15, 0.01 ), matRedTransparent.clone() ), [ 0, 0.15, 0.15 ], [ 0, Math.PI / 2, 0 ]]
				],
				XZ: [
					[ new Mesh( new BoxGeometry( 0.15, 0.15, 0.01 ), matGreenTransparent.clone() ), [ 0.15, 0, 0.15 ], [ - Math.PI / 2, 0, 0 ]]
				]
			};

			const pickerTranslate = {
				X: [
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0.3, 0, 0 ], [ 0, 0, - Math.PI / 2 ]],
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ - 0.3, 0, 0 ], [ 0, 0, Math.PI / 2 ]]
				],
				Y: [
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0, 0.3, 0 ]],
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0, - 0.3, 0 ], [ 0, 0, Math.PI ]]
				],
				Z: [
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0, 0, 0.3 ], [ Math.PI / 2, 0, 0 ]],
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0, 0, - 0.3 ], [ - Math.PI / 2, 0, 0 ]]
				],
				XYZ: [
					[ new Mesh( new OctahedronGeometry( 0.2, 0 ), matInvisible ) ]
				],
				XY: [
					[ new Mesh( new BoxGeometry( 0.2, 0.2, 0.01 ), matInvisible ), [ 0.15, 0.15, 0 ]]
				],
				YZ: [
					[ new Mesh( new BoxGeometry( 0.2, 0.2, 0.01 ), matInvisible ), [ 0, 0.15, 0.15 ], [ 0, Math.PI / 2, 0 ]]
				],
				XZ: [
					[ new Mesh( new BoxGeometry( 0.2, 0.2, 0.01 ), matInvisible ), [ 0.15, 0, 0.15 ], [ - Math.PI / 2, 0, 0 ]]
				]
			};

			const helperTranslate = {
				START: [
					[ new Mesh( new OctahedronGeometry( 0.01, 2 ), matHelper ), null, null, null, 'helper' ]
				],
				END: [
					[ new Mesh( new OctahedronGeometry( 0.01, 2 ), matHelper ), null, null, null, 'helper' ]
				],
				DELTA: [
					[ new Line( TranslateHelperGeometry(), matHelper ), null, null, null, 'helper' ]
				],
				X: [
					[ new Line( lineGeometry, matHelper.clone() ), [ - 1e3, 0, 0 ], null, [ 1e6, 1, 1 ], 'helper' ]
				],
				Y: [
					[ new Line( lineGeometry, matHelper.clone() ), [ 0, - 1e3, 0 ], [ 0, 0, Math.PI / 2 ], [ 1e6, 1, 1 ], 'helper' ]
				],
				Z: [
					[ new Line( lineGeometry, matHelper.clone() ), [ 0, 0, - 1e3 ], [ 0, - Math.PI / 2, 0 ], [ 1e6, 1, 1 ], 'helper' ]
				]
			};

			const gizmoRotate = {
				XYZE: [
					[ new Mesh( CircleGeometry( 0.5, 1 ), matGray ), null, [ 0, Math.PI / 2, 0 ]]
				],
				X: [
					[ new Mesh( CircleGeometry( 0.5, 0.5 ), matRed ) ]
				],
				Y: [
					[ new Mesh( CircleGeometry( 0.5, 0.5 ), matGreen ), null, [ 0, 0, - Math.PI / 2 ]]
				],
				Z: [
					[ new Mesh( CircleGeometry( 0.5, 0.5 ), matBlue ), null, [ 0, Math.PI / 2, 0 ]]
				],
				E: [
					[ new Mesh( CircleGeometry( 0.75, 1 ), matYellowTransparent ), null, [ 0, Math.PI / 2, 0 ]]
				]
			};

			const helperRotate = {
				AXIS: [
					[ new Line( lineGeometry, matHelper.clone() ), [ - 1e3, 0, 0 ], null, [ 1e6, 1, 1 ], 'helper' ]
				]
			};

			const pickerRotate = {
				XYZE: [
					[ new Mesh( new SphereGeometry( 0.25, 10, 8 ), matInvisible ) ]
				],
				X: [
					[ new Mesh( new TorusGeometry( 0.5, 0.1, 4, 24 ), matInvisible ), [ 0, 0, 0 ], [ 0, - Math.PI / 2, - Math.PI / 2 ]],
				],
				Y: [
					[ new Mesh( new TorusGeometry( 0.5, 0.1, 4, 24 ), matInvisible ), [ 0, 0, 0 ], [ Math.PI / 2, 0, 0 ]],
				],
				Z: [
					[ new Mesh( new TorusGeometry( 0.5, 0.1, 4, 24 ), matInvisible ), [ 0, 0, 0 ], [ 0, 0, - Math.PI / 2 ]],
				],
				E: [
					[ new Mesh( new TorusGeometry( 0.75, 0.1, 2, 24 ), matInvisible ) ]
				]
			};

			const gizmoScale = {
				X: [
					[ new Mesh( scaleHandleGeometry, matRed ), [ 0.5, 0, 0 ], [ 0, 0, - Math.PI / 2 ]],
					[ new Mesh( lineGeometry2, matRed ), [ 0, 0, 0 ], [ 0, 0, - Math.PI / 2 ]],
					[ new Mesh( scaleHandleGeometry, matRed ), [ - 0.5, 0, 0 ], [ 0, 0, Math.PI / 2 ]],
				],
				Y: [
					[ new Mesh( scaleHandleGeometry, matGreen ), [ 0, 0.5, 0 ]],
					[ new Mesh( lineGeometry2, matGreen ) ],
					[ new Mesh( scaleHandleGeometry, matGreen ), [ 0, - 0.5, 0 ], [ 0, 0, Math.PI ]],
				],
				Z: [
					[ new Mesh( scaleHandleGeometry, matBlue ), [ 0, 0, 0.5 ], [ Math.PI / 2, 0, 0 ]],
					[ new Mesh( lineGeometry2, matBlue ), [ 0, 0, 0 ], [ Math.PI / 2, 0, 0 ]],
					[ new Mesh( scaleHandleGeometry, matBlue ), [ 0, 0, - 0.5 ], [ - Math.PI / 2, 0, 0 ]]
				],
				XY: [
					[ new Mesh( new BoxGeometry( 0.15, 0.15, 0.01 ), matBlueTransparent ), [ 0.15, 0.15, 0 ]]
				],
				YZ: [
					[ new Mesh( new BoxGeometry( 0.15, 0.15, 0.01 ), matRedTransparent ), [ 0, 0.15, 0.15 ], [ 0, Math.PI / 2, 0 ]]
				],
				XZ: [
					[ new Mesh( new BoxGeometry( 0.15, 0.15, 0.01 ), matGreenTransparent ), [ 0.15, 0, 0.15 ], [ - Math.PI / 2, 0, 0 ]]
				],
				XYZ: [
					[ new Mesh( new BoxGeometry( 0.1, 0.1, 0.1 ), matWhiteTransparent.clone() ) ],
				]
			};

			const pickerScale = {
				X: [
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0.3, 0, 0 ], [ 0, 0, - Math.PI / 2 ]],
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ - 0.3, 0, 0 ], [ 0, 0, Math.PI / 2 ]]
				],
				Y: [
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0, 0.3, 0 ]],
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0, - 0.3, 0 ], [ 0, 0, Math.PI ]]
				],
				Z: [
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0, 0, 0.3 ], [ Math.PI / 2, 0, 0 ]],
					[ new Mesh( new CylinderGeometry( 0.2, 0, 0.6, 4 ), matInvisible ), [ 0, 0, - 0.3 ], [ - Math.PI / 2, 0, 0 ]]
				],
				XY: [
					[ new Mesh( new BoxGeometry( 0.2, 0.2, 0.01 ), matInvisible ), [ 0.15, 0.15, 0 ]],
				],
				YZ: [
					[ new Mesh( new BoxGeometry( 0.2, 0.2, 0.01 ), matInvisible ), [ 0, 0.15, 0.15 ], [ 0, Math.PI / 2, 0 ]],
				],
				XZ: [
					[ new Mesh( new BoxGeometry( 0.2, 0.2, 0.01 ), matInvisible ), [ 0.15, 0, 0.15 ], [ - Math.PI / 2, 0, 0 ]],
				],
				XYZ: [
					[ new Mesh( new BoxGeometry( 0.2, 0.2, 0.2 ), matInvisible ), [ 0, 0, 0 ]],
				]
			};

			const helperScale = {
				X: [
					[ new Line( lineGeometry, matHelper.clone() ), [ - 1e3, 0, 0 ], null, [ 1e6, 1, 1 ], 'helper' ]
				],
				Y: [
					[ new Line( lineGeometry, matHelper.clone() ), [ 0, - 1e3, 0 ], [ 0, 0, Math.PI / 2 ], [ 1e6, 1, 1 ], 'helper' ]
				],
				Z: [
					[ new Line( lineGeometry, matHelper.clone() ), [ 0, 0, - 1e3 ], [ 0, - Math.PI / 2, 0 ], [ 1e6, 1, 1 ], 'helper' ]
				]
			};

			// Creates an Object3D with gizmos described in custom hierarchy definition.

			function setupGizmo( gizmoMap ) {

				const gizmo = new Object3D();

				for ( const name in gizmoMap ) {

					for ( let i = gizmoMap[ name ].length; i --; ) {

						const object = gizmoMap[ name ][ i ][ 0 ].clone();
						const position = gizmoMap[ name ][ i ][ 1 ];
						const rotation = gizmoMap[ name ][ i ][ 2 ];
						const scale = gizmoMap[ name ][ i ][ 3 ];
						const tag = gizmoMap[ name ][ i ][ 4 ];

						// name and tag properties are essential for picking and updating logic.
						object.name = name;
						object.tag = tag;

						if ( position ) {

							object.position.set( position[ 0 ], position[ 1 ], position[ 2 ] );

						}

						if ( rotation ) {

							object.rotation.set( rotation[ 0 ], rotation[ 1 ], rotation[ 2 ] );

						}

						if ( scale ) {

							object.scale.set( scale[ 0 ], scale[ 1 ], scale[ 2 ] );

						}

						object.updateMatrix();

						const tempGeometry = object.geometry.clone();
						tempGeometry.applyMatrix4( object.matrix );
						object.geometry = tempGeometry;
						object.renderOrder = Infinity;

						object.position.set( 0, 0, 0 );
						object.rotation.set( 0, 0, 0 );
						object.scale.set( 1, 1, 1 );

						gizmo.add( object );

					}

				}

				return gizmo;

			}

			// Gizmo creation

			this.gizmo = {};
			this.picker = {};
			this.helper = {};

			this.add( this.gizmo[ 'translate' ] = setupGizmo( gizmoTranslate ) );
			this.add( this.gizmo[ 'rotate' ] = setupGizmo( gizmoRotate ) );
			this.add( this.gizmo[ 'scale' ] = setupGizmo( gizmoScale ) );
			this.add( this.picker[ 'translate' ] = setupGizmo( pickerTranslate ) );
			this.add( this.picker[ 'rotate' ] = setupGizmo( pickerRotate ) );
			this.add( this.picker[ 'scale' ] = setupGizmo( pickerScale ) );
			this.add( this.helper[ 'translate' ] = setupGizmo( helperTranslate ) );
			this.add( this.helper[ 'rotate' ] = setupGizmo( helperRotate ) );
			this.add( this.helper[ 'scale' ] = setupGizmo( helperScale ) );

			// Pickers should be hidden always

			this.picker[ 'translate' ].visible = false;
			this.picker[ 'rotate' ].visible = false;
			this.picker[ 'scale' ].visible = false;

		}

		// updateMatrixWorld will update transformations and appearance of individual handles

		updateMatrixWorld( force ) {

			const space = ( this.mode === 'scale' ) ? 'local' : this.space; // scale always oriented to local rotation

			const quaternion = ( space === 'local' ) ? this.worldQuaternion : _identityQuaternion;

			// Show only gizmos for current transform mode

			this.gizmo[ 'translate' ].visible = this.mode === 'translate';
			this.gizmo[ 'rotate' ].visible = this.mode === 'rotate';
			this.gizmo[ 'scale' ].visible = this.mode === 'scale';

			this.helper[ 'translate' ].visible = this.mode === 'translate';
			this.helper[ 'rotate' ].visible = this.mode === 'rotate';
			this.helper[ 'scale' ].visible = this.mode === 'scale';


			let handles = [];
			handles = handles.concat( this.picker[ this.mode ].children );
			handles = handles.concat( this.gizmo[ this.mode ].children );
			handles = handles.concat( this.helper[ this.mode ].children );

			for ( let i = 0; i < handles.length; i ++ ) {

				const handle = handles[ i ];

				// hide aligned to camera

				handle.visible = true;
				handle.rotation.set( 0, 0, 0 );
				handle.position.copy( this.worldPosition );

				let factor;

				if ( this.camera.isOrthographicCamera ) {

					factor = ( this.camera.top - this.camera.bottom ) / this.camera.zoom;

				} else {

					factor = this.worldPosition.distanceTo( this.cameraPosition ) * Math.min( 1.9 * Math.tan( Math.PI * this.camera.fov / 360 ) / this.camera.zoom, 7 );

				}

				handle.scale.set( 1, 1, 1 ).multiplyScalar( factor * this.size / 4 );

				// TODO: simplify helpers and consider decoupling from gizmo

				if ( handle.tag === 'helper' ) {

					handle.visible = false;

					if ( handle.name === 'AXIS' ) {

						handle.visible = !! this.axis;

						if ( this.axis === 'X' ) {

							_tempQuaternion.setFromEuler( _tempEuler.set( 0, 0, 0 ) );
							handle.quaternion.copy( quaternion ).multiply( _tempQuaternion );

							if ( Math.abs( _alignVector.copy( _unitX ).applyQuaternion( quaternion ).dot( this.eye ) ) > 0.9 ) {

								handle.visible = false;

							}

						}

						if ( this.axis === 'Y' ) {

							_tempQuaternion.setFromEuler( _tempEuler.set( 0, 0, Math.PI / 2 ) );
							handle.quaternion.copy( quaternion ).multiply( _tempQuaternion );

							if ( Math.abs( _alignVector.copy( _unitY ).applyQuaternion( quaternion ).dot( this.eye ) ) > 0.9 ) {

								handle.visible = false;

							}

						}

						if ( this.axis === 'Z' ) {

							_tempQuaternion.setFromEuler( _tempEuler.set( 0, Math.PI / 2, 0 ) );
							handle.quaternion.copy( quaternion ).multiply( _tempQuaternion );

							if ( Math.abs( _alignVector.copy( _unitZ ).applyQuaternion( quaternion ).dot( this.eye ) ) > 0.9 ) {

								handle.visible = false;

							}

						}

						if ( this.axis === 'XYZE' ) {

							_tempQuaternion.setFromEuler( _tempEuler.set( 0, Math.PI / 2, 0 ) );
							_alignVector.copy( this.rotationAxis );
							handle.quaternion.setFromRotationMatrix( _lookAtMatrix.lookAt( _zeroVector, _alignVector, _unitY ) );
							handle.quaternion.multiply( _tempQuaternion );
							handle.visible = this.dragging;

						}

						if ( this.axis === 'E' ) {

							handle.visible = false;

						}


					} else if ( handle.name === 'START' ) {

						handle.position.copy( this.worldPositionStart );
						handle.visible = this.dragging;

					} else if ( handle.name === 'END' ) {

						handle.position.copy( this.worldPosition );
						handle.visible = this.dragging;

					} else if ( handle.name === 'DELTA' ) {

						handle.position.copy( this.worldPositionStart );
						handle.quaternion.copy( this.worldQuaternionStart );
						_tempVector.set( 1e-10, 1e-10, 1e-10 ).add( this.worldPositionStart ).sub( this.worldPosition ).multiplyScalar( - 1 );
						_tempVector.applyQuaternion( this.worldQuaternionStart.clone().invert() );
						handle.scale.copy( _tempVector );
						handle.visible = this.dragging;

					} else {

						handle.quaternion.copy( quaternion );

						if ( this.dragging ) {

							handle.position.copy( this.worldPositionStart );

						} else {

							handle.position.copy( this.worldPosition );

						}

						if ( this.axis ) {

							handle.visible = this.axis.search( handle.name ) !== - 1;

						}

					}

					// If updating helper, skip rest of the loop
					continue;

				}

				// Align handles to current local or world rotation

				handle.quaternion.copy( quaternion );

				if ( this.mode === 'translate' || this.mode === 'scale' ) {

					// Hide translate and scale axis facing the camera

					const AXIS_HIDE_THRESHOLD = 0.99;
					const PLANE_HIDE_THRESHOLD = 0.2;

					if ( handle.name === 'X' ) {

						if ( Math.abs( _alignVector.copy( _unitX ).applyQuaternion( quaternion ).dot( this.eye ) ) > AXIS_HIDE_THRESHOLD ) {

							handle.scale.set( 1e-10, 1e-10, 1e-10 );
							handle.visible = false;

						}

					}

					if ( handle.name === 'Y' ) {

						if ( Math.abs( _alignVector.copy( _unitY ).applyQuaternion( quaternion ).dot( this.eye ) ) > AXIS_HIDE_THRESHOLD ) {

							handle.scale.set( 1e-10, 1e-10, 1e-10 );
							handle.visible = false;

						}

					}

					if ( handle.name === 'Z' ) {

						if ( Math.abs( _alignVector.copy( _unitZ ).applyQuaternion( quaternion ).dot( this.eye ) ) > AXIS_HIDE_THRESHOLD ) {

							handle.scale.set( 1e-10, 1e-10, 1e-10 );
							handle.visible = false;

						}

					}

					if ( handle.name === 'XY' ) {

						if ( Math.abs( _alignVector.copy( _unitZ ).applyQuaternion( quaternion ).dot( this.eye ) ) < PLANE_HIDE_THRESHOLD ) {

							handle.scale.set( 1e-10, 1e-10, 1e-10 );
							handle.visible = false;

						}

					}

					if ( handle.name === 'YZ' ) {

						if ( Math.abs( _alignVector.copy( _unitX ).applyQuaternion( quaternion ).dot( this.eye ) ) < PLANE_HIDE_THRESHOLD ) {

							handle.scale.set( 1e-10, 1e-10, 1e-10 );
							handle.visible = false;

						}

					}

					if ( handle.name === 'XZ' ) {

						if ( Math.abs( _alignVector.copy( _unitY ).applyQuaternion( quaternion ).dot( this.eye ) ) < PLANE_HIDE_THRESHOLD ) {

							handle.scale.set( 1e-10, 1e-10, 1e-10 );
							handle.visible = false;

						}

					}

				} else if ( this.mode === 'rotate' ) {

					// Align handles to current local or world rotation

					_tempQuaternion2.copy( quaternion );
					_alignVector.copy( this.eye ).applyQuaternion( _tempQuaternion.copy( quaternion ).invert() );

					if ( handle.name.search( 'E' ) !== - 1 ) {

						handle.quaternion.setFromRotationMatrix( _lookAtMatrix.lookAt( this.eye, _zeroVector, _unitY ) );

					}

					if ( handle.name === 'X' ) {

						_tempQuaternion.setFromAxisAngle( _unitX, Math.atan2( - _alignVector.y, _alignVector.z ) );
						_tempQuaternion.multiplyQuaternions( _tempQuaternion2, _tempQuaternion );
						handle.quaternion.copy( _tempQuaternion );

					}

					if ( handle.name === 'Y' ) {

						_tempQuaternion.setFromAxisAngle( _unitY, Math.atan2( _alignVector.x, _alignVector.z ) );
						_tempQuaternion.multiplyQuaternions( _tempQuaternion2, _tempQuaternion );
						handle.quaternion.copy( _tempQuaternion );

					}

					if ( handle.name === 'Z' ) {

						_tempQuaternion.setFromAxisAngle( _unitZ, Math.atan2( _alignVector.y, _alignVector.x ) );
						_tempQuaternion.multiplyQuaternions( _tempQuaternion2, _tempQuaternion );
						handle.quaternion.copy( _tempQuaternion );

					}

				}

				// Hide disabled axes
				handle.visible = handle.visible && ( handle.name.indexOf( 'X' ) === - 1 || this.showX );
				handle.visible = handle.visible && ( handle.name.indexOf( 'Y' ) === - 1 || this.showY );
				handle.visible = handle.visible && ( handle.name.indexOf( 'Z' ) === - 1 || this.showZ );
				handle.visible = handle.visible && ( handle.name.indexOf( 'E' ) === - 1 || ( this.showX && this.showY && this.showZ ) );

				// highlight selected axis

				handle.material._color = handle.material._color || handle.material.color.clone();
				handle.material._opacity = handle.material._opacity || handle.material.opacity;

				handle.material.color.copy( handle.material._color );
				handle.material.opacity = handle.material._opacity;

				if ( this.enabled && this.axis ) {

					if ( handle.name === this.axis ) {

						handle.material.color.setHex( 0xffff00 );
						handle.material.opacity = 1.0;

					} else if ( this.axis.split( '' ).some( function ( a ) {

						return handle.name === a;

					} ) ) {

						handle.material.color.setHex( 0xffff00 );
						handle.material.opacity = 1.0;

					}

				}

			}

			super.updateMatrixWorld( force );

		}

	}

	//

	class TransformControlsPlane extends Mesh {

		constructor() {

			super(
				new PlaneGeometry( 100000, 100000, 2, 2 ),
				new MeshBasicMaterial( { visible: false, wireframe: true, side: DoubleSide, transparent: true, opacity: 0.1, toneMapped: false } )
			);

			this.isTransformControlsPlane = true;

			this.type = 'TransformControlsPlane';

		}

		updateMatrixWorld( force ) {

			let space = this.space;

			this.position.copy( this.worldPosition );

			if ( this.mode === 'scale' ) space = 'local'; // scale always oriented to local rotation

			_v1.copy( _unitX ).applyQuaternion( space === 'local' ? this.worldQuaternion : _identityQuaternion );
			_v2.copy( _unitY ).applyQuaternion( space === 'local' ? this.worldQuaternion : _identityQuaternion );
			_v3.copy( _unitZ ).applyQuaternion( space === 'local' ? this.worldQuaternion : _identityQuaternion );

			// Align the plane for current transform mode, axis and space.

			_alignVector.copy( _v2 );

			switch ( this.mode ) {

				case 'translate':
				case 'scale':
					switch ( this.axis ) {

						case 'X':
							_alignVector.copy( this.eye ).cross( _v1 );
							_dirVector.copy( _v1 ).cross( _alignVector );
							break;
						case 'Y':
							_alignVector.copy( this.eye ).cross( _v2 );
							_dirVector.copy( _v2 ).cross( _alignVector );
							break;
						case 'Z':
							_alignVector.copy( this.eye ).cross( _v3 );
							_dirVector.copy( _v3 ).cross( _alignVector );
							break;
						case 'XY':
							_dirVector.copy( _v3 );
							break;
						case 'YZ':
							_dirVector.copy( _v1 );
							break;
						case 'XZ':
							_alignVector.copy( _v3 );
							_dirVector.copy( _v2 );
							break;
						case 'XYZ':
						case 'E':
							_dirVector.set( 0, 0, 0 );
							break;

					}

					break;
				case 'rotate':
				default:
					// special case for rotate
					_dirVector.set( 0, 0, 0 );

			}

			if ( _dirVector.length() === 0 ) {

				// If in rotate mode, make the plane parallel to camera
				this.quaternion.copy( this.cameraQuaternion );

			} else {

				_tempMatrix.lookAt( _tempVector.set( 0, 0, 0 ), _dirVector, _alignVector );

				this.quaternion.setFromRotationMatrix( _tempMatrix );

			}

			super.updateMatrixWorld( force );

		}

	}

	function boxHelper(targetMesh, program) {
	    const box = new BoxHelper( targetMesh, 0xffff00 );
	    program.scene.add(box);
	    return box
	}

	function transformControls(targetMesh, program) {
	    const control = new TransformControls( program.camera, program.renderer.domElement );
		//controls.attach( heart.mesh );
		control.attach( targetMesh );

	    const box = boxHelper(targetMesh, program);

	    const helper = control.getHelper();
	    program.scene.add(helper);
	    
	    return {
	        helper, control, box
	    }

	}

	function normalizePosition(pos = 0) {
		return pos / 100
	}
	function degtorad(deg = 0) {
		return deg * (Math.PI/180)
	}


	function planeFitPerspectiveCamera(plane, camera, relativeZ = null) {
	  const cameraZ = relativeZ !== null ? relativeZ : camera.position.z;
	  const distance = cameraZ - plane.position.z;
	  const vFov = camera.fov * Math.PI / 180;
	  const scaleY = 2 * Math.tan(vFov / 2) * distance;
	  const scaleX = scaleY * camera.aspect;
	  
	  plane.scale.set(scaleX, scaleY, 1);
	}



	const BLENDMODES = {
		"none": NoBlending ,
		"normal": NormalBlending ,
		"additive": AdditiveBlending,
		"subtractive": SubtractiveBlending ,
		"multiply": MultiplyBlending ,
		"custom": CustomBlending
	};


	const PARTICLE_TYPES = {
		'disc': 1,
		'ring': 2,
		'square': 3,
		'box': 4
	};

	function vertex$i() {
		return `
	vec4 clr(in vec4 pos) {
		return(pos);
	}
	`;
	}


	function fragment$i() {
		return `
	vec4 clr(in vec4 clr) {
		return(clr);
	}
	`
	}

	function vertex$j() {
		return `
	vec4 texr(in vec4 pos) {
		return(pos);
	}
	`;
	}


	function fragment$j() {
		return `
	vec4 texr(in vec4 color) {
		vec4 tex = texture2D(tMap, vUv);
		return(tex);
	}
	`
	}

	function vertex$k() {
		return `
	vec4 lighting(in vec4 pos) {
		return(pos);
	}
	`;
	}


	function fragment$k() {
		return `
	vec4 lighting(in vec4 clr) {
		vec3 normal = normalize(vNormal);

		vec3 light = normalize(uLight);
		float shading = dot(normal, light) * 0.15;

		vec4 ret = clr;
		ret.rgb = clr.rgb + shading;
		ret.a = clr.a;

		return(ret);
	}
	`
	}

	function addLineNumbers(string) {
	    let lines = string.split('\n');
	    for (let i = 0; i < lines.length; i ++) {
	        lines[i] = (i + 1) + ': ' + lines[i];
	    }
	    return lines.join('\n');
	}



	const vertex$l = `
precision highp float;
precision highp int;

attribute vec2 uv;
attribute vec3 position;
attribute vec3 normal;

uniform mat4 modelViewMatrix;
uniform mat4 projectionMatrix;
uniform mat3 normalMatrix;

varying vec2 vUv;
varying vec3 vNormal;
`;

	const fragment$l = `
precision highp float;
precision highp int;

varying vec2 vUv;
varying vec3 vNormal;

uniform sampler2D tMap;
uniform float uTime;
uniform vec3 uLight;
uniform vec4 uColor;
`;




	function testShaders(gl, v, f) {
		let hasErrors = false;

		// compile vertex shader and log errors
		const vertexShader = gl.createShader(gl.VERTEX_SHADER);
		gl.shaderSource(vertexShader, v);
		gl.compileShader(vertexShader);
		if (gl.getShaderInfoLog(vertexShader) !== '') {
			console.warn(`${gl.getShaderInfoLog(vertexShader)}\nVertex Shader\n${addLineNumbers(v)}`);
			hasErrors = true;
		}

		// compile fragment shader and log errors
		const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
		gl.shaderSource(fragmentShader, f);
		gl.compileShader(fragmentShader);
		if (gl.getShaderInfoLog(fragmentShader) !== '') {
			console.warn(`${gl.getShaderInfoLog(fragmentShader)}\nFragment Shader\n${addLineNumbers(f)}`);
			hasErrors = true;
		}

		return hasErrors
	}




	function createShaders(gl, materials) {

		const funcs = new Map();

		if (materials) {
			console.log("shader has nodes", materials.nodes);
			materials.each(n => {
				funcs.set(n.id, n);
			});
		}


		var v = vertex$l;

		funcs.forEach(n => {
			//console.log("material node", n, n.vertex, n.fragment, n.uniforms );
			if (n.uniforms) {
				n.uniforms.forEach(u => {
					v += `uniform ${u.type} ${u.name}; \n\r`;
				});
			}
		});


		v += vertex$i();
		v += vertex$j();

		funcs.forEach(n => {
			//console.log("material node", n, n.vertex, n.fragment, n.uniforms );
			v += n.vertex || '';
		});

		v += vertex$k();
		v += `

	void main() {
		vUv = uv;
		vNormal = normalize(normalMatrix * normal);

		vec4 pos = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
		pos = clr(pos);
		pos = texr(pos);
		pos = lighting(pos);

		gl_Position = pos;
	}`;

		var f = fragment$l;

		funcs.forEach(n => {
			//console.log("material node", n, n.vertex, n.fragment, n.uniforms );
			if (n.uniforms) {
				n.uniforms.forEach(u => {
					f += `uniform ${u.type} ${u.name}; \n\r`;
				});
			}
		});


		f += fragment$i();
		f += fragment$j();

		funcs.forEach(n => {
			//console.log("material node", n, n.vertex, n.fragment, n.uniforms );
			f += n.fragment || '';
		});

		f += fragment$k();
		f += `
	void main() {
		vec4 dest = uColor;
		dest = clr(dest);
		dest = texr(dest);
		dest = lighting(dest);

		gl_FragColor = dest;
	}`;

		const hasErrors = testShaders(gl, v, f);

		if (hasErrors) {
			return defaultShaders()
		}



		console.log({ v, f });

		return { vertex: v, fragment: f }
	}




	function defaultShaders() {
		const vertex = `
precision highp float;
precision highp int;
attribute vec2 uv;
attribute vec3 position;
attribute vec3 normal;
uniform mat4 modelViewMatrix;
uniform mat4 projectionMatrix;
uniform mat3 normalMatrix;
varying vec2 vUv;
varying vec3 vNormal;
void main() {
	vUv = uv;
	vNormal = normalize(normalMatrix * normal);

	gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}
`;

		const fragment = `
precision highp float;
precision highp int;

varying vec2 vUv;
varying vec3 vNormal;

uniform float uTime;
uniform sampler2D tMap;
uniform vec3 uLight;

void main() {
	vec3 normal = normalize(vNormal);
	vec4 tex = texture2D(tMap, vUv);

	vec3 light = normalize(uLight);
	float shading = dot(normal, light) * 0.15;

	gl_FragColor.rgb = tex.rgb + shading;
	gl_FragColor.a = tex.a;
}
	`;

		return { vertex, fragment }
	}

	class Textures {
		constructor({ width, height }) {
			this.width = width;
			this.height = height;
			this.images = [];
		}

		async init(color = {}, images = []) {
			
			this.color = color;

			const _this = this;

			function addStops(grad, stops) {
				for (let st of stops) {
					const { at = 0, color = {} } = st;
					const { h, s, l, a } = color;
					grad.addColorStop((st.at || 0) / 100,  `hsla(${h}, ${s}%, ${l}%, ${a})`);
				}
			}

			function blendImage(ctx, image) {
				const { blend = 'source-over', opacity = 100 } = image;

				ctx.globalCompositeOperation = blend;
				ctx.globalAlpha = opacity / 100;
			}

			function linear(conf) {
				var gr;
				const { image, params } = conf;
				const { stops, angle = 0 } = image;

				return {
					draw(ctx) {
						if (!gr) {
							var x1 = 0, y1 = 0, x2, y2;
							var ang = +angle / 180 * Math.PI;
							x2 = x1 + Math.cos(ang) * _this.width;
							y2 = y1 + Math.sin(ang) * _this.height;
							gr = ctx.createLinearGradient(x1, y1, x2, y2);
							addStops(gr, stops);
						}
						blendImage(ctx, image);
						ctx.fillStyle = gr;
						ctx.fillRect(0, 0, _this.width, _this.height);
					},
					init() { }
				}
			}

			function radial(conf) {
				var gr;
				const { image, params } = conf;
				const { stops } = image;

				return {
					draw(ctx) {
						if (!gr) {
							var x0 = 0, y0 = 0, r0 = 0, x1 = 0, y1 = 0, r1 = _this.width;

							gr = ctx.createRadialGradient(x0, y0, r0, x1, y1, r1);
							// Add three color stops
							addStops(gr, stops);
							blendImage(ctx, image);
							ctx.fillStyle = gr;
							ctx.fillRect(0, 0, _this.width, _this.height);
						}
					},
					init() { }
				}
			}


			function image(conf) {
				const { image, params } = conf;
				const { src, blend = 'source-over', opacity = 100 } = image;
				var img;
				return {
					draw(ctx) {

						blendImage(ctx, image);
						ctx.drawImage(img, 0, 0, _this.width, _this.height);
					},
					init() {
						return new Promise((resolve, reject) => {
							img = new Image();
							img.onload = function() {
								if (_this.width < img.width) {
									_this.width = img.width;
								}
								if (_this.height < img.height) {
									_this.height = img.height;
								}

								resolve(img);
							};
							img.src = src;
						})
					}
				}
			}

			const types = { linear, radial, image };

			this.images = Array.from(images).map(img => {
				if (!img && img.image) return
				const type = img.image.type;
				const func = types[type];
				if (!func) return
				return func(img)
			}).filter(Boolean);

			await Promise.all(this.images.map(img => img.init()));
		}


		draw(ctx) {
			const alpha = ctx.globalAlpha || 1;
			const blend = ctx.globalCompositeOperation || 'source-over';

			const { h = 100, s = 70, l = 70, a = 1 } = this.color;
			ctx.fillStyle = `hsla(${h}, ${s}%, ${l}%, ${a})`;
			ctx.fillRect(0,0,this.width,this.height);

			this.images.forEach(img => {
				img.draw(ctx);
			});
			// restore
			ctx.globalAlpha = alpha;
			ctx.globalCompositeOperation = blend;
		}
	}

	class Canvas {

		static instance(canvas, opts) {
			if (canvas instanceof Canvas) {
				return canvas
			}
			return new Canvas(canvas, opts)
		}

		constructor(elem, { ratio }) {
			this.elem = elem;

			this.ctx = elem.getContext("2d", {
				alpha: true,
				desynchronized: true,
				preserveDrawingBuffer: true
			});

			this.ratio = ratio;

			this.ctx.scale(ratio, ratio);
	    	//this.ctx.commit()

			const { width, height } = elem;
			this.setSize(width, height);
		}


		setSize(w, h) {
			// element should not be resized here in case this is an offscreen canvas
			// and we are running in a worker
			this.width = w / this.ratio;
			this.height = h / this.ratio;
		}

		clear() {
			const { width, height, ctx } = this;
			ctx.clearRect(0, 0, width, height);
		}

		clearGrid(dir, s = 2, g = s/2) {
			const { width, height, ctx } = this;
			if (dir !== 'h') {
				for (let i = 0; i <= width; i += s) {
					ctx.clearRect(i, 0, g, height);
				}
			}
			if (dir !== 'w') {
				for (let i = 0; i <= height; i += s) {
					ctx.clearRect(0, i, width, g);
				}
			}
		}

		clear() {
			const { width, height, ratio, ctx } = this;
			ctx.clearRect(0, 0, width, height);
		}


		drawText(text, params = {}) {
			const { width, height, ratio, ctx } = this;
			const { position } = params;


			ctx.font = params.font || '20px serif';
	        
	        
	        //const x = textWidth * (0.5 - alignX * 0.5);
	        //const y = 0.5 // * ((lineHeight * options.lineHeight || 1) - lineHeight);
			const textWidth = Math.ceil(ctx.measureText(text).width) * ratio;

			let tx = position.x;
			let ty = position.y;

			if (params.textAlign === 'right') {
				ctx.textAlign = "right";
				tx = width - tx;
				ty = height - ty;
			} else if (params.textAlign === 'left') {
				ctx.textAlign = "left";
			} else {
				ctx.textAlign = "center";
				tx = width / 2;
				ty = height / 2;
			}

			// console.log("textWidth", textWidth, tx, ty );
			
	        ctx.fillStyle = params.color || 'black';
	        ctx.fillText(text, tx, ty);

		}


		plot(data, opts = {}) {
			const { width, height, ctx } = this;
			const { mid } = opts;

			ctx.clearRect(0,0, width, height);

			const l = data.length, bar = width/(l || 1);

			for (let i=0; i<l; i++) {

				const pt = data[i];
				//const peak = peaks[i]

				const bh = pt.value / 100 * height;
				//const ph = peak.value / 100 * height

				const barw = bar-1;
				const m = mid / 100;


				ctx.fillStyle = '#fff';
				ctx.fillRect(i*bar, (height - bh)*m, barw, bh);


				// mid line
				ctx.clearRect(0, height*m, width, 1);

			}

		}

		lines(data, opts = {}) {
			const { width, height, ctx } = this;
			const { mid } = opts;

			const l = data.length, bar = width/(l || 1);
			for (let i=0; i<l; i++) {

				const pt = data[i];
				//const peak = peaks[i]

				const bh = pt.value / 100 * height;
				//const ph = peak.value / 100 * height

				const barw = bar-1;
				const m = mid / 100;

				ctx.fillStyle = '#fff';
				ctx.fillRect(i*bar, (height - bh)*m, barw, 1);

			}

		}



	}

	async function createCanvas(width, height) {

		// TODO: check if this is in a worker context
		// then get a reference to an offscreen canvas
		//
		// setting pixel ratio has a problem with tex cords and uv unwrapped images
		const ratio = 1;
		const el = document.createElement('canvas');
		el.width = (width || 100) * ratio;
		el.height = (height || 100) * ratio;

		//document.body.appendChild(el)
		//el.style.cssText = `position:absolute;left: 0;top: 0;z-index:2000;`

		const texCanvas = Canvas.instance(el, { ratio });
		return texCanvas
	}

	class Tex {
		constructor() {

		}
		init(params) {
			var textures, canvas;

			this.update = async (params) => {
				textures = new Textures({ width: 256, height: 256 });

				await textures.init(params.color, params.texture);

				if (!canvas) {
					canvas = await createCanvas(textures.width, textures.height);
				}
				// TODO: remove offscreen refs and resize canvas

				canvas.clear();
				textures.draw(canvas.ctx);

				let imageData = canvas.ctx.getImageData(0, 0, textures.width, textures.height);
				this.image = imageData;
			};

			//await this.update(params)
		}
	}

	// TODO: facilitate Compressed Textures
	// TODO: cube map
	// TODO: delete texture
	// TODO: should I support anisotropy? Maybe a way to extend the update easily
	// TODO: check is ArrayBuffer.isView is best way to check for Typed Arrays?
	// TODO: use texSubImage2D for updates
	// TODO: need? encoding = linearEncoding

	const emptyPixel = new Uint8Array(4);

	function isPowerOf2(value) {
	    return (value & (value - 1)) === 0;
	}

	let ID = 0;

	class Texture$1 {
	    constructor(gl, {
	        image,
	        target = gl.TEXTURE_2D,
	        type = gl.UNSIGNED_BYTE,
	        format = gl.RGBA,
	        internalFormat = format,
	        wrapS = gl.CLAMP_TO_EDGE,
	        wrapT = gl.CLAMP_TO_EDGE,
	        generateMipmaps = true,
	        minFilter = generateMipmaps ? gl.NEAREST_MIPMAP_LINEAR : gl.LINEAR,
	        magFilter = gl.LINEAR,
	        premultiplyAlpha = false,
	        unpackAlignment = 4,
	        flipY = true,
	        level = 0,
	        width, // used for RenderTargets or Data Textures
	        height = width,
	    } = {}) {
	        this.gl = gl;
	        this.id = ID++;

	        this.image = image;
	        this.target = target;
	        this.type = type;
	        this.format = format;
	        this.internalFormat = internalFormat;
	        this.minFilter = minFilter;
	        this.magFilter = magFilter;
	        this.wrapS = wrapS;
	        this.wrapT = wrapT;
	        this.generateMipmaps = generateMipmaps;
	        this.premultiplyAlpha = premultiplyAlpha;
	        this.unpackAlignment = unpackAlignment;
	        this.flipY = flipY;
	        this.level = level;
	        this.width = width;
	        this.height = height;
	        this.texture = this.gl.createTexture();

	        this.store = {
	            image: null,
	        };

	        // Alias for state store to avoid redundant calls for global state
	        this.glState = this.gl.renderer.state;

	        // State store to avoid redundant calls for per-texture state
	        this.state = {};
	        this.state.minFilter = this.gl.NEAREST_MIPMAP_LINEAR;
	        this.state.magFilter = this.gl.LINEAR;
	        this.state.wrapS = this.gl.REPEAT;
	        this.state.wrapT = this.gl.REPEAT;
	    }

	    bind() {

	        // Already bound to active texture unit
	        if (this.glState.textureUnits[this.glState.activeTextureUnit] === this.id) return;
	        this.gl.bindTexture(this.target, this.texture);
	        this.glState.textureUnits[this.glState.activeTextureUnit] = this.id;
	    }

	    update(textureUnit = 0) {
	        const needsUpdate = !(this.image === this.store.image && !this.needsUpdate);

	        // Make sure that texture is bound to its texture unit
	        if (needsUpdate || this.glState.textureUnits[textureUnit] !== this.id) {

	            // set active texture unit to perform texture functions
	            this.gl.renderer.activeTexture(textureUnit);
	            this.bind();
	        }

	        if (!needsUpdate) return;
	        this.needsUpdate = false;

	        if (this.flipY !== this.glState.flipY) {
	            this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, this.flipY);
	            this.glState.flipY = this.flipY;
	        }

	        if (this.premultiplyAlpha !== this.glState.premultiplyAlpha) {
	            this.gl.pixelStorei(this.gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, this.premultiplyAlpha);
	            this.glState.premultiplyAlpha = this.premultiplyAlpha;
	        }

	        if (this.unpackAlignment !== this.glState.unpackAlignment) {
	            this.gl.pixelStorei(this.gl.UNPACK_ALIGNMENT, this.unpackAlignment);
	            this.glState.unpackAlignment = this.unpackAlignment;
	        }

	        if (this.minFilter !== this.state.minFilter) {
	            this.gl.texParameteri(this.target, this.gl.TEXTURE_MIN_FILTER, this.minFilter);
	            this.state.minFilter = this.minFilter;
	        }

	        if (this.magFilter !== this.state.magFilter) {
	            this.gl.texParameteri(this.target, this.gl.TEXTURE_MAG_FILTER, this.magFilter);
	            this.state.magFilter = this.magFilter;
	        }

	        if (this.wrapS !== this.state.wrapS) {
	            this.gl.texParameteri(this.target, this.gl.TEXTURE_WRAP_S, this.wrapS);
	            this.state.wrapS = this.wrapS;
	        }

	        if (this.wrapT !== this.state.wrapT) {
	            this.gl.texParameteri(this.target, this.gl.TEXTURE_WRAP_T, this.wrapT);
	            this.state.wrapT = this.wrapT;
	        }

	        if (this.image) {

	            if (this.image.width) {
	                this.width = this.image.width;
	                this.height = this.image.height;
	            }

	            // TODO: all sides if cubemap
	            // gl.TEXTURE_CUBE_MAP_POSITIVE_X
	            
	            // TODO: check is ArrayBuffer.isView is best way to check for Typed Arrays?
	            if (this.gl.renderer.isWebgl2 || ArrayBuffer.isView(this.image)) {
	                this.gl.texImage2D(this.target, this.level, this.internalFormat, this.width, this.height, 0 /* border */, this.format, this.type, this.image);
	            } else {
	                this.gl.texImage2D(this.target, this.level, this.internalFormat, this.format, this.type, this.image);
	            }

	            // TODO: support everything
	            // WebGL1:
	            // gl.texImage2D(target, level, internalformat, width, height, border, format, type, ArrayBufferView? pixels);
	            // gl.texImage2D(target, level, internalformat, format, type, ImageData? pixels);
	            // gl.texImage2D(target, level, internalformat, format, type, HTMLImageElement? pixels);
	            // gl.texImage2D(target, level, internalformat, format, type, HTMLCanvasElement? pixels);
	            // gl.texImage2D(target, level, internalformat, format, type, HTMLVideoElement? pixels);
	            // gl.texImage2D(target, level, internalformat, format, type, ImageBitmap? pixels);

	            // WebGL2:
	            // gl.texImage2D(target, level, internalformat, width, height, border, format, type, GLintptr offset);
	            // gl.texImage2D(target, level, internalformat, width, height, border, format, type, HTMLCanvasElement source);
	            // gl.texImage2D(target, level, internalformat, width, height, border, format, type, HTMLImageElement source);
	            // gl.texImage2D(target, level, internalformat, width, height, border, format, type, HTMLVideoElement source);
	            // gl.texImage2D(target, level, internalformat, width, height, border, format, type, ImageBitmap source);
	            // gl.texImage2D(target, level, internalformat, width, height, border, format, type, ImageData source);
	            // gl.texImage2D(target, level, internalformat, width, height, border, format, type, ArrayBufferView srcData, srcOffset);

	            if (this.generateMipmaps) {

	                // For WebGL1, if not a power of 2, turn off mips, set wrapping to clamp to edge and minFilter to linear
	                if (!this.gl.renderer.isWebgl2 && (!isPowerOf2(this.image.width) || !isPowerOf2(this.image.height))) {
	                    this.generateMipmaps = false;
	                    this.wrapS = this.wrapT = this.gl.CLAMP_TO_EDGE;
	                    this.minFilter = this.gl.LINEAR;
	                } else {
	                    this.gl.generateMipmap(this.target);
	                }
	            }
	        } else {

	            if (this.width) {

	                // image intentionally left null for RenderTarget
	                this.gl.texImage2D(this.target, this.level, this.internalFormat, this.width, this.height, 0, this.format, this.type, null);
	            } else {

	                // Upload empty pixel if no image to avoid errors while image or video loading
	                this.gl.texImage2D(this.target, 0, this.gl.RGBA, 1, 1, 0, this.gl.RGBA, this.gl.UNSIGNED_BYTE, emptyPixel);
	            }

	        }
	        this.store.image = this.image;

	        this.onUpdate && this.onUpdate();
	    }
	}

	const _transition_ = Symbol('transition');


	const MATERIALS = {
		basic: MeshBasicMaterial,
		standard: MeshStandardMaterial,
		physical: MeshPhysicalMaterial,
		normal: MeshNormalMaterial,
		depth: MeshDepthMaterial
	};


	function hslToRgb(h, s, l, a){
	    var r, g, b;

	    if(s == 0){
	        r = g = b = l; // achromatic
	    }else {
	        var hue2rgb = function hue2rgb(p, q, t){
	            if(t < 0) t += 1;
	            if(t > 1) t -= 1;
	            if(t < 1/6) return p + (q - p) * 6 * t;
	            if(t < 1/2) return q;
	            if(t < 2/3) return p + (q - p) * (2/3 - t) * 6;
	            return p;
	        };

	        var q = l < 0.5 ? l * (1 + s) : l + s - l * s;
	        var p = 2 * l - q;
	        r = hue2rgb(p, q, h + 1/3);
	        g = hue2rgb(p, q, h);
	        b = hue2rgb(p, q, h - 1/3);
	    }

	    return [r, g, b, a];
	}


	//const dracoLoader = new DRACOLoader();
	//dracoLoader.setDecoderPath('three/examples/jsm/libs/draco/gltf/'); // e.g., 'https://www.gstatic.com/draco/v1/decoders/' or a local path

	class Shape$1 {
	    constructor(entity, ...rest) {

			// console.log("SHAPE INIT", entity, rest);

			this.entity = entity;

	        this.attrs = new Style({}, this);
	        this.style = new Style({}, this);
	    }

		set params(params) {
			this._params = params;
			this.removeNodes();
		}
		get params() {
			return this._params
		}

		get filters() {
			return this._filters
		}

		set filters(filters) {
			this._filters = filters;
			this.removeNodes();
	//		console.log("got filters", filters);
		}

		// material nodes
		get materials() {
			return this.filters && this.filters.get('material')
		}

		// texture nodes
		get textures() {
			if (this._texs) {
				return this._texs
			}

			this._texs = new Tex();
			this._texs.init();

			return this._texs
		}

	    setAttribute(name, value) {
	        this.attrs.set(name, value);
	        //this.attrs[name] = value
	        //console.log("SET ATTR", name, value);
	    }
	    getAttribute(name) {
	        //console.log("GET ATTR", name);
	        return this.attrs[name]
	        //return this.attrs[name]
	    }
	    removeAttribute(name) {
	        delete this.attrs[name];
	    }

	    replaceChild(node) {
	        console.log("REPLACE CHILD", node);
	    }

	    removeChild(node) {
	        console.log("REMOVE CHILD", node);
	    }

	    insertBefore(node, target) {
	        console.log("insertBefore CHILD", node, target);
	    }

	    get parentNode() {
	        return this._parent
	    }
		set parentNode(node) {
	        this._parent = node;
	    }

	    get childNodes() {
	        return this.children
	    }

		appendChild(node) {
			node.parentNode = this;

	        if (!this.children) {
	            this.children = [];
	        }
	        this.children.push(node);
	    }

		get props() {
	        return this._props
	    }

	    set props(props) {
	        this._props = props;
	        console.log("WEBGL SHAPE::: setting props", props, this);
	    }


	    get properties() {
	        return this._props
	    }

	    set properties(props) {
	        this._props = props;
	        console.log("WEBGL SHAPE::: setting properties", props, this);
	    }

	    set transition(trans) {
	        this[_transition_] = trans;

	        const DEFAULT_EASING = {
	            'ease': TWEEN.Easing.Quadratic.InOut,
	            'ease-in': TWEEN.Easing.Quadratic.In,
	            'ease-out': TWEEN.Easing.Quadratic.Out,
	            'ease-in-out': TWEEN.Easing.Cubic.InOut,
	            'linear': TWEEN.Easing.Linear.None,
	            stepFunc: function(step) {
	                return function(k) {
	                    return (Math.floor(k * step) / step);
	                }
	            }
	        };

	        for (let key of Object.keys(trans)) {
				let tr = trans[key];
				if (typeof tr === 'string') {
					console.error('TR IS A STRING');
					continue;
				}

	            if (typeof tr.easing === 'object') {
	                if (tr.easing.bezier) {
	                    let args = tr.easing.bezier.args[0];
	                    let dur = tr.duration * 1000;
	                    let epsilon = (1000 / 60 / dur) / 4;
	                    tr.ease = Bezier(...args, epsilon);
	                } else if (tr.easing.func) {
	                    let args = tr.easing.func.args[0];
	                    let F = TWEEN.Easing[args[0]] || TWEEN.Easing.Linear;
	                    let ease = F[args[1]] || F.None;
	                    tr.ease = ease;
	                } else if (tr.easing.steps) {
	                    let step = tr.easing.steps.args[0];
	                    tr.ease = DEFAULT_EASING.stepFunc(step);
	                }
	            } else {
	                tr.ease = DEFAULT_EASING[tr.easing];
	            }
	        }
	        //console.log("************* TRANSITION SET ", trans);

	    }
	    get transition() {
	        return this[_transition_] || {}
	    }


		set __scope(context) {
			console.log("setting scope", context);
		}

		set styles(styles) {
			console.log("SHAPE SET STYLES", styles, this, this.style);
			Object.assign(this.style, styles);
		}
		get styles() {
			return this.params
		}


		// expressions will call this function to set the value of a mesh/shader
		setStyleProps(styles) {
			//console.log("SET >>>>>>>>><<<<<<<<<<< STYLE PROPS", this, styles);
			
			if (!this.mesh) { return }

			if (styles.transform) {

				const pos = this.position;
				const translate = styles.transform.translate;

				const x = pos[0] + translate[0];
				const y = pos[1] + translate[1];
				const z = pos[2] + translate[2];

				this.mesh.position.set(x, y, z);
			}

			if (this.applyStyle) {
				Object.entries(styles).forEach(([key, param]) => {
					this.applyStyle(key, param);
				});
			}
		}


		get position() {
			const tr = this.params.transform || {};
			const translate = tr.translate || {};
			const x = normalizePosition(translate.x);
			const y = normalizePosition((translate.y || 0) * -1);
			const z = normalizePosition(translate.z);

			return [x, y, z]
		}
		get rotation() {
			const tr = this.params.transform || {};
			const rotate = tr.rotate || {};
			const x = degtorad(rotate.x);
			const y = degtorad(rotate.y);
			const z = degtorad(rotate.z);
			return [x, y, z]
		}
		get scale() {
			const tr = this.params.transform || {};
			const scale = tr.scale || {};
			const x = scale.x || 1;
			const y = scale.y || 1;
			const z = scale.z || 1;
			return [x, y, z]
		}

		get color() {

			const texture = this.params.texture || {};

			const c = texture.color || this.params.color || {};
			const { h = 130, s = 80, l = 50, a = 1 } = c;
			const rgb = hslToRgb(h/360, s/100, l/100, a);
			return rgb //hslToRgb(h/360, s/100, l/100)
		}

		get colorAlpha() {
			const c = this.params.color || {};
			return c.a || 1
		}

		getGeometry(program) {

			const planeGeometry = new PlaneGeometry(
				this.params.width
				,this.params.height, 32, 32);

			return planeGeometry
		}

		getShaders(gl) {
			let shdrs = createShaders(gl, );
			let { vertex, fragment } = shdrs;
			return [vertex, fragment]
		}

		getMaterial(program) {
			const color = new Color(...this.color);

			console.log("CUBE MATERIAL", this.params);

			const { materialType = 'standard' } = this.params;

			const Material = MATERIALS[materialType] || MeshBasicMaterial;


			const material = new Material({ 
				color
			});
			return material
		}


		// default mesh
		createMesh(program) {		
			const geometry = this.getGeometry(program);
			const material = this.getMaterial(program);

			const mesh = new Mesh(geometry, material);
			this.applyTransforms(mesh);
			return mesh;
		}


		applyTransforms(mesh) {
			mesh.position.set(...this.position);
			mesh.rotation.set(...this.rotation);
			mesh.scale.set(...this.scale);
		}


		get controls() {
			return this._controls 
		}

		set controls(state = false) {
			this._controls = state;

			
		}

		toggleControls(program) {
			if (!this.__ctrls && this.mesh) {
				this.__ctrls = transformControls(this.mesh, program);
			} else {
				if (this.__ctrls) {
					this.__ctrls.dispose();
				}
			}
		}




		createNode(program, parent) {

			const mesh = this.createMesh(program);
			// mesh.onBeforeRender = updateColor

			// console.log("new node created", mesh, parent)

			if (mesh) {
				//console.log("PARENT ADDING MESH", mesh, parent)
				parent.add(mesh);
			} else {
				console.warn("Shape did not return a mesh", this);
			}
			

			//console.log("drawing webgl mesh", mesh, this)
			return mesh
		}



	    node(program, parent) {

			//console.log("making node for ", this, program, parent)

			this.context = program.context;

			if (!this.mesh) {
				this.mesh = this.createNode(program, parent);
				//if (this.controls) {
				//	this.toggleControls(program);
				//}
			}

			//this.mesh.$____parent = parent
			if (this.mesh) {
				this.getChildNodes(program, this.mesh);
			}
			
			return this.mesh
	    }

		removeNodes() {
			console.log("removing nodes", this.mesh);
			if (this.mesh && this.mesh.parent) {
				this.mesh.parent.remove(this.mesh);
			}
			this.mesh = null;
			this.geometry = null;
		}


		getChildNodes(program, parent) {

			// console.log("get children of node", program)

	        var child;
	        if (this.children) {
	            for (child of this.children) {
	                child.node(program, parent);
	            }
	        }
	    }


		updateChildNodes(program, parent) {
	        var child;
	        if (this.children) {
	            for (child of this.children) {
	                child.updateNode(program, parent);
	            }
	        }
	    }



		updateNode(program, parent) {
			//this.removeNodes(program, parent)
			if (this.mesh) {
				return;
			}
			const node = this.node(program, parent);
			this.updateChildNodes(program, node);
		}

		update(program, parent) {
			if (this.beforeUpdate) {
				this.beforeUpdate(program);
			}
			console.log("SCENE UPDATING with program", program);
			this.updateNode(program, parent);
		}

		render(context) {
			this.parentNode.render(context);
		}



		destroyMesh() {
	        if (this.children) {
	            for (let child of this.children) {
					if (child.destroy) {
						child.destroy();
					}

					if (child.destroyMesh) {
						child.destroyMesh();
					} else {
						if (child.isMesh) {
							console.log("FOUND MESH", child);
						}
					}
	                
	            }
	        }
		}


		async loadGLTF(url, program) {

			const { assetManager } = program;

			const modelPromise = new Promise((resolve, reject) => {
				const loader = new GLTFLoader(assetManager);
				//loader.setDRACOLoader(dracoLoader);

				loader.load(url, function(resp) {
					resolve(resp);
				});
			});

			// MODDEL_LOADERS[url]  = modelPromise

			return modelPromise
		}


		tick(context) {
			
			if (this._tick) {
				this._tick(context);
			}
			const children = this.childNodes;
			if (children && children.length) {
				for (let child of children) {
					child.tick(context);
				}
			}
		}


	}


	class Empty extends Shape$1 {

		// default mesh
		createMesh(program) {		
			const group = new Group$1();
			return group;
		}
	}

	/**
	 * Main content for the worker that handles the loading and execution of
	 * modules within it.
	 */
	function workerBootstrap() {
	  var modules = Object.create(null);

	  // Handle messages for registering a module
	  function registerModule(ref, callback) {
	    var id = ref.id;
	    var name = ref.name;
	    var dependencies = ref.dependencies; if ( dependencies === void 0 ) dependencies = [];
	    var init = ref.init; if ( init === void 0 ) init = function(){};
	    var getTransferables = ref.getTransferables; if ( getTransferables === void 0 ) getTransferables = null;

	    // Only register once
	    if (modules[id]) { return }

	    try {
	      // If any dependencies are modules, ensure they're registered and grab their value
	      dependencies = dependencies.map(function (dep) {
	        if (dep && dep.isWorkerModule) {
	          registerModule(dep, function (depResult) {
	            if (depResult instanceof Error) { throw depResult }
	          });
	          dep = modules[dep.id].value;
	        }
	        return dep
	      });

	      // Rehydrate functions
	      init = rehydrate(("<" + name + ">.init"), init);
	      if (getTransferables) {
	        getTransferables = rehydrate(("<" + name + ">.getTransferables"), getTransferables);
	      }

	      // Initialize the module and store its value
	      var value = null;
	      if (typeof init === 'function') {
	        value = init.apply(void 0, dependencies);
	      } else {
	        console.error('worker module init function failed to rehydrate');
	      }
	      modules[id] = {
	        id: id,
	        value: value,
	        getTransferables: getTransferables
	      };
	      callback(value);
	    } catch(err) {
	      if (!(err && err.noLog)) {
	        console.error(err);
	      }
	      callback(err);
	    }
	  }

	  // Handle messages for calling a registered module's result function
	  function callModule(ref, callback) {
	    var ref$1;

	    var id = ref.id;
	    var args = ref.args;
	    if (!modules[id] || typeof modules[id].value !== 'function') {
	      callback(new Error(("Worker module " + id + ": not found or its 'init' did not return a function")));
	    }
	    try {
	      var result = (ref$1 = modules[id]).value.apply(ref$1, args);
	      if (result && typeof result.then === 'function') {
	        result.then(handleResult, function (rej) { return callback(rej instanceof Error ? rej : new Error('' + rej)); });
	      } else {
	        handleResult(result);
	      }
	    } catch(err) {
	      callback(err);
	    }
	    function handleResult(result) {
	      try {
	        var tx = modules[id].getTransferables && modules[id].getTransferables(result);
	        if (!tx || !Array.isArray(tx) || !tx.length) {
	          tx = undefined; //postMessage is very picky about not passing null or empty transferables
	        }
	        callback(result, tx);
	      } catch(err) {
	        console.error(err);
	        callback(err);
	      }
	    }
	  }

	  function rehydrate(name, str) {
	    var result = void 0;
	    self.troikaDefine = function (r) { return result = r; };
	    var url = URL.createObjectURL(
	      new Blob(
	        [("/** " + (name.replace(/\*/g, '')) + " **/\n\ntroikaDefine(\n" + str + "\n)")],
	        {type: 'application/javascript'}
	      )
	    );
	    try {
	      importScripts(url);
	    } catch(err) {
	      console.error(err);
	    }
	    URL.revokeObjectURL(url);
	    delete self.troikaDefine;
	    return result
	  }

	  // Handler for all messages within the worker
	  self.addEventListener('message', function (e) {
	    var ref = e.data;
	    var messageId = ref.messageId;
	    var action = ref.action;
	    var data = ref.data;
	    try {
	      // Module registration
	      if (action === 'registerModule') {
	        registerModule(data, function (result) {
	          if (result instanceof Error) {
	            postMessage({
	              messageId: messageId,
	              success: false,
	              error: result.message
	            });
	          } else {
	            postMessage({
	              messageId: messageId,
	              success: true,
	              result: {isCallable: typeof result === 'function'}
	            });
	          }
	        });
	      }
	      // Invocation
	      if (action === 'callModule') {
	        callModule(data, function (result, transferables) {
	          if (result instanceof Error) {
	            postMessage({
	              messageId: messageId,
	              success: false,
	              error: result.message
	            });
	          } else {
	            postMessage({
	              messageId: messageId,
	              success: true,
	              result: result
	            }, transferables || undefined);
	          }
	        });
	      }
	    } catch(err) {
	      postMessage({
	        messageId: messageId,
	        success: false,
	        error: err.stack
	      });
	    }
	  });
	}

	/**
	 * Fallback for `defineWorkerModule` that behaves identically but runs in the main
	 * thread, for when the execution environment doesn't support web workers or they
	 * are disallowed due to e.g. CSP security restrictions.
	 */
	function defineMainThreadModule(options) {
	  var moduleFunc = function() {
	    var args = [], len = arguments.length;
	    while ( len-- ) args[ len ] = arguments[ len ];

	    return moduleFunc._getInitResult().then(function (initResult) {
	      if (typeof initResult === 'function') {
	        return initResult.apply(void 0, args)
	      } else {
	        throw new Error('Worker module function was called but `init` did not return a callable function')
	      }
	    })
	  };
	  moduleFunc._getInitResult = function() {
	    // We can ignore getTransferables in main thread. TODO workerId?
	    var dependencies = options.dependencies;
	    var init = options.init;

	    // Resolve dependencies
	    dependencies = Array.isArray(dependencies) ? dependencies.map(function (dep) {
	      if (dep) {
	        // If it's a worker module, use its main thread impl
	        dep = dep.onMainThread || dep;
	        // If it's a main thread worker module, use its init return value
	        if (dep._getInitResult) {
	          dep = dep._getInitResult();
	        }
	      }
	      return dep
	    }) : [];

	    // Invoke init with the resolved dependencies
	    var initPromise = Promise.all(dependencies).then(function (deps) {
	      return init.apply(null, deps)
	    });

	    // Cache the resolved promise for subsequent calls
	    moduleFunc._getInitResult = function () { return initPromise; };

	    return initPromise
	  };
	  return moduleFunc
	}

	var supportsWorkers = function () {
	  var supported = false;

	  // Only attempt worker initialization in browsers; elsewhere it would just be
	  // noise e.g. loading into a Node environment for SSR.
	  if (typeof window !== 'undefined' && typeof window.document !== 'undefined') {
	    try {
	      // TODO additional checks for things like importScripts within the worker?
	      //  Would need to be an async check.
	      var worker = new Worker(
	        URL.createObjectURL(new Blob([''], { type: 'application/javascript' }))
	      );
	      worker.terminate();
	      supported = true;
	    } catch (err) {
	      if (typeof process !== 'undefined' && process.env.NODE_ENV === 'test') ; else {
	        console.log(
	          ("Troika createWorkerModule: web workers not allowed; falling back to main thread execution. Cause: [" + (err.message) + "]")
	        );
	      }
	    }
	  }

	  // Cached result
	  supportsWorkers = function () { return supported; };
	  return supported
	};

	var _workerModuleId = 0;
	var _messageId = 0;
	var _allowInitAsString = false;
	var workers = Object.create(null);
	var registeredModules = Object.create(null); //workerId -> Set<unregisterFn>
	var openRequests = Object.create(null);


	/**
	 * Define a module of code that will be executed with a web worker. This provides a simple
	 * interface for moving chunks of logic off the main thread, and managing their dependencies
	 * among one another.
	 *
	 * @param {object} options
	 * @param {function} options.init
	 * @param {array} [options.dependencies]
	 * @param {function} [options.getTransferables]
	 * @param {string} [options.name]
	 * @param {string} [options.workerId]
	 * @return {function(...[*]): {then}}
	 */
	function defineWorkerModule(options) {
	  if ((!options || typeof options.init !== 'function') && !_allowInitAsString) {
	    throw new Error('requires `options.init` function')
	  }
	  var dependencies = options.dependencies;
	  var init = options.init;
	  var getTransferables = options.getTransferables;
	  var workerId = options.workerId;

	  var onMainThread = defineMainThreadModule(options);

	  if (workerId == null) {
	    workerId = '#default';
	  }
	  var id = "workerModule" + (++_workerModuleId);
	  var name = options.name || id;
	  var registrationPromise = null;

	  dependencies = dependencies && dependencies.map(function (dep) {
	    // Wrap raw functions as worker modules with no dependencies
	    if (typeof dep === 'function' && !dep.workerModuleData) {
	      _allowInitAsString = true;
	      dep = defineWorkerModule({
	        workerId: workerId,
	        name: ("<" + name + "> function dependency: " + (dep.name)),
	        init: ("function(){return (\n" + (stringifyFunction(dep)) + "\n)}")
	      });
	      _allowInitAsString = false;
	    }
	    // Grab postable data for worker modules
	    if (dep && dep.workerModuleData) {
	      dep = dep.workerModuleData;
	    }
	    return dep
	  });

	  function moduleFunc() {
	    var args = [], len = arguments.length;
	    while ( len-- ) args[ len ] = arguments[ len ];

	    if (!supportsWorkers()) {
	      return onMainThread.apply(void 0, args)
	    }

	    // Register this module if needed
	    if (!registrationPromise) {
	      registrationPromise = callWorker(workerId,'registerModule', moduleFunc.workerModuleData);
	      var unregister = function () {
	        registrationPromise = null;
	        registeredModules[workerId].delete(unregister);
	      }
	      ;(registeredModules[workerId] || (registeredModules[workerId] = new Set())).add(unregister);
	    }

	    // Invoke the module, returning a promise
	    return registrationPromise.then(function (ref) {
	      var isCallable = ref.isCallable;

	      if (isCallable) {
	        return callWorker(workerId,'callModule', {id: id, args: args})
	      } else {
	        throw new Error('Worker module function was called but `init` did not return a callable function')
	      }
	    })
	  }
	  moduleFunc.workerModuleData = {
	    isWorkerModule: true,
	    id: id,
	    name: name,
	    dependencies: dependencies,
	    init: stringifyFunction(init),
	    getTransferables: getTransferables && stringifyFunction(getTransferables)
	  };

	  moduleFunc.onMainThread = onMainThread;

	  return moduleFunc
	}

	/**
	 * Terminate an active Worker by a workerId that was passed to defineWorkerModule.
	 * This only terminates the Worker itself; the worker module will remain available
	 * and if you call it again its Worker will be respawned.
	 * @param {string} workerId
	 */
	function terminateWorker(workerId) {
	  // Unregister all modules that were registered in that worker
	  if (registeredModules[workerId]) {
	    registeredModules[workerId].forEach(function (unregister) {
	      unregister();
	    });
	  }
	  // Terminate the Worker object
	  if (workers[workerId]) {
	    workers[workerId].terminate();
	    delete workers[workerId];
	  }
	}

	/**
	 * Stringifies a function into a form that can be deserialized in the worker
	 * @param fn
	 */
	function stringifyFunction(fn) {
	  var str = fn.toString();
	  // If it was defined in object method/property format, it needs to be modified
	  if (!/^function/.test(str) && /^\w+\s*\(/.test(str)) {
	    str = 'function ' + str;
	  }
	  return str
	}


	function getWorker(workerId) {
	  var worker = workers[workerId];
	  if (!worker) {
	    // Bootstrap the worker's content
	    var bootstrap = stringifyFunction(workerBootstrap);

	    // Create the worker from the bootstrap function content
	    worker = workers[workerId] = new Worker(
	      URL.createObjectURL(
	        new Blob(
	          [("/** Worker Module Bootstrap: " + (workerId.replace(/\*/g, '')) + " **/\n\n;(" + bootstrap + ")()")],
	          {type: 'application/javascript'}
	        )
	      )
	    );

	    // Single handler for response messages from the worker
	    worker.onmessage = function (e) {
	      var response = e.data;
	      var msgId = response.messageId;
	      var callback = openRequests[msgId];
	      if (!callback) {
	        throw new Error('WorkerModule response with empty or unknown messageId')
	      }
	      delete openRequests[msgId];
	      callback(response);
	    };
	  }
	  return worker
	}

	// Issue a call to the worker with a callback to handle the response
	function callWorker(workerId, action, data) {
	  return new Promise(function (resolve, reject) {
	    var messageId = ++_messageId;
	    openRequests[messageId] = function (response) {
	      if (response.success) {
	        resolve(response.result);
	      } else {
	        reject(new Error(("Error in worker " + action + " call: " + (response.error))));
	      }
	    };
	    getWorker(workerId).postMessage({
	      messageId: messageId,
	      action: action,
	      data: data
	    });
	  })
	}

	function SDFGenerator() {
	var exports = (function (exports) {

	  /**
	   * Find the point on a quadratic bezier curve at t where t is in the range [0, 1]
	   */
	  function pointOnQuadraticBezier (x0, y0, x1, y1, x2, y2, t, pointOut) {
	    var t2 = 1 - t;
	    pointOut.x = t2 * t2 * x0 + 2 * t2 * t * x1 + t * t * x2;
	    pointOut.y = t2 * t2 * y0 + 2 * t2 * t * y1 + t * t * y2;
	  }

	  /**
	   * Find the point on a cubic bezier curve at t where t is in the range [0, 1]
	   */
	  function pointOnCubicBezier (x0, y0, x1, y1, x2, y2, x3, y3, t, pointOut) {
	    var t2 = 1 - t;
	    pointOut.x = t2 * t2 * t2 * x0 + 3 * t2 * t2 * t * x1 + 3 * t2 * t * t * x2 + t * t * t * x3;
	    pointOut.y = t2 * t2 * t2 * y0 + 3 * t2 * t2 * t * y1 + 3 * t2 * t * t * y2 + t * t * t * y3;
	  }

	  /**
	   * Parse a path string into its constituent line/curve commands, invoking a callback for each.
	   * @param {string} pathString - An SVG-like path string to parse; should only contain commands: M/L/Q/C/Z
	   * @param {function(
	   *   command: 'L'|'Q'|'C',
	   *   startX: number,
	   *   startY: number,
	   *   endX: number,
	   *   endY: number,
	   *   ctrl1X?: number,
	   *   ctrl1Y?: number,
	   *   ctrl2X?: number,
	   *   ctrl2Y?: number
	   * )} commandCallback - A callback function that will be called once for each parsed path command, passing the
	   *                      command identifier (only L/Q/C commands) and its numeric arguments.
	   */
	  function forEachPathCommand(pathString, commandCallback) {
	    var segmentRE = /([MLQCZ])([^MLQCZ]*)/g;
	    var match, firstX, firstY, prevX, prevY;
	    while ((match = segmentRE.exec(pathString))) {
	      var args = match[2]
	        .replace(/^\s*|\s*$/g, '')
	        .split(/[,\s]+/)
	        .map(function (v) { return parseFloat(v); });
	      switch (match[1]) {
	        case 'M':
	          prevX = firstX = args[0];
	          prevY = firstY = args[1];
	          break
	        case 'L':
	          if (args[0] !== prevX || args[1] !== prevY) { // yup, some fonts have zero-length line commands
	            commandCallback('L', prevX, prevY, (prevX = args[0]), (prevY = args[1]));
	          }
	          break
	        case 'Q': {
	          commandCallback('Q', prevX, prevY, (prevX = args[2]), (prevY = args[3]), args[0], args[1]);
	          break
	        }
	        case 'C': {
	          commandCallback('C', prevX, prevY, (prevX = args[4]), (prevY = args[5]), args[0], args[1], args[2], args[3]);
	          break
	        }
	        case 'Z':
	          if (prevX !== firstX || prevY !== firstY) {
	            commandCallback('L', prevX, prevY, firstX, firstY);
	          }
	          break
	      }
	    }
	  }

	  /**
	   * Convert a path string to a series of straight line segments
	   * @param {string} pathString - An SVG-like path string to parse; should only contain commands: M/L/Q/C/Z
	   * @param {function(x1:number, y1:number, x2:number, y2:number)} segmentCallback - A callback
	   *        function that will be called once for every line segment
	   * @param {number} [curvePoints] - How many straight line segments to use when approximating a
	   *        bezier curve in the path. Defaults to 16.
	   */
	  function pathToLineSegments (pathString, segmentCallback, curvePoints) {
	    if ( curvePoints === void 0 ) curvePoints = 16;

	    var tempPoint = { x: 0, y: 0 };
	    forEachPathCommand(pathString, function (command, startX, startY, endX, endY, ctrl1X, ctrl1Y, ctrl2X, ctrl2Y) {
	      switch (command) {
	        case 'L':
	          segmentCallback(startX, startY, endX, endY);
	          break
	        case 'Q': {
	          var prevCurveX = startX;
	          var prevCurveY = startY;
	          for (var i = 1; i < curvePoints; i++) {
	            pointOnQuadraticBezier(
	              startX, startY,
	              ctrl1X, ctrl1Y,
	              endX, endY,
	              i / (curvePoints - 1),
	              tempPoint
	            );
	            segmentCallback(prevCurveX, prevCurveY, tempPoint.x, tempPoint.y);
	            prevCurveX = tempPoint.x;
	            prevCurveY = tempPoint.y;
	          }
	          break
	        }
	        case 'C': {
	          var prevCurveX$1 = startX;
	          var prevCurveY$1 = startY;
	          for (var i$1 = 1; i$1 < curvePoints; i$1++) {
	            pointOnCubicBezier(
	              startX, startY,
	              ctrl1X, ctrl1Y,
	              ctrl2X, ctrl2Y,
	              endX, endY,
	              i$1 / (curvePoints - 1),
	              tempPoint
	            );
	            segmentCallback(prevCurveX$1, prevCurveY$1, tempPoint.x, tempPoint.y);
	            prevCurveX$1 = tempPoint.x;
	            prevCurveY$1 = tempPoint.y;
	          }
	          break
	        }
	      }
	    });
	  }

	  var viewportQuadVertex = "precision highp float;attribute vec2 aUV;varying vec2 vUV;void main(){vUV=aUV;gl_Position=vec4(mix(vec2(-1.0),vec2(1.0),aUV),0.0,1.0);}";

	  var copyTexFragment = "precision highp float;uniform sampler2D tex;varying vec2 vUV;void main(){gl_FragColor=texture2D(tex,vUV);}";

	  var cache = new WeakMap();

	  var glContextParams = {
	    premultipliedAlpha: false,
	    preserveDrawingBuffer: true,
	    antialias: false,
	    depth: false,
	  };

	  /**
	   * This is a little helper library for WebGL. It assists with state management for a GL context.
	   * It's pretty tightly wrapped to the needs of this package, not very general-purpose.
	   *
	   * @param { WebGLRenderingContext | HTMLCanvasElement | OffscreenCanvas } glOrCanvas - the GL context to wrap
	   * @param { ({gl, getExtension, withProgram, withTexture, withTextureFramebuffer, handleContextLoss}) => void } callback
	   */
	  function withWebGLContext (glOrCanvas, callback) {
	    var gl = glOrCanvas.getContext ? glOrCanvas.getContext('webgl', glContextParams) : glOrCanvas;
	    var wrapper = cache.get(gl);
	    if (!wrapper) {
	      var isWebGL2 = typeof WebGL2RenderingContext !== 'undefined' && gl instanceof WebGL2RenderingContext;
	      var extensions = {};
	      var programs = {};
	      var textures = {};
	      var textureUnit = -1;
	      var framebufferStack = [];

	      gl.canvas.addEventListener('webglcontextlost', function (e) {
	        handleContextLoss();
	        e.preventDefault();
	      }, false);

	      function getExtension (name) {
	        var ext = extensions[name];
	        if (!ext) {
	          ext = extensions[name] = gl.getExtension(name);
	          if (!ext) {
	            throw new Error((name + " not supported"))
	          }
	        }
	        return ext
	      }

	      function compileShader (src, type) {
	        var shader = gl.createShader(type);
	        gl.shaderSource(shader, src);
	        gl.compileShader(shader);
	        // const status = gl.getShaderParameter(shader, gl.COMPILE_STATUS)
	        // if (!status && !gl.isContextLost()) {
	        //   throw new Error(gl.getShaderInfoLog(shader).trim())
	        // }
	        return shader
	      }

	      function withProgram (name, vert, frag, func) {
	        if (!programs[name]) {
	          var attributes = {};
	          var uniforms = {};
	          var program = gl.createProgram();
	          gl.attachShader(program, compileShader(vert, gl.VERTEX_SHADER));
	          gl.attachShader(program, compileShader(frag, gl.FRAGMENT_SHADER));
	          gl.linkProgram(program);

	          programs[name] = {
	            program: program,
	            transaction: function transaction (func) {
	              gl.useProgram(program);
	              func({
	                setUniform: function setUniform (type, name) {
	                  var values = [], len = arguments.length - 2;
	                  while ( len-- > 0 ) values[ len ] = arguments[ len + 2 ];

	                  var uniformLoc = uniforms[name] || (uniforms[name] = gl.getUniformLocation(program, name));
	                  gl[("uniform" + type)].apply(gl, [ uniformLoc ].concat( values ));
	                },

	                setAttribute: function setAttribute (name, size, usage, instancingDivisor, data) {
	                  var attr = attributes[name];
	                  if (!attr) {
	                    attr = attributes[name] = {
	                      buf: gl.createBuffer(), // TODO should we destroy our buffers?
	                      loc: gl.getAttribLocation(program, name),
	                      data: null
	                    };
	                  }
	                  gl.bindBuffer(gl.ARRAY_BUFFER, attr.buf);
	                  gl.vertexAttribPointer(attr.loc, size, gl.FLOAT, false, 0, 0);
	                  gl.enableVertexAttribArray(attr.loc);
	                  if (isWebGL2) {
	                    gl.vertexAttribDivisor(attr.loc, instancingDivisor);
	                  } else {
	                    getExtension('ANGLE_instanced_arrays').vertexAttribDivisorANGLE(attr.loc, instancingDivisor);
	                  }
	                  if (data !== attr.data) {
	                    gl.bufferData(gl.ARRAY_BUFFER, data, usage);
	                    attr.data = data;
	                  }
	                }
	              });
	            }
	          };
	        }

	        programs[name].transaction(func);
	      }

	      function withTexture (name, func) {
	        textureUnit++;
	        try {
	          gl.activeTexture(gl.TEXTURE0 + textureUnit);
	          var texture = textures[name];
	          if (!texture) {
	            texture = textures[name] = gl.createTexture();
	            gl.bindTexture(gl.TEXTURE_2D, texture);
	            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
	            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
	          }
	          gl.bindTexture(gl.TEXTURE_2D, texture);
	          func(texture, textureUnit);
	        } finally {
	          textureUnit--;
	        }
	      }

	      function withTextureFramebuffer (texture, textureUnit, func) {
	        var framebuffer = gl.createFramebuffer();
	        framebufferStack.push(framebuffer);
	        gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
	        gl.activeTexture(gl.TEXTURE0 + textureUnit);
	        gl.bindTexture(gl.TEXTURE_2D, texture);
	        gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
	        try {
	          func(framebuffer);
	        } finally {
	          gl.deleteFramebuffer(framebuffer);
	          gl.bindFramebuffer(gl.FRAMEBUFFER, framebufferStack[--framebufferStack.length - 1] || null);
	        }
	      }

	      function handleContextLoss () {
	        extensions = {};
	        programs = {};
	        textures = {};
	        textureUnit = -1;
	        framebufferStack.length = 0;
	      }

	      cache.set(gl, wrapper = {
	        gl: gl,
	        isWebGL2: isWebGL2,
	        getExtension: getExtension,
	        withProgram: withProgram,
	        withTexture: withTexture,
	        withTextureFramebuffer: withTextureFramebuffer,
	        handleContextLoss: handleContextLoss,
	      });
	    }
	    callback(wrapper);
	  }


	  function renderImageData(glOrCanvas, imageData, x, y, width, height, channels, framebuffer) {
	    if ( channels === void 0 ) channels = 15;
	    if ( framebuffer === void 0 ) framebuffer = null;

	    withWebGLContext(glOrCanvas, function (ref) {
	      var gl = ref.gl;
	      var withProgram = ref.withProgram;
	      var withTexture = ref.withTexture;

	      withTexture('copy', function (tex, texUnit) {
	        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, imageData);
	        withProgram('copy', viewportQuadVertex, copyTexFragment, function (ref) {
	          var setUniform = ref.setUniform;
	          var setAttribute = ref.setAttribute;

	          setAttribute('aUV', 2, gl.STATIC_DRAW, 0, new Float32Array([0, 0, 2, 0, 0, 2]));
	          setUniform('1i', 'image', texUnit);
	          gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer || null);
	          gl.disable(gl.BLEND);
	          gl.colorMask(channels & 8, channels & 4, channels & 2, channels & 1);
	          gl.viewport(x, y, width, height);
	          gl.scissor(x, y, width, height);
	          gl.drawArrays(gl.TRIANGLES, 0, 3);
	        });
	      });
	    });
	  }

	  /**
	   * Resizing a canvas clears its contents; this utility copies the previous contents over.
	   * @param canvas
	   * @param newWidth
	   * @param newHeight
	   */
	  function resizeWebGLCanvasWithoutClearing(canvas, newWidth, newHeight) {
	    var width = canvas.width;
	    var height = canvas.height;
	    withWebGLContext(canvas, function (ref) {
	      var gl = ref.gl;

	      var data = new Uint8Array(width * height * 4);
	      gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, data);
	      canvas.width = newWidth;
	      canvas.height = newHeight;
	      renderImageData(gl, data, 0, 0, width, height);
	    });
	  }

	  var webglUtils = /*#__PURE__*/Object.freeze({
	    __proto__: null,
	    withWebGLContext: withWebGLContext,
	    renderImageData: renderImageData,
	    resizeWebGLCanvasWithoutClearing: resizeWebGLCanvasWithoutClearing
	  });

	  function generate$2 (sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent) {
	    if ( sdfExponent === void 0 ) sdfExponent = 1;

	    var textureData = new Uint8Array(sdfWidth * sdfHeight);

	    var viewBoxWidth = viewBox[2] - viewBox[0];
	    var viewBoxHeight = viewBox[3] - viewBox[1];

	    // Decompose all paths into straight line segments and add them to an index
	    var segments = [];
	    pathToLineSegments(path, function (x1, y1, x2, y2) {
	      segments.push({
	        x1: x1, y1: y1, x2: x2, y2: y2,
	        minX: Math.min(x1, x2),
	        minY: Math.min(y1, y2),
	        maxX: Math.max(x1, x2),
	        maxY: Math.max(y1, y2)
	      });
	    });

	    // Sort segments by maxX, this will let us short-circuit some loops below
	    segments.sort(function (a, b) { return a.maxX - b.maxX; });

	    // For each target SDF texel, find the distance from its center to its nearest line segment,
	    // map that distance to an alpha value, and write that alpha to the texel
	    for (var sdfX = 0; sdfX < sdfWidth; sdfX++) {
	      for (var sdfY = 0; sdfY < sdfHeight; sdfY++) {
	        var signedDist = findNearestSignedDistance(
	          viewBox[0] + viewBoxWidth * (sdfX + 0.5) / sdfWidth,
	          viewBox[1] + viewBoxHeight * (sdfY + 0.5) / sdfHeight
	        );

	        // Use an exponential scale to ensure the texels very near the glyph path have adequate
	        // precision, while allowing the distance field to cover the entire texture, given that
	        // there are only 8 bits available. Formula visualized: https://www.desmos.com/calculator/uiaq5aqiam
	        var alpha = Math.pow((1 - Math.abs(signedDist) / maxDistance), sdfExponent) / 2;
	        if (signedDist < 0) {
	          alpha = 1 - alpha;
	        }

	        alpha = Math.max(0, Math.min(255, Math.round(alpha * 255))); //clamp
	        textureData[sdfY * sdfWidth + sdfX] = alpha;
	      }
	    }

	    return textureData

	    /**
	     * For a given x/y, search the index for the closest line segment and return
	     * its signed distance. Negative = inside, positive = outside, zero = on edge
	     * @param x
	     * @param y
	     * @returns {number}
	     */
	    function findNearestSignedDistance (x, y) {
	      var closestDistSq = Infinity;
	      var closestDist = Infinity;

	      for (var i = segments.length; i--;) {
	        var seg = segments[i];
	        if (seg.maxX + closestDist <= x) { break } //sorting by maxX means no more can be closer, so we can short-circuit
	        if (x + closestDist > seg.minX && y - closestDist < seg.maxY && y + closestDist > seg.minY) {
	          var distSq = absSquareDistanceToLineSegment(x, y, seg.x1, seg.y1, seg.x2, seg.y2);
	          if (distSq < closestDistSq) {
	            closestDistSq = distSq;
	            closestDist = Math.sqrt(closestDistSq);
	          }
	        }
	      }

	      // Flip to negative distance if inside the poly
	      if (isPointInPoly(x, y)) {
	        closestDist = -closestDist;
	      }
	      return closestDist
	    }

	    /**
	     * Determine whether the given point lies inside or outside the glyph. Uses a simple
	     * winding-number ray casting algorithm using a ray pointing east from the point.
	     */
	    function isPointInPoly (x, y) {
	      var winding = 0;
	      for (var i = segments.length; i--;) {
	        var seg = segments[i];
	        if (seg.maxX <= x) { break } //sorting by maxX means no more can cross, so we can short-circuit
	        var intersects = ((seg.y1 > y) !== (seg.y2 > y)) && (x < (seg.x2 - seg.x1) * (y - seg.y1) / (seg.y2 - seg.y1) + seg.x1);
	        if (intersects) {
	          winding += seg.y1 < seg.y2 ? 1 : -1;
	        }
	      }
	      return winding !== 0
	    }
	  }

	  function generateIntoCanvas$2(sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent, canvas, x, y, channel) {
	    if ( sdfExponent === void 0 ) sdfExponent = 1;
	    if ( x === void 0 ) x = 0;
	    if ( y === void 0 ) y = 0;
	    if ( channel === void 0 ) channel = 0;

	    generateIntoFramebuffer$1(sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent, canvas, null, x, y, channel);
	  }

	  function generateIntoFramebuffer$1 (sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent, glOrCanvas, framebuffer, x, y, channel) {
	    if ( sdfExponent === void 0 ) sdfExponent = 1;
	    if ( x === void 0 ) x = 0;
	    if ( y === void 0 ) y = 0;
	    if ( channel === void 0 ) channel = 0;

	    var data = generate$2(sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent);
	    // Expand single-channel data to rbga
	    var rgbaData = new Uint8Array(data.length * 4);
	    for (var i = 0; i < data.length; i++) {
	      rgbaData[i * 4 + channel] = data[i];
	    }
	    renderImageData(glOrCanvas, rgbaData, x, y, sdfWidth, sdfHeight, 1 << (3 - channel), framebuffer);
	  }

	  /**
	   * Find the absolute distance from a point to a line segment at closest approach
	   */
	  function absSquareDistanceToLineSegment (x, y, lineX0, lineY0, lineX1, lineY1) {
	    var ldx = lineX1 - lineX0;
	    var ldy = lineY1 - lineY0;
	    var lengthSq = ldx * ldx + ldy * ldy;
	    var t = lengthSq ? Math.max(0, Math.min(1, ((x - lineX0) * ldx + (y - lineY0) * ldy) / lengthSq)) : 0;
	    var dx = x - (lineX0 + t * ldx);
	    var dy = y - (lineY0 + t * ldy);
	    return dx * dx + dy * dy
	  }

	  var javascript = /*#__PURE__*/Object.freeze({
	    __proto__: null,
	    generate: generate$2,
	    generateIntoCanvas: generateIntoCanvas$2,
	    generateIntoFramebuffer: generateIntoFramebuffer$1
	  });

	  var mainVertex = "precision highp float;uniform vec4 uGlyphBounds;attribute vec2 aUV;attribute vec4 aLineSegment;varying vec4 vLineSegment;varying vec2 vGlyphXY;void main(){vLineSegment=aLineSegment;vGlyphXY=mix(uGlyphBounds.xy,uGlyphBounds.zw,aUV);gl_Position=vec4(mix(vec2(-1.0),vec2(1.0),aUV),0.0,1.0);}";

	  var mainFragment = "precision highp float;uniform vec4 uGlyphBounds;uniform float uMaxDistance;uniform float uExponent;varying vec4 vLineSegment;varying vec2 vGlyphXY;float absDistToSegment(vec2 point,vec2 lineA,vec2 lineB){vec2 lineDir=lineB-lineA;float lenSq=dot(lineDir,lineDir);float t=lenSq==0.0 ? 0.0 : clamp(dot(point-lineA,lineDir)/lenSq,0.0,1.0);vec2 linePt=lineA+t*lineDir;return distance(point,linePt);}void main(){vec4 seg=vLineSegment;vec2 p=vGlyphXY;float dist=absDistToSegment(p,seg.xy,seg.zw);float val=pow(1.0-clamp(dist/uMaxDistance,0.0,1.0),uExponent)*0.5;bool crossing=(seg.y>p.y!=seg.w>p.y)&&(p.x<(seg.z-seg.x)*(p.y-seg.y)/(seg.w-seg.y)+seg.x);bool crossingUp=crossing&&vLineSegment.y<vLineSegment.w;gl_FragColor=vec4(crossingUp ? 1.0/255.0 : 0.0,crossing&&!crossingUp ? 1.0/255.0 : 0.0,0.0,val);}";

	  var postFragment = "precision highp float;uniform sampler2D tex;varying vec2 vUV;void main(){vec4 color=texture2D(tex,vUV);bool inside=color.r!=color.g;float val=inside ? 1.0-color.a : color.a;gl_FragColor=vec4(val);}";

	  // Single triangle covering viewport
	  var viewportUVs = new Float32Array([0, 0, 2, 0, 0, 2]);

	  var implicitContext = null;
	  var isTestingSupport = false;
	  var NULL_OBJECT = {};
	  var supportByCanvas = new WeakMap(); // canvas -> bool

	  function validateSupport (glOrCanvas) {
	    if (!isTestingSupport && !isSupported(glOrCanvas)) {
	      throw new Error('WebGL generation not supported')
	    }
	  }

	  function generate$1 (sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent, glOrCanvas) {
	    if ( sdfExponent === void 0 ) sdfExponent = 1;
	    if ( glOrCanvas === void 0 ) glOrCanvas = null;

	    if (!glOrCanvas) {
	      glOrCanvas = implicitContext;
	      if (!glOrCanvas) {
	        var canvas = typeof OffscreenCanvas === 'function'
	          ? new OffscreenCanvas(1, 1)
	          : typeof document !== 'undefined'
	            ? document.createElement('canvas')
	            : null;
	        if (!canvas) {
	          throw new Error('OffscreenCanvas or DOM canvas not supported')
	        }
	        glOrCanvas = implicitContext = canvas.getContext('webgl', { depth: false });
	      }
	    }

	    validateSupport(glOrCanvas);

	    var rgbaData = new Uint8Array(sdfWidth * sdfHeight * 4); //not Uint8ClampedArray, cuz Safari

	    // Render into a background texture framebuffer
	    withWebGLContext(glOrCanvas, function (ref) {
	      var gl = ref.gl;
	      var withTexture = ref.withTexture;
	      var withTextureFramebuffer = ref.withTextureFramebuffer;

	      withTexture('readable', function (texture, textureUnit) {
	        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, sdfWidth, sdfHeight, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);

	        withTextureFramebuffer(texture, textureUnit, function (framebuffer) {
	          generateIntoFramebuffer(
	            sdfWidth,
	            sdfHeight,
	            path,
	            viewBox,
	            maxDistance,
	            sdfExponent,
	            gl,
	            framebuffer,
	            0,
	            0,
	            0 // red channel
	          );
	          gl.readPixels(0, 0, sdfWidth, sdfHeight, gl.RGBA, gl.UNSIGNED_BYTE, rgbaData);
	        });
	      });
	    });

	    // Throw away all but the red channel
	    var data = new Uint8Array(sdfWidth * sdfHeight);
	    for (var i = 0, j = 0; i < rgbaData.length; i += 4) {
	      data[j++] = rgbaData[i];
	    }

	    return data
	  }

	  function generateIntoCanvas$1(sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent, canvas, x, y, channel) {
	    if ( sdfExponent === void 0 ) sdfExponent = 1;
	    if ( x === void 0 ) x = 0;
	    if ( y === void 0 ) y = 0;
	    if ( channel === void 0 ) channel = 0;

	    generateIntoFramebuffer(sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent, canvas, null, x, y, channel);
	  }

	  function generateIntoFramebuffer (sdfWidth, sdfHeight, path, viewBox, maxDistance, sdfExponent, glOrCanvas, framebuffer, x, y, channel) {
	    if ( sdfExponent === void 0 ) sdfExponent = 1;
	    if ( x === void 0 ) x = 0;
	    if ( y === void 0 ) y = 0;
	    if ( channel === void 0 ) channel = 0;

	    // Verify support
	    validateSupport(glOrCanvas);

	    // Compute path segments
	    var lineSegmentCoords = [];
	    pathToLineSegments(path, function (x1, y1, x2, y2) {
	      lineSegmentCoords.push(x1, y1, x2, y2);
	    });
	    lineSegmentCoords = new Float32Array(lineSegmentCoords);

	    withWebGLContext(glOrCanvas, function (ref) {
	      var gl = ref.gl;
	      var isWebGL2 = ref.isWebGL2;
	      var getExtension = ref.getExtension;
	      var withProgram = ref.withProgram;
	      var withTexture = ref.withTexture;
	      var withTextureFramebuffer = ref.withTextureFramebuffer;
	      var handleContextLoss = ref.handleContextLoss;

	      withTexture('rawDistances', function (intermediateTexture, intermediateTextureUnit) {
	        if (sdfWidth !== intermediateTexture._lastWidth || sdfHeight !== intermediateTexture._lastHeight) {
	          gl.texImage2D(
	            gl.TEXTURE_2D, 0, gl.RGBA,
	            intermediateTexture._lastWidth = sdfWidth,
	            intermediateTexture._lastHeight = sdfHeight,
	            0, gl.RGBA, gl.UNSIGNED_BYTE, null
	          );
	        }

	        // Unsigned distance pass
	        withProgram('main', mainVertex, mainFragment, function (ref) {
	          var setAttribute = ref.setAttribute;
	          var setUniform = ref.setUniform;

	          // Init extensions
	          var instancingExtension = !isWebGL2 && getExtension('ANGLE_instanced_arrays');
	          var blendMinMaxExtension = !isWebGL2 && getExtension('EXT_blend_minmax');

	          // Init/update attributes
	          setAttribute('aUV', 2, gl.STATIC_DRAW, 0, viewportUVs);
	          setAttribute('aLineSegment', 4, gl.DYNAMIC_DRAW, 1, lineSegmentCoords);

	          // Init/update uniforms
	          setUniform.apply(void 0, [ '4f', 'uGlyphBounds' ].concat( viewBox ));
	          setUniform('1f', 'uMaxDistance', maxDistance);
	          setUniform('1f', 'uExponent', sdfExponent);

	          // Render initial unsigned distance / winding number info to a texture
	          withTextureFramebuffer(intermediateTexture, intermediateTextureUnit, function (framebuffer) {
	            gl.enable(gl.BLEND);
	            gl.colorMask(true, true, true, true);
	            gl.viewport(0, 0, sdfWidth, sdfHeight);
	            gl.scissor(0, 0, sdfWidth, sdfHeight);
	            gl.blendFunc(gl.ONE, gl.ONE);
	            // Red+Green channels are incremented (FUNC_ADD) for segment-ray crossings to give a "winding number".
	            // Alpha holds the closest (MAX) unsigned distance.
	            gl.blendEquationSeparate(gl.FUNC_ADD, isWebGL2 ? gl.MAX : blendMinMaxExtension.MAX_EXT);
	            gl.clear(gl.COLOR_BUFFER_BIT);
	            if (isWebGL2) {
	              gl.drawArraysInstanced(gl.TRIANGLES, 0, 3, lineSegmentCoords.length / 4);
	            } else {
	              instancingExtension.drawArraysInstancedANGLE(gl.TRIANGLES, 0, 3, lineSegmentCoords.length / 4);
	            }
	            // Debug
	            // const debug = new Uint8Array(sdfWidth * sdfHeight * 4)
	            // gl.readPixels(0, 0, sdfWidth, sdfHeight, gl.RGBA, gl.UNSIGNED_BYTE, debug)
	            // console.log('intermediate texture data: ', debug)
	          });
	        });

	        // Use the data stored in the texture to apply inside/outside and write to the output framebuffer rect+channel.
	        withProgram('post', viewportQuadVertex, postFragment, function (program) {
	          program.setAttribute('aUV', 2, gl.STATIC_DRAW, 0, viewportUVs);
	          program.setUniform('1i', 'tex', intermediateTextureUnit);
	          gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
	          gl.disable(gl.BLEND);
	          gl.colorMask(channel === 0, channel === 1, channel === 2, channel === 3);
	          gl.viewport(x, y, sdfWidth, sdfHeight);
	          gl.scissor(x, y, sdfWidth, sdfHeight);
	          gl.drawArrays(gl.TRIANGLES, 0, 3);
	        });
	      });

	      // Handle context loss occurring during any of the above calls
	      if (gl.isContextLost()) {
	        handleContextLoss();
	        throw new Error('webgl context lost')
	      }
	    });
	  }

	  function isSupported (glOrCanvas) {
	    var key = (!glOrCanvas || glOrCanvas === implicitContext) ? NULL_OBJECT : (glOrCanvas.canvas || glOrCanvas);
	    var supported = supportByCanvas.get(key);
	    if (supported === undefined) {
	      isTestingSupport = true;
	      var failReason = null;
	      try {
	        // Since we can't detect all failure modes up front, let's just do a trial run of a
	        // simple path and compare what we get back to the correct expected result. This will
	        // also serve to prime the shader compilation.
	        var expectedResult = [
	          97, 106, 97, 61,
	          99, 137, 118, 80,
	          80, 118, 137, 99,
	          61, 97, 106, 97
	        ];
	        var testResult = generate$1(
	          4,
	          4,
	          'M8,8L16,8L24,24L16,24Z',
	          [0, 0, 32, 32],
	          24,
	          1,
	          glOrCanvas
	        );
	        supported = testResult && expectedResult.length === testResult.length &&
	          testResult.every(function (val, i) { return val === expectedResult[i]; });
	        if (!supported) {
	          failReason = 'bad trial run results';
	          console.info(expectedResult, testResult);
	        }
	      } catch (err) {
	        // TODO if it threw due to webgl context loss, should we maybe leave isSupported as null and try again later?
	        supported = false;
	        failReason = err.message;
	      }
	      if (failReason) {
	        console.warn('WebGL SDF generation not supported:', failReason);
	      }
	      isTestingSupport = false;
	      supportByCanvas.set(key, supported);
	    }
	    return supported
	  }

	  var webgl = /*#__PURE__*/Object.freeze({
	    __proto__: null,
	    generate: generate$1,
	    generateIntoCanvas: generateIntoCanvas$1,
	    generateIntoFramebuffer: generateIntoFramebuffer,
	    isSupported: isSupported
	  });

	  /**
	   * Generate an SDF texture image for a 2D path.
	   *
	   * @param {number} sdfWidth - width of the SDF output image in pixels.
	   * @param {number} sdfHeight - height of the SDF output image in pixels.
	   * @param {string} path - an SVG-like path string describing the glyph; should only contain commands: M/L/Q/C/Z.
	   * @param {number[]} viewBox - [minX, minY, maxX, maxY] in font units aligning with the texture's edges.
	   * @param {number} maxDistance - the maximum distance from the glyph path in font units that will be encoded; defaults
	   *        to half the maximum viewBox dimension.
	   * @param {number} [sdfExponent] - specifies an exponent for encoding the SDF's distance values; higher exponents
	   *        will give greater precision nearer the glyph's path.
	   * @return {Uint8Array}
	   */
	  function generate(
	    sdfWidth,
	    sdfHeight,
	    path,
	    viewBox,
	    maxDistance,
	    sdfExponent
	  ) {
	    if ( maxDistance === void 0 ) maxDistance = Math.max(viewBox[2] - viewBox[0], viewBox[3] - viewBox[1]) / 2;
	    if ( sdfExponent === void 0 ) sdfExponent = 1;

	    try {
	      return generate$1.apply(webgl, arguments)
	    } catch(e) {
	      console.info('WebGL SDF generation failed, falling back to JS', e);
	      return generate$2.apply(javascript, arguments)
	    }
	  }

	  /**
	   * Generate an SDF texture image for a 2D path, inserting the result into a WebGL `canvas` at a given x/y position
	   * and color channel. This is generally much faster than calling `generate` because it does not require reading pixels
	   * back from the GPU->CPU -- the `canvas` can be used directly as a WebGL texture image, so it all stays on the GPU.
	   *
	   * @param {number} sdfWidth - width of the SDF output image in pixels.
	   * @param {number} sdfHeight - height of the SDF output image in pixels.
	   * @param {string} path - an SVG-like path string describing the glyph; should only contain commands: M/L/Q/C/Z.
	   * @param {number[]} viewBox - [minX, minY, maxX, maxY] in font units aligning with the texture's edges.
	   * @param {number} maxDistance - the maximum distance from the glyph path in font units that will be encoded; defaults
	   *        to half the maximum viewBox dimension.
	   * @param {number} [sdfExponent] - specifies an exponent for encoding the SDF's distance values; higher exponents
	   *        will give greater precision nearer the glyph's path.
	   * @param {HTMLCanvasElement|OffscreenCanvas} canvas - a WebGL-enabled canvas into which the SDF will be rendered.
	   *        Only the relevant rect/channel will be modified, the rest will be preserved. To avoid unpredictable results
	   *        due to shared GL context state, this canvas should be dedicated to use by this library alone.
	   * @param {number} x - the x position at which to render the SDF.
	   * @param {number} y - the y position at which to render the SDF.
	   * @param {number} channel - the color channel index (0-4) into which the SDF will be rendered.
	   * @return {Uint8Array}
	   */
	  function generateIntoCanvas(
	    sdfWidth,
	    sdfHeight,
	    path,
	    viewBox,
	    maxDistance,
	    sdfExponent,
	    canvas,
	    x,
	    y,
	    channel
	  ) {
	    if ( maxDistance === void 0 ) maxDistance = Math.max(viewBox[2] - viewBox[0], viewBox[3] - viewBox[1]) / 2;
	    if ( sdfExponent === void 0 ) sdfExponent = 1;
	    if ( x === void 0 ) x = 0;
	    if ( y === void 0 ) y = 0;
	    if ( channel === void 0 ) channel = 0;

	    try {
	      return generateIntoCanvas$1.apply(webgl, arguments)
	    } catch(e) {
	      console.info('WebGL SDF generation failed, falling back to JS', e);
	      return generateIntoCanvas$2.apply(javascript, arguments)
	    }
	  }

	  exports.forEachPathCommand = forEachPathCommand;
	  exports.generate = generate;
	  exports.generateIntoCanvas = generateIntoCanvas;
	  exports.javascript = javascript;
	  exports.pathToLineSegments = pathToLineSegments;
	  exports.webgl = webgl;
	  exports.webglUtils = webglUtils;

	  Object.defineProperty(exports, '__esModule', { value: true });

	  return exports;

	}({}));
	return exports
	}

	function bidiFactory() {
	var bidi = (function (exports) {

	  // Bidi character types data, auto generated
	  var DATA = {
	    "R": "13k,1a,2,3,3,2+1j,ch+16,a+1,5+2,2+n,5,a,4,6+16,4+3,h+1b,4mo,179q,2+9,2+11,2i9+7y,2+68,4,3+4,5+13,4+3,2+4k,3+29,8+cf,1t+7z,w+17,3+3m,1t+3z,16o1+5r,8+30,8+mc,29+1r,29+4v,75+73",
	    "EN": "1c+9,3d+1,6,187+9,513,4+5,7+9,sf+j,175h+9,qw+q,161f+1d,4xt+a,25i+9",
	    "ES": "17,2,6dp+1,f+1,av,16vr,mx+1,4o,2",
	    "ET": "z+2,3h+3,b+1,ym,3e+1,2o,p4+1,8,6u,7c,g6,1wc,1n9+4,30+1b,2n,6d,qhx+1,h0m,a+1,49+2,63+1,4+1,6bb+3,12jj",
	    "AN": "16o+5,2j+9,2+1,35,ed,1ff2+9,87+u",
	    "CS": "18,2+1,b,2u,12k,55v,l,17v0,2,3,53,2+1,b",
	    "B": "a,3,f+2,2v,690",
	    "S": "9,2,k",
	    "WS": "c,k,4f4,1vk+a,u,1j,335",
	    "ON": "x+1,4+4,h+5,r+5,r+3,z,5+3,2+1,2+1,5,2+2,3+4,o,w,ci+1,8+d,3+d,6+8,2+g,39+1,9,6+1,2,33,b8,3+1,3c+1,7+1,5r,b,7h+3,sa+5,2,3i+6,jg+3,ur+9,2v,ij+1,9g+9,7+a,8m,4+1,49+x,14u,2+2,c+2,e+2,e+2,e+1,i+n,e+e,2+p,u+2,e+2,36+1,2+3,2+1,b,2+2,6+5,2,2,2,h+1,5+4,6+3,3+f,16+2,5+3l,3+81,1y+p,2+40,q+a,m+13,2r+ch,2+9e,75+hf,3+v,2+2w,6e+5,f+6,75+2a,1a+p,2+2g,d+5x,r+b,6+3,4+o,g,6+1,6+2,2k+1,4,2j,5h+z,1m+1,1e+f,t+2,1f+e,d+3,4o+3,2s+1,w,535+1r,h3l+1i,93+2,2s,b+1,3l+x,2v,4g+3,21+3,kz+1,g5v+1,5a,j+9,n+v,2,3,2+8,2+1,3+2,2,3,46+1,4+4,h+5,r+5,r+a,3h+2,4+6,b+4,78,1r+24,4+c,4,1hb,ey+6,103+j,16j+c,1ux+7,5+g,fsh,jdq+1t,4,57+2e,p1,1m,1m,1m,1m,4kt+1,7j+17,5+2r,d+e,3+e,2+e,2+10,m+4,w,1n+5,1q,4z+5,4b+rb,9+c,4+c,4+37,d+2g,8+b,l+b,5+1j,9+9,7+13,9+t,3+1,27+3c,2+29,2+3q,d+d,3+4,4+2,6+6,a+o,8+6,a+2,e+6,16+42,2+1i",
	    "BN": "0+8,6+d,2s+5,2+p,e,4m9,1kt+2,2b+5,5+5,17q9+v,7k,6p+8,6+1,119d+3,440+7,96s+1,1ekf+1,1ekf+1,1ekf+1,1ekf+1,1ekf+1,1ekf+1,1ekf+1,1ekf+1,1ekf+1,1ekf+1,1ekf+1,1ekf+75,6p+2rz,1ben+1,1ekf+1,1ekf+1",
	    "NSM": "lc+33,7o+6,7c+18,2,2+1,2+1,2,21+a,1d+k,h,2u+6,3+5,3+1,2+3,10,v+q,2k+a,1n+8,a,p+3,2+8,2+2,2+4,18+2,3c+e,2+v,1k,2,5+7,5,4+6,b+1,u,1n,5+3,9,l+1,r,3+1,1m,5+1,5+1,3+2,4,v+1,4,c+1,1m,5+4,2+1,5,l+1,n+5,2,1n,3,2+3,9,8+1,c+1,v,1q,d,1f,4,1m+2,6+2,2+3,8+1,c+1,u,1n,g+1,l+1,t+1,1m+1,5+3,9,l+1,u,21,8+2,2,2j,3+6,d+7,2r,3+8,c+5,23+1,s,2,2,1k+d,2+4,2+1,6+a,2+z,a,2v+3,2+5,2+1,3+1,q+1,5+2,h+3,e,3+1,7,g,jk+2,qb+2,u+2,u+1,v+1,1t+1,2+6,9,3+a,a,1a+2,3c+1,z,3b+2,5+1,a,7+2,64+1,3,1n,2+6,2,2,3+7,7+9,3,1d+g,1s+3,1d,2+4,2,6,15+8,d+1,x+3,3+1,2+2,1l,2+1,4,2+2,1n+7,3+1,49+2,2+c,2+6,5,7,4+1,5j+1l,2+4,k1+w,2db+2,3y,2p+v,ff+3,30+1,n9x+3,2+9,x+1,29+1,7l,4,5,q+1,6,48+1,r+h,e,13+7,q+a,1b+2,1d,3+3,3+1,14,1w+5,3+1,3+1,d,9,1c,1g,2+2,3+1,6+1,2,17+1,9,6n,3,5,fn5,ki+f,h+f,r2,6b,46+4,1af+2,2+1,6+3,15+2,5,4m+1,fy+3,as+1,4a+a,4x,1j+e,1l+2,1e+3,3+1,1y+2,11+4,2+7,1r,d+1,1h+8,b+3,3,2o+2,3,2+1,7,4h,4+7,m+1,1m+1,4,12+6,4+4,5g+7,3+2,2,o,2d+5,2,5+1,2+1,6n+3,7+1,2+1,s+1,2e+7,3,2+1,2z,2,3+5,2,2u+2,3+3,2+4,78+8,2+1,75+1,2,5,41+3,3+1,5,x+5,3+1,15+5,3+3,9,a+5,3+2,1b+c,2+1,bb+6,2+5,2d+l,3+6,2+1,2+1,3f+5,4,2+1,2+6,2,21+1,4,2,9o+1,f0c+4,1o+6,t5,1s+3,2a,f5l+1,43t+2,i+7,3+6,v+3,45+2,1j0+1i,5+1d,9,f,n+4,2+e,11t+6,2+g,3+6,2+1,2+4,7a+6,c6+3,15t+6,32+6,gzhy+6n",
	    "AL": "16w,3,2,e+1b,z+2,2+2s,g+1,8+1,b+m,2+t,s+2i,c+e,4h+f,1d+1e,1bwe+dp,3+3z,x+c,2+1,35+3y,2rm+z,5+7,b+5,dt+l,c+u,17nl+27,1t+27,4x+6n,3+d",
	    "LRO": "6ct",
	    "RLO": "6cu",
	    "LRE": "6cq",
	    "RLE": "6cr",
	    "PDF": "6cs",
	    "LRI": "6ee",
	    "RLI": "6ef",
	    "FSI": "6eg",
	    "PDI": "6eh"
	  };

	  var TYPES = {};
	  var TYPES_TO_NAMES = {};
	  TYPES.L = 1; //L is the default
	  TYPES_TO_NAMES[1] = 'L';
	  Object.keys(DATA).forEach(function (type, i) {
	    TYPES[type] = 1 << (i + 1);
	    TYPES_TO_NAMES[TYPES[type]] = type;
	  });
	  Object.freeze(TYPES);

	  var ISOLATE_INIT_TYPES = TYPES.LRI | TYPES.RLI | TYPES.FSI;
	  var STRONG_TYPES = TYPES.L | TYPES.R | TYPES.AL;
	  var NEUTRAL_ISOLATE_TYPES = TYPES.B | TYPES.S | TYPES.WS | TYPES.ON | TYPES.FSI | TYPES.LRI | TYPES.RLI | TYPES.PDI;
	  var BN_LIKE_TYPES = TYPES.BN | TYPES.RLE | TYPES.LRE | TYPES.RLO | TYPES.LRO | TYPES.PDF;
	  var TRAILING_TYPES = TYPES.S | TYPES.WS | TYPES.B | ISOLATE_INIT_TYPES | TYPES.PDI | BN_LIKE_TYPES;

	  var map = null;

	  function parseData () {
	    if (!map) {
	      //const start = performance.now()
	      map = new Map();
	      var loop = function ( type ) {
	        if (DATA.hasOwnProperty(type)) {
	          var lastCode = 0;
	          DATA[type].split(',').forEach(function (range) {
	            var ref = range.split('+');
	            var skip = ref[0];
	            var step = ref[1];
	            skip = parseInt(skip, 36);
	            step = step ? parseInt(step, 36) : 0;
	            map.set(lastCode += skip, TYPES[type]);
	            for (var i = 0; i < step; i++) {
	              map.set(++lastCode, TYPES[type]);
	            }
	          });
	        }
	      };

	      for (var type in DATA) loop( type );
	      //console.log(`char types parsed in ${performance.now() - start}ms`)
	    }
	  }

	  /**
	   * @param {string} char
	   * @return {number}
	   */
	  function getBidiCharType (char) {
	    parseData();
	    return map.get(char.codePointAt(0)) || TYPES.L
	  }

	  function getBidiCharTypeName(char) {
	    return TYPES_TO_NAMES[getBidiCharType(char)]
	  }

	  // Bidi bracket pairs data, auto generated
	  var data$1 = {
	    "pairs": "14>1,1e>2,u>2,2wt>1,1>1,1ge>1,1wp>1,1j>1,f>1,hm>1,1>1,u>1,u6>1,1>1,+5,28>1,w>1,1>1,+3,b8>1,1>1,+3,1>3,-1>-1,3>1,1>1,+2,1s>1,1>1,x>1,th>1,1>1,+2,db>1,1>1,+3,3>1,1>1,+2,14qm>1,1>1,+1,4q>1,1e>2,u>2,2>1,+1",
	    "canonical": "6f1>-6dx,6dy>-6dx,6ec>-6ed,6ee>-6ed,6ww>2jj,-2ji>2jj,14r4>-1e7l,1e7m>-1e7l,1e7m>-1e5c,1e5d>-1e5b,1e5c>-14qx,14qy>-14qx,14vn>-1ecg,1ech>-1ecg,1edu>-1ecg,1eci>-1ecg,1eda>-1ecg,1eci>-1ecg,1eci>-168q,168r>-168q,168s>-14ye,14yf>-14ye"
	  };

	  /**
	   * Parses an string that holds encoded codepoint mappings, e.g. for bracket pairs or
	   * mirroring characters, as encoded by scripts/generateBidiData.js. Returns an object
	   * holding the `map`, and optionally a `reverseMap` if `includeReverse:true`.
	   * @param {string} encodedString
	   * @param {boolean} includeReverse - true if you want reverseMap in the output
	   * @return {{map: Map<number, number>, reverseMap?: Map<number, number>}}
	   */
	  function parseCharacterMap (encodedString, includeReverse) {
	    var radix = 36;
	    var lastCode = 0;
	    var map = new Map();
	    var reverseMap = includeReverse && new Map();
	    var prevPair;
	    encodedString.split(',').forEach(function visit(entry) {
	      if (entry.indexOf('+') !== -1) {
	        for (var i = +entry; i--;) {
	          visit(prevPair);
	        }
	      } else {
	        prevPair = entry;
	        var ref = entry.split('>');
	        var a = ref[0];
	        var b = ref[1];
	        a = String.fromCodePoint(lastCode += parseInt(a, radix));
	        b = String.fromCodePoint(lastCode += parseInt(b, radix));
	        map.set(a, b);
	        includeReverse && reverseMap.set(b, a);
	      }
	    });
	    return { map: map, reverseMap: reverseMap }
	  }

	  var openToClose, closeToOpen, canonical;

	  function parse$1 () {
	    if (!openToClose) {
	      //const start = performance.now()
	      var ref = parseCharacterMap(data$1.pairs, true);
	      var map = ref.map;
	      var reverseMap = ref.reverseMap;
	      openToClose = map;
	      closeToOpen = reverseMap;
	      canonical = parseCharacterMap(data$1.canonical, false).map;
	      //console.log(`brackets parsed in ${performance.now() - start}ms`)
	    }
	  }

	  function openingToClosingBracket (char) {
	    parse$1();
	    return openToClose.get(char) || null
	  }

	  function closingToOpeningBracket (char) {
	    parse$1();
	    return closeToOpen.get(char) || null
	  }

	  function getCanonicalBracket (char) {
	    parse$1();
	    return canonical.get(char) || null
	  }

	  // Local type aliases
	  var TYPE_L = TYPES.L;
	  var TYPE_R = TYPES.R;
	  var TYPE_EN = TYPES.EN;
	  var TYPE_ES = TYPES.ES;
	  var TYPE_ET = TYPES.ET;
	  var TYPE_AN = TYPES.AN;
	  var TYPE_CS = TYPES.CS;
	  var TYPE_B = TYPES.B;
	  var TYPE_S = TYPES.S;
	  var TYPE_ON = TYPES.ON;
	  var TYPE_BN = TYPES.BN;
	  var TYPE_NSM = TYPES.NSM;
	  var TYPE_AL = TYPES.AL;
	  var TYPE_LRO = TYPES.LRO;
	  var TYPE_RLO = TYPES.RLO;
	  var TYPE_LRE = TYPES.LRE;
	  var TYPE_RLE = TYPES.RLE;
	  var TYPE_PDF = TYPES.PDF;
	  var TYPE_LRI = TYPES.LRI;
	  var TYPE_RLI = TYPES.RLI;
	  var TYPE_FSI = TYPES.FSI;
	  var TYPE_PDI = TYPES.PDI;

	  /**
	   * @typedef {object} GetEmbeddingLevelsResult
	   * @property {{start, end, level}[]} paragraphs
	   * @property {Uint8Array} levels
	   */

	  /**
	   * This function applies the Bidirectional Algorithm to a string, returning the resolved embedding levels
	   * in a single Uint8Array plus a list of objects holding each paragraph's start and end indices and resolved
	   * base embedding level.
	   *
	   * @param {string} string - The input string
	   * @param {"ltr"|"rtl"|"auto"} [baseDirection] - Use "ltr" or "rtl" to force a base paragraph direction,
	   *        otherwise a direction will be chosen automatically from each paragraph's contents.
	   * @return {GetEmbeddingLevelsResult}
	   */
	  function getEmbeddingLevels (string, baseDirection) {
	    var MAX_DEPTH = 125;

	    // Start by mapping all characters to their unicode type, as a bitmask integer
	    var charTypes = new Uint32Array(string.length);
	    for (var i = 0; i < string.length; i++) {
	      charTypes[i] = getBidiCharType(string[i]);
	    }

	    var charTypeCounts = new Map(); //will be cleared at start of each paragraph
	    function changeCharType(i, type) {
	      var oldType = charTypes[i];
	      charTypes[i] = type;
	      charTypeCounts.set(oldType, charTypeCounts.get(oldType) - 1);
	      if (oldType & NEUTRAL_ISOLATE_TYPES) {
	        charTypeCounts.set(NEUTRAL_ISOLATE_TYPES, charTypeCounts.get(NEUTRAL_ISOLATE_TYPES) - 1);
	      }
	      charTypeCounts.set(type, (charTypeCounts.get(type) || 0) + 1);
	      if (type & NEUTRAL_ISOLATE_TYPES) {
	        charTypeCounts.set(NEUTRAL_ISOLATE_TYPES, (charTypeCounts.get(NEUTRAL_ISOLATE_TYPES) || 0) + 1);
	      }
	    }

	    var embedLevels = new Uint8Array(string.length);
	    var isolationPairs = new Map(); //init->pdi and pdi->init

	    // === 3.3.1 The Paragraph Level ===
	    // 3.3.1 P1: Split the text into paragraphs
	    var paragraphs = []; // [{start, end, level}, ...]
	    var paragraph = null;
	    for (var i$1 = 0; i$1 < string.length; i$1++) {
	      if (!paragraph) {
	        paragraphs.push(paragraph = {
	          start: i$1,
	          end: string.length - 1,
	          // 3.3.1 P2-P3: Determine the paragraph level
	          level: baseDirection === 'rtl' ? 1 : baseDirection === 'ltr' ? 0 : determineAutoEmbedLevel(i$1, false)
	        });
	      }
	      if (charTypes[i$1] & TYPE_B) {
	        paragraph.end = i$1;
	        paragraph = null;
	      }
	    }

	    var FORMATTING_TYPES = TYPE_RLE | TYPE_LRE | TYPE_RLO | TYPE_LRO | ISOLATE_INIT_TYPES | TYPE_PDI | TYPE_PDF | TYPE_B;
	    var nextEven = function (n) { return n + ((n & 1) ? 1 : 2); };
	    var nextOdd = function (n) { return n + ((n & 1) ? 2 : 1); };

	    // Everything from here on will operate per paragraph.
	    for (var paraIdx = 0; paraIdx < paragraphs.length; paraIdx++) {
	      paragraph = paragraphs[paraIdx];
	      var statusStack = [{
	        _level: paragraph.level,
	        _override: 0, //0=neutral, 1=L, 2=R
	        _isolate: 0 //bool
	      }];
	      var stackTop = (void 0);
	      var overflowIsolateCount = 0;
	      var overflowEmbeddingCount = 0;
	      var validIsolateCount = 0;
	      charTypeCounts.clear();

	      // === 3.3.2 Explicit Levels and Directions ===
	      for (var i$2 = paragraph.start; i$2 <= paragraph.end; i$2++) {
	        var charType = charTypes[i$2];
	        stackTop = statusStack[statusStack.length - 1];

	        // Set initial counts
	        charTypeCounts.set(charType, (charTypeCounts.get(charType) || 0) + 1);
	        if (charType & NEUTRAL_ISOLATE_TYPES) {
	          charTypeCounts.set(NEUTRAL_ISOLATE_TYPES, (charTypeCounts.get(NEUTRAL_ISOLATE_TYPES) || 0) + 1);
	        }

	        // Explicit Embeddings: 3.3.2 X2 - X3
	        if (charType & FORMATTING_TYPES) { //prefilter all formatters
	          if (charType & (TYPE_RLE | TYPE_LRE)) {
	            embedLevels[i$2] = stackTop._level; // 5.2
	            var level = (charType === TYPE_RLE ? nextOdd : nextEven)(stackTop._level);
	            if (level <= MAX_DEPTH && !overflowIsolateCount && !overflowEmbeddingCount) {
	              statusStack.push({
	                _level: level,
	                _override: 0,
	                _isolate: 0
	              });
	            } else if (!overflowIsolateCount) {
	              overflowEmbeddingCount++;
	            }
	          }

	          // Explicit Overrides: 3.3.2 X4 - X5
	          else if (charType & (TYPE_RLO | TYPE_LRO)) {
	            embedLevels[i$2] = stackTop._level; // 5.2
	            var level$1 = (charType === TYPE_RLO ? nextOdd : nextEven)(stackTop._level);
	            if (level$1 <= MAX_DEPTH && !overflowIsolateCount && !overflowEmbeddingCount) {
	              statusStack.push({
	                _level: level$1,
	                _override: (charType & TYPE_RLO) ? TYPE_R : TYPE_L,
	                _isolate: 0
	              });
	            } else if (!overflowIsolateCount) {
	              overflowEmbeddingCount++;
	            }
	          }

	          // Isolates: 3.3.2 X5a - X5c
	          else if (charType & ISOLATE_INIT_TYPES) {
	            // X5c - FSI becomes either RLI or LRI
	            if (charType & TYPE_FSI) {
	              charType = determineAutoEmbedLevel(i$2 + 1, true) === 1 ? TYPE_RLI : TYPE_LRI;
	            }

	            embedLevels[i$2] = stackTop._level;
	            if (stackTop._override) {
	              changeCharType(i$2, stackTop._override);
	            }
	            var level$2 = (charType === TYPE_RLI ? nextOdd : nextEven)(stackTop._level);
	            if (level$2 <= MAX_DEPTH && overflowIsolateCount === 0 && overflowEmbeddingCount === 0) {
	              validIsolateCount++;
	              statusStack.push({
	                _level: level$2,
	                _override: 0,
	                _isolate: 1,
	                _isolInitIndex: i$2
	              });
	            } else {
	              overflowIsolateCount++;
	            }
	          }

	          // Terminating Isolates: 3.3.2 X6a
	          else if (charType & TYPE_PDI) {
	            if (overflowIsolateCount > 0) {
	              overflowIsolateCount--;
	            } else if (validIsolateCount > 0) {
	              overflowEmbeddingCount = 0;
	              while (!statusStack[statusStack.length - 1]._isolate) {
	                statusStack.pop();
	              }
	              // Add to isolation pairs bidirectional mapping:
	              var isolInitIndex = statusStack[statusStack.length - 1]._isolInitIndex;
	              if (isolInitIndex != null) {
	                isolationPairs.set(isolInitIndex, i$2);
	                isolationPairs.set(i$2, isolInitIndex);
	              }
	              statusStack.pop();
	              validIsolateCount--;
	            }
	            stackTop = statusStack[statusStack.length - 1];
	            embedLevels[i$2] = stackTop._level;
	            if (stackTop._override) {
	              changeCharType(i$2, stackTop._override);
	            }
	          }


	          // Terminating Embeddings and Overrides: 3.3.2 X7
	          else if (charType & TYPE_PDF) {
	            if (overflowIsolateCount === 0) {
	              if (overflowEmbeddingCount > 0) {
	                overflowEmbeddingCount--;
	              } else if (!stackTop._isolate && statusStack.length > 1) {
	                statusStack.pop();
	                stackTop = statusStack[statusStack.length - 1];
	              }
	            }
	            embedLevels[i$2] = stackTop._level; // 5.2
	          }

	          // End of Paragraph: 3.3.2 X8
	          else if (charType & TYPE_B) {
	            embedLevels[i$2] = paragraph.level;
	          }
	        }

	        // Non-formatting characters: 3.3.2 X6
	        else {
	          embedLevels[i$2] = stackTop._level;
	          // NOTE: This exclusion of BN seems to go against what section 5.2 says, but is required for test passage
	          if (stackTop._override && charType !== TYPE_BN) {
	            changeCharType(i$2, stackTop._override);
	          }
	        }
	      }

	      // === 3.3.3 Preparations for Implicit Processing ===

	      // Remove all RLE, LRE, RLO, LRO, PDF, and BN characters: 3.3.3 X9
	      // Note: Due to section 5.2, we won't remove them, but we'll use the BN_LIKE_TYPES bitset to
	      // easily ignore them all from here on out.

	      // 3.3.3 X10
	      // Compute the set of isolating run sequences as specified by BD13
	      var levelRuns = [];
	      var currentRun = null;
	      for (var i$3 = paragraph.start; i$3 <= paragraph.end; i$3++) {
	        var charType$1 = charTypes[i$3];
	        if (!(charType$1 & BN_LIKE_TYPES)) {
	          var lvl = embedLevels[i$3];
	          var isIsolInit = charType$1 & ISOLATE_INIT_TYPES;
	          var isPDI = charType$1 === TYPE_PDI;
	          if (currentRun && lvl === currentRun._level) {
	            currentRun._end = i$3;
	            currentRun._endsWithIsolInit = isIsolInit;
	          } else {
	            levelRuns.push(currentRun = {
	              _start: i$3,
	              _end: i$3,
	              _level: lvl,
	              _startsWithPDI: isPDI,
	              _endsWithIsolInit: isIsolInit
	            });
	          }
	        }
	      }
	      var isolatingRunSeqs = []; // [{seqIndices: [], sosType: L|R, eosType: L|R}]
	      for (var runIdx = 0; runIdx < levelRuns.length; runIdx++) {
	        var run = levelRuns[runIdx];
	        if (!run._startsWithPDI || (run._startsWithPDI && !isolationPairs.has(run._start))) {
	          var seqRuns = [currentRun = run];
	          for (var pdiIndex = (void 0); currentRun && currentRun._endsWithIsolInit && (pdiIndex = isolationPairs.get(currentRun._end)) != null;) {
	            for (var i$4 = runIdx + 1; i$4 < levelRuns.length; i$4++) {
	              if (levelRuns[i$4]._start === pdiIndex) {
	                seqRuns.push(currentRun = levelRuns[i$4]);
	                break
	              }
	            }
	          }
	          // build flat list of indices across all runs:
	          var seqIndices = [];
	          for (var i$5 = 0; i$5 < seqRuns.length; i$5++) {
	            var run$1 = seqRuns[i$5];
	            for (var j = run$1._start; j <= run$1._end; j++) {
	              seqIndices.push(j);
	            }
	          }
	          // determine the sos/eos types:
	          var firstLevel = embedLevels[seqIndices[0]];
	          var prevLevel = paragraph.level;
	          for (var i$6 = seqIndices[0] - 1; i$6 >= 0; i$6--) {
	            if (!(charTypes[i$6] & BN_LIKE_TYPES)) { //5.2
	              prevLevel = embedLevels[i$6];
	              break
	            }
	          }
	          var lastIndex = seqIndices[seqIndices.length - 1];
	          var lastLevel = embedLevels[lastIndex];
	          var nextLevel = paragraph.level;
	          if (!(charTypes[lastIndex] & ISOLATE_INIT_TYPES)) {
	            for (var i$7 = lastIndex + 1; i$7 <= paragraph.end; i$7++) {
	              if (!(charTypes[i$7] & BN_LIKE_TYPES)) { //5.2
	                nextLevel = embedLevels[i$7];
	                break
	              }
	            }
	          }
	          isolatingRunSeqs.push({
	            _seqIndices: seqIndices,
	            _sosType: Math.max(prevLevel, firstLevel) % 2 ? TYPE_R : TYPE_L,
	            _eosType: Math.max(nextLevel, lastLevel) % 2 ? TYPE_R : TYPE_L
	          });
	        }
	      }

	      // The next steps are done per isolating run sequence
	      for (var seqIdx = 0; seqIdx < isolatingRunSeqs.length; seqIdx++) {
	        var ref = isolatingRunSeqs[seqIdx];
	        var seqIndices$1 = ref._seqIndices;
	        var sosType = ref._sosType;
	        var eosType = ref._eosType;
	        /**
	         * All the level runs in an isolating run sequence have the same embedding level.
	         * 
	         * DO NOT change any `embedLevels[i]` within the current scope.
	         */
	        var embedDirection = ((embedLevels[seqIndices$1[0]]) & 1) ? TYPE_R : TYPE_L;

	        // === 3.3.4 Resolving Weak Types ===

	        // W1 + 5.2. Search backward from each NSM to the first character in the isolating run sequence whose
	        // bidirectional type is not BN, and set the NSM to ON if it is an isolate initiator or PDI, and to its
	        // type otherwise. If the NSM is the first non-BN character, change the NSM to the type of sos.
	        if (charTypeCounts.get(TYPE_NSM)) {
	          for (var si = 0; si < seqIndices$1.length; si++) {
	            var i$8 = seqIndices$1[si];
	            if (charTypes[i$8] & TYPE_NSM) {
	              var prevType = sosType;
	              for (var sj = si - 1; sj >= 0; sj--) {
	                if (!(charTypes[seqIndices$1[sj]] & BN_LIKE_TYPES)) { //5.2 scan back to first non-BN
	                  prevType = charTypes[seqIndices$1[sj]];
	                  break
	                }
	              }
	              changeCharType(i$8, (prevType & (ISOLATE_INIT_TYPES | TYPE_PDI)) ? TYPE_ON : prevType);
	            }
	          }
	        }

	        // W2. Search backward from each instance of a European number until the first strong type (R, L, AL, or sos)
	        // is found. If an AL is found, change the type of the European number to Arabic number.
	        if (charTypeCounts.get(TYPE_EN)) {
	          for (var si$1 = 0; si$1 < seqIndices$1.length; si$1++) {
	            var i$9 = seqIndices$1[si$1];
	            if (charTypes[i$9] & TYPE_EN) {
	              for (var sj$1 = si$1 - 1; sj$1 >= -1; sj$1--) {
	                var prevCharType = sj$1 === -1 ? sosType : charTypes[seqIndices$1[sj$1]];
	                if (prevCharType & STRONG_TYPES) {
	                  if (prevCharType === TYPE_AL) {
	                    changeCharType(i$9, TYPE_AN);
	                  }
	                  break
	                }
	              }
	            }
	          }
	        }

	        // W3. Change all ALs to R
	        if (charTypeCounts.get(TYPE_AL)) {
	          for (var si$2 = 0; si$2 < seqIndices$1.length; si$2++) {
	            var i$10 = seqIndices$1[si$2];
	            if (charTypes[i$10] & TYPE_AL) {
	              changeCharType(i$10, TYPE_R);
	            }
	          }
	        }

	        // W4. A single European separator between two European numbers changes to a European number. A single common
	        // separator between two numbers of the same type changes to that type.
	        if (charTypeCounts.get(TYPE_ES) || charTypeCounts.get(TYPE_CS)) {
	          for (var si$3 = 1; si$3 < seqIndices$1.length - 1; si$3++) {
	            var i$11 = seqIndices$1[si$3];
	            if (charTypes[i$11] & (TYPE_ES | TYPE_CS)) {
	              var prevType$1 = 0, nextType = 0;
	              for (var sj$2 = si$3 - 1; sj$2 >= 0; sj$2--) {
	                prevType$1 = charTypes[seqIndices$1[sj$2]];
	                if (!(prevType$1 & BN_LIKE_TYPES)) { //5.2
	                  break
	                }
	              }
	              for (var sj$3 = si$3 + 1; sj$3 < seqIndices$1.length; sj$3++) {
	                nextType = charTypes[seqIndices$1[sj$3]];
	                if (!(nextType & BN_LIKE_TYPES)) { //5.2
	                  break
	                }
	              }
	              if (prevType$1 === nextType && (charTypes[i$11] === TYPE_ES ? prevType$1 === TYPE_EN : (prevType$1 & (TYPE_EN | TYPE_AN)))) {
	                changeCharType(i$11, prevType$1);
	              }
	            }
	          }
	        }

	        // W5. A sequence of European terminators adjacent to European numbers changes to all European numbers.
	        if (charTypeCounts.get(TYPE_EN)) {
	          for (var si$4 = 0; si$4 < seqIndices$1.length; si$4++) {
	            var i$12 = seqIndices$1[si$4];
	            if (charTypes[i$12] & TYPE_EN) {
	              for (var sj$4 = si$4 - 1; sj$4 >= 0 && (charTypes[seqIndices$1[sj$4]] & (TYPE_ET | BN_LIKE_TYPES)); sj$4--) {
	                changeCharType(seqIndices$1[sj$4], TYPE_EN);
	              }
	              for (si$4++; si$4 < seqIndices$1.length && (charTypes[seqIndices$1[si$4]] & (TYPE_ET | BN_LIKE_TYPES | TYPE_EN)); si$4++) {
	                if (charTypes[seqIndices$1[si$4]] !== TYPE_EN) {
	                  changeCharType(seqIndices$1[si$4], TYPE_EN);
	                }
	              }
	            }
	          }
	        }

	        // W6. Otherwise, separators and terminators change to Other Neutral.
	        if (charTypeCounts.get(TYPE_ET) || charTypeCounts.get(TYPE_ES) || charTypeCounts.get(TYPE_CS)) {
	          for (var si$5 = 0; si$5 < seqIndices$1.length; si$5++) {
	            var i$13 = seqIndices$1[si$5];
	            if (charTypes[i$13] & (TYPE_ET | TYPE_ES | TYPE_CS)) {
	              changeCharType(i$13, TYPE_ON);
	              // 5.2 transform adjacent BNs too:
	              for (var sj$5 = si$5 - 1; sj$5 >= 0 && (charTypes[seqIndices$1[sj$5]] & BN_LIKE_TYPES); sj$5--) {
	                changeCharType(seqIndices$1[sj$5], TYPE_ON);
	              }
	              for (var sj$6 = si$5 + 1; sj$6 < seqIndices$1.length && (charTypes[seqIndices$1[sj$6]] & BN_LIKE_TYPES); sj$6++) {
	                changeCharType(seqIndices$1[sj$6], TYPE_ON);
	              }
	            }
	          }
	        }

	        // W7. Search backward from each instance of a European number until the first strong type (R, L, or sos)
	        // is found. If an L is found, then change the type of the European number to L.
	        // NOTE: implemented in single forward pass for efficiency
	        if (charTypeCounts.get(TYPE_EN)) {
	          for (var si$6 = 0, prevStrongType = sosType; si$6 < seqIndices$1.length; si$6++) {
	            var i$14 = seqIndices$1[si$6];
	            var type = charTypes[i$14];
	            if (type & TYPE_EN) {
	              if (prevStrongType === TYPE_L) {
	                changeCharType(i$14, TYPE_L);
	              }
	            } else if (type & STRONG_TYPES) {
	              prevStrongType = type;
	            }
	          }
	        }

	        // === 3.3.5 Resolving Neutral and Isolate Formatting Types ===

	        if (charTypeCounts.get(NEUTRAL_ISOLATE_TYPES)) {
	          // N0. Process bracket pairs in an isolating run sequence sequentially in the logical order of the text
	          // positions of the opening paired brackets using the logic given below. Within this scope, bidirectional
	          // types EN and AN are treated as R.
	          var R_TYPES_FOR_N_STEPS = (TYPE_R | TYPE_EN | TYPE_AN);
	          var STRONG_TYPES_FOR_N_STEPS = R_TYPES_FOR_N_STEPS | TYPE_L;

	          // * Identify the bracket pairs in the current isolating run sequence according to BD16.
	          var bracketPairs = [];
	          {
	            var openerStack = [];
	            for (var si$7 = 0; si$7 < seqIndices$1.length; si$7++) {
	              // NOTE: for any potential bracket character we also test that it still carries a NI
	              // type, as that may have been changed earlier. This doesn't seem to be explicitly
	              // called out in the spec, but is required for passage of certain tests.
	              if (charTypes[seqIndices$1[si$7]] & NEUTRAL_ISOLATE_TYPES) {
	                var char = string[seqIndices$1[si$7]];
	                var oppositeBracket = (void 0);
	                // Opening bracket
	                if (openingToClosingBracket(char) !== null) {
	                  if (openerStack.length < 63) {
	                    openerStack.push({ char: char, seqIndex: si$7 });
	                  } else {
	                    break
	                  }
	                }
	                // Closing bracket
	                else if ((oppositeBracket = closingToOpeningBracket(char)) !== null) {
	                  for (var stackIdx = openerStack.length - 1; stackIdx >= 0; stackIdx--) {
	                    var stackChar = openerStack[stackIdx].char;
	                    if (stackChar === oppositeBracket ||
	                      stackChar === closingToOpeningBracket(getCanonicalBracket(char)) ||
	                      openingToClosingBracket(getCanonicalBracket(stackChar)) === char
	                    ) {
	                      bracketPairs.push([openerStack[stackIdx].seqIndex, si$7]);
	                      openerStack.length = stackIdx; //pop the matching bracket and all following
	                      break
	                    }
	                  }
	                }
	              }
	            }
	            bracketPairs.sort(function (a, b) { return a[0] - b[0]; });
	          }
	          // * For each bracket-pair element in the list of pairs of text positions
	          for (var pairIdx = 0; pairIdx < bracketPairs.length; pairIdx++) {
	            var ref$1 = bracketPairs[pairIdx];
	            var openSeqIdx = ref$1[0];
	            var closeSeqIdx = ref$1[1];
	            // a. Inspect the bidirectional types of the characters enclosed within the bracket pair.
	            // b. If any strong type (either L or R) matching the embedding direction is found, set the type for both
	            // brackets in the pair to match the embedding direction.
	            var foundStrongType = false;
	            var useStrongType = 0;
	            for (var si$8 = openSeqIdx + 1; si$8 < closeSeqIdx; si$8++) {
	              var i$15 = seqIndices$1[si$8];
	              if (charTypes[i$15] & STRONG_TYPES_FOR_N_STEPS) {
	                foundStrongType = true;
	                var lr = (charTypes[i$15] & R_TYPES_FOR_N_STEPS) ? TYPE_R : TYPE_L;
	                if (lr === embedDirection) {
	                  useStrongType = lr;
	                  break
	                }
	              }
	            }
	            // c. Otherwise, if there is a strong type it must be opposite the embedding direction. Therefore, test
	            // for an established context with a preceding strong type by checking backwards before the opening paired
	            // bracket until the first strong type (L, R, or sos) is found.
	            //    1. If the preceding strong type is also opposite the embedding direction, context is established, so
	            //    set the type for both brackets in the pair to that direction.
	            //    2. Otherwise set the type for both brackets in the pair to the embedding direction.
	            if (foundStrongType && !useStrongType) {
	              useStrongType = sosType;
	              for (var si$9 = openSeqIdx - 1; si$9 >= 0; si$9--) {
	                var i$16 = seqIndices$1[si$9];
	                if (charTypes[i$16] & STRONG_TYPES_FOR_N_STEPS) {
	                  var lr$1 = (charTypes[i$16] & R_TYPES_FOR_N_STEPS) ? TYPE_R : TYPE_L;
	                  if (lr$1 !== embedDirection) {
	                    useStrongType = lr$1;
	                  } else {
	                    useStrongType = embedDirection;
	                  }
	                  break
	                }
	              }
	            }
	            if (useStrongType) {
	              charTypes[seqIndices$1[openSeqIdx]] = charTypes[seqIndices$1[closeSeqIdx]] = useStrongType;
	              // * Any number of characters that had original bidirectional character type NSM prior to the application
	              // of W1 that immediately follow a paired bracket which changed to L or R under N0 should change to match
	              // the type of their preceding bracket.
	              if (useStrongType !== embedDirection) {
	                for (var si$10 = openSeqIdx + 1; si$10 < seqIndices$1.length; si$10++) {
	                  if (!(charTypes[seqIndices$1[si$10]] & BN_LIKE_TYPES)) {
	                    if (getBidiCharType(string[seqIndices$1[si$10]]) & TYPE_NSM) {
	                      charTypes[seqIndices$1[si$10]] = useStrongType;
	                    }
	                    break
	                  }
	                }
	              }
	              if (useStrongType !== embedDirection) {
	                for (var si$11 = closeSeqIdx + 1; si$11 < seqIndices$1.length; si$11++) {
	                  if (!(charTypes[seqIndices$1[si$11]] & BN_LIKE_TYPES)) {
	                    if (getBidiCharType(string[seqIndices$1[si$11]]) & TYPE_NSM) {
	                      charTypes[seqIndices$1[si$11]] = useStrongType;
	                    }
	                    break
	                  }
	                }
	              }
	            }
	          }

	          // N1. A sequence of NIs takes the direction of the surrounding strong text if the text on both sides has the
	          // same direction.
	          // N2. Any remaining NIs take the embedding direction.
	          for (var si$12 = 0; si$12 < seqIndices$1.length; si$12++) {
	            if (charTypes[seqIndices$1[si$12]] & NEUTRAL_ISOLATE_TYPES) {
	              var niRunStart = si$12, niRunEnd = si$12;
	              var prevType$2 = sosType; //si === 0 ? sosType : (charTypes[seqIndices[si - 1]] & R_TYPES_FOR_N_STEPS) ? TYPE_R : TYPE_L
	              for (var si2 = si$12 - 1; si2 >= 0; si2--) {
	                if (charTypes[seqIndices$1[si2]] & BN_LIKE_TYPES) {
	                  niRunStart = si2; //5.2 treat BNs adjacent to NIs as NIs
	                } else {
	                  prevType$2 = (charTypes[seqIndices$1[si2]] & R_TYPES_FOR_N_STEPS) ? TYPE_R : TYPE_L;
	                  break
	                }
	              }
	              var nextType$1 = eosType;
	              for (var si2$1 = si$12 + 1; si2$1 < seqIndices$1.length; si2$1++) {
	                if (charTypes[seqIndices$1[si2$1]] & (NEUTRAL_ISOLATE_TYPES | BN_LIKE_TYPES)) {
	                  niRunEnd = si2$1;
	                } else {
	                  nextType$1 = (charTypes[seqIndices$1[si2$1]] & R_TYPES_FOR_N_STEPS) ? TYPE_R : TYPE_L;
	                  break
	                }
	              }
	              for (var sj$7 = niRunStart; sj$7 <= niRunEnd; sj$7++) {
	                charTypes[seqIndices$1[sj$7]] = prevType$2 === nextType$1 ? prevType$2 : embedDirection;
	              }
	              si$12 = niRunEnd;
	            }
	          }
	        }
	      }

	      // === 3.3.6 Resolving Implicit Levels ===

	      for (var i$17 = paragraph.start; i$17 <= paragraph.end; i$17++) {
	        var level$3 = embedLevels[i$17];
	        var type$1 = charTypes[i$17];
	        // I2. For all characters with an odd (right-to-left) embedding level, those of type L, EN or AN go up one level.
	        if (level$3 & 1) {
	          if (type$1 & (TYPE_L | TYPE_EN | TYPE_AN)) {
	            embedLevels[i$17]++;
	          }
	        }
	          // I1. For all characters with an even (left-to-right) embedding level, those of type R go up one level
	        // and those of type AN or EN go up two levels.
	        else {
	          if (type$1 & TYPE_R) {
	            embedLevels[i$17]++;
	          } else if (type$1 & (TYPE_AN | TYPE_EN)) {
	            embedLevels[i$17] += 2;
	          }
	        }

	        // 5.2: Resolve any LRE, RLE, LRO, RLO, PDF, or BN to the level of the preceding character if there is one,
	        // and otherwise to the base level.
	        if (type$1 & BN_LIKE_TYPES) {
	          embedLevels[i$17] = i$17 === 0 ? paragraph.level : embedLevels[i$17 - 1];
	        }

	        // 3.4 L1.1-4: Reset the embedding level of segment/paragraph separators, and any sequence of whitespace or
	        // isolate formatting characters preceding them or the end of the paragraph, to the paragraph level.
	        // NOTE: this will also need to be applied to each individual line ending after line wrapping occurs.
	        if (i$17 === paragraph.end || getBidiCharType(string[i$17]) & (TYPE_S | TYPE_B)) {
	          for (var j$1 = i$17; j$1 >= 0 && (getBidiCharType(string[j$1]) & TRAILING_TYPES); j$1--) {
	            embedLevels[j$1] = paragraph.level;
	          }
	        }
	      }
	    }

	    // DONE! The resolved levels can then be used, after line wrapping, to flip runs of characters
	    // according to section 3.4 Reordering Resolved Levels
	    return {
	      levels: embedLevels,
	      paragraphs: paragraphs
	    }

	    function determineAutoEmbedLevel (start, isFSI) {
	      // 3.3.1 P2 - P3
	      for (var i = start; i < string.length; i++) {
	        var charType = charTypes[i];
	        if (charType & (TYPE_R | TYPE_AL)) {
	          return 1
	        }
	        if ((charType & (TYPE_B | TYPE_L)) || (isFSI && charType === TYPE_PDI)) {
	          return 0
	        }
	        if (charType & ISOLATE_INIT_TYPES) {
	          var pdi = indexOfMatchingPDI(i);
	          i = pdi === -1 ? string.length : pdi;
	        }
	      }
	      return 0
	    }

	    function indexOfMatchingPDI (isolateStart) {
	      // 3.1.2 BD9
	      var isolationLevel = 1;
	      for (var i = isolateStart + 1; i < string.length; i++) {
	        var charType = charTypes[i];
	        if (charType & TYPE_B) {
	          break
	        }
	        if (charType & TYPE_PDI) {
	          if (--isolationLevel === 0) {
	            return i
	          }
	        } else if (charType & ISOLATE_INIT_TYPES) {
	          isolationLevel++;
	        }
	      }
	      return -1
	    }
	  }

	  // Bidi mirrored chars data, auto generated
	  var data = "14>1,j>2,t>2,u>2,1a>g,2v3>1,1>1,1ge>1,1wd>1,b>1,1j>1,f>1,ai>3,-2>3,+1,8>1k0,-1jq>1y7,-1y6>1hf,-1he>1h6,-1h5>1ha,-1h8>1qi,-1pu>1,6>3u,-3s>7,6>1,1>1,f>1,1>1,+2,3>1,1>1,+13,4>1,1>1,6>1eo,-1ee>1,3>1mg,-1me>1mk,-1mj>1mi,-1mg>1mi,-1md>1,1>1,+2,1>10k,-103>1,1>1,4>1,5>1,1>1,+10,3>1,1>8,-7>8,+1,-6>7,+1,a>1,1>1,u>1,u6>1,1>1,+5,26>1,1>1,2>1,2>2,8>1,7>1,4>1,1>1,+5,b8>1,1>1,+3,1>3,-2>1,2>1,1>1,+2,c>1,3>1,1>1,+2,h>1,3>1,a>1,1>1,2>1,3>1,1>1,d>1,f>1,3>1,1a>1,1>1,6>1,7>1,13>1,k>1,1>1,+19,4>1,1>1,+2,2>1,1>1,+18,m>1,a>1,1>1,lk>1,1>1,4>1,2>1,f>1,3>1,1>1,+3,db>1,1>1,+3,3>1,1>1,+2,14qm>1,1>1,+1,6>1,4j>1,j>2,t>2,u>2,2>1,+1";

	  var mirrorMap;

	  function parse () {
	    if (!mirrorMap) {
	      //const start = performance.now()
	      var ref = parseCharacterMap(data, true);
	      var map = ref.map;
	      var reverseMap = ref.reverseMap;
	      // Combine both maps into one
	      reverseMap.forEach(function (value, key) {
	        map.set(key, value);
	      });
	      mirrorMap = map;
	      //console.log(`mirrored chars parsed in ${performance.now() - start}ms`)
	    }
	  }

	  function getMirroredCharacter (char) {
	    parse();
	    return mirrorMap.get(char) || null
	  }

	  /**
	   * Given a string and its resolved embedding levels, build a map of indices to replacement chars
	   * for any characters in right-to-left segments that have defined mirrored characters.
	   * @param string
	   * @param embeddingLevels
	   * @param [start]
	   * @param [end]
	   * @return {Map<number, string>}
	   */
	  function getMirroredCharactersMap(string, embeddingLevels, start, end) {
	    var strLen = string.length;
	    start = Math.max(0, start == null ? 0 : +start);
	    end = Math.min(strLen - 1, end == null ? strLen - 1 : +end);

	    var map = new Map();
	    for (var i = start; i <= end; i++) {
	      if (embeddingLevels[i] & 1) { //only odd (rtl) levels
	        var mirror = getMirroredCharacter(string[i]);
	        if (mirror !== null) {
	          map.set(i, mirror);
	        }
	      }
	    }
	    return map
	  }

	  /**
	   * Given a start and end denoting a single line within a string, and a set of precalculated
	   * bidi embedding levels, produce a list of segments whose ordering should be flipped, in sequence.
	   * @param {string} string - the full input string
	   * @param {GetEmbeddingLevelsResult} embeddingLevelsResult - the result object from getEmbeddingLevels
	   * @param {number} [start] - first character in a subset of the full string
	   * @param {number} [end] - last character in a subset of the full string
	   * @return {number[][]} - the list of start/end segments that should be flipped, in order.
	   */
	  function getReorderSegments(string, embeddingLevelsResult, start, end) {
	    var strLen = string.length;
	    start = Math.max(0, start == null ? 0 : +start);
	    end = Math.min(strLen - 1, end == null ? strLen - 1 : +end);

	    var segments = [];
	    embeddingLevelsResult.paragraphs.forEach(function (paragraph) {
	      var lineStart = Math.max(start, paragraph.start);
	      var lineEnd = Math.min(end, paragraph.end);
	      if (lineStart < lineEnd) {
	        // Local slice for mutation
	        var lineLevels = embeddingLevelsResult.levels.slice(lineStart, lineEnd + 1);

	        // 3.4 L1.4: Reset any sequence of whitespace characters and/or isolate formatting characters at the
	        // end of the line to the paragraph level.
	        for (var i = lineEnd; i >= lineStart && (getBidiCharType(string[i]) & TRAILING_TYPES); i--) {
	          lineLevels[i] = paragraph.level;
	        }

	        // L2. From the highest level found in the text to the lowest odd level on each line, including intermediate levels
	        // not actually present in the text, reverse any contiguous sequence of characters that are at that level or higher.
	        var maxLevel = paragraph.level;
	        var minOddLevel = Infinity;
	        for (var i$1 = 0; i$1 < lineLevels.length; i$1++) {
	          var level = lineLevels[i$1];
	          if (level > maxLevel) { maxLevel = level; }
	          if (level < minOddLevel) { minOddLevel = level | 1; }
	        }
	        for (var lvl = maxLevel; lvl >= minOddLevel; lvl--) {
	          for (var i$2 = 0; i$2 < lineLevels.length; i$2++) {
	            if (lineLevels[i$2] >= lvl) {
	              var segStart = i$2;
	              while (i$2 + 1 < lineLevels.length && lineLevels[i$2 + 1] >= lvl) {
	                i$2++;
	              }
	              if (i$2 > segStart) {
	                segments.push([segStart + lineStart, i$2 + lineStart]);
	              }
	            }
	          }
	        }
	      }
	    });
	    return segments
	  }

	  /**
	   * @param {string} string
	   * @param {GetEmbeddingLevelsResult} embedLevelsResult
	   * @param {number} [start]
	   * @param {number} [end]
	   * @return {string} the new string with bidi segments reordered
	   */
	  function getReorderedString(string, embedLevelsResult, start, end) {
	    var indices = getReorderedIndices(string, embedLevelsResult, start, end);
	    var chars = [].concat( string );
	    indices.forEach(function (charIndex, i) {
	      chars[i] = (
	        (embedLevelsResult.levels[charIndex] & 1) ? getMirroredCharacter(string[charIndex]) : null
	      ) || string[charIndex];
	    });
	    return chars.join('')
	  }

	  /**
	   * @param {string} string
	   * @param {GetEmbeddingLevelsResult} embedLevelsResult
	   * @param {number} [start]
	   * @param {number} [end]
	   * @return {number[]} an array with character indices in their new bidi order
	   */
	  function getReorderedIndices(string, embedLevelsResult, start, end) {
	    var segments = getReorderSegments(string, embedLevelsResult, start, end);
	    // Fill an array with indices
	    var indices = [];
	    for (var i = 0; i < string.length; i++) {
	      indices[i] = i;
	    }
	    // Reverse each segment in order
	    segments.forEach(function (ref) {
	      var start = ref[0];
	      var end = ref[1];

	      var slice = indices.slice(start, end + 1);
	      for (var i = slice.length; i--;) {
	        indices[end - i] = slice[i];
	      }
	    });
	    return indices
	  }

	  exports.closingToOpeningBracket = closingToOpeningBracket;
	  exports.getBidiCharType = getBidiCharType;
	  exports.getBidiCharTypeName = getBidiCharTypeName;
	  exports.getCanonicalBracket = getCanonicalBracket;
	  exports.getEmbeddingLevels = getEmbeddingLevels;
	  exports.getMirroredCharacter = getMirroredCharacter;
	  exports.getMirroredCharactersMap = getMirroredCharactersMap;
	  exports.getReorderSegments = getReorderSegments;
	  exports.getReorderedIndices = getReorderedIndices;
	  exports.getReorderedString = getReorderedString;
	  exports.openingToClosingBracket = openingToClosingBracket;

	  Object.defineProperty(exports, '__esModule', { value: true });

	  return exports;

	}({}));
	return bidi}

	/**
	 * Regular expression for matching the `void main() {` opener line in GLSL.
	 * @type {RegExp}
	 */
	const voidMainRegExp = /\bvoid\s+main\s*\(\s*\)\s*{/g;

	/**
	 * Recursively expands all `#include <xyz>` statements within string of shader code.
	 * Copied from three's WebGLProgram#parseIncludes for external use.
	 *
	 * @param {string} source - The GLSL source code to evaluate
	 * @return {string} The GLSL code with all includes expanded
	 */
	function expandShaderIncludes( source ) {
	  const pattern = /^[ \t]*#include +<([\w\d./]+)>/gm;
	  function replace(match, include) {
	    let chunk = ShaderChunk[include];
	    return chunk ? expandShaderIncludes(chunk) : match
	  }
	  return source.replace( pattern, replace )
	}

	/*
	 * This is a direct copy of MathUtils.generateUUID from Three.js, to preserve compatibility with three
	 * versions before 0.113.0 as it was changed from Math to MathUtils in that version.
	 * https://github.com/mrdoob/three.js/blob/dd8b5aa3b270c17096b90945cd2d6d1b13aaec53/src/math/MathUtils.js#L16
	 */

	const _lut$1 = [];

	for (let i = 0; i < 256; i++) {
	  _lut$1[i] = (i < 16 ? '0' : '') + (i).toString(16);
	}

	function generateUUID$1() {

	  // http://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid-in-javascript/21963136#21963136

	  const d0 = Math.random() * 0xffffffff | 0;
	  const d1 = Math.random() * 0xffffffff | 0;
	  const d2 = Math.random() * 0xffffffff | 0;
	  const d3 = Math.random() * 0xffffffff | 0;
	  const uuid = _lut$1[d0 & 0xff] + _lut$1[d0 >> 8 & 0xff] + _lut$1[d0 >> 16 & 0xff] + _lut$1[d0 >> 24 & 0xff] + '-' +
	    _lut$1[d1 & 0xff] + _lut$1[d1 >> 8 & 0xff] + '-' + _lut$1[d1 >> 16 & 0x0f | 0x40] + _lut$1[d1 >> 24 & 0xff] + '-' +
	    _lut$1[d2 & 0x3f | 0x80] + _lut$1[d2 >> 8 & 0xff] + '-' + _lut$1[d2 >> 16 & 0xff] + _lut$1[d2 >> 24 & 0xff] +
	    _lut$1[d3 & 0xff] + _lut$1[d3 >> 8 & 0xff] + _lut$1[d3 >> 16 & 0xff] + _lut$1[d3 >> 24 & 0xff];

	  // .toUpperCase() here flattens concatenated strings to save heap memory space.
	  return uuid.toUpperCase()

	}

	// Local assign polyfill to avoid importing troika-core
	const assign = Object.assign || function(/*target, ...sources*/) {
	  let target = arguments[0];
	  for (let i = 1, len = arguments.length; i < len; i++) {
	    let source = arguments[i];
	    if (source) {
	      for (let prop in source) {
	        if (Object.prototype.hasOwnProperty.call(source, prop)) {
	          target[prop] = source[prop];
	        }
	      }
	    }
	  }
	  return target
	};


	const epoch = Date.now();
	const CONSTRUCTOR_CACHE = new WeakMap();
	const SHADER_UPGRADE_CACHE = new Map();

	// Material ids must be integers, but we can't access the increment from Three's `Material` module,
	// so let's choose a sufficiently large starting value that should theoretically never collide.
	let materialInstanceId = 1e10;

	/**
	 * A utility for creating a custom shader material derived from another material's
	 * shaders. This allows you to inject custom shader logic and transforms into the
	 * builtin ThreeJS materials without having to recreate them from scratch.
	 *
	 * @param {THREE.Material} baseMaterial - the original material to derive from
	 *
	 * @param {Object} options - How the base material should be modified.
	 * @param {Object=} options.defines - Custom `defines` for the material
	 * @param {Object=} options.extensions - Custom `extensions` for the material, e.g. `{derivatives: true}`
	 * @param {Object=} options.uniforms - Custom `uniforms` for use in the modified shader. These can
	 *        be accessed and manipulated via the resulting material's `uniforms` property, just like
	 *        in a ShaderMaterial. You do not need to repeat the base material's own uniforms here.
	 * @param {String=} options.timeUniform - If specified, a uniform of this name will be injected into
	 *        both shaders, and it will automatically be updated on each render frame with a number of
	 *        elapsed milliseconds. The "zero" epoch time is not significant so don't rely on this as a
	 *        true calendar time.
	 * @param {String=} options.vertexDefs - Custom GLSL code to inject into the vertex shader's top-level
	 *        definitions, above the `void main()` function.
	 * @param {String=} options.vertexMainIntro - Custom GLSL code to inject at the top of the vertex
	 *        shader's `void main` function.
	 * @param {String=} options.vertexMainOutro - Custom GLSL code to inject at the end of the vertex
	 *        shader's `void main` function.
	 * @param {String=} options.vertexTransform - Custom GLSL code to manipulate the `position`, `normal`,
	 *        and/or `uv` vertex attributes. This code will be wrapped within a standalone function with
	 *        those attributes exposed by their normal names as read/write values.
	 * @param {String=} options.fragmentDefs - Custom GLSL code to inject into the fragment shader's top-level
	 *        definitions, above the `void main()` function.
	 * @param {String=} options.fragmentMainIntro - Custom GLSL code to inject at the top of the fragment
	 *        shader's `void main` function.
	 * @param {String=} options.fragmentMainOutro - Custom GLSL code to inject at the end of the fragment
	 *        shader's `void main` function. You can manipulate `gl_FragColor` here but keep in mind it goes
	 *        after any of ThreeJS's color postprocessing shader chunks (tonemapping, fog, etc.), so if you
	 *        want those to apply to your changes use `fragmentColorTransform` instead.
	 * @param {String=} options.fragmentColorTransform - Custom GLSL code to manipulate the `gl_FragColor`
	 *        output value. Will be injected near the end of the `void main` function, but before any
	 *        of ThreeJS's color postprocessing shader chunks (tonemapping, fog, etc.), and before the
	 *        `fragmentMainOutro`.
	 * @param {function({fragmentShader: string, vertexShader:string}):
	 *        {fragmentShader: string, vertexShader:string}} options.customRewriter - A function
	 *        for performing custom rewrites of the full shader code. Useful if you need to do something
	 *        special that's not covered by the other builtin options. This function will be executed before
	 *        any other transforms are applied.
	 * @param {boolean=} options.chained - Set to `true` to prototype-chain the derived material to the base
	 *        material, rather than the default behavior of copying it. This allows the derived material to
	 *        automatically pick up changes made to the base material and its properties. This can be useful
	 *        where the derived material is hidden from the user as an implementation detail, allowing them
	 *        to work with the original material like normal. But it can result in unexpected behavior if not
	 *        handled carefully.
	 *
	 * @return {THREE.Material}
	 *
	 * The returned material will also have two new methods, `getDepthMaterial()` and `getDistanceMaterial()`,
	 * which can be called to get a variant of the derived material for use in shadow casting. If the
	 * target mesh is expected to cast shadows, then you can assign these to the mesh's `customDepthMaterial`
	 * (for directional and spot lights) and/or `customDistanceMaterial` (for point lights) properties to
	 * allow the cast shadow to honor your derived shader's vertex transforms and discarded fragments. These
	 * will also set a custom `#define IS_DEPTH_MATERIAL` or `#define IS_DISTANCE_MATERIAL` that you can look
	 * for in your derived shaders with `#ifdef` to customize their behavior for the depth or distance
	 * scenarios, e.g. skipping antialiasing or expensive shader logic.
	 */
	function createDerivedMaterial(baseMaterial, options) {
	  // Generate a key that is unique to the content of these `options`. We'll use this
	  // throughout for caching and for generating the upgraded shader code. This increases
	  // the likelihood that the resulting shaders will line up across multiple calls so
	  // their GL programs can be shared and cached.
	  const optionsKey = getKeyForOptions(options);

	  // First check to see if we've already derived from this baseMaterial using this
	  // unique set of options, and if so reuse the constructor to avoid some allocations.
	  let ctorsByDerivation = CONSTRUCTOR_CACHE.get(baseMaterial);
	  if (!ctorsByDerivation) {
	    CONSTRUCTOR_CACHE.set(baseMaterial, (ctorsByDerivation = Object.create(null)));
	  }
	  if (ctorsByDerivation[optionsKey]) {
	    return new ctorsByDerivation[optionsKey]()
	  }

	  const privateBeforeCompileProp = `_onBeforeCompile${optionsKey}`;

	  // Private onBeforeCompile handler that injects the modified shaders and uniforms when
	  // the renderer switches to this material's program
	  const onBeforeCompile = function (shaderInfo, renderer) {
	    baseMaterial.onBeforeCompile.call(this, shaderInfo, renderer);

	    // Upgrade the shaders, caching the result by incoming source code
	    const cacheKey = this.customProgramCacheKey() + '|' + shaderInfo.vertexShader + '|' + shaderInfo.fragmentShader;
	    let upgradedShaders = SHADER_UPGRADE_CACHE[cacheKey];
	    if (!upgradedShaders) {
	      const upgraded = upgradeShaders(this, shaderInfo, options, optionsKey);
	      upgradedShaders = SHADER_UPGRADE_CACHE[cacheKey] = upgraded;
	    }

	    // Inject upgraded shaders and uniforms into the program
	    shaderInfo.vertexShader = upgradedShaders.vertexShader;
	    shaderInfo.fragmentShader = upgradedShaders.fragmentShader;
	    assign(shaderInfo.uniforms, this.uniforms);

	    // Inject auto-updating time uniform if requested
	    if (options.timeUniform) {
	      shaderInfo.uniforms[options.timeUniform] = {
	        get value() {return Date.now() - epoch}
	      };
	    }

	    // Users can still add their own handlers on top of ours
	    if (this[privateBeforeCompileProp]) {
	      this[privateBeforeCompileProp](shaderInfo);
	    }
	  };

	  const DerivedMaterial = function DerivedMaterial() {
	    return derive(options.chained ? baseMaterial : baseMaterial.clone())
	  };

	  const derive = function(base) {
	    // Prototype chain to the base material
	    const derived = Object.create(base, descriptor);

	    // Store the baseMaterial for reference; this is always the original even when cloning
	    Object.defineProperty(derived, 'baseMaterial', { value: baseMaterial });

	    // Needs its own ids
	    Object.defineProperty(derived, 'id', { value: materialInstanceId++ });
	    derived.uuid = generateUUID$1();

	    // Merge uniforms, defines, and extensions
	    derived.uniforms = assign({}, base.uniforms, options.uniforms);
	    derived.defines = assign({}, base.defines, options.defines);
	    derived.defines[`TROIKA_DERIVED_MATERIAL_${optionsKey}`] = ''; //force a program change from the base material
	    derived.extensions = assign({}, base.extensions, options.extensions);

	    // Don't inherit EventDispatcher listeners
	    derived._listeners = undefined;

	    return derived
	  };

	  const descriptor = {
	    constructor: {value: DerivedMaterial},
	    isDerivedMaterial: {value: true},

	    type: {
	      get: () => baseMaterial.type,
	      set: (value) => {baseMaterial.type = value;}
	    },

	    isDerivedFrom: {
	      writable: true,
	      configurable: true,
	      value: function (testMaterial) {
	        const base = this.baseMaterial;
	        return testMaterial === base || (base.isDerivedMaterial && base.isDerivedFrom(testMaterial)) || false
	      }
	    },

	    customProgramCacheKey: {
	      writable: true,
	      configurable: true,
	      value: function () {
	        return baseMaterial.customProgramCacheKey() + '|' + optionsKey
	      }
	    },

	    onBeforeCompile: {
	      get() {
	        return onBeforeCompile
	      },
	      set(fn) {
	        this[privateBeforeCompileProp] = fn;
	      }
	    },

	    copy: {
	      writable: true,
	      configurable: true,
	      value: function (source) {
	        baseMaterial.copy.call(this, source);
	        if (!baseMaterial.isShaderMaterial && !baseMaterial.isDerivedMaterial) {
	          assign(this.extensions, source.extensions);
	          assign(this.defines, source.defines);
	          assign(this.uniforms, UniformsUtils.clone(source.uniforms));
	        }
	        return this
	      }
	    },

	    clone: {
	      writable: true,
	      configurable: true,
	      value: function () {
	        const newBase = new baseMaterial.constructor();
	        return derive(newBase).copy(this)
	      }
	    },

	    /**
	     * Utility to get a MeshDepthMaterial that will honor this derived material's vertex
	     * transformations and discarded fragments.
	     */
	    getDepthMaterial: {
	      writable: true,
	      configurable: true,
	      value: function() {
	        let depthMaterial = this._depthMaterial;
	        if (!depthMaterial) {
	          depthMaterial = this._depthMaterial = createDerivedMaterial(
	            baseMaterial.isDerivedMaterial
	              ? baseMaterial.getDepthMaterial()
	              : new MeshDepthMaterial({ depthPacking: RGBADepthPacking }),
	            options
	          );
	          depthMaterial.defines.IS_DEPTH_MATERIAL = '';
	          depthMaterial.uniforms = this.uniforms; //automatically recieve same uniform values
	        }
	        return depthMaterial
	      }
	    },

	    /**
	     * Utility to get a MeshDistanceMaterial that will honor this derived material's vertex
	     * transformations and discarded fragments.
	     */
	    getDistanceMaterial: {
	      writable: true,
	      configurable: true,
	      value: function() {
	        let distanceMaterial = this._distanceMaterial;
	        if (!distanceMaterial) {
	          distanceMaterial = this._distanceMaterial = createDerivedMaterial(
	            baseMaterial.isDerivedMaterial
	              ? baseMaterial.getDistanceMaterial()
	              : new MeshDistanceMaterial(),
	            options
	          );
	          distanceMaterial.defines.IS_DISTANCE_MATERIAL = '';
	          distanceMaterial.uniforms = this.uniforms; //automatically recieve same uniform values
	        }
	        return distanceMaterial
	      }
	    },

	    dispose: {
	      writable: true,
	      configurable: true,
	      value() {
	        const {_depthMaterial, _distanceMaterial} = this;
	        if (_depthMaterial) _depthMaterial.dispose();
	        if (_distanceMaterial) _distanceMaterial.dispose();
	        baseMaterial.dispose.call(this);
	      }
	    }
	  };

	  ctorsByDerivation[optionsKey] = DerivedMaterial;
	  return new DerivedMaterial()
	}


	function upgradeShaders(material, {vertexShader, fragmentShader}, options, key) {
	  let {
	    vertexDefs,
	    vertexMainIntro,
	    vertexMainOutro,
	    vertexTransform,
	    fragmentDefs,
	    fragmentMainIntro,
	    fragmentMainOutro,
	    fragmentColorTransform,
	    customRewriter,
	    timeUniform
	  } = options;

	  vertexDefs = vertexDefs || '';
	  vertexMainIntro = vertexMainIntro || '';
	  vertexMainOutro = vertexMainOutro || '';
	  fragmentDefs = fragmentDefs || '';
	  fragmentMainIntro = fragmentMainIntro || '';
	  fragmentMainOutro = fragmentMainOutro || '';

	  // Expand includes if needed
	  if (vertexTransform || customRewriter) {
	    vertexShader = expandShaderIncludes(vertexShader);
	  }
	  if (fragmentColorTransform || customRewriter) {
	    // We need to be able to find postprocessing chunks after include expansion in order to
	    // put them after the fragmentColorTransform, so mark them with comments first. Even if
	    // this particular derivation doesn't have a fragmentColorTransform, other derivations may,
	    // so we still mark them.
	    fragmentShader = fragmentShader.replace(
	      /^[ \t]*#include <((?:tonemapping|encodings|colorspace|fog|premultiplied_alpha|dithering)_fragment)>/gm,
	      '\n//!BEGIN_POST_CHUNK $1\n$&\n//!END_POST_CHUNK\n'
	    );
	    fragmentShader = expandShaderIncludes(fragmentShader);
	  }

	  // Apply custom rewriter function
	  if (customRewriter) {
	    let res = customRewriter({vertexShader, fragmentShader});
	    vertexShader = res.vertexShader;
	    fragmentShader = res.fragmentShader;
	  }

	  // The fragmentColorTransform needs to go before any postprocessing chunks, so extract
	  // those and re-insert them into the outro in the correct place:
	  if (fragmentColorTransform) {
	    let postChunks = [];
	    fragmentShader = fragmentShader.replace(
	      /^\/\/!BEGIN_POST_CHUNK[^]+?^\/\/!END_POST_CHUNK/gm, // [^]+? = non-greedy match of any chars including newlines
	      match => {
	        postChunks.push(match);
	        return ''
	      }
	    );
	    fragmentMainOutro = `${fragmentColorTransform}\n${postChunks.join('\n')}\n${fragmentMainOutro}`;
	  }

	  // Inject auto-updating time uniform if requested
	  if (timeUniform) {
	    const code = `\nuniform float ${timeUniform};\n`;
	    vertexDefs = code + vertexDefs;
	    fragmentDefs = code + fragmentDefs;
	  }

	  // Inject a function for the vertexTransform and rename all usages of position/normal/uv
	  if (vertexTransform) {
	    // Hoist these defs to the very top so they work in other function defs
	    vertexShader = `vec3 troika_position_${key};
vec3 troika_normal_${key};
vec2 troika_uv_${key};
${vertexShader}
`;
	    vertexDefs = `${vertexDefs}
void troikaVertexTransform${key}(inout vec3 position, inout vec3 normal, inout vec2 uv) {
  ${vertexTransform}
}
`;
	    vertexMainIntro = `
troika_position_${key} = vec3(position);
troika_normal_${key} = vec3(normal);
troika_uv_${key} = vec2(uv);
troikaVertexTransform${key}(troika_position_${key}, troika_normal_${key}, troika_uv_${key});
${vertexMainIntro}
`;
	    vertexShader = vertexShader.replace(/\b(position|normal|uv)\b/g, (match, match1, index, fullStr) => {
	      return /\battribute\s+vec[23]\s+$/.test(fullStr.substr(0, index)) ? match1 : `troika_${match1}_${key}`
	    });

	    // Three r152 introduced the MAP_UV token, replace it too if it's pointing to the main 'uv'
	    // Perhaps the other textures too going forward?
	    if (!(material.map && material.map.channel > 0)) {
	      vertexShader = vertexShader.replace(/\bMAP_UV\b/g, `troika_uv_${key}`);
	    }
	  }

	  // Inject defs and intro/outro snippets
	  vertexShader = injectIntoShaderCode(vertexShader, key, vertexDefs, vertexMainIntro, vertexMainOutro);
	  fragmentShader = injectIntoShaderCode(fragmentShader, key, fragmentDefs, fragmentMainIntro, fragmentMainOutro);

	  return {
	    vertexShader,
	    fragmentShader
	  }
	}

	function injectIntoShaderCode(shaderCode, id, defs, intro, outro) {
	  if (intro || outro || defs) {
	    shaderCode = shaderCode.replace(voidMainRegExp, `
${defs}
void troikaOrigMain${id}() {`
	    );
	    shaderCode += `
void main() {
  ${intro}
  troikaOrigMain${id}();
  ${outro}
}`;
	  }
	  return shaderCode
	}


	function optionsJsonReplacer(key, value) {
	  return key === 'uniforms' ? undefined : typeof value === 'function' ? value.toString() : value
	}

	let _idCtr = 0;
	const optionsHashesToIds = new Map();
	function getKeyForOptions(options) {
	  const optionsHash = JSON.stringify(options, optionsJsonReplacer);
	  let id = optionsHashesToIds.get(optionsHash);
	  if (id == null) {
	    optionsHashesToIds.set(optionsHash, (id = ++_idCtr));
	  }
	  return id
	}

	/*!
	Custom build of Typr.ts (https://github.com/fredli74/Typr.ts) for use in Troika text rendering.
	Original MIT license applies: https://github.com/fredli74/Typr.ts/blob/master/LICENSE
	*/
	function typrFactory(){return "undefined"==typeof window&&(self.window=self),function(r){var e={parse:function(r){var t=e._bin,a=new Uint8Array(r);if("ttcf"==t.readASCII(a,0,4)){var n=4;t.readUshort(a,n),n+=2,t.readUshort(a,n),n+=2;var o=t.readUint(a,n);n+=4;for(var s=[],i=0;i<o;i++){var h=t.readUint(a,n);n+=4,s.push(e._readFont(a,h));}return s}return [e._readFont(a,0)]},_readFont:function(r,t){var a=e._bin,n=t;a.readFixed(r,t),t+=4;var o=a.readUshort(r,t);t+=2,a.readUshort(r,t),t+=2,a.readUshort(r,t),t+=2,a.readUshort(r,t),t+=2;for(var s=["cmap","head","hhea","maxp","hmtx","name","OS/2","post","loca","glyf","kern","CFF ","GDEF","GPOS","GSUB","SVG "],i={_data:r,_offset:n},h={},d=0;d<o;d++){var f=a.readASCII(r,t,4);t+=4,a.readUint(r,t),t+=4;var u=a.readUint(r,t);t+=4;var l=a.readUint(r,t);t+=4,h[f]={offset:u,length:l};}for(d=0;d<s.length;d++){var v=s[d];h[v]&&(i[v.trim()]=e[v.trim()].parse(r,h[v].offset,h[v].length,i));}return i},_tabOffset:function(r,t,a){for(var n=e._bin,o=n.readUshort(r,a+4),s=a+12,i=0;i<o;i++){var h=n.readASCII(r,s,4);s+=4,n.readUint(r,s),s+=4;var d=n.readUint(r,s);if(s+=4,n.readUint(r,s),s+=4,h==t)return d}return 0}};e._bin={readFixed:function(r,e){return (r[e]<<8|r[e+1])+(r[e+2]<<8|r[e+3])/65540},readF2dot14:function(r,t){return e._bin.readShort(r,t)/16384},readInt:function(r,t){return e._bin._view(r).getInt32(t)},readInt8:function(r,t){return e._bin._view(r).getInt8(t)},readShort:function(r,t){return e._bin._view(r).getInt16(t)},readUshort:function(r,t){return e._bin._view(r).getUint16(t)},readUshorts:function(r,t,a){for(var n=[],o=0;o<a;o++)n.push(e._bin.readUshort(r,t+2*o));return n},readUint:function(r,t){return e._bin._view(r).getUint32(t)},readUint64:function(r,t){return 4294967296*e._bin.readUint(r,t)+e._bin.readUint(r,t+4)},readASCII:function(r,e,t){for(var a="",n=0;n<t;n++)a+=String.fromCharCode(r[e+n]);return a},readUnicode:function(r,e,t){for(var a="",n=0;n<t;n++){var o=r[e++]<<8|r[e++];a+=String.fromCharCode(o);}return a},_tdec:"undefined"!=typeof window&&window.TextDecoder?new window.TextDecoder:null,readUTF8:function(r,t,a){var n=e._bin._tdec;return n&&0==t&&a==r.length?n.decode(r):e._bin.readASCII(r,t,a)},readBytes:function(r,e,t){for(var a=[],n=0;n<t;n++)a.push(r[e+n]);return a},readASCIIArray:function(r,e,t){for(var a=[],n=0;n<t;n++)a.push(String.fromCharCode(r[e+n]));return a},_view:function(r){return r._dataView||(r._dataView=r.buffer?new DataView(r.buffer,r.byteOffset,r.byteLength):new DataView(new Uint8Array(r).buffer))}},e._lctf={},e._lctf.parse=function(r,t,a,n,o){var s=e._bin,i={},h=t;s.readFixed(r,t),t+=4;var d=s.readUshort(r,t);t+=2;var f=s.readUshort(r,t);t+=2;var u=s.readUshort(r,t);return t+=2,i.scriptList=e._lctf.readScriptList(r,h+d),i.featureList=e._lctf.readFeatureList(r,h+f),i.lookupList=e._lctf.readLookupList(r,h+u,o),i},e._lctf.readLookupList=function(r,t,a){var n=e._bin,o=t,s=[],i=n.readUshort(r,t);t+=2;for(var h=0;h<i;h++){var d=n.readUshort(r,t);t+=2;var f=e._lctf.readLookupTable(r,o+d,a);s.push(f);}return s},e._lctf.readLookupTable=function(r,t,a){var n=e._bin,o=t,s={tabs:[]};s.ltype=n.readUshort(r,t),t+=2,s.flag=n.readUshort(r,t),t+=2;var i=n.readUshort(r,t);t+=2;for(var h=s.ltype,d=0;d<i;d++){var f=n.readUshort(r,t);t+=2;var u=a(r,h,o+f,s);s.tabs.push(u);}return s},e._lctf.numOfOnes=function(r){for(var e=0,t=0;t<32;t++)0!=(r>>>t&1)&&e++;return e},e._lctf.readClassDef=function(r,t){var a=e._bin,n=[],o=a.readUshort(r,t);if(t+=2,1==o){var s=a.readUshort(r,t);t+=2;var i=a.readUshort(r,t);t+=2;for(var h=0;h<i;h++)n.push(s+h),n.push(s+h),n.push(a.readUshort(r,t)),t+=2;}if(2==o){var d=a.readUshort(r,t);t+=2;for(h=0;h<d;h++)n.push(a.readUshort(r,t)),t+=2,n.push(a.readUshort(r,t)),t+=2,n.push(a.readUshort(r,t)),t+=2;}return n},e._lctf.getInterval=function(r,e){for(var t=0;t<r.length;t+=3){var a=r[t],n=r[t+1];if(r[t+2],a<=e&&e<=n)return t}return -1},e._lctf.readCoverage=function(r,t){var a=e._bin,n={};n.fmt=a.readUshort(r,t),t+=2;var o=a.readUshort(r,t);return t+=2,1==n.fmt&&(n.tab=a.readUshorts(r,t,o)),2==n.fmt&&(n.tab=a.readUshorts(r,t,3*o)),n},e._lctf.coverageIndex=function(r,t){var a=r.tab;if(1==r.fmt)return a.indexOf(t);if(2==r.fmt){var n=e._lctf.getInterval(a,t);if(-1!=n)return a[n+2]+(t-a[n])}return -1},e._lctf.readFeatureList=function(r,t){var a=e._bin,n=t,o=[],s=a.readUshort(r,t);t+=2;for(var i=0;i<s;i++){var h=a.readASCII(r,t,4);t+=4;var d=a.readUshort(r,t);t+=2;var f=e._lctf.readFeatureTable(r,n+d);f.tag=h.trim(),o.push(f);}return o},e._lctf.readFeatureTable=function(r,t){var a=e._bin,n=t,o={},s=a.readUshort(r,t);t+=2,s>0&&(o.featureParams=n+s);var i=a.readUshort(r,t);t+=2,o.tab=[];for(var h=0;h<i;h++)o.tab.push(a.readUshort(r,t+2*h));return o},e._lctf.readScriptList=function(r,t){var a=e._bin,n=t,o={},s=a.readUshort(r,t);t+=2;for(var i=0;i<s;i++){var h=a.readASCII(r,t,4);t+=4;var d=a.readUshort(r,t);t+=2,o[h.trim()]=e._lctf.readScriptTable(r,n+d);}return o},e._lctf.readScriptTable=function(r,t){var a=e._bin,n=t,o={},s=a.readUshort(r,t);t+=2,s>0&&(o.default=e._lctf.readLangSysTable(r,n+s));var i=a.readUshort(r,t);t+=2;for(var h=0;h<i;h++){var d=a.readASCII(r,t,4);t+=4;var f=a.readUshort(r,t);t+=2,o[d.trim()]=e._lctf.readLangSysTable(r,n+f);}return o},e._lctf.readLangSysTable=function(r,t){var a=e._bin,n={};a.readUshort(r,t),t+=2,n.reqFeature=a.readUshort(r,t),t+=2;var o=a.readUshort(r,t);return t+=2,n.features=a.readUshorts(r,t,o),n},e.CFF={},e.CFF.parse=function(r,t,a){var n=e._bin;(r=new Uint8Array(r.buffer,t,a))[t=0],r[++t],r[++t],r[++t],t++;var o=[];t=e.CFF.readIndex(r,t,o);for(var s=[],i=0;i<o.length-1;i++)s.push(n.readASCII(r,t+o[i],o[i+1]-o[i]));t+=o[o.length-1];var h=[];t=e.CFF.readIndex(r,t,h);var d=[];for(i=0;i<h.length-1;i++)d.push(e.CFF.readDict(r,t+h[i],t+h[i+1]));t+=h[h.length-1];var f=d[0],u=[];t=e.CFF.readIndex(r,t,u);var l=[];for(i=0;i<u.length-1;i++)l.push(n.readASCII(r,t+u[i],u[i+1]-u[i]));if(t+=u[u.length-1],e.CFF.readSubrs(r,t,f),f.CharStrings){t=f.CharStrings;u=[];t=e.CFF.readIndex(r,t,u);var v=[];for(i=0;i<u.length-1;i++)v.push(n.readBytes(r,t+u[i],u[i+1]-u[i]));f.CharStrings=v;}if(f.ROS){t=f.FDArray;var c=[];t=e.CFF.readIndex(r,t,c),f.FDArray=[];for(i=0;i<c.length-1;i++){var p=e.CFF.readDict(r,t+c[i],t+c[i+1]);e.CFF._readFDict(r,p,l),f.FDArray.push(p);}t+=c[c.length-1],t=f.FDSelect,f.FDSelect=[];var U=r[t];if(t++,3!=U)throw U;var g=n.readUshort(r,t);t+=2;for(i=0;i<g+1;i++)f.FDSelect.push(n.readUshort(r,t),r[t+2]),t+=3;}return f.Encoding&&(f.Encoding=e.CFF.readEncoding(r,f.Encoding,f.CharStrings.length)),f.charset&&(f.charset=e.CFF.readCharset(r,f.charset,f.CharStrings.length)),e.CFF._readFDict(r,f,l),f},e.CFF._readFDict=function(r,t,a){var n;for(var o in t.Private&&(n=t.Private[1],t.Private=e.CFF.readDict(r,n,n+t.Private[0]),t.Private.Subrs&&e.CFF.readSubrs(r,n+t.Private.Subrs,t.Private)),t)-1!=["FamilyName","FontName","FullName","Notice","version","Copyright"].indexOf(o)&&(t[o]=a[t[o]-426+35]);},e.CFF.readSubrs=function(r,t,a){var n=e._bin,o=[];t=e.CFF.readIndex(r,t,o);var s,i=o.length;s=i<1240?107:i<33900?1131:32768,a.Bias=s,a.Subrs=[];for(var h=0;h<o.length-1;h++)a.Subrs.push(n.readBytes(r,t+o[h],o[h+1]-o[h]));},e.CFF.tableSE=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,0,111,112,113,114,0,115,116,117,118,119,120,121,122,0,123,0,124,125,126,127,128,129,130,131,0,132,133,0,134,135,136,137,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,138,0,139,0,0,0,0,140,141,142,143,0,0,0,0,0,144,0,0,0,145,0,0,146,147,148,149,0,0,0,0],e.CFF.glyphByUnicode=function(r,e){for(var t=0;t<r.charset.length;t++)if(r.charset[t]==e)return t;return -1},e.CFF.glyphBySE=function(r,t){return t<0||t>255?-1:e.CFF.glyphByUnicode(r,e.CFF.tableSE[t])},e.CFF.readEncoding=function(r,t,a){e._bin;var n=[".notdef"],o=r[t];if(t++,0!=o)throw "error: unknown encoding format: "+o;var s=r[t];t++;for(var i=0;i<s;i++)n.push(r[t+i]);return n},e.CFF.readCharset=function(r,t,a){var n=e._bin,o=[".notdef"],s=r[t];if(t++,0==s)for(var i=0;i<a;i++){var h=n.readUshort(r,t);t+=2,o.push(h);}else {if(1!=s&&2!=s)throw "error: format: "+s;for(;o.length<a;){h=n.readUshort(r,t);t+=2;var d=0;1==s?(d=r[t],t++):(d=n.readUshort(r,t),t+=2);for(i=0;i<=d;i++)o.push(h),h++;}}return o},e.CFF.readIndex=function(r,t,a){var n=e._bin,o=n.readUshort(r,t)+1,s=r[t+=2];if(t++,1==s)for(var i=0;i<o;i++)a.push(r[t+i]);else if(2==s)for(i=0;i<o;i++)a.push(n.readUshort(r,t+2*i));else if(3==s)for(i=0;i<o;i++)a.push(16777215&n.readUint(r,t+3*i-1));else if(1!=o)throw "unsupported offset size: "+s+", count: "+o;return (t+=o*s)-1},e.CFF.getCharString=function(r,t,a){var n=e._bin,o=r[t],s=r[t+1];r[t+2],r[t+3],r[t+4];var i=1,h=null,d=null;o<=20&&(h=o,i=1),12==o&&(h=100*o+s,i=2),21<=o&&o<=27&&(h=o,i=1),28==o&&(d=n.readShort(r,t+1),i=3),29<=o&&o<=31&&(h=o,i=1),32<=o&&o<=246&&(d=o-139,i=1),247<=o&&o<=250&&(d=256*(o-247)+s+108,i=2),251<=o&&o<=254&&(d=256*-(o-251)-s-108,i=2),255==o&&(d=n.readInt(r,t+1)/65535,i=5),a.val=null!=d?d:"o"+h,a.size=i;},e.CFF.readCharString=function(r,t,a){for(var n=t+a,o=e._bin,s=[];t<n;){var i=r[t],h=r[t+1];r[t+2],r[t+3],r[t+4];var d=1,f=null,u=null;i<=20&&(f=i,d=1),12==i&&(f=100*i+h,d=2),19!=i&&20!=i||(f=i,d=2),21<=i&&i<=27&&(f=i,d=1),28==i&&(u=o.readShort(r,t+1),d=3),29<=i&&i<=31&&(f=i,d=1),32<=i&&i<=246&&(u=i-139,d=1),247<=i&&i<=250&&(u=256*(i-247)+h+108,d=2),251<=i&&i<=254&&(u=256*-(i-251)-h-108,d=2),255==i&&(u=o.readInt(r,t+1)/65535,d=5),s.push(null!=u?u:"o"+f),t+=d;}return s},e.CFF.readDict=function(r,t,a){for(var n=e._bin,o={},s=[];t<a;){var i=r[t],h=r[t+1];r[t+2],r[t+3],r[t+4];var d=1,f=null,u=null;if(28==i&&(u=n.readShort(r,t+1),d=3),29==i&&(u=n.readInt(r,t+1),d=5),32<=i&&i<=246&&(u=i-139,d=1),247<=i&&i<=250&&(u=256*(i-247)+h+108,d=2),251<=i&&i<=254&&(u=256*-(i-251)-h-108,d=2),255==i)throw u=n.readInt(r,t+1)/65535,d=5,"unknown number";if(30==i){var l=[];for(d=1;;){var v=r[t+d];d++;var c=v>>4,p=15&v;if(15!=c&&l.push(c),15!=p&&l.push(p),15==p)break}for(var U="",g=[0,1,2,3,4,5,6,7,8,9,".","e","e-","reserved","-","endOfNumber"],S=0;S<l.length;S++)U+=g[l[S]];u=parseFloat(U);}if(i<=21)if(f=["version","Notice","FullName","FamilyName","Weight","FontBBox","BlueValues","OtherBlues","FamilyBlues","FamilyOtherBlues","StdHW","StdVW","escape","UniqueID","XUID","charset","Encoding","CharStrings","Private","Subrs","defaultWidthX","nominalWidthX"][i],d=1,12==i)f=["Copyright","isFixedPitch","ItalicAngle","UnderlinePosition","UnderlineThickness","PaintType","CharstringType","FontMatrix","StrokeWidth","BlueScale","BlueShift","BlueFuzz","StemSnapH","StemSnapV","ForceBold",0,0,"LanguageGroup","ExpansionFactor","initialRandomSeed","SyntheticBase","PostScript","BaseFontName","BaseFontBlend",0,0,0,0,0,0,"ROS","CIDFontVersion","CIDFontRevision","CIDFontType","CIDCount","UIDBase","FDArray","FDSelect","FontName"][h],d=2;null!=f?(o[f]=1==s.length?s[0]:s,s=[]):s.push(u),t+=d;}return o},e.cmap={},e.cmap.parse=function(r,t,a){r=new Uint8Array(r.buffer,t,a),t=0;var n=e._bin,o={};n.readUshort(r,t),t+=2;var s=n.readUshort(r,t);t+=2;var i=[];o.tables=[];for(var h=0;h<s;h++){var d=n.readUshort(r,t);t+=2;var f=n.readUshort(r,t);t+=2;var u=n.readUint(r,t);t+=4;var l="p"+d+"e"+f,v=i.indexOf(u);if(-1==v){var c;v=o.tables.length,i.push(u);var p=n.readUshort(r,u);0==p?c=e.cmap.parse0(r,u):4==p?c=e.cmap.parse4(r,u):6==p?c=e.cmap.parse6(r,u):12==p?c=e.cmap.parse12(r,u):console.debug("unknown format: "+p,d,f,u),o.tables.push(c);}if(null!=o[l])throw "multiple tables for one platform+encoding";o[l]=v;}return o},e.cmap.parse0=function(r,t){var a=e._bin,n={};n.format=a.readUshort(r,t),t+=2;var o=a.readUshort(r,t);t+=2,a.readUshort(r,t),t+=2,n.map=[];for(var s=0;s<o-6;s++)n.map.push(r[t+s]);return n},e.cmap.parse4=function(r,t){var a=e._bin,n=t,o={};o.format=a.readUshort(r,t),t+=2;var s=a.readUshort(r,t);t+=2,a.readUshort(r,t),t+=2;var i=a.readUshort(r,t);t+=2;var h=i/2;o.searchRange=a.readUshort(r,t),t+=2,o.entrySelector=a.readUshort(r,t),t+=2,o.rangeShift=a.readUshort(r,t),t+=2,o.endCount=a.readUshorts(r,t,h),t+=2*h,t+=2,o.startCount=a.readUshorts(r,t,h),t+=2*h,o.idDelta=[];for(var d=0;d<h;d++)o.idDelta.push(a.readShort(r,t)),t+=2;for(o.idRangeOffset=a.readUshorts(r,t,h),t+=2*h,o.glyphIdArray=[];t<n+s;)o.glyphIdArray.push(a.readUshort(r,t)),t+=2;return o},e.cmap.parse6=function(r,t){var a=e._bin,n={};n.format=a.readUshort(r,t),t+=2,a.readUshort(r,t),t+=2,a.readUshort(r,t),t+=2,n.firstCode=a.readUshort(r,t),t+=2;var o=a.readUshort(r,t);t+=2,n.glyphIdArray=[];for(var s=0;s<o;s++)n.glyphIdArray.push(a.readUshort(r,t)),t+=2;return n},e.cmap.parse12=function(r,t){var a=e._bin,n={};n.format=a.readUshort(r,t),t+=2,t+=2,a.readUint(r,t),t+=4,a.readUint(r,t),t+=4;var o=a.readUint(r,t);t+=4,n.groups=[];for(var s=0;s<o;s++){var i=t+12*s,h=a.readUint(r,i+0),d=a.readUint(r,i+4),f=a.readUint(r,i+8);n.groups.push([h,d,f]);}return n},e.glyf={},e.glyf.parse=function(r,e,t,a){for(var n=[],o=0;o<a.maxp.numGlyphs;o++)n.push(null);return n},e.glyf._parseGlyf=function(r,t){var a=e._bin,n=r._data,o=e._tabOffset(n,"glyf",r._offset)+r.loca[t];if(r.loca[t]==r.loca[t+1])return null;var s={};if(s.noc=a.readShort(n,o),o+=2,s.xMin=a.readShort(n,o),o+=2,s.yMin=a.readShort(n,o),o+=2,s.xMax=a.readShort(n,o),o+=2,s.yMax=a.readShort(n,o),o+=2,s.xMin>=s.xMax||s.yMin>=s.yMax)return null;if(s.noc>0){s.endPts=[];for(var i=0;i<s.noc;i++)s.endPts.push(a.readUshort(n,o)),o+=2;var h=a.readUshort(n,o);if(o+=2,n.length-o<h)return null;s.instructions=a.readBytes(n,o,h),o+=h;var d=s.endPts[s.noc-1]+1;s.flags=[];for(i=0;i<d;i++){var f=n[o];if(o++,s.flags.push(f),0!=(8&f)){var u=n[o];o++;for(var l=0;l<u;l++)s.flags.push(f),i++;}}s.xs=[];for(i=0;i<d;i++){var v=0!=(2&s.flags[i]),c=0!=(16&s.flags[i]);v?(s.xs.push(c?n[o]:-n[o]),o++):c?s.xs.push(0):(s.xs.push(a.readShort(n,o)),o+=2);}s.ys=[];for(i=0;i<d;i++){v=0!=(4&s.flags[i]),c=0!=(32&s.flags[i]);v?(s.ys.push(c?n[o]:-n[o]),o++):c?s.ys.push(0):(s.ys.push(a.readShort(n,o)),o+=2);}var p=0,U=0;for(i=0;i<d;i++)p+=s.xs[i],U+=s.ys[i],s.xs[i]=p,s.ys[i]=U;}else {var g;s.parts=[];do{g=a.readUshort(n,o),o+=2;var S={m:{a:1,b:0,c:0,d:1,tx:0,ty:0},p1:-1,p2:-1};if(s.parts.push(S),S.glyphIndex=a.readUshort(n,o),o+=2,1&g){var m=a.readShort(n,o);o+=2;var b=a.readShort(n,o);o+=2;}else {m=a.readInt8(n,o);o++;b=a.readInt8(n,o);o++;}2&g?(S.m.tx=m,S.m.ty=b):(S.p1=m,S.p2=b),8&g?(S.m.a=S.m.d=a.readF2dot14(n,o),o+=2):64&g?(S.m.a=a.readF2dot14(n,o),o+=2,S.m.d=a.readF2dot14(n,o),o+=2):128&g&&(S.m.a=a.readF2dot14(n,o),o+=2,S.m.b=a.readF2dot14(n,o),o+=2,S.m.c=a.readF2dot14(n,o),o+=2,S.m.d=a.readF2dot14(n,o),o+=2);}while(32&g);if(256&g){var y=a.readUshort(n,o);o+=2,s.instr=[];for(i=0;i<y;i++)s.instr.push(n[o]),o++;}}return s},e.GDEF={},e.GDEF.parse=function(r,t,a,n){var o=t;t+=4;var s=e._bin.readUshort(r,t);return {glyphClassDef:0===s?null:e._lctf.readClassDef(r,o+s)}},e.GPOS={},e.GPOS.parse=function(r,t,a,n){return e._lctf.parse(r,t,a,n,e.GPOS.subt)},e.GPOS.subt=function(r,t,a,n){var o=e._bin,s=a,i={};if(i.fmt=o.readUshort(r,a),a+=2,1==t||2==t||3==t||7==t||8==t&&i.fmt<=2){var h=o.readUshort(r,a);a+=2,i.coverage=e._lctf.readCoverage(r,h+s);}if(1==t&&1==i.fmt){var d=o.readUshort(r,a);a+=2,0!=d&&(i.pos=e.GPOS.readValueRecord(r,a,d));}else if(2==t&&i.fmt>=1&&i.fmt<=2){d=o.readUshort(r,a);a+=2;var f=o.readUshort(r,a);a+=2;var u=e._lctf.numOfOnes(d),l=e._lctf.numOfOnes(f);if(1==i.fmt){i.pairsets=[];var v=o.readUshort(r,a);a+=2;for(var c=0;c<v;c++){var p=s+o.readUshort(r,a);a+=2;var U=o.readUshort(r,p);p+=2;for(var g=[],S=0;S<U;S++){var m=o.readUshort(r,p);p+=2,0!=d&&(P=e.GPOS.readValueRecord(r,p,d),p+=2*u),0!=f&&(x=e.GPOS.readValueRecord(r,p,f),p+=2*l),g.push({gid2:m,val1:P,val2:x});}i.pairsets.push(g);}}if(2==i.fmt){var b=o.readUshort(r,a);a+=2;var y=o.readUshort(r,a);a+=2;var F=o.readUshort(r,a);a+=2;var C=o.readUshort(r,a);a+=2,i.classDef1=e._lctf.readClassDef(r,s+b),i.classDef2=e._lctf.readClassDef(r,s+y),i.matrix=[];for(c=0;c<F;c++){var _=[];for(S=0;S<C;S++){var P=null,x=null;0!=d&&(P=e.GPOS.readValueRecord(r,a,d),a+=2*u),0!=f&&(x=e.GPOS.readValueRecord(r,a,f),a+=2*l),_.push({val1:P,val2:x});}i.matrix.push(_);}}}else if(4==t&&1==i.fmt)i.markCoverage=e._lctf.readCoverage(r,o.readUshort(r,a)+s),i.baseCoverage=e._lctf.readCoverage(r,o.readUshort(r,a+2)+s),i.markClassCount=o.readUshort(r,a+4),i.markArray=e.GPOS.readMarkArray(r,o.readUshort(r,a+6)+s),i.baseArray=e.GPOS.readBaseArray(r,o.readUshort(r,a+8)+s,i.markClassCount);else if(6==t&&1==i.fmt)i.mark1Coverage=e._lctf.readCoverage(r,o.readUshort(r,a)+s),i.mark2Coverage=e._lctf.readCoverage(r,o.readUshort(r,a+2)+s),i.markClassCount=o.readUshort(r,a+4),i.mark1Array=e.GPOS.readMarkArray(r,o.readUshort(r,a+6)+s),i.mark2Array=e.GPOS.readBaseArray(r,o.readUshort(r,a+8)+s,i.markClassCount);else {if(9==t&&1==i.fmt){var I=o.readUshort(r,a);a+=2;var w=o.readUint(r,a);if(a+=4,9==n.ltype)n.ltype=I;else if(n.ltype!=I)throw "invalid extension substitution";return e.GPOS.subt(r,n.ltype,s+w)}console.debug("unsupported GPOS table LookupType",t,"format",i.fmt);}return i},e.GPOS.readValueRecord=function(r,t,a){var n=e._bin,o=[];return o.push(1&a?n.readShort(r,t):0),t+=1&a?2:0,o.push(2&a?n.readShort(r,t):0),t+=2&a?2:0,o.push(4&a?n.readShort(r,t):0),t+=4&a?2:0,o.push(8&a?n.readShort(r,t):0),t+=8&a?2:0,o},e.GPOS.readBaseArray=function(r,t,a){var n=e._bin,o=[],s=t,i=n.readUshort(r,t);t+=2;for(var h=0;h<i;h++){for(var d=[],f=0;f<a;f++)d.push(e.GPOS.readAnchorRecord(r,s+n.readUshort(r,t))),t+=2;o.push(d);}return o},e.GPOS.readMarkArray=function(r,t){var a=e._bin,n=[],o=t,s=a.readUshort(r,t);t+=2;for(var i=0;i<s;i++){var h=e.GPOS.readAnchorRecord(r,a.readUshort(r,t+2)+o);h.markClass=a.readUshort(r,t),n.push(h),t+=4;}return n},e.GPOS.readAnchorRecord=function(r,t){var a=e._bin,n={};return n.fmt=a.readUshort(r,t),n.x=a.readShort(r,t+2),n.y=a.readShort(r,t+4),n},e.GSUB={},e.GSUB.parse=function(r,t,a,n){return e._lctf.parse(r,t,a,n,e.GSUB.subt)},e.GSUB.subt=function(r,t,a,n){var o=e._bin,s=a,i={};if(i.fmt=o.readUshort(r,a),a+=2,1!=t&&2!=t&&4!=t&&5!=t&&6!=t)return null;if(1==t||2==t||4==t||5==t&&i.fmt<=2||6==t&&i.fmt<=2){var h=o.readUshort(r,a);a+=2,i.coverage=e._lctf.readCoverage(r,s+h);}if(1==t&&i.fmt>=1&&i.fmt<=2){if(1==i.fmt)i.delta=o.readShort(r,a),a+=2;else if(2==i.fmt){var d=o.readUshort(r,a);a+=2,i.newg=o.readUshorts(r,a,d),a+=2*i.newg.length;}}else if(2==t&&1==i.fmt){d=o.readUshort(r,a);a+=2,i.seqs=[];for(var f=0;f<d;f++){var u=o.readUshort(r,a)+s;a+=2;var l=o.readUshort(r,u);i.seqs.push(o.readUshorts(r,u+2,l));}}else if(4==t){i.vals=[];d=o.readUshort(r,a);a+=2;for(f=0;f<d;f++){var v=o.readUshort(r,a);a+=2,i.vals.push(e.GSUB.readLigatureSet(r,s+v));}}else if(5==t&&2==i.fmt){if(2==i.fmt){var c=o.readUshort(r,a);a+=2,i.cDef=e._lctf.readClassDef(r,s+c),i.scset=[];var p=o.readUshort(r,a);a+=2;for(f=0;f<p;f++){var U=o.readUshort(r,a);a+=2,i.scset.push(0==U?null:e.GSUB.readSubClassSet(r,s+U));}}}else if(6==t&&3==i.fmt){if(3==i.fmt){for(f=0;f<3;f++){d=o.readUshort(r,a);a+=2;for(var g=[],S=0;S<d;S++)g.push(e._lctf.readCoverage(r,s+o.readUshort(r,a+2*S)));a+=2*d,0==f&&(i.backCvg=g),1==f&&(i.inptCvg=g),2==f&&(i.ahedCvg=g);}d=o.readUshort(r,a);a+=2,i.lookupRec=e.GSUB.readSubstLookupRecords(r,a,d);}}else {if(7==t&&1==i.fmt){var m=o.readUshort(r,a);a+=2;var b=o.readUint(r,a);if(a+=4,9==n.ltype)n.ltype=m;else if(n.ltype!=m)throw "invalid extension substitution";return e.GSUB.subt(r,n.ltype,s+b)}console.debug("unsupported GSUB table LookupType",t,"format",i.fmt);}return i},e.GSUB.readSubClassSet=function(r,t){var a=e._bin.readUshort,n=t,o=[],s=a(r,t);t+=2;for(var i=0;i<s;i++){var h=a(r,t);t+=2,o.push(e.GSUB.readSubClassRule(r,n+h));}return o},e.GSUB.readSubClassRule=function(r,t){var a=e._bin.readUshort,n={},o=a(r,t),s=a(r,t+=2);t+=2,n.input=[];for(var i=0;i<o-1;i++)n.input.push(a(r,t)),t+=2;return n.substLookupRecords=e.GSUB.readSubstLookupRecords(r,t,s),n},e.GSUB.readSubstLookupRecords=function(r,t,a){for(var n=e._bin.readUshort,o=[],s=0;s<a;s++)o.push(n(r,t),n(r,t+2)),t+=4;return o},e.GSUB.readChainSubClassSet=function(r,t){var a=e._bin,n=t,o=[],s=a.readUshort(r,t);t+=2;for(var i=0;i<s;i++){var h=a.readUshort(r,t);t+=2,o.push(e.GSUB.readChainSubClassRule(r,n+h));}return o},e.GSUB.readChainSubClassRule=function(r,t){for(var a=e._bin,n={},o=["backtrack","input","lookahead"],s=0;s<o.length;s++){var i=a.readUshort(r,t);t+=2,1==s&&i--,n[o[s]]=a.readUshorts(r,t,i),t+=2*n[o[s]].length;}i=a.readUshort(r,t);return t+=2,n.subst=a.readUshorts(r,t,2*i),t+=2*n.subst.length,n},e.GSUB.readLigatureSet=function(r,t){var a=e._bin,n=t,o=[],s=a.readUshort(r,t);t+=2;for(var i=0;i<s;i++){var h=a.readUshort(r,t);t+=2,o.push(e.GSUB.readLigature(r,n+h));}return o},e.GSUB.readLigature=function(r,t){var a=e._bin,n={chain:[]};n.nglyph=a.readUshort(r,t),t+=2;var o=a.readUshort(r,t);t+=2;for(var s=0;s<o-1;s++)n.chain.push(a.readUshort(r,t)),t+=2;return n},e.head={},e.head.parse=function(r,t,a){var n=e._bin,o={};return n.readFixed(r,t),t+=4,o.fontRevision=n.readFixed(r,t),t+=4,n.readUint(r,t),t+=4,n.readUint(r,t),t+=4,o.flags=n.readUshort(r,t),t+=2,o.unitsPerEm=n.readUshort(r,t),t+=2,o.created=n.readUint64(r,t),t+=8,o.modified=n.readUint64(r,t),t+=8,o.xMin=n.readShort(r,t),t+=2,o.yMin=n.readShort(r,t),t+=2,o.xMax=n.readShort(r,t),t+=2,o.yMax=n.readShort(r,t),t+=2,o.macStyle=n.readUshort(r,t),t+=2,o.lowestRecPPEM=n.readUshort(r,t),t+=2,o.fontDirectionHint=n.readShort(r,t),t+=2,o.indexToLocFormat=n.readShort(r,t),t+=2,o.glyphDataFormat=n.readShort(r,t),t+=2,o},e.hhea={},e.hhea.parse=function(r,t,a){var n=e._bin,o={};return n.readFixed(r,t),t+=4,o.ascender=n.readShort(r,t),t+=2,o.descender=n.readShort(r,t),t+=2,o.lineGap=n.readShort(r,t),t+=2,o.advanceWidthMax=n.readUshort(r,t),t+=2,o.minLeftSideBearing=n.readShort(r,t),t+=2,o.minRightSideBearing=n.readShort(r,t),t+=2,o.xMaxExtent=n.readShort(r,t),t+=2,o.caretSlopeRise=n.readShort(r,t),t+=2,o.caretSlopeRun=n.readShort(r,t),t+=2,o.caretOffset=n.readShort(r,t),t+=2,t+=8,o.metricDataFormat=n.readShort(r,t),t+=2,o.numberOfHMetrics=n.readUshort(r,t),t+=2,o},e.hmtx={},e.hmtx.parse=function(r,t,a,n){for(var o=e._bin,s={aWidth:[],lsBearing:[]},i=0,h=0,d=0;d<n.maxp.numGlyphs;d++)d<n.hhea.numberOfHMetrics&&(i=o.readUshort(r,t),t+=2,h=o.readShort(r,t),t+=2),s.aWidth.push(i),s.lsBearing.push(h);return s},e.kern={},e.kern.parse=function(r,t,a,n){var o=e._bin,s=o.readUshort(r,t);if(t+=2,1==s)return e.kern.parseV1(r,t-2,a,n);var i=o.readUshort(r,t);t+=2;for(var h={glyph1:[],rval:[]},d=0;d<i;d++){t+=2;a=o.readUshort(r,t);t+=2;var f=o.readUshort(r,t);t+=2;var u=f>>>8;if(0!=(u&=15))throw "unknown kern table format: "+u;t=e.kern.readFormat0(r,t,h);}return h},e.kern.parseV1=function(r,t,a,n){var o=e._bin;o.readFixed(r,t),t+=4;var s=o.readUint(r,t);t+=4;for(var i={glyph1:[],rval:[]},h=0;h<s;h++){o.readUint(r,t),t+=4;var d=o.readUshort(r,t);t+=2,o.readUshort(r,t),t+=2;var f=d>>>8;if(0!=(f&=15))throw "unknown kern table format: "+f;t=e.kern.readFormat0(r,t,i);}return i},e.kern.readFormat0=function(r,t,a){var n=e._bin,o=-1,s=n.readUshort(r,t);t+=2,n.readUshort(r,t),t+=2,n.readUshort(r,t),t+=2,n.readUshort(r,t),t+=2;for(var i=0;i<s;i++){var h=n.readUshort(r,t);t+=2;var d=n.readUshort(r,t);t+=2;var f=n.readShort(r,t);t+=2,h!=o&&(a.glyph1.push(h),a.rval.push({glyph2:[],vals:[]}));var u=a.rval[a.rval.length-1];u.glyph2.push(d),u.vals.push(f),o=h;}return t},e.loca={},e.loca.parse=function(r,t,a,n){var o=e._bin,s=[],i=n.head.indexToLocFormat,h=n.maxp.numGlyphs+1;if(0==i)for(var d=0;d<h;d++)s.push(o.readUshort(r,t+(d<<1))<<1);if(1==i)for(d=0;d<h;d++)s.push(o.readUint(r,t+(d<<2)));return s},e.maxp={},e.maxp.parse=function(r,t,a){var n=e._bin,o={},s=n.readUint(r,t);return t+=4,o.numGlyphs=n.readUshort(r,t),t+=2,65536==s&&(o.maxPoints=n.readUshort(r,t),t+=2,o.maxContours=n.readUshort(r,t),t+=2,o.maxCompositePoints=n.readUshort(r,t),t+=2,o.maxCompositeContours=n.readUshort(r,t),t+=2,o.maxZones=n.readUshort(r,t),t+=2,o.maxTwilightPoints=n.readUshort(r,t),t+=2,o.maxStorage=n.readUshort(r,t),t+=2,o.maxFunctionDefs=n.readUshort(r,t),t+=2,o.maxInstructionDefs=n.readUshort(r,t),t+=2,o.maxStackElements=n.readUshort(r,t),t+=2,o.maxSizeOfInstructions=n.readUshort(r,t),t+=2,o.maxComponentElements=n.readUshort(r,t),t+=2,o.maxComponentDepth=n.readUshort(r,t),t+=2),o},e.name={},e.name.parse=function(r,t,a){var n=e._bin,o={};n.readUshort(r,t),t+=2;var s=n.readUshort(r,t);t+=2,n.readUshort(r,t);for(var i,h=["copyright","fontFamily","fontSubfamily","ID","fullName","version","postScriptName","trademark","manufacturer","designer","description","urlVendor","urlDesigner","licence","licenceURL","---","typoFamilyName","typoSubfamilyName","compatibleFull","sampleText","postScriptCID","wwsFamilyName","wwsSubfamilyName","lightPalette","darkPalette"],d=t+=2,f=0;f<s;f++){var u=n.readUshort(r,t);t+=2;var l=n.readUshort(r,t);t+=2;var v=n.readUshort(r,t);t+=2;var c=n.readUshort(r,t);t+=2;var p=n.readUshort(r,t);t+=2;var U=n.readUshort(r,t);t+=2;var g,S=h[c],m=d+12*s+U;if(0==u)g=n.readUnicode(r,m,p/2);else if(3==u&&0==l)g=n.readUnicode(r,m,p/2);else if(0==l)g=n.readASCII(r,m,p);else if(1==l)g=n.readUnicode(r,m,p/2);else if(3==l)g=n.readUnicode(r,m,p/2);else {if(1!=u)throw "unknown encoding "+l+", platformID: "+u;g=n.readASCII(r,m,p),console.debug("reading unknown MAC encoding "+l+" as ASCII");}var b="p"+u+","+v.toString(16);null==o[b]&&(o[b]={}),o[b][void 0!==S?S:c]=g,o[b]._lang=v;}for(var y in o)if(null!=o[y].postScriptName&&1033==o[y]._lang)return o[y];for(var y in o)if(null!=o[y].postScriptName&&0==o[y]._lang)return o[y];for(var y in o)if(null!=o[y].postScriptName&&3084==o[y]._lang)return o[y];for(var y in o)if(null!=o[y].postScriptName)return o[y];for(var y in o){i=y;break}return console.debug("returning name table with languageID "+o[i]._lang),o[i]},e["OS/2"]={},e["OS/2"].parse=function(r,t,a){var n=e._bin.readUshort(r,t);t+=2;var o={};if(0==n)e["OS/2"].version0(r,t,o);else if(1==n)e["OS/2"].version1(r,t,o);else if(2==n||3==n||4==n)e["OS/2"].version2(r,t,o);else {if(5!=n)throw "unknown OS/2 table version: "+n;e["OS/2"].version5(r,t,o);}return o},e["OS/2"].version0=function(r,t,a){var n=e._bin;return a.xAvgCharWidth=n.readShort(r,t),t+=2,a.usWeightClass=n.readUshort(r,t),t+=2,a.usWidthClass=n.readUshort(r,t),t+=2,a.fsType=n.readUshort(r,t),t+=2,a.ySubscriptXSize=n.readShort(r,t),t+=2,a.ySubscriptYSize=n.readShort(r,t),t+=2,a.ySubscriptXOffset=n.readShort(r,t),t+=2,a.ySubscriptYOffset=n.readShort(r,t),t+=2,a.ySuperscriptXSize=n.readShort(r,t),t+=2,a.ySuperscriptYSize=n.readShort(r,t),t+=2,a.ySuperscriptXOffset=n.readShort(r,t),t+=2,a.ySuperscriptYOffset=n.readShort(r,t),t+=2,a.yStrikeoutSize=n.readShort(r,t),t+=2,a.yStrikeoutPosition=n.readShort(r,t),t+=2,a.sFamilyClass=n.readShort(r,t),t+=2,a.panose=n.readBytes(r,t,10),t+=10,a.ulUnicodeRange1=n.readUint(r,t),t+=4,a.ulUnicodeRange2=n.readUint(r,t),t+=4,a.ulUnicodeRange3=n.readUint(r,t),t+=4,a.ulUnicodeRange4=n.readUint(r,t),t+=4,a.achVendID=[n.readInt8(r,t),n.readInt8(r,t+1),n.readInt8(r,t+2),n.readInt8(r,t+3)],t+=4,a.fsSelection=n.readUshort(r,t),t+=2,a.usFirstCharIndex=n.readUshort(r,t),t+=2,a.usLastCharIndex=n.readUshort(r,t),t+=2,a.sTypoAscender=n.readShort(r,t),t+=2,a.sTypoDescender=n.readShort(r,t),t+=2,a.sTypoLineGap=n.readShort(r,t),t+=2,a.usWinAscent=n.readUshort(r,t),t+=2,a.usWinDescent=n.readUshort(r,t),t+=2},e["OS/2"].version1=function(r,t,a){var n=e._bin;return t=e["OS/2"].version0(r,t,a),a.ulCodePageRange1=n.readUint(r,t),t+=4,a.ulCodePageRange2=n.readUint(r,t),t+=4},e["OS/2"].version2=function(r,t,a){var n=e._bin;return t=e["OS/2"].version1(r,t,a),a.sxHeight=n.readShort(r,t),t+=2,a.sCapHeight=n.readShort(r,t),t+=2,a.usDefault=n.readUshort(r,t),t+=2,a.usBreak=n.readUshort(r,t),t+=2,a.usMaxContext=n.readUshort(r,t),t+=2},e["OS/2"].version5=function(r,t,a){var n=e._bin;return t=e["OS/2"].version2(r,t,a),a.usLowerOpticalPointSize=n.readUshort(r,t),t+=2,a.usUpperOpticalPointSize=n.readUshort(r,t),t+=2},e.post={},e.post.parse=function(r,t,a){var n=e._bin,o={};return o.version=n.readFixed(r,t),t+=4,o.italicAngle=n.readFixed(r,t),t+=4,o.underlinePosition=n.readShort(r,t),t+=2,o.underlineThickness=n.readShort(r,t),t+=2,o},null==e&&(e={}),null==e.U&&(e.U={}),e.U.codeToGlyph=function(r,e){var t=r.cmap,a=-1;if(null!=t.p0e4?a=t.p0e4:null!=t.p3e1?a=t.p3e1:null!=t.p1e0?a=t.p1e0:null!=t.p0e3&&(a=t.p0e3),-1==a)throw "no familiar platform and encoding!";var n=t.tables[a];if(0==n.format)return e>=n.map.length?0:n.map[e];if(4==n.format){for(var o=-1,s=0;s<n.endCount.length;s++)if(e<=n.endCount[s]){o=s;break}if(-1==o)return 0;if(n.startCount[o]>e)return 0;return 65535&(0!=n.idRangeOffset[o]?n.glyphIdArray[e-n.startCount[o]+(n.idRangeOffset[o]>>1)-(n.idRangeOffset.length-o)]:e+n.idDelta[o])}if(12==n.format){if(e>n.groups[n.groups.length-1][1])return 0;for(s=0;s<n.groups.length;s++){var i=n.groups[s];if(i[0]<=e&&e<=i[1])return i[2]+(e-i[0])}return 0}throw "unknown cmap table format "+n.format},e.U.glyphToPath=function(r,t){var a={cmds:[],crds:[]};if(r.SVG&&r.SVG.entries[t]){var n=r.SVG.entries[t];return null==n?a:("string"==typeof n&&(n=e.SVG.toPath(n),r.SVG.entries[t]=n),n)}if(r.CFF){var o={x:0,y:0,stack:[],nStems:0,haveWidth:!1,width:r.CFF.Private?r.CFF.Private.defaultWidthX:0,open:!1},s=r.CFF,i=r.CFF.Private;if(s.ROS){for(var h=0;s.FDSelect[h+2]<=t;)h+=2;i=s.FDArray[s.FDSelect[h+1]].Private;}e.U._drawCFF(r.CFF.CharStrings[t],o,s,i,a);}else r.glyf&&e.U._drawGlyf(t,r,a);return a},e.U._drawGlyf=function(r,t,a){var n=t.glyf[r];null==n&&(n=t.glyf[r]=e.glyf._parseGlyf(t,r)),null!=n&&(n.noc>-1?e.U._simpleGlyph(n,a):e.U._compoGlyph(n,t,a));},e.U._simpleGlyph=function(r,t){for(var a=0;a<r.noc;a++){for(var n=0==a?0:r.endPts[a-1]+1,o=r.endPts[a],s=n;s<=o;s++){var i=s==n?o:s-1,h=s==o?n:s+1,d=1&r.flags[s],f=1&r.flags[i],u=1&r.flags[h],l=r.xs[s],v=r.ys[s];if(s==n)if(d){if(!f){e.U.P.moveTo(t,l,v);continue}e.U.P.moveTo(t,r.xs[i],r.ys[i]);}else f?e.U.P.moveTo(t,r.xs[i],r.ys[i]):e.U.P.moveTo(t,(r.xs[i]+l)/2,(r.ys[i]+v)/2);d?f&&e.U.P.lineTo(t,l,v):u?e.U.P.qcurveTo(t,l,v,r.xs[h],r.ys[h]):e.U.P.qcurveTo(t,l,v,(l+r.xs[h])/2,(v+r.ys[h])/2);}e.U.P.closePath(t);}},e.U._compoGlyph=function(r,t,a){for(var n=0;n<r.parts.length;n++){var o={cmds:[],crds:[]},s=r.parts[n];e.U._drawGlyf(s.glyphIndex,t,o);for(var i=s.m,h=0;h<o.crds.length;h+=2){var d=o.crds[h],f=o.crds[h+1];a.crds.push(d*i.a+f*i.b+i.tx),a.crds.push(d*i.c+f*i.d+i.ty);}for(h=0;h<o.cmds.length;h++)a.cmds.push(o.cmds[h]);}},e.U._getGlyphClass=function(r,t){var a=e._lctf.getInterval(t,r);return -1==a?0:t[a+2]},e.U._applySubs=function(r,t,a,n){for(var o=r.length-t-1,s=0;s<a.tabs.length;s++)if(null!=a.tabs[s]){var i,h=a.tabs[s];if(!h.coverage||-1!=(i=e._lctf.coverageIndex(h.coverage,r[t])))if(1==a.ltype)r[t],1==h.fmt?r[t]=r[t]+h.delta:r[t]=h.newg[i];else if(4==a.ltype)for(var d=h.vals[i],f=0;f<d.length;f++){var u=d[f],l=u.chain.length;if(!(l>o)){for(var v=!0,c=0,p=0;p<l;p++){for(;-1==r[t+c+(1+p)];)c++;u.chain[p]!=r[t+c+(1+p)]&&(v=!1);}if(v){r[t]=u.nglyph;for(p=0;p<l+c;p++)r[t+p+1]=-1;break}}}else if(5==a.ltype&&2==h.fmt)for(var U=e._lctf.getInterval(h.cDef,r[t]),g=h.cDef[U+2],S=h.scset[g],m=0;m<S.length;m++){var b=S[m],y=b.input;if(!(y.length>o)){for(v=!0,p=0;p<y.length;p++){var F=e._lctf.getInterval(h.cDef,r[t+1+p]);if(-1==U&&h.cDef[F+2]!=y[p]){v=!1;break}}if(v){var C=b.substLookupRecords;for(f=0;f<C.length;f+=2)C[f],C[f+1];}}}else if(6==a.ltype&&3==h.fmt){if(!e.U._glsCovered(r,h.backCvg,t-h.backCvg.length))continue;if(!e.U._glsCovered(r,h.inptCvg,t))continue;if(!e.U._glsCovered(r,h.ahedCvg,t+h.inptCvg.length))continue;var _=h.lookupRec;for(m=0;m<_.length;m+=2){U=_[m];var P=n[_[m+1]];e.U._applySubs(r,t+U,P,n);}}}},e.U._glsCovered=function(r,t,a){for(var n=0;n<t.length;n++){if(-1==e._lctf.coverageIndex(t[n],r[a+n]))return !1}return !0},e.U.glyphsToPath=function(r,t,a){for(var n={cmds:[],crds:[]},o=0,s=0;s<t.length;s++){var i=t[s];if(-1!=i){for(var h=s<t.length-1&&-1!=t[s+1]?t[s+1]:0,d=e.U.glyphToPath(r,i),f=0;f<d.crds.length;f+=2)n.crds.push(d.crds[f]+o),n.crds.push(d.crds[f+1]);a&&n.cmds.push(a);for(f=0;f<d.cmds.length;f++)n.cmds.push(d.cmds[f]);a&&n.cmds.push("X"),o+=r.hmtx.aWidth[i],s<t.length-1&&(o+=e.U.getPairAdjustment(r,i,h));}}return n},e.U.P={},e.U.P.moveTo=function(r,e,t){r.cmds.push("M"),r.crds.push(e,t);},e.U.P.lineTo=function(r,e,t){r.cmds.push("L"),r.crds.push(e,t);},e.U.P.curveTo=function(r,e,t,a,n,o,s){r.cmds.push("C"),r.crds.push(e,t,a,n,o,s);},e.U.P.qcurveTo=function(r,e,t,a,n){r.cmds.push("Q"),r.crds.push(e,t,a,n);},e.U.P.closePath=function(r){r.cmds.push("Z");},e.U._drawCFF=function(r,t,a,n,o){for(var s=t.stack,i=t.nStems,h=t.haveWidth,d=t.width,f=t.open,u=0,l=t.x,v=t.y,c=0,p=0,U=0,g=0,S=0,m=0,b=0,y=0,F=0,C=0,_={val:0,size:0};u<r.length;){e.CFF.getCharString(r,u,_);var P=_.val;if(u+=_.size,"o1"==P||"o18"==P)s.length%2!=0&&!h&&(d=s.shift()+n.nominalWidthX),i+=s.length>>1,s.length=0,h=!0;else if("o3"==P||"o23"==P){s.length%2!=0&&!h&&(d=s.shift()+n.nominalWidthX),i+=s.length>>1,s.length=0,h=!0;}else if("o4"==P)s.length>1&&!h&&(d=s.shift()+n.nominalWidthX,h=!0),f&&e.U.P.closePath(o),v+=s.pop(),e.U.P.moveTo(o,l,v),f=!0;else if("o5"==P)for(;s.length>0;)l+=s.shift(),v+=s.shift(),e.U.P.lineTo(o,l,v);else if("o6"==P||"o7"==P)for(var x=s.length,I="o6"==P,w=0;w<x;w++){var k=s.shift();I?l+=k:v+=k,I=!I,e.U.P.lineTo(o,l,v);}else if("o8"==P||"o24"==P){x=s.length;for(var G=0;G+6<=x;)c=l+s.shift(),p=v+s.shift(),U=c+s.shift(),g=p+s.shift(),l=U+s.shift(),v=g+s.shift(),e.U.P.curveTo(o,c,p,U,g,l,v),G+=6;"o24"==P&&(l+=s.shift(),v+=s.shift(),e.U.P.lineTo(o,l,v));}else {if("o11"==P)break;if("o1234"==P||"o1235"==P||"o1236"==P||"o1237"==P)"o1234"==P&&(p=v,U=(c=l+s.shift())+s.shift(),C=g=p+s.shift(),m=g,y=v,l=(b=(S=(F=U+s.shift())+s.shift())+s.shift())+s.shift(),e.U.P.curveTo(o,c,p,U,g,F,C),e.U.P.curveTo(o,S,m,b,y,l,v)),"o1235"==P&&(c=l+s.shift(),p=v+s.shift(),U=c+s.shift(),g=p+s.shift(),F=U+s.shift(),C=g+s.shift(),S=F+s.shift(),m=C+s.shift(),b=S+s.shift(),y=m+s.shift(),l=b+s.shift(),v=y+s.shift(),s.shift(),e.U.P.curveTo(o,c,p,U,g,F,C),e.U.P.curveTo(o,S,m,b,y,l,v)),"o1236"==P&&(c=l+s.shift(),p=v+s.shift(),U=c+s.shift(),C=g=p+s.shift(),m=g,b=(S=(F=U+s.shift())+s.shift())+s.shift(),y=m+s.shift(),l=b+s.shift(),e.U.P.curveTo(o,c,p,U,g,F,C),e.U.P.curveTo(o,S,m,b,y,l,v)),"o1237"==P&&(c=l+s.shift(),p=v+s.shift(),U=c+s.shift(),g=p+s.shift(),F=U+s.shift(),C=g+s.shift(),S=F+s.shift(),m=C+s.shift(),b=S+s.shift(),y=m+s.shift(),Math.abs(b-l)>Math.abs(y-v)?l=b+s.shift():v=y+s.shift(),e.U.P.curveTo(o,c,p,U,g,F,C),e.U.P.curveTo(o,S,m,b,y,l,v));else if("o14"==P){if(s.length>0&&!h&&(d=s.shift()+a.nominalWidthX,h=!0),4==s.length){var O=s.shift(),T=s.shift(),D=s.shift(),B=s.shift(),A=e.CFF.glyphBySE(a,D),R=e.CFF.glyphBySE(a,B);e.U._drawCFF(a.CharStrings[A],t,a,n,o),t.x=O,t.y=T,e.U._drawCFF(a.CharStrings[R],t,a,n,o);}f&&(e.U.P.closePath(o),f=!1);}else if("o19"==P||"o20"==P){s.length%2!=0&&!h&&(d=s.shift()+n.nominalWidthX),i+=s.length>>1,s.length=0,h=!0,u+=i+7>>3;}else if("o21"==P)s.length>2&&!h&&(d=s.shift()+n.nominalWidthX,h=!0),v+=s.pop(),l+=s.pop(),f&&e.U.P.closePath(o),e.U.P.moveTo(o,l,v),f=!0;else if("o22"==P)s.length>1&&!h&&(d=s.shift()+n.nominalWidthX,h=!0),l+=s.pop(),f&&e.U.P.closePath(o),e.U.P.moveTo(o,l,v),f=!0;else if("o25"==P){for(;s.length>6;)l+=s.shift(),v+=s.shift(),e.U.P.lineTo(o,l,v);c=l+s.shift(),p=v+s.shift(),U=c+s.shift(),g=p+s.shift(),l=U+s.shift(),v=g+s.shift(),e.U.P.curveTo(o,c,p,U,g,l,v);}else if("o26"==P)for(s.length%2&&(l+=s.shift());s.length>0;)c=l,p=v+s.shift(),l=U=c+s.shift(),v=(g=p+s.shift())+s.shift(),e.U.P.curveTo(o,c,p,U,g,l,v);else if("o27"==P)for(s.length%2&&(v+=s.shift());s.length>0;)p=v,U=(c=l+s.shift())+s.shift(),g=p+s.shift(),l=U+s.shift(),v=g,e.U.P.curveTo(o,c,p,U,g,l,v);else if("o10"==P||"o29"==P){var L="o10"==P?n:a;if(0==s.length)console.debug("error: empty stack");else {var W=s.pop(),M=L.Subrs[W+L.Bias];t.x=l,t.y=v,t.nStems=i,t.haveWidth=h,t.width=d,t.open=f,e.U._drawCFF(M,t,a,n,o),l=t.x,v=t.y,i=t.nStems,h=t.haveWidth,d=t.width,f=t.open;}}else if("o30"==P||"o31"==P){var V=s.length,E=(G=0,"o31"==P);for(G+=V-(x=-3&V);G<x;)E?(p=v,U=(c=l+s.shift())+s.shift(),v=(g=p+s.shift())+s.shift(),x-G==5?(l=U+s.shift(),G++):l=U,E=!1):(c=l,p=v+s.shift(),U=c+s.shift(),g=p+s.shift(),l=U+s.shift(),x-G==5?(v=g+s.shift(),G++):v=g,E=!0),e.U.P.curveTo(o,c,p,U,g,l,v),G+=4;}else {if("o"==(P+"").charAt(0))throw console.debug("Unknown operation: "+P,r),P;s.push(P);}}}t.x=l,t.y=v,t.nStems=i,t.haveWidth=h,t.width=d,t.open=f;};var t=e,a={Typr:t};return r.Typr=t,r.default=a,Object.defineProperty(r,"__esModule",{value:!0}),r}({}).Typr}

	/*!
	Custom bundle of woff2otf (https://github.com/arty-name/woff2otf) with fflate
	(https://github.com/101arrowz/fflate) for use in Troika text rendering. 
	Original licenses apply: 
	- fflate: https://github.com/101arrowz/fflate/blob/master/LICENSE (MIT)
	- woff2otf.js: https://github.com/arty-name/woff2otf/blob/master/woff2otf.js (Apache2)
	*/
	function woff2otfFactory(){return function(r){var e=Uint8Array,n=Uint16Array,t=Uint32Array,a=new e([0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,0,0,0]),i=new e([0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13,0,0]),o=new e([16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15]),f=function(r,e){for(var a=new n(31),i=0;i<31;++i)a[i]=e+=1<<r[i-1];var o=new t(a[30]);for(i=1;i<30;++i)for(var f=a[i];f<a[i+1];++f)o[f]=f-a[i]<<5|i;return [a,o]},u=f(a,2),v=u[0],s=u[1];v[28]=258,s[258]=28;for(var l=f(i,0)[0],c=new n(32768),g=0;g<32768;++g){var h=(43690&g)>>>1|(21845&g)<<1;h=(61680&(h=(52428&h)>>>2|(13107&h)<<2))>>>4|(3855&h)<<4,c[g]=((65280&h)>>>8|(255&h)<<8)>>>1;}var w=function(r,e,t){for(var a=r.length,i=0,o=new n(e);i<a;++i)++o[r[i]-1];var f,u=new n(e);for(i=0;i<e;++i)u[i]=u[i-1]+o[i-1]<<1;if(t){f=new n(1<<e);var v=15-e;for(i=0;i<a;++i)if(r[i])for(var s=i<<4|r[i],l=e-r[i],g=u[r[i]-1]++<<l,h=g|(1<<l)-1;g<=h;++g)f[c[g]>>>v]=s;}else for(f=new n(a),i=0;i<a;++i)r[i]&&(f[i]=c[u[r[i]-1]++]>>>15-r[i]);return f},d=new e(288);for(g=0;g<144;++g)d[g]=8;for(g=144;g<256;++g)d[g]=9;for(g=256;g<280;++g)d[g]=7;for(g=280;g<288;++g)d[g]=8;var m=new e(32);for(g=0;g<32;++g)m[g]=5;var b=w(d,9,1),p=w(m,5,1),y=function(r){for(var e=r[0],n=1;n<r.length;++n)r[n]>e&&(e=r[n]);return e},L=function(r,e,n){var t=e/8|0;return (r[t]|r[t+1]<<8)>>(7&e)&n},U=function(r,e){var n=e/8|0;return (r[n]|r[n+1]<<8|r[n+2]<<16)>>(7&e)},k=["unexpected EOF","invalid block type","invalid length/literal","invalid distance","stream finished","no stream handler",,"no callback","invalid UTF-8 data","extra field too long","date not in range 1980-2099","filename too long","stream finishing","invalid zip data"],T=function(r,e,n){var t=new Error(e||k[r]);if(t.code=r,Error.captureStackTrace&&Error.captureStackTrace(t,T),!n)throw t;return t},O=function(r,f,u){var s=r.length;if(!s||u&&!u.l&&s<5)return f||new e(0);var c=!f||u,g=!u||u.i;u||(u={}),f||(f=new e(3*s));var h,d=function(r){var n=f.length;if(r>n){var t=new e(Math.max(2*n,r));t.set(f),f=t;}},m=u.f||0,k=u.p||0,O=u.b||0,A=u.l,x=u.d,E=u.m,D=u.n,M=8*s;do{if(!A){u.f=m=L(r,k,1);var S=L(r,k+1,3);if(k+=3,!S){var V=r[(I=((h=k)/8|0)+(7&h&&1)+4)-4]|r[I-3]<<8,_=I+V;if(_>s){g&&T(0);break}c&&d(O+V),f.set(r.subarray(I,_),O),u.b=O+=V,u.p=k=8*_;continue}if(1==S)A=b,x=p,E=9,D=5;else if(2==S){var j=L(r,k,31)+257,z=L(r,k+10,15)+4,C=j+L(r,k+5,31)+1;k+=14;for(var F=new e(C),P=new e(19),q=0;q<z;++q)P[o[q]]=L(r,k+3*q,7);k+=3*z;var B=y(P),G=(1<<B)-1,H=w(P,B,1);for(q=0;q<C;){var I,J=H[L(r,k,G)];if(k+=15&J,(I=J>>>4)<16)F[q++]=I;else {var K=0,N=0;for(16==I?(N=3+L(r,k,3),k+=2,K=F[q-1]):17==I?(N=3+L(r,k,7),k+=3):18==I&&(N=11+L(r,k,127),k+=7);N--;)F[q++]=K;}}var Q=F.subarray(0,j),R=F.subarray(j);E=y(Q),D=y(R),A=w(Q,E,1),x=w(R,D,1);}else T(1);if(k>M){g&&T(0);break}}c&&d(O+131072);for(var W=(1<<E)-1,X=(1<<D)-1,Y=k;;Y=k){var Z=(K=A[U(r,k)&W])>>>4;if((k+=15&K)>M){g&&T(0);break}if(K||T(2),Z<256)f[O++]=Z;else {if(256==Z){Y=k,A=null;break}var $=Z-254;if(Z>264){var rr=a[q=Z-257];$=L(r,k,(1<<rr)-1)+v[q],k+=rr;}var er=x[U(r,k)&X],nr=er>>>4;er||T(3),k+=15&er;R=l[nr];if(nr>3){rr=i[nr];R+=U(r,k)&(1<<rr)-1,k+=rr;}if(k>M){g&&T(0);break}c&&d(O+131072);for(var tr=O+$;O<tr;O+=4)f[O]=f[O-R],f[O+1]=f[O+1-R],f[O+2]=f[O+2-R],f[O+3]=f[O+3-R];O=tr;}}u.l=A,u.p=Y,u.b=O,A&&(m=1,u.m=E,u.d=x,u.n=D);}while(!m);return O==f.length?f:function(r,a,i){(null==a||a<0)&&(a=0),(null==i||i>r.length)&&(i=r.length);var o=new(r instanceof n?n:r instanceof t?t:e)(i-a);return o.set(r.subarray(a,i)),o}(f,0,O)},A=new e(0);var x="undefined"!=typeof TextDecoder&&new TextDecoder;try{x.decode(A,{stream:!0}),1;}catch(r){}return r.convert_streams=function(r){var e=new DataView(r),n=0;function t(){var r=e.getUint16(n);return n+=2,r}function a(){var r=e.getUint32(n);return n+=4,r}function i(r){m.setUint16(b,r),b+=2;}function o(r){m.setUint32(b,r),b+=4;}for(var f={signature:a(),flavor:a(),length:a(),numTables:t(),reserved:t(),totalSfntSize:a(),majorVersion:t(),minorVersion:t(),metaOffset:a(),metaLength:a(),metaOrigLength:a(),privOffset:a(),privLength:a()},u=0;Math.pow(2,u)<=f.numTables;)u++;u--;for(var v=16*Math.pow(2,u),s=16*f.numTables-v,l=12,c=[],g=0;g<f.numTables;g++)c.push({tag:a(),offset:a(),compLength:a(),origLength:a(),origChecksum:a()}),l+=16;var h,w=new Uint8Array(12+16*c.length+c.reduce((function(r,e){return r+e.origLength+4}),0)),d=w.buffer,m=new DataView(d),b=0;return o(f.flavor),i(f.numTables),i(v),i(u),i(s),c.forEach((function(r){o(r.tag),o(r.origChecksum),o(l),o(r.origLength),r.outOffset=l,(l+=r.origLength)%4!=0&&(l+=4-l%4);})),c.forEach((function(e){var n,t=r.slice(e.offset,e.offset+e.compLength);if(e.compLength!=e.origLength){var a=new Uint8Array(e.origLength);n=new Uint8Array(t,2),O(n,a);}else a=new Uint8Array(t);w.set(a,e.outOffset);var i=0;(l=e.outOffset+e.origLength)%4!=0&&(i=4-l%4),w.set(new Uint8Array(i).buffer,e.outOffset+e.origLength),h=l+i;})),d.slice(0,h)},Object.defineProperty(r,"__esModule",{value:!0}),r}({}).convert_streams}

	/**
	 * A factory wrapper parsing a font file using Typr.
	 * Also adds support for WOFF files (not WOFF2).
	 */

	/**
	 * @typedef ParsedFont
	 * @property {number} ascender
	 * @property {number} descender
	 * @property {number} xHeight
	 * @property {(number) => boolean} supportsCodePoint
	 * @property {(text:string, fontSize:number, letterSpacing:number, callback) => number} forEachGlyph
	 * @property {number} lineGap
	 * @property {number} capHeight
	 * @property {number} unitsPerEm
	 */

	/**
	 * @typedef {(buffer: ArrayBuffer) => ParsedFont} FontParser
	 */

	/**
	 * @returns {FontParser}
	 */
	function parserFactory(Typr, woff2otf) {
	  const cmdArgLengths = {
	    M: 2,
	    L: 2,
	    Q: 4,
	    C: 6,
	    Z: 0
	  };

	  // {joinType: "skip+step,..."}
	  const joiningTypeRawData = {"C":"18g,ca,368,1kz","D":"17k,6,2,2+4,5+c,2+6,2+1,10+1,9+f,j+11,2+1,a,2,2+1,15+2,3,j+2,6+3,2+8,2,2,2+1,w+a,4+e,3+3,2,3+2,3+5,23+w,2f+4,3,2+9,2,b,2+3,3,1k+9,6+1,3+1,2+2,2+d,30g,p+y,1,1+1g,f+x,2,sd2+1d,jf3+4,f+3,2+4,2+2,b+3,42,2,4+2,2+1,2,3,t+1,9f+w,2,el+2,2+g,d+2,2l,2+1,5,3+1,2+1,2,3,6,16wm+1v","R":"17m+3,2,2,6+3,m,15+2,2+2,h+h,13,3+8,2,2,3+1,2,p+1,x,5+4,5,a,2,2,3,u,c+2,g+1,5,2+1,4+1,5j,6+1,2,b,2+2,f,2+1,1s+2,2,3+1,7,1ez0,2,2+1,4+4,b,4,3,b,42,2+2,4,3,2+1,2,o+3,ae,ep,x,2o+2,3+1,3,5+1,6","L":"x9u,jff,a,fd,jv","T":"4t,gj+33,7o+4,1+1,7c+18,2,2+1,2+1,2,21+a,2,1b+k,h,2u+6,3+5,3+1,2+3,y,2,v+q,2k+a,1n+8,a,p+3,2+8,2+2,2+4,18+2,3c+e,2+v,1k,2,5+7,5,4+6,b+1,u,1n,5+3,9,l+1,r,3+1,1m,5+1,5+1,3+2,4,v+1,4,c+1,1m,5+4,2+1,5,l+1,n+5,2,1n,3,2+3,9,8+1,c+1,v,1q,d,1f,4,1m+2,6+2,2+3,8+1,c+1,u,1n,3,7,6+1,l+1,t+1,1m+1,5+3,9,l+1,u,21,8+2,2,2j,3+6,d+7,2r,3+8,c+5,23+1,s,2,2,1k+d,2+4,2+1,6+a,2+z,a,2v+3,2+5,2+1,3+1,q+1,5+2,h+3,e,3+1,7,g,jk+2,qb+2,u+2,u+1,v+1,1t+1,2+6,9,3+a,a,1a+2,3c+1,z,3b+2,5+1,a,7+2,64+1,3,1n,2+6,2,2,3+7,7+9,3,1d+d,1,1+1,1s+3,1d,2+4,2,6,15+8,d+1,x+3,3+1,2+2,1l,2+1,4,2+2,1n+7,3+1,49+2,2+c,2+6,5,7,4+1,5j+1l,2+4,ek,3+1,r+4,1e+4,6+5,2p+c,1+3,1,1+2,1+b,2db+2,3y,2p+v,ff+3,30+1,n9x,1+2,2+9,x+1,29+1,7l,4,5,q+1,6,48+1,r+h,e,13+7,q+a,1b+2,1d,3+3,3+1,14,1w+5,3+1,3+1,d,9,1c,1g,2+2,3+1,6+1,2,17+1,9,6n,3,5,fn5,ki+f,h+f,5s,6y+2,ea,6b,46+4,1af+2,2+1,6+3,15+2,5,4m+1,fy+3,as+1,4a+a,4x,1j+e,1l+2,1e+3,3+1,1y+2,11+4,2+7,1r,d+1,1h+8,b+3,3,2o+2,3,2+1,7,4h,4+7,m+1,1m+1,4,12+6,4+4,5g+7,3+2,2,o,2d+5,2,5+1,2+1,6n+3,7+1,2+1,s+1,2e+7,3,2+1,2z,2,3+5,2,2u+2,3+3,2+4,78+8,2+1,75+1,2,5,41+3,3+1,5,x+9,15+5,3+3,9,a+5,3+2,1b+c,2+1,bb+6,2+5,2,2b+l,3+6,2+1,2+1,3f+5,4,2+1,2+6,2,21+1,4,2,9o+1,470+8,at4+4,1o+6,t5,1s+3,2a,f5l+1,2+3,43o+2,a+7,1+7,3+6,v+3,45+2,1j0+1i,5+1d,9,f,n+4,2+e,11t+6,2+g,3+6,2+1,2+4,7a+6,c6+3,15t+6,32+6,1,gzau,v+2n,3l+6n"};

	  const JT_LEFT = 1, //indicates that a character joins with the subsequent character, but does not join with the preceding character.
	    JT_RIGHT = 2, //indicates that a character joins with the preceding character, but does not join with the subsequent character.
	    JT_DUAL = 4, //indicates that a character joins with the preceding character and joins with the subsequent character.
	    JT_TRANSPARENT = 8, //indicates that the character does not join with adjacent characters and that the character must be skipped over when the shaping engine is evaluating the joining positions in a sequence of characters. When a JT_TRANSPARENT character is encountered in a sequence, the JOINING_TYPE of the preceding character passes through. Diacritical marks are frequently assigned this value.
	    JT_JOIN_CAUSING = 16, //indicates that the character forces the use of joining forms with the preceding and subsequent characters. Kashidas and the Zero Width Joiner (U+200D) are both JOIN_CAUSING characters.
	    JT_NON_JOINING = 32; //indicates that a character does not join with the preceding or with the subsequent character.,

	  let joiningTypeMap;
	  function getCharJoiningType(ch) {
	    if (!joiningTypeMap) {
	      const m = {
	        R: JT_RIGHT,
	        L: JT_LEFT,
	        D: JT_DUAL,
	        C: JT_JOIN_CAUSING,
	        U: JT_NON_JOINING,
	        T: JT_TRANSPARENT
	      };
	      joiningTypeMap = new Map();
	      for (let type in joiningTypeRawData) {
	        let lastCode = 0;
	        joiningTypeRawData[type].split(',').forEach(range => {
	          let [skip, step] = range.split('+');
	          skip = parseInt(skip,36);
	          step = step ? parseInt(step, 36) : 0;
	          joiningTypeMap.set(lastCode += skip, m[type]);
	          for (let i = step; i--;) {
	            joiningTypeMap.set(++lastCode, m[type]);
	          }
	        });
	      }
	    }
	    return joiningTypeMap.get(ch) || JT_NON_JOINING
	  }

	  const ISOL = 1, INIT = 2, FINA = 3, MEDI = 4;
	  const formsToFeatures = [null, 'isol', 'init', 'fina', 'medi'];

	  function detectJoiningForms(str) {
	    // This implements the algorithm described here:
	    // https://github.com/n8willis/opentype-shaping-documents/blob/master/opentype-shaping-arabic-general.md
	    const joiningForms = new Uint8Array(str.length);
	    let prevJoiningType = JT_NON_JOINING;
	    let prevForm = ISOL;
	    let prevIndex = -1;
	    for (let i = 0; i < str.length; i++) {
	      const code = str.codePointAt(i);
	      let joiningType = getCharJoiningType(code) | 0;
	      let form = ISOL;
	      if (joiningType & JT_TRANSPARENT) {
	        continue
	      }
	      if (prevJoiningType & (JT_LEFT | JT_DUAL | JT_JOIN_CAUSING)) {
	        if (joiningType & (JT_RIGHT | JT_DUAL | JT_JOIN_CAUSING)) {
	          form = FINA;
	          // isol->init, fina->medi
	          if (prevForm === ISOL || prevForm === FINA) {
	            joiningForms[prevIndex]++;
	          }
	        }
	        else if (joiningType & (JT_LEFT | JT_NON_JOINING)) {
	          // medi->fina, init->isol
	          if (prevForm === INIT || prevForm === MEDI) {
	            joiningForms[prevIndex]--;
	          }
	        }
	      }
	      else if (prevJoiningType & (JT_RIGHT | JT_NON_JOINING)) {
	        // medi->fina, init->isol
	        if (prevForm === INIT || prevForm === MEDI) {
	          joiningForms[prevIndex]--;
	        }
	      }
	      prevForm = joiningForms[i] = form;
	      prevJoiningType = joiningType;
	      prevIndex = i;
	      if (code > 0xffff) i++;
	    }
	    // console.log(str.split('').map(ch => ch.codePointAt(0).toString(16)))
	    // console.log(str.split('').map(ch => getCharJoiningType(ch.codePointAt(0))))
	    // console.log(Array.from(joiningForms).map(f => formsToFeatures[f] || 'none'))
	    return joiningForms
	  }

	  function stringToGlyphs (font, str) {
	    const glyphIds = [];
	    for (let i = 0; i < str.length; i++) {
	      const cc = str.codePointAt(i);
	      if (cc > 0xffff) i++;
	      glyphIds.push(Typr.U.codeToGlyph(font, cc));
	    }

	    const gsub = font['GSUB'];
	    if (gsub) {
	      const {lookupList, featureList} = gsub;
	      let joiningForms;
	      const supportedFeatures = /^(rlig|liga|mset|isol|init|fina|medi|half|pres|blws|ccmp)$/;
	      const usedLookups = [];
	      featureList.forEach(feature => {
	        if (supportedFeatures.test(feature.tag)) {
	          for (let ti = 0; ti < feature.tab.length; ti++) {
	            if (usedLookups[feature.tab[ti]]) continue
	            usedLookups[feature.tab[ti]] = true;
	            const tab = lookupList[feature.tab[ti]];
	            const isJoiningFeature = /^(isol|init|fina|medi)$/.test(feature.tag);
	            if (isJoiningFeature && !joiningForms) { //lazy
	              joiningForms = detectJoiningForms(str);
	            }
	            for (let ci = 0; ci < glyphIds.length; ci++) {
	              if (!joiningForms || !isJoiningFeature || formsToFeatures[joiningForms[ci]] === feature.tag) {
	                Typr.U._applySubs(glyphIds, ci, tab, lookupList);
	              }
	            }
	          }
	        }
	      });
	    }

	    return glyphIds
	  }

	  // Calculate advances and x/y offsets for each glyph, e.g. kerning and mark
	  // attachments. This is a more complete version of Typr.U.getPairAdjustment
	  // and should become an upstream replacement eventually.
	  function calcGlyphPositions(font, glyphIds) {
	    const positions = new Int16Array(glyphIds.length * 3); // [offsetX, offsetY, advanceX, ...]
	    let glyphIndex = 0;
	    for (; glyphIndex < glyphIds.length; glyphIndex++) {
	      const glyphId = glyphIds[glyphIndex];
	      if (glyphId === -1) continue;

	      positions[glyphIndex * 3 + 2] = font.hmtx.aWidth[glyphId]; // populate advanceX in...advance.

	      const gpos = font.GPOS;
	      if (gpos) {
	        const llist = gpos.lookupList;
	        for (let i = 0; i < llist.length; i++) {
	          const lookup = llist[i];
	          for (let j = 0; j < lookup.tabs.length; j++) {
	            const tab = lookup.tabs[j];
	            // Single char placement
	            if (lookup.ltype === 1) {
	              const ind = Typr._lctf.coverageIndex(tab.coverage, glyphId);
	              if (ind !== -1 && tab.pos) {
	                applyValueRecord(tab.pos, glyphIndex);
	                break
	              }
	            }
	            // Pairs (kerning)
	            else if (lookup.ltype === 2) {
	              let adj = null;
	              let prevGlyphIndex = getPrevGlyphIndex();
	              if (prevGlyphIndex !== -1) {
	                const coverageIndex = Typr._lctf.coverageIndex(tab.coverage, glyphIds[prevGlyphIndex]);
	                if (coverageIndex !== -1) {
	                  if (tab.fmt === 1) {
	                    const right = tab.pairsets[coverageIndex];
	                    for (let k = 0; k < right.length; k++) {
	                      if (right[k].gid2 === glyphId) adj = right[k];
	                    }
	                  } else if (tab.fmt === 2) {
	                    const c1 = Typr.U._getGlyphClass(glyphIds[prevGlyphIndex], tab.classDef1);
	                    const c2 = Typr.U._getGlyphClass(glyphId, tab.classDef2);
	                    adj = tab.matrix[c1][c2];
	                  }
	                  if (adj) {
	                    if (adj.val1) applyValueRecord(adj.val1, prevGlyphIndex);
	                    if (adj.val2) applyValueRecord(adj.val2, glyphIndex);
	                    break
	                  }
	                }
	              }
	            }
	            // Mark to base
	            else if (lookup.ltype === 4) {
	              const markArrIndex = Typr._lctf.coverageIndex(tab.markCoverage, glyphId);
	              if (markArrIndex !== -1) {
	                const baseGlyphIndex = getPrevGlyphIndex(isBaseGlyph);
	                const baseArrIndex = baseGlyphIndex === -1 ? -1 : Typr._lctf.coverageIndex(tab.baseCoverage, glyphIds[baseGlyphIndex]);
	                if (baseArrIndex !== -1) {
	                  const markRecord = tab.markArray[markArrIndex];
	                  const baseAnchor = tab.baseArray[baseArrIndex][markRecord.markClass];
	                  positions[glyphIndex * 3] = baseAnchor.x - markRecord.x + positions[baseGlyphIndex * 3] - positions[baseGlyphIndex * 3 + 2];
	                  positions[glyphIndex * 3 + 1] = baseAnchor.y - markRecord.y + positions[baseGlyphIndex * 3 + 1];
	                  break;
	                }
	              }
	            }
	            // Mark to mark
	            else if (lookup.ltype === 6) {
	              const mark1ArrIndex = Typr._lctf.coverageIndex(tab.mark1Coverage, glyphId);
	              if (mark1ArrIndex !== -1) {
	                const prevGlyphIndex = getPrevGlyphIndex();
	                if (prevGlyphIndex !== -1) {
	                  const prevGlyphId = glyphIds[prevGlyphIndex];
	                  if (getGlyphClass(font, prevGlyphId) === 3) { // only check mark glyphs
	                    const mark2ArrIndex = Typr._lctf.coverageIndex(tab.mark2Coverage, prevGlyphId);
	                    if (mark2ArrIndex !== -1) {
	                      const mark1Record = tab.mark1Array[mark1ArrIndex];
	                      const mark2Anchor = tab.mark2Array[mark2ArrIndex][mark1Record.markClass];
	                      positions[glyphIndex * 3] = mark2Anchor.x - mark1Record.x + positions[prevGlyphIndex * 3] - positions[prevGlyphIndex * 3 + 2];
	                      positions[glyphIndex * 3 + 1] = mark2Anchor.y - mark1Record.y + positions[prevGlyphIndex * 3 + 1];
	                      break;
	                    }
	                  }
	                }
	              }
	            }
	          }
	        }
	      }
	      // Check kern table if no GPOS
	      else if (font.kern && !font.cff) {
	        const prevGlyphIndex = getPrevGlyphIndex();
	        if (prevGlyphIndex !== -1) {
	          const ind1 = font.kern.glyph1.indexOf(glyphIds[prevGlyphIndex]);
	          if (ind1 !== -1) {
	            const ind2 = font.kern.rval[ind1].glyph2.indexOf(glyphId);
	            if (ind2 !== -1) {
	              positions[prevGlyphIndex * 3 + 2] += font.kern.rval[ind1].vals[ind2];
	            }
	          }
	        }
	      }
	    }

	    return positions;

	    function getPrevGlyphIndex(filter) {
	      for (let i = glyphIndex - 1; i >=0; i--) {
	        if (glyphIds[i] !== -1 && (!filter || filter(glyphIds[i]))) {
	          return i
	        }
	      }
	      return -1;
	    }

	    function isBaseGlyph(glyphId) {
	      return getGlyphClass(font, glyphId) === 1;
	    }

	    function applyValueRecord(source, gi) {
	      for (let i = 0; i < 3; i++) {
	        positions[gi * 3 + i] += source[i] || 0;
	      }
	    }
	  }

	  function getGlyphClass(font, glyphId) {
	    const classDef = font.GDEF && font.GDEF.glyphClassDef;
	    return classDef ? Typr.U._getGlyphClass(glyphId, classDef) : 0;
	  }

	  function firstNum(...args) {
	    for (let i = 0; i < args.length; i++) {
	      if (typeof args[i] === 'number') {
	        return args[i]
	      }
	    }
	  }

	  /**
	   * @returns ParsedFont
	   */
	  function wrapFontObj(typrFont) {
	    const glyphMap = Object.create(null);

	    const os2 = typrFont['OS/2'];
	    const hhea = typrFont.hhea;
	    const unitsPerEm = typrFont.head.unitsPerEm;
	    const ascender = firstNum(os2 && os2.sTypoAscender, hhea && hhea.ascender, unitsPerEm);

	    /** @type ParsedFont */
	    const fontObj = {
	      unitsPerEm,
	      ascender,
	      descender: firstNum(os2 && os2.sTypoDescender, hhea && hhea.descender, 0),
	      capHeight: firstNum(os2 && os2.sCapHeight, ascender),
	      xHeight: firstNum(os2 && os2.sxHeight, ascender),
	      lineGap: firstNum(os2 && os2.sTypoLineGap, hhea && hhea.lineGap),
	      supportsCodePoint(code) {
	        return Typr.U.codeToGlyph(typrFont, code) > 0
	      },
	      forEachGlyph(text, fontSize, letterSpacing, callback) {
	        let penX = 0;
	        const fontScale = 1 / fontObj.unitsPerEm * fontSize;

	        const glyphIds = stringToGlyphs(typrFont, text);
	        let charIndex = 0;
	        const positions = calcGlyphPositions(typrFont, glyphIds);

	        glyphIds.forEach((glyphId, i) => {
	          // Typr returns a glyph index per string codepoint, with -1s in place of those that
	          // were omitted due to ligature substitution. So we can track original index in the
	          // string via simple increment, and skip everything else when seeing a -1.
	          if (glyphId !== -1) {
	            let glyphObj = glyphMap[glyphId];
	            if (!glyphObj) {
	              const {cmds, crds} = Typr.U.glyphToPath(typrFont, glyphId);

	              // Build path string
	              let path = '';
	              let crdsIdx = 0;
	              for (let i = 0, len = cmds.length; i < len; i++) {
	                const numArgs = cmdArgLengths[cmds[i]];
	                path += cmds[i];
	                for (let j = 1; j <= numArgs; j++) {
	                  path += (j > 1 ? ',' : '') + crds[crdsIdx++];
	                }
	              }

	              // Find extents - Glyf gives this in metadata but not CFF, and Typr doesn't
	              // normalize the two, so it's simplest just to iterate ourselves.
	              let xMin, yMin, xMax, yMax;
	              if (crds.length) {
	                xMin = yMin = Infinity;
	                xMax = yMax = -Infinity;
	                for (let i = 0, len = crds.length; i < len; i += 2) {
	                  let x = crds[i];
	                  let y = crds[i + 1];
	                  if (x < xMin) xMin = x;
	                  if (y < yMin) yMin = y;
	                  if (x > xMax) xMax = x;
	                  if (y > yMax) yMax = y;
	                }
	              } else {
	                xMin = xMax = yMin = yMax = 0;
	              }

	              glyphObj = glyphMap[glyphId] = {
	                index: glyphId,
	                advanceWidth: typrFont.hmtx.aWidth[glyphId],
	                xMin,
	                yMin,
	                xMax,
	                yMax,
	                path,
	              };
	            }

	            callback.call(
	              null,
	              glyphObj,
	              penX + positions[i * 3] * fontScale,
	              positions[i * 3 + 1] * fontScale,
	              charIndex
	            );

	            penX += positions[i * 3 + 2] * fontScale;
	            if (letterSpacing) {
	              penX += letterSpacing * fontSize;
	            }
	          }
	          charIndex += (text.codePointAt(charIndex) > 0xffff ? 2 : 1);
	        });

	        return penX
	      }
	    };

	    return fontObj
	  }

	  /**
	   * @type FontParser
	   */
	  return function parse(buffer) {
	    // Look to see if we have a WOFF file and convert it if so:
	    const peek = new Uint8Array(buffer, 0, 4);
	    const tag = Typr._bin.readASCII(peek, 0, 4);
	    if (tag === 'wOFF') {
	      buffer = woff2otf(buffer);
	    } else if (tag === 'wOF2') {
	      throw new Error('woff2 fonts not supported')
	    }
	    return wrapFontObj(Typr.parse(buffer)[0])
	  }
	}


	const workerModule = /*#__PURE__*/defineWorkerModule({
	  name: 'Typr Font Parser',
	  dependencies: [typrFactory, woff2otfFactory, parserFactory],
	  init(typrFactory, woff2otfFactory, parserFactory) {
	    const Typr = typrFactory();
	    const woff2otf = woff2otfFactory();
	    return parserFactory(Typr, woff2otf)
	  }
	});

	/*!
	Custom bundle of @unicode-font-resolver/client v1.0.2 (https://github.com/lojjic/unicode-font-resolver)
	for use in Troika text rendering. 
	Original MIT license applies
	*/
	function unicodeFontResolverClientFactory(){return function(t){var n=function(){this.buckets=new Map;};n.prototype.add=function(t){var n=t>>5;this.buckets.set(n,(this.buckets.get(n)||0)|1<<(31&t));},n.prototype.has=function(t){var n=this.buckets.get(t>>5);return void 0!==n&&0!=(n&1<<(31&t))},n.prototype.serialize=function(){var t=[];return this.buckets.forEach((function(n,r){t.push((+r).toString(36)+":"+n.toString(36));})),t.join(",")},n.prototype.deserialize=function(t){var n=this;this.buckets.clear(),t.split(",").forEach((function(t){var r=t.split(":");n.buckets.set(parseInt(r[0],36),parseInt(r[1],36));}));};var r=Math.pow(2,8),e=r-1,o=~e;function a(t){var n=function(t){return t&o}(t).toString(16),e=function(t){return (t&o)+r-1}(t).toString(16);return "codepoint-index/plane"+(t>>16)+"/"+n+"-"+e+".json"}function i(t,n){var r=t&e,o=n.codePointAt(r/6|0);return 0!=((o=(o||48)-48)&1<<r%6)}function u(t,n){var r;(r=t,r.replace(/U\+/gi,"").replace(/^,+|,+$/g,"").split(/,+/).map((function(t){return t.split("-").map((function(t){return parseInt(t.trim(),16)}))}))).forEach((function(t){var r=t[0],e=t[1];void 0===e&&(e=r),n(r,e);}));}function c(t,n){u(t,(function(t,r){for(var e=t;e<=r;e++)n(e);}));}var s={},f={},l=new WeakMap,v="https://cdn.jsdelivr.net/gh/lojjic/unicode-font-resolver@v1.0.1/packages/data";function d(t){var r=l.get(t);return r||(r=new n,c(t.ranges,(function(t){return r.add(t)})),l.set(t,r)),r}var h,p=new Map;function g(t,n,r){return t[n]?n:t[r]?r:function(t){for(var n in t)return n}(t)}function w(t,n){var r=n;if(!t.includes(r)){r=1/0;for(var e=0;e<t.length;e++)Math.abs(t[e]-n)<Math.abs(r-n)&&(r=t[e]);}return r}function k(t){return h||(h=new Set,c("9-D,20,85,A0,1680,2000-200A,2028-202F,205F,3000",(function(t){h.add(t);}))),h.has(t)}return t.CodePointSet=n,t.clearCache=function(){s={},f={};},t.getFontsForString=function(t,n){void 0===n&&(n={});var r,e=n.lang;void 0===e&&(e=/\p{Script=Hangul}/u.test(r=t)?"ko":/\p{Script=Hiragana}|\p{Script=Katakana}/u.test(r)?"ja":"en");var o=n.category;void 0===o&&(o="sans-serif");var u=n.style;void 0===u&&(u="normal");var c=n.weight;void 0===c&&(c=400);var l=(n.dataUrl||v).replace(/\/$/g,""),h=new Map,y=new Uint8Array(t.length),b={},m={},A=new Array(t.length),S=new Map,j=!1;function M(t){var n=p.get(t);return n||(n=fetch(l+"/"+t).then((function(t){if(!t.ok)throw new Error(t.statusText);return t.json().then((function(t){if(!Array.isArray(t)||1!==t[0])throw new Error("Incorrect schema version; need 1, got "+t[0]);return t[1]}))})).catch((function(n){if(l!==v)return j||(console.error('unicode-font-resolver: Failed loading from dataUrl "'+l+'", trying default CDN. '+n.message),j=!0),l=v,p.delete(t),M(t);throw n})),p.set(t,n)),n}for(var P=function(n){var r=t.codePointAt(n),e=a(r);A[n]=e,s[e]||S.has(e)||S.set(e,M(e).then((function(t){s[e]=t;}))),r>65535&&(n++,E=n);},E=0;E<t.length;E++)P(E);return Promise.all(S.values()).then((function(){S.clear();for(var n=function(n){var o=t.codePointAt(n),a=null,u=s[A[n]],c=void 0;for(var l in u){var v=m[l];if(void 0===v&&(v=m[l]=new RegExp(l).test(e||"en")),v){for(var d in c=l,u[l])if(i(o,u[l][d])){a=d;break}break}}if(!a)t:for(var h in u)if(h!==c)for(var p in u[h])if(i(o,u[h][p])){a=p;break t}a||(console.debug("No font coverage for U+"+o.toString(16)),a="latin"),A[n]=a,f[a]||S.has(a)||S.set(a,M("font-meta/"+a+".json").then((function(t){f[a]=t;}))),o>65535&&(n++,r=n);},r=0;r<t.length;r++)n(r);return Promise.all(S.values())})).then((function(){for(var n,r=null,e=0;e<t.length;e++){var a=t.codePointAt(e);if(r&&(k(a)||d(r).has(a)))y[e]=y[e-1];else {r=f[A[e]];var i=b[r.id];if(!i){var s=r.typeforms,v=g(s,o,"sans-serif"),p=g(s[v],u,"normal"),m=w(null===(n=s[v])||void 0===n?void 0:n[p],c);i=b[r.id]=l+"/font-files/"+r.id+"/"+v+"."+p+"."+m+".woff";}var S=h.get(i);null==S&&(S=h.size,h.set(i,S)),y[e]=S;}a>65535&&(e++,y[e]=y[e-1]);}return {fontUrls:Array.from(h.keys()),chars:y}}))},Object.defineProperty(t,"__esModule",{value:!0}),t}({})}

	/**
	 * @typedef {string | {src:string, label?:string, unicodeRange?:string, lang?:string}} UserFont
	 */

	/**
	 * @typedef {ClientOptions} FontResolverOptions
	 * @property {Array<UserFont>|UserFont} [fonts]
	 * @property {'normal'|'italic'} [style]
	 * @property {'normal'|'bold'|number} [style]
	 * @property {string} [unicodeFontsURL]
	 */

	/**
	 * @typedef {Object} FontResolverResult
	 * @property {Uint8Array} chars
	 * @property {Array<ParsedFont & {src:string}>} fonts
	 */

	/**
	 * @typedef {function} FontResolver
	 * @param {string} text
	 * @param {(FontResolverResult) => void} callback
	 * @param {FontResolverOptions} [options]
	 */

	/**
	 * Factory for the FontResolver function.
	 * @param {FontParser} fontParser
	 * @param {{getFontsForString: function, CodePointSet: function}} unicodeFontResolverClient
	 * @return {FontResolver}
	 */
	function createFontResolver(fontParser, unicodeFontResolverClient) {
	  /**
	   * @type {Record<string, ParsedFont>}
	   */
	  const parsedFonts = Object.create(null);

	  /**
	   * @type {Record<string, Array<(ParsedFont) => void>>}
	   */
	  const loadingFonts = Object.create(null);

	  /**
	   * Load a given font url
	   */
	  function doLoadFont(url, callback) {
	    const onError = err => {
	      console.error(`Failure loading font ${url}`, err);
	    };
	    try {
	      const request = new XMLHttpRequest();
	      request.open('get', url, true);
	      request.responseType = 'arraybuffer';
	      request.onload = function () {
	        if (request.status >= 400) {
	          onError(new Error(request.statusText));
	        }
	        else if (request.status > 0) {
	          try {
	            const fontObj = fontParser(request.response);
	            fontObj.src = url;
	            callback(fontObj);
	          } catch (e) {
	            onError(e);
	          }
	        }
	      };
	      request.onerror = onError;
	      request.send();
	    } catch(err) {
	      onError(err);
	    }
	  }


	  /**
	   * Load a given font url if needed, invoking a callback when it's loaded. If already
	   * loaded, the callback will be called synchronously.
	   * @param {string} fontUrl
	   * @param {(font: ParsedFont) => void} callback
	   */
	  function loadFont(fontUrl, callback) {
	    let font = parsedFonts[fontUrl];
	    if (font) {
	      callback(font);
	    } else if (loadingFonts[fontUrl]) {
	      loadingFonts[fontUrl].push(callback);
	    } else {
	      loadingFonts[fontUrl] = [callback];
	      doLoadFont(fontUrl, fontObj => {
	        fontObj.src = fontUrl;
	        parsedFonts[fontUrl] = fontObj;
	        loadingFonts[fontUrl].forEach(cb => cb(fontObj));
	        delete loadingFonts[fontUrl];
	      });
	    }
	  }

	  /**
	   * For a given string of text, determine which fonts are required to fully render it and
	   * ensure those fonts are loaded.
	   */
	  return function (text, callback, {
	    lang,
	    fonts: userFonts = [],
	    style = 'normal',
	    weight = 'normal',
	    unicodeFontsURL
	  } = {}) {
	    const charResolutions = new Uint8Array(text.length);
	    const fontResolutions = [];
	    if (!text.length) {
	      allDone();
	    }

	    const fontIndices = new Map();
	    const fallbackRanges = []; // [[start, end], ...]

	    if (style !== 'italic') style = 'normal';
	    if (typeof weight !== 'number') {
	      weight = weight === 'bold' ? 700 : 400;
	    }

	    if (userFonts && !Array.isArray(userFonts)) {
	      userFonts = [userFonts];
	    }
	    userFonts = userFonts.slice()
	      // filter by language
	      .filter(def => !def.lang || def.lang.test(lang))
	      // switch order for easier iteration
	      .reverse();
	    if (userFonts.length) {
	      const UNKNOWN = 0;
	      const RESOLVED = 1;
	      const NEEDS_FALLBACK = 2;
	      let prevCharResult = UNKNOWN

	      ;(function resolveUserFonts (startIndex = 0) {
	        for (let i = startIndex, iLen = text.length; i < iLen; i++) {
	          const codePoint = text.codePointAt(i);
	          // Carry previous character's result forward if:
	          // - it resolved to a font that also covers this character
	          // - this character is whitespace
	          if (
	            (prevCharResult === RESOLVED && fontResolutions[charResolutions[i - 1]].supportsCodePoint(codePoint)) ||
	            (i > 0 && /\s/.test(text[i]))
	          ) {
	            charResolutions[i] = charResolutions[i - 1];
	            if (prevCharResult === NEEDS_FALLBACK) {
	              fallbackRanges[fallbackRanges.length - 1][1] = i;
	            }
	          } else {
	            for (let j = charResolutions[i], jLen = userFonts.length; j <= jLen; j++) {
	              if (j === jLen) {
	                // none of the user fonts matched; needs fallback
	                const range = prevCharResult === NEEDS_FALLBACK ?
	                  fallbackRanges[fallbackRanges.length - 1] :
	                  (fallbackRanges[fallbackRanges.length] = [i, i]);
	                range[1] = i;
	                prevCharResult = NEEDS_FALLBACK;
	              } else {
	                charResolutions[i] = j;
	                const { src, unicodeRange } = userFonts[j];
	                // filter by optional explicit unicode ranges
	                if (!unicodeRange || isCodeInRanges(codePoint, unicodeRange)) {
	                  const fontObj = parsedFonts[src];
	                  // font not yet loaded, load it and resume
	                  if (!fontObj) {
	                    loadFont(src, () => {
	                      resolveUserFonts(i);
	                    });
	                    return;
	                  }
	                  // if the font actually contains a glyph for this char, lock it in
	                  if (fontObj.supportsCodePoint(codePoint)) {
	                    let fontIndex = fontIndices.get(fontObj);
	                    if (typeof fontIndex !== 'number') {
	                      fontIndex = fontResolutions.length;
	                      fontResolutions.push(fontObj);
	                      fontIndices.set(fontObj, fontIndex);
	                    }
	                    charResolutions[i] = fontIndex;
	                    prevCharResult = RESOLVED;
	                    break;
	                  }
	                }
	              }
	            }
	          }

	          if (codePoint > 0xffff && i + 1 < iLen) {
	            charResolutions[i + 1] = charResolutions[i];
	            i++;
	            if (prevCharResult === NEEDS_FALLBACK) {
	              fallbackRanges[fallbackRanges.length - 1][1] = i;
	            }
	          }
	        }
	        resolveFallbacks();
	      })();
	    } else {
	      fallbackRanges.push([0, text.length - 1]);
	      resolveFallbacks();
	    }

	    function resolveFallbacks() {
	      if (fallbackRanges.length) {
	        // Combine all fallback substrings into a single string for querying
	        const fallbackString = fallbackRanges.map(range => text.substring(range[0], range[1] + 1)).join('\n');
	        unicodeFontResolverClient.getFontsForString(fallbackString, {
	          lang: lang || undefined,
	          style,
	          weight,
	          dataUrl: unicodeFontsURL
	        }).then(({fontUrls, chars}) => {
	          // Extract results and put them back in the main array
	          const fontIndexOffset = fontResolutions.length;
	          let charIdx = 0;
	          fallbackRanges.forEach(range => {
	            for (let i = 0, endIdx = range[1] - range[0]; i <= endIdx; i++) {
	              charResolutions[range[0] + i] = chars[charIdx++] + fontIndexOffset;
	            }
	            charIdx++; //skip segment separator
	          });

	          // Load and parse the fallback fonts - avoiding Promise here to prevent polyfills in the worker
	          let loadedCount = 0;
	          fontUrls.forEach((url, i) => {
	            loadFont(url, fontObj => {
	              fontResolutions[i + fontIndexOffset] = fontObj;
	              if (++loadedCount === fontUrls.length) {
	                allDone();
	              }
	            });
	          });
	        });
	      } else {
	        allDone();
	      }
	    }

	    function allDone() {
	      callback({
	        chars: charResolutions,
	        fonts: fontResolutions
	      });
	    }

	    function isCodeInRanges(code, ranges) {
	      // todo optimize search - CodePointSet from unicode-font-resolver?
	      for (let k = 0; k < ranges.length; k++) {
	        const [start, end = start] = ranges[k];
	        if (start <= code && code <= end) {
	          return true
	        }
	      }
	      return false
	    }
	  }
	}

	const fontResolverWorkerModule = /*#__PURE__*/defineWorkerModule({
	  name: 'FontResolver',
	  dependencies: [
	    createFontResolver,
	    workerModule,
	    unicodeFontResolverClientFactory,
	  ],
	  init(createFontResolver, fontParser, unicodeFontResolverClientFactory) {
	    return createFontResolver(fontParser, unicodeFontResolverClientFactory());
	  }
	});

	/**
	 * @typedef {number|'left'|'center'|'right'} AnchorXValue
	 */
	/**
	 * @typedef {number|'top'|'top-baseline'|'top-cap'|'top-ex'|'middle'|'bottom-baseline'|'bottom'} AnchorYValue
	 */

	/**
	 * @typedef {object} TypesetParams
	 * @property {string} text
	 * @property {UserFont|UserFont[]} [font]
	 * @property {string} [lang]
	 * @property {number} [sdfGlyphSize=64]
	 * @property {number} [fontSize=1]
	 * @property {number|'normal'|'bold'} [fontWeight='normal']
	 * @property {'normal'|'italic'} [fontStyle='normal']
	 * @property {number} [letterSpacing=0]
	 * @property {'normal'|number} [lineHeight='normal']
	 * @property {number} [maxWidth]
	 * @property {'ltr'|'rtl'} [direction='ltr']
	 * @property {string} [textAlign='left']
	 * @property {number} [textIndent=0]
	 * @property {'normal'|'nowrap'} [whiteSpace='normal']
	 * @property {'normal'|'break-word'} [overflowWrap='normal']
	 * @property {AnchorXValue} [anchorX=0]
	 * @property {AnchorYValue} [anchorY=0]
	 * @property {boolean} [metricsOnly=false]
	 * @property {string} [unicodeFontsURL]
	 * @property {FontResolverResult} [preResolvedFonts]
	 * @property {boolean} [includeCaretPositions=false]
	 * @property {number} [chunkedBoundsSize=8192]
	 * @property {{[rangeStartIndex]: number}} [colorRanges]
	 */

	/**
	 * @typedef {object} TypesetResult
	 * @property {Uint16Array} glyphIds id for each glyph, specific to that glyph's font
	 * @property {Uint8Array} glyphFontIndices index into fontData for each glyph
	 * @property {Float32Array} glyphPositions x,y of each glyph's origin in layout
	 * @property {{[font]: {[glyphId]: {path: string, pathBounds: number[]}}}} glyphData data about each glyph appearing in the text
	 * @property {TypesetFontData[]} fontData data about each font used in the text
	 * @property {Float32Array} [caretPositions] startX,endX,bottomY caret positions for each char
	 * @property {Uint8Array} [glyphColors] color for each glyph, if color ranges supplied
	 *         chunkedBounds, //total rects per (n=chunkedBoundsSize) consecutive glyphs
	 *         fontSize, //calculated em height
	 *         topBaseline: anchorYOffset + lines[0].baseline, //y coordinate of the top line's baseline
	 *         blockBounds: [ //bounds for the whole block of text, including vertical padding for lineHeight
	 *           anchorXOffset,
	 *           anchorYOffset - totalHeight,
	 *           anchorXOffset + maxLineWidth,
	 *           anchorYOffset
	 *         ],
	 *         visibleBounds, //total bounds of visible text paths, may be larger or smaller than blockBounds
	 *         timings
	 */

	/**
	 * @typedef {object} TypesetFontData
	 * @property src
	 * @property unitsPerEm
	 * @property ascender
	 * @property descender
	 * @property lineHeight
	 * @property capHeight
	 * @property xHeight
	 */

	/**
	 * @typedef {function} TypesetterTypesetFunction - compute fonts and layout for some text.
	 * @param {TypesetParams} params
	 * @param {(TypesetResult) => void} callback - function called when typesetting is complete.
	 *    If the params included `preResolvedFonts`, this will be called synchronously.
	 */

	/**
	 * @typedef {function} TypesetterMeasureFunction - compute width/height for some text.
	 * @param {TypesetParams} params
	 * @param {(width:number, height:number) => void} callback - function called when measurement is complete.
	 *    If the params included `preResolvedFonts`, this will be called synchronously.
	 */


	/**
	 * Factory function that creates a self-contained environment for processing text typesetting requests.
	 *
	 * It is important that this function has no closure dependencies, so that it can be easily injected
	 * into the source for a Worker without requiring a build step or complex dependency loading. All its
	 * dependencies must be passed in at initialization.
	 *
	 * @param {FontResolver} resolveFonts - function to resolve a string to parsed fonts
	 * @param {object} bidi - the bidi.js implementation object
	 * @return {{typeset: TypesetterTypesetFunction, measure: TypesetterMeasureFunction}}
	 */
	function createTypesetter(resolveFonts, bidi) {
	  const INF = Infinity;

	  // Set of Unicode Default_Ignorable_Code_Point characters, these will not produce visible glyphs
	  // eslint-disable-next-line no-misleading-character-class
	  const DEFAULT_IGNORABLE_CHARS = /[\u00AD\u034F\u061C\u115F-\u1160\u17B4-\u17B5\u180B-\u180E\u200B-\u200F\u202A-\u202E\u2060-\u206F\u3164\uFE00-\uFE0F\uFEFF\uFFA0\uFFF0-\uFFF8]/;

	  // This regex (instead of /\s/) allows us to select all whitespace EXCEPT for non-breaking white spaces
	  const lineBreakingWhiteSpace = `[^\\S\\u00A0]`;

	  // Incomplete set of characters that allow line breaking after them
	  // In the future we may consider a full Unicode line breaking algorithm impl: https://www.unicode.org/reports/tr14
	  const BREAK_AFTER_CHARS = new RegExp(`${lineBreakingWhiteSpace}|[\\-\\u007C\\u00AD\\u2010\\u2012-\\u2014\\u2027\\u2056\\u2E17\\u2E40]`);

	  /**
	   * Load and parse all the necessary fonts to render a given string of text, then group
	   * them into consecutive runs of characters sharing a font.
	   */
	  function calculateFontRuns({text, lang, fonts, style, weight, preResolvedFonts, unicodeFontsURL}, onDone) {
	    const onResolved = ({chars, fonts: parsedFonts}) => {
	      let curRun, prevVal;
	      const runs = [];
	      for (let i = 0; i < chars.length; i++) {
	        if (chars[i] !== prevVal) {
	          prevVal = chars[i];
	          runs.push(curRun = { start: i, end: i, fontObj: parsedFonts[chars[i]]});
	        } else {
	          curRun.end = i;
	        }
	      }
	      onDone(runs);
	    };
	    if (preResolvedFonts) {
	      onResolved(preResolvedFonts);
	    } else {
	      resolveFonts(
	        text,
	        onResolved,
	        { lang, fonts, style, weight, unicodeFontsURL }
	      );
	    }
	  }

	  /**
	   * Main entry point.
	   * Process a text string with given font and formatting parameters, and return all info
	   * necessary to render all its glyphs.
	   * @type TypesetterTypesetFunction
	   */
	  function typeset(
	    {
	      text='',
	      font,
	      lang,
	      sdfGlyphSize=64,
	      fontSize=400,
	      fontWeight=1,
	      fontStyle='normal',
	      letterSpacing=0,
	      lineHeight='normal',
	      maxWidth=INF,
	      direction,
	      textAlign='left',
	      textIndent=0,
	      whiteSpace='normal',
	      overflowWrap='normal',
	      anchorX = 0,
	      anchorY = 0,
	      metricsOnly=false,
	      unicodeFontsURL,
	      preResolvedFonts=null,
	      includeCaretPositions=false,
	      chunkedBoundsSize=8192,
	      colorRanges=null
	    },
	    callback
	  ) {
	    const mainStart = now();
	    const timings = {fontLoad: 0, typesetting: 0};

	    // Ensure newlines are normalized
	    if (text.indexOf('\r') > -1) {
	      console.info('Typesetter: got text with \\r chars; normalizing to \\n');
	      text = text.replace(/\r\n/g, '\n').replace(/\r/g, '\n');
	    }

	    // Ensure we've got numbers not strings
	    fontSize = +fontSize;
	    letterSpacing = +letterSpacing;
	    maxWidth = +maxWidth;
	    lineHeight = lineHeight || 'normal';
	    textIndent = +textIndent;

	    calculateFontRuns({
	      text,
	      lang,
	      style: fontStyle,
	      weight: fontWeight,
	      fonts: typeof font === 'string' ? [{src: font}] : font,
	      unicodeFontsURL,
	      preResolvedFonts
	    }, runs => {
	      timings.fontLoad = now() - mainStart;
	      const hasMaxWidth = isFinite(maxWidth);
	      let glyphIds = null;
	      let glyphFontIndices = null;
	      let glyphPositions = null;
	      let glyphData = null;
	      let glyphColors = null;
	      let caretPositions = null;
	      let visibleBounds = null;
	      let chunkedBounds = null;
	      let maxLineWidth = 0;
	      let renderableGlyphCount = 0;
	      let canWrap = whiteSpace !== 'nowrap';
	      const metricsByFont = new Map(); // fontObj -> metrics
	      const typesetStart = now();

	      // Distribute glyphs into lines based on wrapping
	      let lineXOffset = textIndent;
	      let prevRunEndX = 0;
	      let currentLine = new TextLine();
	      const lines = [currentLine];
	      runs.forEach(run => {
	        const { fontObj } = run;
	        const { ascender, descender, unitsPerEm, lineGap, capHeight, xHeight } = fontObj;

	        // Calculate metrics for each font used
	        let fontData = metricsByFont.get(fontObj);
	        if (!fontData) {
	          // Find conversion between native font units and fontSize units
	          const fontSizeMult = fontSize / unitsPerEm;

	          // Determine appropriate value for 'normal' line height based on the font's actual metrics
	          // This does not guarantee individual glyphs won't exceed the line height, e.g. Roboto; should we use yMin/Max instead?
	          const calcLineHeight = lineHeight === 'normal' ?
	            (ascender - descender + lineGap) * fontSizeMult : lineHeight * fontSize;

	          // Determine line height and leading adjustments
	          const halfLeading = (calcLineHeight - (ascender - descender) * fontSizeMult) / 2;
	          const caretHeight = Math.min(calcLineHeight, (ascender - descender) * fontSizeMult);
	          const caretTop = (ascender + descender) / 2 * fontSizeMult + caretHeight / 2;
	          fontData = {
	            index: metricsByFont.size,
	            src: fontObj.src,
	            fontObj,
	            fontSizeMult,
	            unitsPerEm,
	            ascender: ascender * fontSizeMult,
	            descender: descender * fontSizeMult,
	            capHeight: capHeight * fontSizeMult,
	            xHeight: xHeight * fontSizeMult,
	            lineHeight: calcLineHeight,
	            baseline: -halfLeading - ascender * fontSizeMult, // baseline offset from top of line height
	            // cap: -halfLeading - capHeight * fontSizeMult, // cap from top of line height
	            // ex: -halfLeading - xHeight * fontSizeMult, // ex from top of line height
	            caretTop,
	            caretBottom: caretTop - caretHeight
	          };
	          metricsByFont.set(fontObj, fontData);
	        }
	        const { fontSizeMult } = fontData;

	        const runText = text.slice(run.start, run.end + 1);
	        let prevGlyphX, prevGlyphObj;
	        fontObj.forEachGlyph(runText, fontSize, letterSpacing, (glyphObj, glyphX, glyphY, charIndex) => {
	          glyphX += prevRunEndX;
	          charIndex += run.start;
	          prevGlyphX = glyphX;
	          prevGlyphObj = glyphObj;
	          const char = text.charAt(charIndex);
	          const glyphWidth = glyphObj.advanceWidth * fontSizeMult;
	          const curLineCount = currentLine.count;
	          let nextLine;

	          // Calc isWhitespace and isEmpty once per glyphObj
	          if (!('isEmpty' in glyphObj)) {
	            glyphObj.isWhitespace = !!char && new RegExp(lineBreakingWhiteSpace).test(char);
	            glyphObj.canBreakAfter = !!char && BREAK_AFTER_CHARS.test(char);
	            glyphObj.isEmpty = glyphObj.xMin === glyphObj.xMax || glyphObj.yMin === glyphObj.yMax || DEFAULT_IGNORABLE_CHARS.test(char);
	          }
	          if (!glyphObj.isWhitespace && !glyphObj.isEmpty) {
	            renderableGlyphCount++;
	          }

	          // If a non-whitespace character overflows the max width, we need to soft-wrap
	          if (canWrap && hasMaxWidth && !glyphObj.isWhitespace && glyphX + glyphWidth + lineXOffset > maxWidth && curLineCount) {
	            // If it's the first char after a whitespace, start a new line
	            if (currentLine.glyphAt(curLineCount - 1).glyphObj.canBreakAfter) {
	              nextLine = new TextLine();
	              lineXOffset = -glyphX;
	            } else {
	              // Back up looking for a whitespace character to wrap at
	              for (let i = curLineCount; i--;) {
	                // If we got the start of the line there's no soft break point; make hard break if overflowWrap='break-word'
	                if (i === 0 && overflowWrap === 'break-word') {
	                  nextLine = new TextLine();
	                  lineXOffset = -glyphX;
	                  break
	                }
	                // Found a soft break point; move all chars since it to a new line
	                else if (currentLine.glyphAt(i).glyphObj.canBreakAfter) {
	                  nextLine = currentLine.splitAt(i + 1);
	                  const adjustX = nextLine.glyphAt(0).x;
	                  lineXOffset -= adjustX;
	                  for (let j = nextLine.count; j--;) {
	                    nextLine.glyphAt(j).x -= adjustX;
	                  }
	                  break
	                }
	              }
	            }
	            if (nextLine) {
	              currentLine.isSoftWrapped = true;
	              currentLine = nextLine;
	              lines.push(currentLine);
	              maxLineWidth = maxWidth; //after soft wrapping use maxWidth as calculated width
	            }
	          }

	          let fly = currentLine.glyphAt(currentLine.count);
	          fly.glyphObj = glyphObj;
	          fly.x = glyphX + lineXOffset;
	          fly.y = glyphY;
	          fly.width = glyphWidth;
	          fly.charIndex = charIndex;
	          fly.fontData = fontData;

	          // Handle hard line breaks
	          if (char === '\n') {
	            currentLine = new TextLine();
	            lines.push(currentLine);
	            lineXOffset = -(glyphX + glyphWidth + (letterSpacing * fontSize)) + textIndent;
	          }
	        });
	        // At the end of a run we must capture the x position as the starting point for the next run
	        prevRunEndX = prevGlyphX + prevGlyphObj.advanceWidth * fontSizeMult + letterSpacing * fontSize;
	      });

	      // Calculate width/height/baseline of each line (excluding trailing whitespace) and maximum block width
	      let totalHeight = 0;
	      lines.forEach(line => {
	        let isTrailingWhitespace = true;
	        for (let i = line.count; i--;) {
	          const glyphInfo = line.glyphAt(i);
	          // omit trailing whitespace from width calculation
	          if (isTrailingWhitespace && !glyphInfo.glyphObj.isWhitespace) {
	            line.width = glyphInfo.x + glyphInfo.width;
	            if (line.width > maxLineWidth) {
	              maxLineWidth = line.width;
	            }
	            isTrailingWhitespace = false;
	          }
	          // use the tallest line height, lowest baseline, and highest cap/ex
	          let {lineHeight, capHeight, xHeight, baseline} = glyphInfo.fontData;
	          if (lineHeight > line.lineHeight) line.lineHeight = lineHeight;
	          const baselineDiff = baseline - line.baseline;
	          if (baselineDiff < 0) { //shift all metrics down
	            line.baseline += baselineDiff;
	            line.cap += baselineDiff;
	            line.ex += baselineDiff;
	          }
	          // compare cap/ex based on new lowest baseline
	          line.cap = Math.max(line.cap, line.baseline + capHeight);
	          line.ex = Math.max(line.ex, line.baseline + xHeight);
	        }
	        line.baseline -= totalHeight;
	        line.cap -= totalHeight;
	        line.ex -= totalHeight;
	        totalHeight += line.lineHeight;
	      });

	      // Find overall position adjustments for anchoring
	      let anchorXOffset = 0;
	      let anchorYOffset = 0;
	      if (anchorX) {
	        if (typeof anchorX === 'number') {
	          anchorXOffset = -anchorX;
	        }
	        else if (typeof anchorX === 'string') {
	          anchorXOffset = -maxLineWidth * (
	            anchorX === 'left' ? 0 :
	            anchorX === 'center' ? 0.5 :
	            anchorX === 'right' ? 1 :
	            parsePercent(anchorX)
	          );
	        }
	      }
	      if (anchorY) {
	        if (typeof anchorY === 'number') {
	          anchorYOffset = -anchorY;
	        }
	        else if (typeof anchorY === 'string') {
	          anchorYOffset = anchorY === 'top' ? 0 :
	            anchorY === 'top-baseline' ? -lines[0].baseline :
	            anchorY === 'top-cap' ? -lines[0].cap :
	            anchorY === 'top-ex' ? -lines[0].ex :
	            anchorY === 'middle' ? totalHeight / 2 :
	            anchorY === 'bottom' ? totalHeight :
	            anchorY === 'bottom-baseline' ? -lines[lines.length - 1].baseline :
	            parsePercent(anchorY) * totalHeight;
	        }
	      }

	      if (!metricsOnly) {
	        // Resolve bidi levels
	        const bidiLevelsResult = bidi.getEmbeddingLevels(text, direction);

	        // Process each line, applying alignment offsets, adding each glyph to the atlas, and
	        // collecting all renderable glyphs into a single collection.
	        glyphIds = new Uint16Array(renderableGlyphCount);
	        glyphFontIndices = new Uint8Array(renderableGlyphCount);
	        glyphPositions = new Float32Array(renderableGlyphCount * 2);
	        glyphData = {};
	        visibleBounds = [INF, INF, -INF, -INF];
	        chunkedBounds = [];
	        if (includeCaretPositions) {
	          caretPositions = new Float32Array(text.length * 4);
	        }
	        if (colorRanges) {
	          glyphColors = new Uint8Array(renderableGlyphCount * 3);
	        }
	        let renderableGlyphIndex = 0;
	        let prevCharIndex = -1;
	        let colorCharIndex = -1;
	        let chunk;
	        let currentColor;
	        lines.forEach((line, lineIndex) => {
	          let {count:lineGlyphCount, width:lineWidth} = line;

	          // Ignore empty lines
	          if (lineGlyphCount > 0) {
	            // Count trailing whitespaces, we want to ignore these for certain things
	            let trailingWhitespaceCount = 0;
	            for (let i = lineGlyphCount; i-- && line.glyphAt(i).glyphObj.isWhitespace;) {
	              trailingWhitespaceCount++;
	            }

	            // Apply horizontal alignment adjustments
	            let lineXOffset = 0;
	            let justifyAdjust = 0;
	            if (textAlign === 'center') {
	              lineXOffset = (maxLineWidth - lineWidth) / 2;
	            } else if (textAlign === 'right') {
	              lineXOffset = maxLineWidth - lineWidth;
	            } else if (textAlign === 'justify' && line.isSoftWrapped) {
	              // count non-trailing whitespace characters, and we'll adjust the offsets per character in the next loop
	              let whitespaceCount = 0;
	              for (let i = lineGlyphCount - trailingWhitespaceCount; i--;) {
	                if (line.glyphAt(i).glyphObj.isWhitespace) {
	                  whitespaceCount++;
	                }
	              }
	              justifyAdjust = (maxLineWidth - lineWidth) / whitespaceCount;
	            }
	            if (justifyAdjust || lineXOffset) {
	              let justifyOffset = 0;
	              for (let i = 0; i < lineGlyphCount; i++) {
	                let glyphInfo = line.glyphAt(i);
	                const glyphObj = glyphInfo.glyphObj;
	                glyphInfo.x += lineXOffset + justifyOffset;
	                // Expand non-trailing whitespaces for justify alignment
	                if (justifyAdjust !== 0 && glyphObj.isWhitespace && i < lineGlyphCount - trailingWhitespaceCount) {
	                  justifyOffset += justifyAdjust;
	                  glyphInfo.width += justifyAdjust;
	                }
	              }
	            }

	            // Perform bidi range flipping
	            const flips = bidi.getReorderSegments(
	              text, bidiLevelsResult, line.glyphAt(0).charIndex, line.glyphAt(line.count - 1).charIndex
	            );
	            for (let fi = 0; fi < flips.length; fi++) {
	              const [start, end] = flips[fi];
	              // Map start/end string indices to indices in the line
	              let left = Infinity, right = -Infinity;
	              for (let i = 0; i < lineGlyphCount; i++) {
	                if (line.glyphAt(i).charIndex >= start) { // gte to handle removed characters
	                  let startInLine = i, endInLine = i;
	                  for (; endInLine < lineGlyphCount; endInLine++) {
	                    let info = line.glyphAt(endInLine);
	                    if (info.charIndex > end) {
	                      break
	                    }
	                    if (endInLine < lineGlyphCount - trailingWhitespaceCount) { //don't include trailing ws in flip width
	                      left = Math.min(left, info.x);
	                      right = Math.max(right, info.x + info.width);
	                    }
	                  }
	                  for (let j = startInLine; j < endInLine; j++) {
	                    const glyphInfo = line.glyphAt(j);
	                    glyphInfo.x = right - (glyphInfo.x + glyphInfo.width - left);
	                  }
	                  break
	                }
	              }
	            }

	            // Assemble final data arrays
	            let glyphObj;
	            const setGlyphObj = g => glyphObj = g;
	            for (let i = 0; i < lineGlyphCount; i++) {
	              const glyphInfo = line.glyphAt(i);
	              glyphObj = glyphInfo.glyphObj;
	              const glyphId = glyphObj.index;

	              // Replace mirrored characters in rtl
	              const rtl = bidiLevelsResult.levels[glyphInfo.charIndex] & 1; //odd level means rtl
	              if (rtl) {
	                const mirrored = bidi.getMirroredCharacter(text[glyphInfo.charIndex]);
	                if (mirrored) {
	                  glyphInfo.fontData.fontObj.forEachGlyph(mirrored, 0, 0, setGlyphObj);
	                }
	              }

	              // Add caret positions
	              if (includeCaretPositions) {
	                const {charIndex, fontData} = glyphInfo;
	                const caretLeft = glyphInfo.x + anchorXOffset;
	                const caretRight = glyphInfo.x + glyphInfo.width + anchorXOffset;
	                caretPositions[charIndex * 4] = rtl ? caretRight : caretLeft; //start edge x
	                caretPositions[charIndex * 4 + 1] = rtl ? caretLeft : caretRight; //end edge x
	                caretPositions[charIndex * 4 + 2] = line.baseline + fontData.caretBottom + anchorYOffset; //common bottom y
	                caretPositions[charIndex * 4 + 3] = line.baseline + fontData.caretTop + anchorYOffset; //common top y

	                // If we skipped any chars from the previous glyph (due to ligature subs), fill in caret
	                // positions for those missing char indices; currently this uses a best-guess by dividing
	                // the ligature's width evenly. In the future we may try to use the font's LigatureCaretList
	                // table to get better interior caret positions.
	                const ligCount = charIndex - prevCharIndex;
	                if (ligCount > 1) {
	                  fillLigatureCaretPositions(caretPositions, prevCharIndex, ligCount);
	                }
	                prevCharIndex = charIndex;
	              }

	              // Track current color range
	              if (colorRanges) {
	                const {charIndex} = glyphInfo;
	                while(charIndex > colorCharIndex) {
	                  colorCharIndex++;
	                  if (colorRanges.hasOwnProperty(colorCharIndex)) {
	                    currentColor = colorRanges[colorCharIndex];
	                  }
	                }
	              }

	              // Get atlas data for renderable glyphs
	              if (!glyphObj.isWhitespace && !glyphObj.isEmpty) {
	                const idx = renderableGlyphIndex++;
	                const {fontSizeMult, src: fontSrc, index: fontIndex} = glyphInfo.fontData;

	                // Add this glyph's path data
	                const fontGlyphData = glyphData[fontSrc] || (glyphData[fontSrc] = {});
	                if (!fontGlyphData[glyphId]) {
	                  fontGlyphData[glyphId] = {
	                    path: glyphObj.path,
	                    pathBounds: [glyphObj.xMin, glyphObj.yMin, glyphObj.xMax, glyphObj.yMax]
	                  };
	                }

	                // Determine final glyph position and add to glyphPositions array
	                const glyphX = glyphInfo.x + anchorXOffset;
	                const glyphY = glyphInfo.y + line.baseline + anchorYOffset;
	                glyphPositions[idx * 2] = glyphX;
	                glyphPositions[idx * 2 + 1] = glyphY;

	                // Track total visible bounds
	                const visX0 = glyphX + glyphObj.xMin * fontSizeMult;
	                const visY0 = glyphY + glyphObj.yMin * fontSizeMult;
	                const visX1 = glyphX + glyphObj.xMax * fontSizeMult;
	                const visY1 = glyphY + glyphObj.yMax * fontSizeMult;
	                if (visX0 < visibleBounds[0]) visibleBounds[0] = visX0;
	                if (visY0 < visibleBounds[1]) visibleBounds[1] = visY0;
	                if (visX1 > visibleBounds[2]) visibleBounds[2] = visX1;
	                if (visY1 > visibleBounds[3]) visibleBounds[3] = visY1;

	                // Track bounding rects for each chunk of N glyphs
	                if (idx % chunkedBoundsSize === 0) {
	                  chunk = {start: idx, end: idx, rect: [INF, INF, -INF, -INF]};
	                  chunkedBounds.push(chunk);
	                }
	                chunk.end++;
	                const chunkRect = chunk.rect;
	                if (visX0 < chunkRect[0]) chunkRect[0] = visX0;
	                if (visY0 < chunkRect[1]) chunkRect[1] = visY0;
	                if (visX1 > chunkRect[2]) chunkRect[2] = visX1;
	                if (visY1 > chunkRect[3]) chunkRect[3] = visY1;

	                // Add to glyph ids and font indices arrays
	                glyphIds[idx] = glyphId;
	                glyphFontIndices[idx] = fontIndex;

	                // Add colors
	                if (colorRanges) {
	                  const start = idx * 3;
	                  glyphColors[start] = currentColor >> 16 & 255;
	                  glyphColors[start + 1] = currentColor >> 8 & 255;
	                  glyphColors[start + 2] = currentColor & 255;
	                }
	              }
	            }
	          }
	        });

	        // Fill in remaining caret positions in case the final character was a ligature
	        if (caretPositions) {
	          const ligCount = text.length - prevCharIndex;
	          if (ligCount > 1) {
	            fillLigatureCaretPositions(caretPositions, prevCharIndex, ligCount);
	          }
	        }
	      }

	      // Assemble final data about each font used
	      const fontData = [];
	      metricsByFont.forEach(({index, src, unitsPerEm, ascender, descender, lineHeight, capHeight, xHeight}) => {
	        fontData[index] = {src, unitsPerEm, ascender, descender, lineHeight, capHeight, xHeight};
	      });

	      // Timing stats
	      timings.typesetting = now() - typesetStart;

	      callback({
	        glyphIds, //id for each glyph, specific to that glyph's font
	        glyphFontIndices, //index into fontData for each glyph
	        glyphPositions, //x,y of each glyph's origin in layout
	        glyphData, //dict holding data about each glyph appearing in the text
	        fontData, //data about each font used in the text
	        caretPositions, //startX,endX,bottomY caret positions for each char
	        // caretHeight, //height of cursor from bottom to top - todo per glyph?
	        glyphColors, //color for each glyph, if color ranges supplied
	        chunkedBounds, //total rects per (n=chunkedBoundsSize) consecutive glyphs
	        fontSize, //calculated em height
	        topBaseline: anchorYOffset + lines[0].baseline, //y coordinate of the top line's baseline
	        blockBounds: [ //bounds for the whole block of text, including vertical padding for lineHeight
	          anchorXOffset,
	          anchorYOffset - totalHeight,
	          anchorXOffset + maxLineWidth,
	          anchorYOffset
	        ],
	        visibleBounds, //total bounds of visible text paths, may be larger or smaller than blockBounds
	        timings
	      });
	    });
	  }


	  /**
	   * For a given text string and font parameters, determine the resulting block dimensions
	   * after wrapping for the given maxWidth.
	   * @param args
	   * @param callback
	   */
	  function measure(args, callback) {
	    typeset({...args, metricsOnly: true}, (result) => {
	      const [x0, y0, x1, y1] = result.blockBounds;
	      callback({
	        width: x1 - x0,
	        height: y1 - y0
	      });
	    });
	  }

	  function parsePercent(str) {
	    let match = str.match(/^([\d.]+)%$/);
	    let pct = match ? parseFloat(match[1]) : NaN;
	    return isNaN(pct) ? 0 : pct / 100
	  }

	  function fillLigatureCaretPositions(caretPositions, ligStartIndex, ligCount) {
	    const ligStartX = caretPositions[ligStartIndex * 4];
	    const ligEndX = caretPositions[ligStartIndex * 4 + 1];
	    const ligBottom = caretPositions[ligStartIndex * 4 + 2];
	    const ligTop = caretPositions[ligStartIndex * 4 + 3];
	    const guessedAdvanceX = (ligEndX - ligStartX) / ligCount;
	    for (let i = 0; i < ligCount; i++) {
	      const startIndex = (ligStartIndex + i) * 4;
	      caretPositions[startIndex] = ligStartX + guessedAdvanceX * i;
	      caretPositions[startIndex + 1] = ligStartX + guessedAdvanceX * (i + 1);
	      caretPositions[startIndex + 2] = ligBottom;
	      caretPositions[startIndex + 3] = ligTop;
	    }
	  }

	  function now() {
	    return (self.performance || Date).now()
	  }

	  // Array-backed structure for a single line's glyphs data
	  function TextLine() {
	    this.data = [];
	  }
	  const textLineProps = ['glyphObj', 'x', 'y', 'width', 'charIndex', 'fontData'];
	  TextLine.prototype = {
	    width: 0,
	    lineHeight: 0,
	    baseline: 0,
	    cap: 0,
	    ex: 0,
	    isSoftWrapped: false,
	    get count() {
	      return Math.ceil(this.data.length / textLineProps.length)
	    },
	    glyphAt(i) {
	      let fly = TextLine.flyweight;
	      fly.data = this.data;
	      fly.index = i;
	      return fly
	    },
	    splitAt(i) {
	      let newLine = new TextLine();
	      newLine.data = this.data.splice(i * textLineProps.length);
	      return newLine
	    }
	  };
	  TextLine.flyweight = textLineProps.reduce((obj, prop, i, all) => {
	    Object.defineProperty(obj, prop, {
	      get() {
	        return this.data[this.index * textLineProps.length + i]
	      },
	      set(val) {
	        this.data[this.index * textLineProps.length + i] = val;
	      }
	    });
	    return obj
	  }, {data: null, index: 0});


	  return {
	    typeset,
	    measure,
	  }
	}

	const now$1 = () => (self.performance || Date).now();

	const mainThreadGenerator = /*#__PURE__*/ SDFGenerator();

	let warned;

	/**
	 * Generate an SDF texture image for a single glyph path, placing the result into a webgl canvas at a
	 * given location and channel. Utilizes the webgl-sdf-generator external package for GPU-accelerated SDF
	 * generation when supported.
	 */
	function generateSDF(width, height, path, viewBox, distance, exponent, canvas, x, y, channel, useWebGL = true) {
	  // Allow opt-out
	  if (!useWebGL) {
	    return generateSDF_JS_Worker(width, height, path, viewBox, distance, exponent, canvas, x, y, channel)
	  }

	  // Attempt GPU-accelerated generation first
	  return generateSDF_GL(width, height, path, viewBox, distance, exponent, canvas, x, y, channel).then(
	    null,
	    err => {
	      // WebGL failed either due to a hard error or unexpected results; fall back to JS in workers
	      if (!warned) {
	        console.warn(`WebGL SDF generation failed, falling back to JS`, err);
	        warned = true;
	      }
	      return generateSDF_JS_Worker(width, height, path, viewBox, distance, exponent, canvas, x, y, channel)
	    }
	  )
	}

	const queue = [];
	const chunkTimeBudget = 5; // ms
	let timer = 0;

	function nextChunk() {
	  const start = now$1();
	  while (queue.length && now$1() - start < chunkTimeBudget) {
	    queue.shift()();
	  }
	  timer = queue.length ? setTimeout(nextChunk, 0) : 0;
	}

	/**
	 * WebGL-based implementation executed on the main thread. Requests are executed in time-bounded
	 * macrotask chunks to allow render frames to execute in between.
	 */
	const generateSDF_GL = (...args) => {
	  return new Promise((resolve, reject) => {
	    queue.push(() => {
	      const start = now$1();
	      try {
	        mainThreadGenerator.webgl.generateIntoCanvas(...args);
	        resolve({ timing: now$1() - start });
	      } catch (err) {
	        reject(err);
	      }
	    });
	    if (!timer) {
	      timer = setTimeout(nextChunk, 0);
	    }
	  })
	};

	const threadCount = 4; // how many workers to spawn
	const idleTimeout = 2000; // workers will be terminated after being idle this many milliseconds
	const threads = {};
	let callNum = 0;

	/**
	 * Fallback JS-based implementation, fanned out to a number of worker threads for parallelism
	 */
	function generateSDF_JS_Worker(width, height, path, viewBox, distance, exponent, canvas, x, y, channel) {
	  const workerId = 'TroikaTextSDFGenerator_JS_' + ((callNum++) % threadCount);
	  let thread = threads[workerId];
	  if (!thread) {
	    thread = threads[workerId] = {
	      workerModule: defineWorkerModule({
	        name: workerId,
	        workerId,
	        dependencies: [
	          SDFGenerator,
	          now$1
	        ],
	        init(_createSDFGenerator, now) {
	          const generate = _createSDFGenerator().javascript.generate;
	          return function (...args) {
	            const start = now();
	            const textureData = generate(...args);
	            return {
	              textureData,
	              timing: now() - start
	            }
	          }
	        },
	        getTransferables(result) {
	          return [result.textureData.buffer]
	        }
	      }),
	      requests: 0,
	      idleTimer: null
	    };
	  }

	  thread.requests++;
	  clearTimeout(thread.idleTimer);
	  return thread.workerModule(width, height, path, viewBox, distance, exponent)
	    .then(({ textureData, timing }) => {
	      // copy result data into the canvas
	      const start = now$1();
	      // expand single-channel data into rgba
	      const imageData = new Uint8Array(textureData.length * 4);
	      for (let i = 0; i < textureData.length; i++) {
	        imageData[i * 4 + channel] = textureData[i];
	      }
	      mainThreadGenerator.webglUtils.renderImageData(canvas, imageData, x, y, width, height, 1 << (3 - channel));
	      timing += now$1() - start;

	      // clean up workers after a while
	      if (--thread.requests === 0) {
	        thread.idleTimer = setTimeout(() => { terminateWorker(workerId); }, idleTimeout);
	      }
	      return { timing }
	    })
	}

	function warmUpSDFCanvas(canvas) {
	  if (!canvas._warm) {
	    mainThreadGenerator.webgl.isSupported(canvas);
	    canvas._warm = true;
	  }
	}

	const resizeWebGLCanvasWithoutClearing = mainThreadGenerator.webglUtils.resizeWebGLCanvasWithoutClearing;

	const CONFIG = {
	  defaultFontURL: null,
	  unicodeFontsURL: null,
	  sdfGlyphSize: 64,
	  sdfMargin: 1 / 16,
	  sdfExponent: 9,
	  textureWidth: 2048,
	  useWorker: true,
	};
	const tempColor = /*#__PURE__*/new Color();

	function now$1$1() {
	  return (self.performance || Date).now()
	}

	/**
	 * Repository for all font SDF atlas textures and their glyph mappings. There is a separate atlas for
	 * each sdfGlyphSize. Each atlas has a single Texture that holds all glyphs for all fonts.
	 *
	 *   {
	 *     [sdfGlyphSize]: {
	 *       glyphCount: number,
	 *       sdfGlyphSize: number,
	 *       sdfTexture: Texture,
	 *       sdfCanvas: HTMLCanvasElement,
	 *       contextLost: boolean,
	 *       glyphsByFont: Map<fontURL, Map<glyphID, {path, atlasIndex, sdfViewBox}>>
	 *     }
	 *   }
	 */
	const atlases = Object.create(null);

	/**
	 * @typedef {object} TroikaTextRenderInfo - Format of the result from `getTextRenderInfo`.
	 * @property {TypesetParams} parameters - The normalized input arguments to the render call.
	 * @property {Texture} sdfTexture - The SDF atlas texture.
	 * @property {number} sdfGlyphSize - The size of each glyph's SDF; see `configureTextBuilder`.
	 * @property {number} sdfExponent - The exponent used in encoding the SDF's values; see `configureTextBuilder`.
	 * @property {Float32Array} glyphBounds - List of [minX, minY, maxX, maxY] quad bounds for each glyph.
	 * @property {Float32Array} glyphAtlasIndices - List holding each glyph's index in the SDF atlas.
	 * @property {Uint8Array} [glyphColors] - List holding each glyph's [r, g, b] color, if `colorRanges` was supplied.
	 * @property {Float32Array} [caretPositions] - A list of caret positions for all characters in the string; each is
	 *           four elements: the starting X, the ending X, the bottom Y, and the top Y for the caret.
	 * @property {number} [caretHeight] - An appropriate height for all selection carets.
	 * @property {number} ascender - The font's ascender metric.
	 * @property {number} descender - The font's descender metric.
	 * @property {number} capHeight - The font's cap height metric, based on the height of Latin capital letters.
	 * @property {number} xHeight - The font's x height metric, based on the height of Latin lowercase letters.
	 * @property {number} lineHeight - The final computed lineHeight measurement.
	 * @property {number} topBaseline - The y position of the top line's baseline.
	 * @property {Array<number>} blockBounds - The total [minX, minY, maxX, maxY] rect of the whole text block;
	 *           this can include extra vertical space beyond the visible glyphs due to lineHeight, and is
	 *           equivalent to the dimensions of a block-level text element in CSS.
	 * @property {Array<number>} visibleBounds - The total [minX, minY, maxX, maxY] rect of the whole text block;
	 *           unlike `blockBounds` this is tightly wrapped to the visible glyph paths.
	 * @property {Array<object>} chunkedBounds - List of bounding rects for each consecutive set of N glyphs,
	 *           in the format `{start:N, end:N, rect:[minX, minY, maxX, maxY]}`.
	 * @property {object} timings - Timing info for various parts of the rendering logic including SDF
	 *           generation, typesetting, etc.
	 * @frozen
	 */

	/**
	 * @callback getTextRenderInfo~callback
	 * @param {TroikaTextRenderInfo} textRenderInfo
	 */

	/**
	 * Main entry point for requesting the data needed to render a text string with given font parameters.
	 * This is an asynchronous call, performing most of the logic in a web worker thread.
	 * @param {TypesetParams} args
	 * @param {getTextRenderInfo~callback} callback
	 */
	function getTextRenderInfo(args, callback) {
	  args = assign$1({}, args);
	  const totalStart = now$1$1();

	  // Convert relative URL to absolute so it can be resolved in the worker, and add fallbacks.
	  // In the future we'll allow args.font to be a list with unicode ranges too.
	  const { defaultFontURL } = CONFIG;
	  const fonts = [];
	  if (defaultFontURL) {
	    fonts.push({label: 'default', src: toAbsoluteURL(defaultFontURL)});
	  }
	  if (args.font) {
	    fonts.push({label: 'user', src: toAbsoluteURL(args.font)});
	  }
	  args.font = fonts;

	  // Normalize text to a string
	  args.text = '' + args.text;

	  args.sdfGlyphSize = args.sdfGlyphSize || CONFIG.sdfGlyphSize;
	  args.unicodeFontsURL = args.unicodeFontsURL || CONFIG.unicodeFontsURL;

	  // Normalize colors
	  if (args.colorRanges != null) {
	    let colors = {};
	    for (let key in args.colorRanges) {
	      if (args.colorRanges.hasOwnProperty(key)) {
	        let val = args.colorRanges[key];
	        if (typeof val !== 'number') {
	          val = tempColor.set(val).getHex();
	        }
	        colors[key] = val;
	      }
	    }
	    args.colorRanges = colors;
	  }

	  Object.freeze(args);

	  // Init the atlas if needed
	  const {textureWidth, sdfExponent} = CONFIG;
	  const {sdfGlyphSize} = args;
	  const glyphsPerRow = (textureWidth / sdfGlyphSize * 4);
	  let atlas = atlases[sdfGlyphSize];
	  if (!atlas) {
	    const canvas = document.createElement('canvas');
	    canvas.width = textureWidth;
	    canvas.height = sdfGlyphSize * 256 / glyphsPerRow; // start tall enough to fit 256 glyphs
	    atlas = atlases[sdfGlyphSize] = {
	      glyphCount: 0,
	      sdfGlyphSize,
	      sdfCanvas: canvas,
	      sdfTexture: new Texture(
	        canvas,
	        undefined,
	        undefined,
	        undefined,
	        LinearFilter,
	        LinearFilter
	      ),
	      contextLost: false,
	      glyphsByFont: new Map()
	    };
	    atlas.sdfTexture.generateMipmaps = false;
	    initContextLossHandling(atlas);
	  }

	  const {sdfTexture, sdfCanvas} = atlas;

	  // Issue request to the typesetting engine in the worker
	  const typeset = CONFIG.useWorker ? typesetInWorker : typesetOnMainThread;
	  typeset(args).then(result => {
	    const {glyphIds, glyphFontIndices, fontData, glyphPositions, fontSize, timings} = result;
	    const neededSDFs = [];
	    const glyphBounds = new Float32Array(glyphIds.length * 4);
	    let boundsIdx = 0;
	    let positionsIdx = 0;
	    const quadsStart = now$1$1();

	    const fontGlyphMaps = fontData.map(font => {
	      let map = atlas.glyphsByFont.get(font.src);
	      if (!map) {
	        atlas.glyphsByFont.set(font.src, map = new Map());
	      }
	      return map
	    });

	    glyphIds.forEach((glyphId, i) => {
	      const fontIndex = glyphFontIndices[i];
	      const {src: fontSrc, unitsPerEm} = fontData[fontIndex];
	      let glyphInfo = fontGlyphMaps[fontIndex].get(glyphId);

	      // If this is a glyphId not seen before, add it to the atlas
	      if (!glyphInfo) {
	        const {path, pathBounds} = result.glyphData[fontSrc][glyphId];

	        // Margin around path edges in SDF, based on a percentage of the glyph's max dimension.
	        // Note we add an extra 0.5 px over the configured value because the outer 0.5 doesn't contain
	        // useful interpolated values and will be ignored anyway.
	        const fontUnitsMargin = Math.max(pathBounds[2] - pathBounds[0], pathBounds[3] - pathBounds[1])
	          / sdfGlyphSize * (CONFIG.sdfMargin * sdfGlyphSize + 0.5);

	        const atlasIndex = atlas.glyphCount++;
	        const sdfViewBox = [
	          pathBounds[0] - fontUnitsMargin,
	          pathBounds[1] - fontUnitsMargin,
	          pathBounds[2] + fontUnitsMargin,
	          pathBounds[3] + fontUnitsMargin,
	        ];
	        fontGlyphMaps[fontIndex].set(glyphId, (glyphInfo = { path, atlasIndex, sdfViewBox }));

	        // Collect those that need SDF generation
	        neededSDFs.push(glyphInfo);
	      }

	      // Calculate bounds for renderable quads
	      // TODO can we get this back off the main thread?
	      const {sdfViewBox} = glyphInfo;
	      const posX = glyphPositions[positionsIdx++];
	      const posY = glyphPositions[positionsIdx++];
	      const fontSizeMult = fontSize / unitsPerEm;
	      glyphBounds[boundsIdx++] = posX + sdfViewBox[0] * fontSizeMult;
	      glyphBounds[boundsIdx++] = posY + sdfViewBox[1] * fontSizeMult;
	      glyphBounds[boundsIdx++] = posX + sdfViewBox[2] * fontSizeMult;
	      glyphBounds[boundsIdx++] = posY + sdfViewBox[3] * fontSizeMult;

	      // Convert glyphId to SDF index for the shader
	      glyphIds[i] = glyphInfo.atlasIndex;
	    });
	    timings.quads = (timings.quads || 0) + (now$1$1() - quadsStart);

	    const sdfStart = now$1$1();
	    timings.sdf = {};

	    // Grow the texture height by power of 2 if needed
	    const currentHeight = sdfCanvas.height;
	    const neededRows = Math.ceil(atlas.glyphCount / glyphsPerRow);
	    const neededHeight = Math.pow(2, Math.ceil(Math.log2(neededRows * sdfGlyphSize)));
	    if (neededHeight > currentHeight) {
	      // Since resizing the canvas clears its render buffer, it needs special handling to copy the old contents over
	      console.info(`Increasing SDF texture size ${currentHeight}->${neededHeight}`);
	      resizeWebGLCanvasWithoutClearing(sdfCanvas, textureWidth, neededHeight);
	      // As of Three r136 textures cannot be resized once they're allocated on the GPU, we must dispose to reallocate it
	      sdfTexture.dispose();
	    }

	    Promise.all(neededSDFs.map(glyphInfo =>
	      generateGlyphSDF(glyphInfo, atlas, args.gpuAccelerateSDF).then(({timing}) => {
	        timings.sdf[glyphInfo.atlasIndex] = timing;
	      })
	    )).then(() => {
	      if (neededSDFs.length && !atlas.contextLost) {
	        safariPre15Workaround(atlas);
	        sdfTexture.needsUpdate = true;
	      }
	      timings.sdfTotal = now$1$1() - sdfStart;
	      timings.total = now$1$1() - totalStart;
	      // console.log(`SDF - ${timings.sdfTotal}, Total - ${timings.total - timings.fontLoad}`)

	      // Invoke callback with the text layout arrays and updated texture
	      callback(Object.freeze({
	        parameters: args,
	        sdfTexture,
	        sdfGlyphSize,
	        sdfExponent,
	        glyphBounds,
	        glyphAtlasIndices: glyphIds,
	        glyphColors: result.glyphColors,
	        caretPositions: result.caretPositions,
	        chunkedBounds: result.chunkedBounds,
	        ascender: result.ascender,
	        descender: result.descender,
	        lineHeight: result.lineHeight,
	        capHeight: result.capHeight,
	        xHeight: result.xHeight,
	        topBaseline: result.topBaseline,
	        blockBounds: result.blockBounds,
	        visibleBounds: result.visibleBounds,
	        timings: result.timings,
	      }));
	    });
	  });

	  // While the typesetting request is being handled, go ahead and make sure the atlas canvas context is
	  // "warmed up"; the first request will be the longest due to shader program compilation so this gets
	  // a head start on that process before SDFs actually start getting processed.
	  Promise.resolve().then(() => {
	    if (!atlas.contextLost) {
	      warmUpSDFCanvas(sdfCanvas);
	    }
	  });
	}

	function generateGlyphSDF({path, atlasIndex, sdfViewBox}, {sdfGlyphSize, sdfCanvas, contextLost}, useGPU) {
	  if (contextLost) {
	    // If the context is lost there's nothing we can do, just quit silently and let it
	    // get regenerated when the context is restored
	    return Promise.resolve({timing: -1})
	  }
	  const {textureWidth, sdfExponent} = CONFIG;
	  const maxDist = Math.max(sdfViewBox[2] - sdfViewBox[0], sdfViewBox[3] - sdfViewBox[1]);
	  const squareIndex = Math.floor(atlasIndex / 4);
	  const x = squareIndex % (textureWidth / sdfGlyphSize) * sdfGlyphSize;
	  const y = Math.floor(squareIndex / (textureWidth / sdfGlyphSize)) * sdfGlyphSize;
	  const channel = atlasIndex % 4;
	  return generateSDF(sdfGlyphSize, sdfGlyphSize, path, sdfViewBox, maxDist, sdfExponent, sdfCanvas, x, y, channel, useGPU)
	}

	function initContextLossHandling(atlas) {
	  const canvas = atlas.sdfCanvas;

	  /*
	  // Begin context loss simulation
	  if (!window.WebGLDebugUtils) {
	    let script = document.getElementById('WebGLDebugUtilsScript')
	    if (!script) {
	      script = document.createElement('script')
	      script.id = 'WebGLDebugUtils'
	      document.head.appendChild(script)
	      script.src = 'https://cdn.jsdelivr.net/gh/KhronosGroup/WebGLDeveloperTools@b42e702/src/debug/webgl-debug.js'
	    }
	    script.addEventListener('load', () => {
	      initContextLossHandling(atlas)
	    })
	    return
	  }
	  window.WebGLDebugUtils.makeLostContextSimulatingCanvas(canvas)
	  canvas.loseContextInNCalls(500)
	  canvas.addEventListener('webglcontextrestored', (event) => {
	    canvas.loseContextInNCalls(5000)
	  })
	  // End context loss simulation
	  */

	  canvas.addEventListener('webglcontextlost', (event) => {
	    console.log('Context Lost', event);
	    event.preventDefault();
	    atlas.contextLost = true;
	  });
	  canvas.addEventListener('webglcontextrestored', (event) => {
	    console.log('Context Restored', event);
	    atlas.contextLost = false;
	    // Regenerate all glyphs into the restored canvas:
	    const promises = [];
	    atlas.glyphsByFont.forEach(glyphMap => {
	      glyphMap.forEach(glyph => {
	        promises.push(generateGlyphSDF(glyph, atlas, true));
	      });
	    });
	    Promise.all(promises).then(() => {
	      safariPre15Workaround(atlas);
	      atlas.sdfTexture.needsUpdate = true;
	    });
	  });
	}


	// Local assign impl so we don't have to import troika-core
	function assign$1(toObj, fromObj) {
	  for (let key in fromObj) {
	    if (fromObj.hasOwnProperty(key)) {
	      toObj[key] = fromObj[key];
	    }
	  }
	  return toObj
	}

	// Utility for making URLs absolute
	let linkEl;
	function toAbsoluteURL(path) {
	  if (!linkEl) {
	    linkEl = typeof document === 'undefined' ? {} : document.createElement('a');
	  }
	  linkEl.href = path;
	  return linkEl.href
	}

	/**
	 * Safari < v15 seems unable to use the SDF webgl canvas as a texture. This applies a workaround
	 * where it reads the pixels out of that canvas and uploads them as a data texture instead, at
	 * a slight performance cost.
	 */
	function safariPre15Workaround(atlas) {
	  // Use createImageBitmap support as a proxy for Safari<15, all other mainstream browsers
	  // have supported it for a long while so any false positives should be minimal.
	  if (typeof createImageBitmap !== 'function') {
	    console.info('Safari<15: applying SDF canvas workaround');
	    const {sdfCanvas, sdfTexture} = atlas;
	    const {width, height} = sdfCanvas;
	    const gl = atlas.sdfCanvas.getContext('webgl');
	    let pixels = sdfTexture.image.data;
	    if (!pixels || pixels.length !== width * height * 4) {
	      pixels = new Uint8Array(width * height * 4);
	      sdfTexture.image = {width, height, data: pixels};
	      sdfTexture.flipY = false;
	      sdfTexture.isDataTexture = true;
	    }
	    gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);
	  }
	}

	const typesetterWorkerModule = /*#__PURE__*/defineWorkerModule({
	  name: 'Typesetter',
	  dependencies: [
	    createTypesetter,
	    fontResolverWorkerModule,
	    bidiFactory,
	  ],
	  init(createTypesetter, fontResolver, bidiFactory) {
	    return createTypesetter(fontResolver, bidiFactory())
	  }
	});

	const typesetInWorker = /*#__PURE__*/defineWorkerModule({
	  name: 'Typesetter',
	  dependencies: [
	    typesetterWorkerModule,
	  ],
	  init(typesetter) {
	    return function(args) {
	      return new Promise(resolve => {
	        typesetter.typeset(args, resolve);
	      })
	    }
	  },
	  getTransferables(result) {
	    // Mark array buffers as transferable to avoid cloning during postMessage
	    const transferables = [];
	    for (let p in result) {
	      if (result[p] && result[p].buffer) {
	        transferables.push(result[p].buffer);
	      }
	    }
	    return transferables
	  }
	});

	const typesetOnMainThread = typesetInWorker.onMainThread;

	const templateGeometries = {};

	function getTemplateGeometry(detail) {
	  let geom = templateGeometries[detail];
	  if (!geom) {
	    geom = templateGeometries[detail] = new PlaneGeometry(1, 1, detail, detail).translate(0.5, 0.5, 0);
	  }
	  return geom
	}

	const glyphBoundsAttrName = 'aTroikaGlyphBounds';
	const glyphIndexAttrName = 'aTroikaGlyphIndex';
	const glyphColorAttrName = 'aTroikaGlyphColor';

	/**
	@class GlyphsGeometry

	A specialized Geometry for rendering a set of text glyphs. Uses InstancedBufferGeometry to
	render the glyphs using GPU instancing of a single quad, rather than constructing a whole
	geometry with vertices, for much smaller attribute arraybuffers according to this math:

	  Where N = number of glyphs...

	  Instanced:
	  - position: 4 * 3
	  - index: 2 * 3
	  - normal: 4 * 3
	  - uv: 4 * 2
	  - glyph x/y bounds: N * 4
	  - glyph indices: N * 1
	  = 5N + 38

	  Non-instanced:
	  - position: N * 4 * 3
	  - index: N * 2 * 3
	  - normal: N * 4 * 3
	  - uv: N * 4 * 2
	  - glyph indices: N * 1
	  = 39N

	A downside of this is the rare-but-possible lack of the instanced arrays extension,
	which we could potentially work around with a fallback non-instanced implementation.

	*/
	class GlyphsGeometry extends InstancedBufferGeometry {
	  constructor() {
	    super();

	    this.detail = 1;
	    this.curveRadius = 0;

	    // Define groups for rendering text outline as a separate pass; these will only
	    // be used when the `material` getter returns an array, i.e. outlineWidth > 0.
	    this.groups = [
	      {start: 0, count: Infinity, materialIndex: 0},
	      {start: 0, count: Infinity, materialIndex: 1}
	    ];

	    // Preallocate empty bounding objects
	    this.boundingSphere = new Sphere();
	    this.boundingBox = new Box3();
	  }

	  computeBoundingSphere () {
	    // No-op; we'll sync the boundingSphere proactively when needed.
	  }

	  computeBoundingBox() {
	    // No-op; we'll sync the boundingBox proactively when needed.
	  }

	  set detail(detail) {
	    if (detail !== this._detail) {
	      this._detail = detail;
	      if (typeof detail !== 'number' || detail < 1) {
	        detail = 1;
	      }
	      let tpl = getTemplateGeometry(detail)
	      ;['position', 'normal', 'uv'].forEach(attr => {
	        this.attributes[attr] = tpl.attributes[attr].clone();
	      });
	      this.setIndex(tpl.getIndex().clone());
	    }
	  }
	  get detail() {
	    return this._detail
	  }

	  set curveRadius(r) {
	    if (r !== this._curveRadius) {
	      this._curveRadius = r;
	      this._updateBounds();
	    }
	  }
	  get curveRadius() {
	    return this._curveRadius
	  }

	  /**
	   * Update the geometry for a new set of glyphs.
	   * @param {Float32Array} glyphBounds - An array holding the planar bounds for all glyphs
	   *        to be rendered, 4 entries for each glyph: x1,x2,y1,y1
	   * @param {Float32Array} glyphAtlasIndices - An array holding the index of each glyph within
	   *        the SDF atlas texture.
	   * @param {Array} blockBounds - An array holding the [minX, minY, maxX, maxY] across all glyphs
	   * @param {Array} [chunkedBounds] - An array of objects describing bounds for each chunk of N
	   *        consecutive glyphs: `{start:N, end:N, rect:[minX, minY, maxX, maxY]}`. This can be
	   *        used with `applyClipRect` to choose an optimized `instanceCount`.
	   * @param {Uint8Array} [glyphColors] - An array holding r,g,b values for each glyph.
	   */
	  updateGlyphs(glyphBounds, glyphAtlasIndices, blockBounds, chunkedBounds, glyphColors) {
	    // Update the instance attributes
	    this.updateAttributeData(glyphBoundsAttrName, glyphBounds, 4);
	    this.updateAttributeData(glyphIndexAttrName, glyphAtlasIndices, 1);
	    this.updateAttributeData(glyphColorAttrName, glyphColors, 3);
	    this._blockBounds = blockBounds;
	    this._chunkedBounds = chunkedBounds;
	    this.instanceCount = glyphAtlasIndices.length;
	    this._updateBounds();
	  }

	  _updateBounds() {
	    const bounds = this._blockBounds;
	    if (bounds) {
	      const { curveRadius, boundingBox: bbox } = this;
	      if (curveRadius) {
	        const { PI, floor, min, max, sin, cos } = Math;
	        const halfPi = PI / 2;
	        const twoPi = PI * 2;
	        const absR = Math.abs(curveRadius);
	        const leftAngle = bounds[0] / absR;
	        const rightAngle = bounds[2] / absR;
	        const minX = floor((leftAngle + halfPi) / twoPi) !== floor((rightAngle + halfPi) / twoPi)
	          ? -absR : min(sin(leftAngle) * absR, sin(rightAngle) * absR);
	        const maxX = floor((leftAngle - halfPi) / twoPi) !== floor((rightAngle - halfPi) / twoPi)
	          ? absR : max(sin(leftAngle) * absR, sin(rightAngle) * absR);
	        const maxZ = floor((leftAngle + PI) / twoPi) !== floor((rightAngle + PI) / twoPi)
	          ? absR * 2 : max(absR - cos(leftAngle) * absR, absR - cos(rightAngle) * absR);
	        bbox.min.set(minX, bounds[1], curveRadius < 0 ? -maxZ : 0);
	        bbox.max.set(maxX, bounds[3], curveRadius < 0 ? 0 : maxZ);
	      } else {
	        bbox.min.set(bounds[0], bounds[1], 0);
	        bbox.max.set(bounds[2], bounds[3], 0);
	      }
	      bbox.getBoundingSphere(this.boundingSphere);
	    }
	  }

	  /**
	   * Given a clipping rect, and the chunkedBounds from the last updateGlyphs call, choose the lowest
	   * `instanceCount` that will show all glyphs within the clipped view. This is an optimization
	   * for long blocks of text that are clipped, to skip vertex shader evaluation for glyphs that would
	   * be clipped anyway.
	   *
	   * Note that since `drawElementsInstanced[ANGLE]` only accepts an instance count and not a starting
	   * offset, this optimization becomes less effective as the clipRect moves closer to the end of the
	   * text block. We could fix that by switching from instancing to a full geometry with a drawRange,
	   * but at the expense of much larger attribute buffers (see classdoc above.)
	   *
	   * @param {Vector4} clipRect
	   */
	  applyClipRect(clipRect) {
	    let count = this.getAttribute(glyphIndexAttrName).count;
	    let chunks = this._chunkedBounds;
	    if (chunks) {
	      for (let i = chunks.length; i--;) {
	        count = chunks[i].end;
	        let rect = chunks[i].rect;
	        // note: both rects are l-b-r-t
	        if (rect[1] < clipRect.w && rect[3] > clipRect.y && rect[0] < clipRect.z && rect[2] > clipRect.x) {
	          break
	        }
	      }
	    }
	    this.instanceCount = count;
	  }

	  /**
	   * Utility for updating instance attributes with automatic resizing
	   */
	  updateAttributeData(attrName, newArray, itemSize) {
	    const attr = this.getAttribute(attrName);
	    if (newArray) {
	      // If length isn't changing, just update the attribute's array data
	      if (attr && attr.array.length === newArray.length) {
	        attr.array.set(newArray);
	        attr.needsUpdate = true;
	      } else {
	        this.setAttribute(attrName, new InstancedBufferAttribute(newArray, itemSize));
	        // If the new attribute has a different size, we also have to (as of r117) manually clear the
	        // internal cached max instance count. See https://github.com/mrdoob/three.js/issues/19706
	        // It's unclear if this is a threejs bug or a truly unsupported scenario; discussion in
	        // that ticket is ambiguous as to whether replacing a BufferAttribute with one of a
	        // different size is supported, but https://github.com/mrdoob/three.js/pull/17418 strongly
	        // implies it should be supported. It's possible we need to
	        delete this._maxInstanceCount; //for r117+, could be fragile
	        this.dispose(); //for r118+, more robust feeling, but more heavy-handed than I'd like
	      }
	    } else if (attr) {
	      this.deleteAttribute(attrName);
	    }
	  }
	}

	// language=GLSL
	const VERTEX_DEFS = `
uniform vec2 uTroikaSDFTextureSize;
uniform float uTroikaSDFGlyphSize;
uniform vec4 uTroikaTotalBounds;
uniform vec4 uTroikaClipRect;
uniform mat3 uTroikaOrient;
uniform bool uTroikaUseGlyphColors;
uniform float uTroikaEdgeOffset;
uniform float uTroikaBlurRadius;
uniform vec2 uTroikaPositionOffset;
uniform float uTroikaCurveRadius;
attribute vec4 aTroikaGlyphBounds;
attribute float aTroikaGlyphIndex;
attribute vec3 aTroikaGlyphColor;
varying vec2 vTroikaGlyphUV;
varying vec4 vTroikaTextureUVBounds;
varying float vTroikaTextureChannel;
varying vec3 vTroikaGlyphColor;
varying vec2 vTroikaGlyphDimensions;
`;

	// language=GLSL prefix="void main() {" suffix="}"
	const VERTEX_TRANSFORM = `
vec4 bounds = aTroikaGlyphBounds;
bounds.xz += uTroikaPositionOffset.x;
bounds.yw -= uTroikaPositionOffset.y;

vec4 outlineBounds = vec4(
  bounds.xy - uTroikaEdgeOffset - uTroikaBlurRadius,
  bounds.zw + uTroikaEdgeOffset + uTroikaBlurRadius
);
vec4 clippedBounds = vec4(
  clamp(outlineBounds.xy, uTroikaClipRect.xy, uTroikaClipRect.zw),
  clamp(outlineBounds.zw, uTroikaClipRect.xy, uTroikaClipRect.zw)
);

vec2 clippedXY = (mix(clippedBounds.xy, clippedBounds.zw, position.xy) - bounds.xy) / (bounds.zw - bounds.xy);

position.xy = mix(bounds.xy, bounds.zw, clippedXY);

uv = (position.xy - uTroikaTotalBounds.xy) / (uTroikaTotalBounds.zw - uTroikaTotalBounds.xy);

float rad = uTroikaCurveRadius;
if (rad != 0.0) {
  float angle = position.x / rad;
  position.xz = vec2(sin(angle) * rad, rad - cos(angle) * rad);
  normal.xz = vec2(sin(angle), cos(angle));
}
  
position = uTroikaOrient * position;
normal = uTroikaOrient * normal;

vTroikaGlyphUV = clippedXY.xy;
vTroikaGlyphDimensions = vec2(bounds[2] - bounds[0], bounds[3] - bounds[1]);

${''/* NOTE: it seems important to calculate the glyph's bounding texture UVs here in the
  vertex shader, rather than in the fragment shader, as the latter gives strange artifacts
  on some glyphs (those in the leftmost texture column) on some systems. The exact reason
  isn't understood but doing this here, then mix()-ing in the fragment shader, seems to work. */}
float txCols = uTroikaSDFTextureSize.x / uTroikaSDFGlyphSize;
vec2 txUvPerSquare = uTroikaSDFGlyphSize / uTroikaSDFTextureSize;
vec2 txStartUV = txUvPerSquare * vec2(
  mod(floor(aTroikaGlyphIndex / 4.0), txCols),
  floor(floor(aTroikaGlyphIndex / 4.0) / txCols)
);
vTroikaTextureUVBounds = vec4(txStartUV, vec2(txStartUV) + txUvPerSquare);
vTroikaTextureChannel = mod(aTroikaGlyphIndex, 4.0);
`;

	// language=GLSL
	const FRAGMENT_DEFS = `
uniform sampler2D uTroikaSDFTexture;
uniform vec2 uTroikaSDFTextureSize;
uniform float uTroikaSDFGlyphSize;
uniform float uTroikaSDFExponent;
uniform float uTroikaEdgeOffset;
uniform float uTroikaFillOpacity;
uniform float uTroikaBlurRadius;
uniform vec3 uTroikaStrokeColor;
uniform float uTroikaStrokeWidth;
uniform float uTroikaStrokeOpacity;
uniform bool uTroikaSDFDebug;
varying vec2 vTroikaGlyphUV;
varying vec4 vTroikaTextureUVBounds;
varying float vTroikaTextureChannel;
varying vec2 vTroikaGlyphDimensions;

float troikaSdfValueToSignedDistance(float alpha) {
  // Inverse of exponential encoding in webgl-sdf-generator
  ${''/* TODO - there's some slight inaccuracy here when dealing with interpolated alpha values; those
    are linearly interpolated where the encoding is exponential. Look into improving this by rounding
    to nearest 2 whole texels, decoding those exponential values, and linearly interpolating the result.
  */}
  float maxDimension = max(vTroikaGlyphDimensions.x, vTroikaGlyphDimensions.y);
  float absDist = (1.0 - pow(2.0 * (alpha > 0.5 ? 1.0 - alpha : alpha), 1.0 / uTroikaSDFExponent)) * maxDimension;
  float signedDist = absDist * (alpha > 0.5 ? -1.0 : 1.0);
  return signedDist;
}

float troikaGlyphUvToSdfValue(vec2 glyphUV) {
  vec2 textureUV = mix(vTroikaTextureUVBounds.xy, vTroikaTextureUVBounds.zw, glyphUV);
  vec4 rgba = texture2D(uTroikaSDFTexture, textureUV);
  float ch = floor(vTroikaTextureChannel + 0.5); //NOTE: can't use round() in WebGL1
  return ch == 0.0 ? rgba.r : ch == 1.0 ? rgba.g : ch == 2.0 ? rgba.b : rgba.a;
}

float troikaGlyphUvToDistance(vec2 uv) {
  return troikaSdfValueToSignedDistance(troikaGlyphUvToSdfValue(uv));
}

float troikaGetAADist() {
  ${''/*
    When the standard derivatives extension is available, we choose an antialiasing alpha threshold based
    on the potential change in the SDF's alpha from this fragment to its neighbor. This strategy maximizes 
    readability and edge crispness at all sizes and screen resolutions.
  */}
  #if defined(GL_OES_standard_derivatives) || __VERSION__ >= 300
  return length(fwidth(vTroikaGlyphUV * vTroikaGlyphDimensions)) * 0.5;
  #else
  return vTroikaGlyphDimensions.x / 64.0;
  #endif
}

float troikaGetFragDistValue() {
  vec2 clampedGlyphUV = clamp(vTroikaGlyphUV, 0.5 / uTroikaSDFGlyphSize, 1.0 - 0.5 / uTroikaSDFGlyphSize);
  float distance = troikaGlyphUvToDistance(clampedGlyphUV);
 
  // Extrapolate distance when outside bounds:
  distance += clampedGlyphUV == vTroikaGlyphUV ? 0.0 : 
    length((vTroikaGlyphUV - clampedGlyphUV) * vTroikaGlyphDimensions);

  ${''/* 
  // TODO more refined extrapolated distance by adjusting for angle of gradient at edge...
  // This has potential but currently gives very jagged extensions, maybe due to precision issues?
  float uvStep = 1.0 / uTroikaSDFGlyphSize;
  vec2 neighbor1UV = clampedGlyphUV + (
    vTroikaGlyphUV.x != clampedGlyphUV.x ? vec2(0.0, uvStep * sign(0.5 - vTroikaGlyphUV.y)) :
    vTroikaGlyphUV.y != clampedGlyphUV.y ? vec2(uvStep * sign(0.5 - vTroikaGlyphUV.x), 0.0) :
    vec2(0.0)
  );
  vec2 neighbor2UV = clampedGlyphUV + (
    vTroikaGlyphUV.x != clampedGlyphUV.x ? vec2(0.0, uvStep * -sign(0.5 - vTroikaGlyphUV.y)) :
    vTroikaGlyphUV.y != clampedGlyphUV.y ? vec2(uvStep * -sign(0.5 - vTroikaGlyphUV.x), 0.0) :
    vec2(0.0)
  );
  float neighbor1Distance = troikaGlyphUvToDistance(neighbor1UV);
  float neighbor2Distance = troikaGlyphUvToDistance(neighbor2UV);
  float distToUnclamped = length((vTroikaGlyphUV - clampedGlyphUV) * vTroikaGlyphDimensions);
  float distToNeighbor = length((clampedGlyphUV - neighbor1UV) * vTroikaGlyphDimensions);
  float gradientAngle1 = min(asin(abs(neighbor1Distance - distance) / distToNeighbor), PI / 2.0);
  float gradientAngle2 = min(asin(abs(neighbor2Distance - distance) / distToNeighbor), PI / 2.0);
  distance += (cos(gradientAngle1) + cos(gradientAngle2)) / 2.0 * distToUnclamped;
  */}

  return distance;
}

float troikaGetEdgeAlpha(float distance, float distanceOffset, float aaDist) {
  #if defined(IS_DEPTH_MATERIAL) || defined(IS_DISTANCE_MATERIAL)
  float alpha = step(-distanceOffset, -distance);
  #else

  float alpha = smoothstep(
    distanceOffset + aaDist,
    distanceOffset - aaDist,
    distance
  );
  #endif

  return alpha;
}
`;

	// language=GLSL prefix="void main() {" suffix="}"
	const FRAGMENT_TRANSFORM = `
float aaDist = troikaGetAADist();
float fragDistance = troikaGetFragDistValue();
float edgeAlpha = uTroikaSDFDebug ?
  troikaGlyphUvToSdfValue(vTroikaGlyphUV) :
  troikaGetEdgeAlpha(fragDistance, uTroikaEdgeOffset, max(aaDist, uTroikaBlurRadius));

#if !defined(IS_DEPTH_MATERIAL) && !defined(IS_DISTANCE_MATERIAL)
vec4 fillRGBA = gl_FragColor;
fillRGBA.a *= uTroikaFillOpacity;
vec4 strokeRGBA = uTroikaStrokeWidth == 0.0 ? fillRGBA : vec4(uTroikaStrokeColor, uTroikaStrokeOpacity);
if (fillRGBA.a == 0.0) fillRGBA.rgb = strokeRGBA.rgb;
gl_FragColor = mix(fillRGBA, strokeRGBA, smoothstep(
  -uTroikaStrokeWidth - aaDist,
  -uTroikaStrokeWidth + aaDist,
  fragDistance
));
gl_FragColor.a *= edgeAlpha;
#endif

if (edgeAlpha == 0.0) {
  discard;
}
`;


	/**
	 * Create a material for rendering text, derived from a baseMaterial
	 */
	function createTextDerivedMaterial(baseMaterial) {
	  const textMaterial = createDerivedMaterial(baseMaterial, {
	    chained: true,
	    extensions: {
	      derivatives: true
	    },
	    uniforms: {
	      uTroikaSDFTexture: {value: null},
	      uTroikaSDFTextureSize: {value: new Vector2()},
	      uTroikaSDFGlyphSize: {value: 0},
	      uTroikaSDFExponent: {value: 0},
	      uTroikaTotalBounds: {value: new Vector4(0,0,0,0)},
	      uTroikaClipRect: {value: new Vector4(0,0,0,0)},
	      uTroikaEdgeOffset: {value: 0},
	      uTroikaFillOpacity: {value: 1},
	      uTroikaPositionOffset: {value: new Vector2()},
	      uTroikaCurveRadius: {value: 0},
	      uTroikaBlurRadius: {value: 0},
	      uTroikaStrokeWidth: {value: 0},
	      uTroikaStrokeColor: {value: new Color()},
	      uTroikaStrokeOpacity: {value: 1},
	      uTroikaOrient: {value: new Matrix3()},
	      uTroikaUseGlyphColors: {value: true},
	      uTroikaSDFDebug: {value: false}
	    },
	    vertexDefs: VERTEX_DEFS,
	    vertexTransform: VERTEX_TRANSFORM,
	    fragmentDefs: FRAGMENT_DEFS,
	    fragmentColorTransform: FRAGMENT_TRANSFORM,
	    customRewriter({vertexShader, fragmentShader}) {
	      let uDiffuseRE = /\buniform\s+vec3\s+diffuse\b/;
	      if (uDiffuseRE.test(fragmentShader)) {
	        // Replace all instances of `diffuse` with our varying
	        fragmentShader = fragmentShader
	          .replace(uDiffuseRE, 'varying vec3 vTroikaGlyphColor')
	          .replace(/\bdiffuse\b/g, 'vTroikaGlyphColor');
	        // Make sure the vertex shader declares the uniform so we can grab it as a fallback
	        if (!uDiffuseRE.test(vertexShader)) {
	          vertexShader = vertexShader.replace(
	            voidMainRegExp,
	            'uniform vec3 diffuse;\n$&\nvTroikaGlyphColor = uTroikaUseGlyphColors ? aTroikaGlyphColor / 255.0 : diffuse;\n'
	          );
	        }
	      }
	      return { vertexShader, fragmentShader }
	    }
	  });

	  // Force transparency - TODO is this reasonable?
	  textMaterial.transparent = true;

	  // Force single draw call when double-sided
	  textMaterial.forceSinglePass = true;

	  Object.defineProperties(textMaterial, {
	    isTroikaTextMaterial: {value: true},

	    // WebGLShadowMap reverses the side of the shadow material by default, which fails
	    // for planes, so here we force the `shadowSide` to always match the main side.
	    shadowSide: {
	      get() {
	        return this.side
	      },
	      set() {
	        //no-op
	      }
	    }
	  });

	  return textMaterial
	}

	const defaultMaterial = /*#__PURE__*/ new MeshBasicMaterial({
	  color: 0xffffff,
	  side: DoubleSide,
	  transparent: true
	});
	const defaultStrokeColor = 0x808080;

	const tempMat4 = /*#__PURE__*/ new Matrix4();
	const tempVec3a = /*#__PURE__*/ new Vector3();
	const tempVec3b = /*#__PURE__*/ new Vector3();
	const tempArray = [];
	const origin = /*#__PURE__*/ new Vector3();
	const defaultOrient = '+x+y';

	function first(o) {
	  return Array.isArray(o) ? o[0] : o
	}

	let getFlatRaycastMesh = () => {
	  const mesh = new Mesh(
	    new PlaneGeometry(1, 1),
	    defaultMaterial
	  );
	  getFlatRaycastMesh = () => mesh;
	  return mesh
	};
	let getCurvedRaycastMesh = () => {
	  const mesh = new Mesh(
	    new PlaneGeometry(1, 1, 32, 1),
	    defaultMaterial
	  );
	  getCurvedRaycastMesh = () => mesh;
	  return mesh
	};

	const syncStartEvent = { type: 'syncstart' };
	const syncCompleteEvent = { type: 'synccomplete' };

	const SYNCABLE_PROPS = [
	  'font',
	  'fontSize',
	  'fontStyle',
	  'fontWeight',
	  'lang',
	  'letterSpacing',
	  'lineHeight',
	  'maxWidth',
	  'overflowWrap',
	  'text',
	  'direction',
	  'textAlign',
	  'textIndent',
	  'whiteSpace',
	  'anchorX',
	  'anchorY',
	  'colorRanges',
	  'sdfGlyphSize'
	];

	const COPYABLE_PROPS = SYNCABLE_PROPS.concat(
	  'material',
	  'color',
	  'depthOffset',
	  'clipRect',
	  'curveRadius',
	  'orientation',
	  'glyphGeometryDetail'
	);

	/**
	 * @class Text
	 *
	 * A ThreeJS Mesh that renders a string of text on a plane in 3D space using signed distance
	 * fields (SDF).
	 */
	class Text extends Mesh {
	  constructor() {
	    const geometry = new GlyphsGeometry();
	    super(geometry, null);

	    // === Text layout properties: === //

	    /**
	     * @member {string} text
	     * The string of text to be rendered.
	     */
	    this.text = '';

	    /**
	     * @member {number|string} anchorX
	     * Defines the horizontal position in the text block that should line up with the local origin.
	     * Can be specified as a numeric x position in local units, a string percentage of the total
	     * text block width e.g. `'25%'`, or one of the following keyword strings: 'left', 'center',
	     * or 'right'.
	     */
	    this.anchorX = 0;

	    /**
	     * @member {number|string} anchorY
	     * Defines the vertical position in the text block that should line up with the local origin.
	     * Can be specified as a numeric y position in local units (note: down is negative y), a string
	     * percentage of the total text block height e.g. `'25%'`, or one of the following keyword strings:
	     * 'top', 'top-baseline', 'top-cap', 'top-ex', 'middle', 'bottom-baseline', or 'bottom'.
	     */
	    this.anchorY = 0;

	    /**
	     * @member {number} curveRadius
	     * Defines a cylindrical radius along which the text's plane will be curved. Positive numbers put
	     * the cylinder's centerline (oriented vertically) that distance in front of the text, for a concave
	     * curvature, while negative numbers put it behind the text for a convex curvature. The centerline
	     * will be aligned with the text's local origin; you can use `anchorX` to offset it.
	     *
	     * Since each glyph is by default rendered with a simple quad, each glyph remains a flat plane
	     * internally. You can use `glyphGeometryDetail` to add more vertices for curvature inside glyphs.
	     */
	    this.curveRadius = 0;

	    /**
	     * @member {string} direction
	     * Sets the base direction for the text. The default value of "auto" will choose a direction based
	     * on the text's content according to the bidi spec. A value of "ltr" or "rtl" will force the direction.
	     */
	    this.direction = 'auto';

	    /**
	     * @member {string|null} font
	     * URL of a custom font to be used. Font files can be in .ttf, .otf, or .woff (not .woff2) formats.
	     * Defaults to Noto Sans.
	     */
	    this.font = null; //will use default from TextBuilder

	    this.unicodeFontsURL = null; //defaults to CDN

	    /**
	     * @member {number} fontSize
	     * The size at which to render the font in local units; corresponds to the em-box height
	     * of the chosen `font`.
	     */
	    this.fontSize = 0.1;

	    /**
	     * @member {number|'normal'|'bold'}
	     * The weight of the font. Currently only used for fallback Noto fonts.
	     */
	    this.fontWeight = 'normal';

	    /**
	     * @member {'normal'|'italic'}
	     * The style of the font. Currently only used for fallback Noto fonts.
	     */
	    this.fontStyle = 'normal';

	    /**
	     * @member {string|null} lang
	     * The language code of this text; can be used for explicitly selecting certain CJK fonts.
	     */
	    this.lang = null;

	      /**
	     * @member {number} letterSpacing
	     * Sets a uniform adjustment to spacing between letters after kerning is applied. Positive
	     * numbers increase spacing and negative numbers decrease it.
	     */
	    this.letterSpacing = 0;

	    /**
	     * @member {number|string} lineHeight
	     * Sets the height of each line of text, as a multiple of the `fontSize`. Defaults to 'normal'
	     * which chooses a reasonable height based on the chosen font's ascender/descender metrics.
	     */
	    this.lineHeight = 'normal';

	    /**
	     * @member {number} maxWidth
	     * The maximum width of the text block, above which text may start wrapping according to the
	     * `whiteSpace` and `overflowWrap` properties.
	     */
	    this.maxWidth = Infinity;

	    /**
	     * @member {string} overflowWrap
	     * Defines how text wraps if the `whiteSpace` property is `normal`. Can be either `'normal'`
	     * to break at whitespace characters, or `'break-word'` to allow breaking within words.
	     * Defaults to `'normal'`.
	     */
	    this.overflowWrap = 'normal';

	    /**
	     * @member {string} textAlign
	     * The horizontal alignment of each line of text within the overall text bounding box.
	     */
	    this.textAlign = 'left';

	    /**
	     * @member {number} textIndent
	     * Indentation for the first character of a line; see CSS `text-indent`.
	     */
	    this.textIndent = 0;

	    /**
	     * @member {string} whiteSpace
	     * Defines whether text should wrap when a line reaches the `maxWidth`. Can
	     * be either `'normal'` (the default), to allow wrapping according to the `overflowWrap` property,
	     * or `'nowrap'` to prevent wrapping. Note that `'normal'` here honors newline characters to
	     * manually break lines, making it behave more like `'pre-wrap'` does in CSS.
	     */
	    this.whiteSpace = 'normal';


	    // === Presentation properties: === //

	    /**
	     * @member {THREE.Material} material
	     * Defines a _base_ material to be used when rendering the text. This material will be
	     * automatically replaced with a material derived from it, that adds shader code to
	     * decrease the alpha for each fragment (pixel) outside the text glyphs, with antialiasing.
	     * By default it will derive from a simple white MeshBasicMaterial, but you can use any
	     * of the other mesh materials to gain other features like lighting, texture maps, etc.
	     *
	     * Also see the `color` shortcut property.
	     */
	    this.material = null;

	    /**
	     * @member {string|number|THREE.Color} color
	     * This is a shortcut for setting the `color` of the text's material. You can use this
	     * if you don't want to specify a whole custom `material`. Also, if you do use a custom
	     * `material`, this color will only be used for this particuar Text instance, even if
	     * that same material instance is shared across multiple Text objects.
	     */
	    this.color = null;

	    /**
	     * @member {object|null} colorRanges
	     * WARNING: This API is experimental and may change.
	     * This allows more fine-grained control of colors for individual or ranges of characters,
	     * taking precedence over the material's `color`. Its format is an Object whose keys each
	     * define a starting character index for a range, and whose values are the color for each
	     * range. The color value can be a numeric hex color value, a `THREE.Color` object, or
	     * any of the strings accepted by `THREE.Color`.
	     */
	    this.colorRanges = null;

	    /**
	     * @member {number|string} outlineWidth
	     * WARNING: This API is experimental and may change.
	     * The width of an outline/halo to be drawn around each text glyph using the `outlineColor` and `outlineOpacity`.
	     * Can be specified as either an absolute number in local units, or as a percentage string e.g.
	     * `"12%"` which is treated as a percentage of the `fontSize`. Defaults to `0`, which means
	     * no outline will be drawn unless an `outlineOffsetX/Y` or `outlineBlur` is set.
	     */
	    this.outlineWidth = 0;

	    /**
	     * @member {string|number|THREE.Color} outlineColor
	     * WARNING: This API is experimental and may change.
	     * The color of the text outline, if `outlineWidth`/`outlineBlur`/`outlineOffsetX/Y` are set.
	     * Defaults to black.
	     */
	    this.outlineColor = 0x000000;

	    /**
	     * @member {number} outlineOpacity
	     * WARNING: This API is experimental and may change.
	     * The opacity of the outline, if `outlineWidth`/`outlineBlur`/`outlineOffsetX/Y` are set.
	     * Defaults to `1`.
	     */
	    this.outlineOpacity = 1;

	    /**
	     * @member {number|string} outlineBlur
	     * WARNING: This API is experimental and may change.
	     * A blur radius applied to the outer edge of the text's outline. If the `outlineWidth` is
	     * zero, the blur will be applied at the glyph edge, like CSS's `text-shadow` blur radius.
	     * Can be specified as either an absolute number in local units, or as a percentage string e.g.
	     * `"12%"` which is treated as a percentage of the `fontSize`. Defaults to `0`.
	     */
	    this.outlineBlur = 0;

	    /**
	     * @member {number|string} outlineOffsetX
	     * WARNING: This API is experimental and may change.
	     * A horizontal offset for the text outline.
	     * Can be specified as either an absolute number in local units, or as a percentage string e.g. `"12%"`
	     * which is treated as a percentage of the `fontSize`. Defaults to `0`.
	     */
	    this.outlineOffsetX = 0;

	    /**
	     * @member {number|string} outlineOffsetY
	     * WARNING: This API is experimental and may change.
	     * A vertical offset for the text outline.
	     * Can be specified as either an absolute number in local units, or as a percentage string e.g. `"12%"`
	     * which is treated as a percentage of the `fontSize`. Defaults to `0`.
	     */
	    this.outlineOffsetY = 0;

	    /**
	     * @member {number|string} strokeWidth
	     * WARNING: This API is experimental and may change.
	     * The width of an inner stroke drawn inside each text glyph using the `strokeColor` and `strokeOpacity`.
	     * Can be specified as either an absolute number in local units, or as a percentage string e.g. `"12%"`
	     * which is treated as a percentage of the `fontSize`. Defaults to `0`.
	     */
	    this.strokeWidth = 0;

	    /**
	     * @member {string|number|THREE.Color} strokeColor
	     * WARNING: This API is experimental and may change.
	     * The color of the text stroke, if `strokeWidth` is greater than zero. Defaults to gray.
	     */
	    this.strokeColor = defaultStrokeColor;

	    /**
	     * @member {number} strokeOpacity
	     * WARNING: This API is experimental and may change.
	     * The opacity of the stroke, if `strokeWidth` is greater than zero. Defaults to `1`.
	     */
	    this.strokeOpacity = 1;

	    /**
	     * @member {number} fillOpacity
	     * WARNING: This API is experimental and may change.
	     * The opacity of the glyph's fill from 0 to 1. This behaves like the material's `opacity` but allows
	     * giving the fill a different opacity than the `strokeOpacity`. A fillOpacity of `0` makes the
	     * interior of the glyph invisible, leaving just the `strokeWidth`. Defaults to `1`.
	     */
	    this.fillOpacity = 1;

	    /**
	     * @member {number} depthOffset
	     * This is a shortcut for setting the material's `polygonOffset` and related properties,
	     * which can be useful in preventing z-fighting when this text is laid on top of another
	     * plane in the scene. Positive numbers are further from the camera, negatives closer.
	     */
	    this.depthOffset = 0;

	    /**
	     * @member {Array<number>} clipRect
	     * If specified, defines a `[minX, minY, maxX, maxY]` of a rectangle outside of which all
	     * pixels will be discarded. This can be used for example to clip overflowing text when
	     * `whiteSpace='nowrap'`.
	     */
	    this.clipRect = null;

	    /**
	     * @member {string} orientation
	     * Defines the axis plane on which the text should be laid out when the mesh has no extra
	     * rotation transform. It is specified as a string with two axes: the horizontal axis with
	     * positive pointing right, and the vertical axis with positive pointing up. By default this
	     * is '+x+y', meaning the text sits on the xy plane with the text's top toward positive y
	     * and facing positive z. A value of '+x-z' would place it on the xz plane with the text's
	     * top toward negative z and facing positive y.
	     */
	    this.orientation = defaultOrient;

	    /**
	     * @member {number} glyphGeometryDetail
	     * Controls number of vertical/horizontal segments that make up each glyph's rectangular
	     * plane. Defaults to 1. This can be increased to provide more geometrical detail for custom
	     * vertex shader effects, for example.
	     */
	    this.glyphGeometryDetail = 1;

	    /**
	     * @member {number|null} sdfGlyphSize
	     * The size of each glyph's SDF (signed distance field) used for rendering. This must be a
	     * power-of-two number. Defaults to 64 which is generally a good balance of size and quality
	     * for most fonts. Larger sizes can improve the quality of glyph rendering by increasing
	     * the sharpness of corners and preventing loss of very thin lines, at the expense of
	     * increased memory footprint and longer SDF generation time.
	     */
	    this.sdfGlyphSize = null;

	    /**
	     * @member {boolean} gpuAccelerateSDF
	     * When `true`, the SDF generation process will be GPU-accelerated with WebGL when possible,
	     * making it much faster especially for complex glyphs, and falling back to a JavaScript version
	     * executed in web workers when support isn't available. It should automatically detect support,
	     * but it's still somewhat experimental, so you can set it to `false` to force it to use the JS
	     * version if you encounter issues with it.
	     */
	    this.gpuAccelerateSDF = true;

	    this.debugSDF = false;
	  }

	  /**
	   * Updates the text rendering according to the current text-related configuration properties.
	   * This is an async process, so you can pass in a callback function to be executed when it
	   * finishes.
	   * @param {function} [callback]
	   */
	  sync(callback) {
	    if (this._needsSync) {
	      this._needsSync = false;

	      // If there's another sync still in progress, queue
	      if (this._isSyncing) {
	        (this._queuedSyncs || (this._queuedSyncs = [])).push(callback);
	      } else {
	        this._isSyncing = true;
	        this.dispatchEvent(syncStartEvent);

	        getTextRenderInfo({
	          text: this.text,
	          font: this.font,
	          lang: this.lang,
	          fontSize: this.fontSize || 0.1,
	          fontWeight: this.fontWeight || 'normal',
	          fontStyle: this.fontStyle || 'normal',
	          letterSpacing: this.letterSpacing || 0,
	          lineHeight: this.lineHeight || 'normal',
	          maxWidth: this.maxWidth,
	          direction: this.direction || 'auto',
	          textAlign: this.textAlign,
	          textIndent: this.textIndent,
	          whiteSpace: this.whiteSpace,
	          overflowWrap: this.overflowWrap,
	          anchorX: this.anchorX,
	          anchorY: this.anchorY,
	          colorRanges: this.colorRanges,
	          includeCaretPositions: true, //TODO parameterize
	          sdfGlyphSize: this.sdfGlyphSize,
	          gpuAccelerateSDF: this.gpuAccelerateSDF,
	          unicodeFontsURL: this.unicodeFontsURL,
	        }, textRenderInfo => {
	          this._isSyncing = false;

	          // Save result for later use in onBeforeRender
	          this._textRenderInfo = textRenderInfo;

	          // Update the geometry attributes
	          this.geometry.updateGlyphs(
	            textRenderInfo.glyphBounds,
	            textRenderInfo.glyphAtlasIndices,
	            textRenderInfo.blockBounds,
	            textRenderInfo.chunkedBounds,
	            textRenderInfo.glyphColors
	          );

	          // If we had extra sync requests queued up, kick it off
	          const queued = this._queuedSyncs;
	          if (queued) {
	            this._queuedSyncs = null;
	            this._needsSync = true;
	            this.sync(() => {
	              queued.forEach(fn => fn && fn());
	            });
	          }

	          this.dispatchEvent(syncCompleteEvent);
	          if (callback) {
	            callback();
	          }
	        });
	      }
	    }
	  }

	  /**
	   * Initiate a sync if needed - note it won't complete until next frame at the
	   * earliest so if possible it's a good idea to call sync() manually as soon as
	   * all the properties have been set.
	   * @override
	   */
	  onBeforeRender(renderer, scene, camera, geometry, material, group) {
	    this.sync();

	    // This may not always be a text material, e.g. if there's a scene.overrideMaterial present
	    if (material.isTroikaTextMaterial) {
	      this._prepareForRender(material);
	    }
	  }

	  /**
	   * Shortcut to dispose the geometry specific to this instance.
	   * Note: we don't also dispose the derived material here because if anything else is
	   * sharing the same base material it will result in a pause next frame as the program
	   * is recompiled. Instead users can dispose the base material manually, like normal,
	   * and we'll also dispose the derived material at that time.
	   */
	  dispose() {
	    this.geometry.dispose();
	  }

	  /**
	   * @property {TroikaTextRenderInfo|null} textRenderInfo
	   * @readonly
	   * The current processed rendering data for this TextMesh, returned by the TextBuilder after
	   * a `sync()` call. This will be `null` initially, and may be stale for a short period until
	   * the asynchrous `sync()` process completes.
	   */
	  get textRenderInfo() {
	    return this._textRenderInfo || null
	  }

	  /**
	   * Create the text derived material from the base material. Can be overridden to use a custom
	   * derived material.
	   */
	  createDerivedMaterial(baseMaterial) {
	    return createTextDerivedMaterial(baseMaterial)
	  }

	  // Handler for automatically wrapping the base material with our upgrades. We do the wrapping
	  // lazily on _read_ rather than write to avoid unnecessary wrapping on transient values.
	  get material() {
	    let derivedMaterial = this._derivedMaterial;
	    const baseMaterial = this._baseMaterial || this._defaultMaterial || (this._defaultMaterial = defaultMaterial.clone());
	    if (!derivedMaterial || !derivedMaterial.isDerivedFrom(baseMaterial)) {
	      derivedMaterial = this._derivedMaterial = this.createDerivedMaterial(baseMaterial);
	      // dispose the derived material when its base material is disposed:
	      baseMaterial.addEventListener('dispose', function onDispose() {
	        baseMaterial.removeEventListener('dispose', onDispose);
	        derivedMaterial.dispose();
	      });
	    }
	    // If text outline is configured, render it as a preliminary draw using Three's multi-material
	    // feature (see GlyphsGeometry which sets up `groups` for this purpose) Doing it with multi
	    // materials ensures the layers are always rendered consecutively in a consistent order.
	    // Each layer will trigger onBeforeRender with the appropriate material.
	    if (this.hasOutline()) {
	      let outlineMaterial = derivedMaterial._outlineMtl;
	      if (!outlineMaterial) {
	        outlineMaterial = derivedMaterial._outlineMtl = Object.create(derivedMaterial, {
	          id: {value: derivedMaterial.id + 0.1}
	        });
	        outlineMaterial.isTextOutlineMaterial = true;
	        outlineMaterial.depthWrite = false;
	        outlineMaterial.map = null; //???
	        derivedMaterial.addEventListener('dispose', function onDispose() {
	          derivedMaterial.removeEventListener('dispose', onDispose);
	          outlineMaterial.dispose();
	        });
	      }
	      return [
	        outlineMaterial,
	        derivedMaterial
	      ]
	    } else {
	      return derivedMaterial
	    }
	  }
	  set material(baseMaterial) {
	    if (baseMaterial && baseMaterial.isTroikaTextMaterial) { //prevent double-derivation
	      this._derivedMaterial = baseMaterial;
	      this._baseMaterial = baseMaterial.baseMaterial;
	    } else {
	      this._baseMaterial = baseMaterial;
	    }
	  }

	  hasOutline() {
	    return !!(this.outlineWidth || this.outlineBlur || this.outlineOffsetX || this.outlineOffsetY)
	  }

	  get glyphGeometryDetail() {
	    return this.geometry.detail
	  }
	  set glyphGeometryDetail(detail) {
	    this.geometry.detail = detail;
	  }

	  get curveRadius() {
	    return this.geometry.curveRadius
	  }
	  set curveRadius(r) {
	    this.geometry.curveRadius = r;
	  }

	  // Create and update material for shadows upon request:
	  get customDepthMaterial() {
	    return first(this.material).getDepthMaterial()
	  }
	  set customDepthMaterial(m) {
	    // future: let the user override with their own?
	  }
	  get customDistanceMaterial() {
	    return first(this.material).getDistanceMaterial()
	  }
	  set customDistanceMaterial(m) {
	    // future: let the user override with their own?
	  }

	  _prepareForRender(material) {
	    const isOutline = material.isTextOutlineMaterial;
	    const uniforms = material.uniforms;
	    const textInfo = this.textRenderInfo;
	    if (textInfo) {
	      const {sdfTexture, blockBounds} = textInfo;
	      uniforms.uTroikaSDFTexture.value = sdfTexture;
	      uniforms.uTroikaSDFTextureSize.value.set(sdfTexture.image.width, sdfTexture.image.height);
	      uniforms.uTroikaSDFGlyphSize.value = textInfo.sdfGlyphSize;
	      uniforms.uTroikaSDFExponent.value = textInfo.sdfExponent;
	      uniforms.uTroikaTotalBounds.value.fromArray(blockBounds);
	      uniforms.uTroikaUseGlyphColors.value = !isOutline && !!textInfo.glyphColors;

	      let distanceOffset = 0;
	      let blurRadius = 0;
	      let strokeWidth = 0;
	      let fillOpacity;
	      let strokeOpacity;
	      let strokeColor;
	      let offsetX = 0;
	      let offsetY = 0;

	      if (isOutline) {
	        let {outlineWidth, outlineOffsetX, outlineOffsetY, outlineBlur, outlineOpacity} = this;
	        distanceOffset = this._parsePercent(outlineWidth) || 0;
	        blurRadius = Math.max(0, this._parsePercent(outlineBlur) || 0);
	        fillOpacity = outlineOpacity;
	        offsetX = this._parsePercent(outlineOffsetX) || 0;
	        offsetY = this._parsePercent(outlineOffsetY) || 0;
	      } else {
	        strokeWidth = Math.max(0, this._parsePercent(this.strokeWidth) || 0);
	        if (strokeWidth) {
	          strokeColor = this.strokeColor;
	          uniforms.uTroikaStrokeColor.value.set(strokeColor == null ? defaultStrokeColor : strokeColor);
	          strokeOpacity = this.strokeOpacity;
	          if (strokeOpacity == null) strokeOpacity = 1;
	        }
	        fillOpacity = this.fillOpacity;
	      }

	      uniforms.uTroikaEdgeOffset.value = distanceOffset;
	      uniforms.uTroikaPositionOffset.value.set(offsetX, offsetY);
	      uniforms.uTroikaBlurRadius.value = blurRadius;
	      uniforms.uTroikaStrokeWidth.value = strokeWidth;
	      uniforms.uTroikaStrokeOpacity.value = strokeOpacity;
	      uniforms.uTroikaFillOpacity.value = fillOpacity == null ? 1 : fillOpacity;
	      uniforms.uTroikaCurveRadius.value = this.curveRadius || 0;

	      let clipRect = this.clipRect;
	      if (clipRect && Array.isArray(clipRect) && clipRect.length === 4) {
	        uniforms.uTroikaClipRect.value.fromArray(clipRect);
	      } else {
	        // no clipping - choose a finite rect that shouldn't ever be reached by overflowing glyphs or outlines
	        const pad = (this.fontSize || 0.1) * 100;
	        uniforms.uTroikaClipRect.value.set(
	          blockBounds[0] - pad,
	          blockBounds[1] - pad,
	          blockBounds[2] + pad,
	          blockBounds[3] + pad
	        );
	      }
	      this.geometry.applyClipRect(uniforms.uTroikaClipRect.value);
	    }
	    uniforms.uTroikaSDFDebug.value = !!this.debugSDF;
	    material.polygonOffset = !!this.depthOffset;
	    material.polygonOffsetFactor = material.polygonOffsetUnits = this.depthOffset || 0;

	    // Shortcut for setting material color via `color` prop on the mesh; this is
	    // applied only to the derived material to avoid mutating a shared base material.
	    const color = isOutline ? (this.outlineColor || 0) : this.color;

	    if (color == null) {
	      delete material.color; //inherit from base
	    } else {
	      const colorObj = material.hasOwnProperty('color') ? material.color : (material.color = new Color());
	      if (color !== colorObj._input || typeof color === 'object') {
	        colorObj.set(colorObj._input = color);
	      }
	    }

	    // base orientation
	    let orient = this.orientation || defaultOrient;
	    if (orient !== material._orientation) {
	      let rotMat = uniforms.uTroikaOrient.value;
	      orient = orient.replace(/[^-+xyz]/g, '');
	      let match = orient !== defaultOrient && orient.match(/^([-+])([xyz])([-+])([xyz])$/);
	      if (match) {
	        let [, hSign, hAxis, vSign, vAxis] = match;
	        tempVec3a.set(0, 0, 0)[hAxis] = hSign === '-' ? 1 : -1;
	        tempVec3b.set(0, 0, 0)[vAxis] = vSign === '-' ? -1 : 1;
	        tempMat4.lookAt(origin, tempVec3a.cross(tempVec3b), tempVec3b);
	        rotMat.setFromMatrix4(tempMat4);
	      } else {
	        rotMat.identity();
	      }
	      material._orientation = orient;
	    }
	  }

	  _parsePercent(value) {
	    if (typeof value === 'string') {
	      let match = value.match(/^(-?[\d.]+)%$/);
	      let pct = match ? parseFloat(match[1]) : NaN;
	      value = (isNaN(pct) ? 0 : pct / 100) * this.fontSize;
	    }
	    return value
	  }

	  /**
	   * Translate a point in local space to an x/y in the text plane.
	   */
	  localPositionToTextCoords(position, target = new Vector2()) {
	    target.copy(position); //simple non-curved case is 1:1
	    const r = this.curveRadius;
	    if (r) { //flatten the curve
	      target.x = Math.atan2(position.x, Math.abs(r) - Math.abs(position.z)) * Math.abs(r);
	    }
	    return target
	  }

	  /**
	   * Translate a point in world space to an x/y in the text plane.
	   */
	  worldPositionToTextCoords(position, target = new Vector2()) {
	    tempVec3a.copy(position);
	    return this.localPositionToTextCoords(this.worldToLocal(tempVec3a), target)
	  }

	  /**
	   * @override Custom raycasting to test against the whole text block's max rectangular bounds
	   * TODO is there any reason to make this more granular, like within individual line or glyph rects?
	   */
	  raycast(raycaster, intersects) {
	    const {textRenderInfo, curveRadius} = this;
	    if (textRenderInfo) {
	      const bounds = textRenderInfo.blockBounds;
	      const raycastMesh = curveRadius ? getCurvedRaycastMesh() : getFlatRaycastMesh();
	      const geom = raycastMesh.geometry;
	      const {position, uv} = geom.attributes;
	      for (let i = 0; i < uv.count; i++) {
	        let x = bounds[0] + (uv.getX(i) * (bounds[2] - bounds[0]));
	        const y = bounds[1] + (uv.getY(i) * (bounds[3] - bounds[1]));
	        let z = 0;
	        if (curveRadius) {
	          z = curveRadius - Math.cos(x / curveRadius) * curveRadius;
	          x = Math.sin(x / curveRadius) * curveRadius;
	        }
	        position.setXYZ(i, x, y, z);
	      }
	      geom.boundingSphere = this.geometry.boundingSphere;
	      geom.boundingBox = this.geometry.boundingBox;
	      raycastMesh.matrixWorld = this.matrixWorld;
	      raycastMesh.material.side = this.material.side;
	      tempArray.length = 0;
	      raycastMesh.raycast(raycaster, tempArray);
	      for (let i = 0; i < tempArray.length; i++) {
	        tempArray[i].object = this;
	        intersects.push(tempArray[i]);
	      }
	    }
	  }

	  copy(source) {
	    // Prevent copying the geometry reference so we don't end up sharing attributes between instances
	    const geom = this.geometry;
	    super.copy(source);
	    this.geometry = geom;

	    COPYABLE_PROPS.forEach(prop => {
	      this[prop] = source[prop];
	    });
	    return this
	  }

	  clone() {
	    return new this.constructor().copy(this)
	  }
	}


	// Create setters for properties that affect text layout:
	SYNCABLE_PROPS.forEach(prop => {
	  const privateKey = '_private_' + prop;
	  Object.defineProperty(Text.prototype, prop, {
	    get() {
	      return this[privateKey]
	    },
	    set(value) {
	      if (value !== this[privateKey]) {
	        this[privateKey] = value;
	        this._needsSync = true;
	      }
	    }
	  });
	});

	const tempBox3 = new Box3();
	const tempColor$1 = new Color();

	function createTextNode(text, params = {}) {
	    const {
	            family = "",
	            fontSize = 1,
	            anchorX = 'center',
	            anchorY = 'middle',
	            textAlign = 'left',
	            lineHeight = 1,
	            lineSpacing = 0.4,
	            letterSpacing = 0,
	            textTransform = 'none',
	            splitLines = false,
	            lineDelim = '|',
	            splitText = 'yes',
	            delim = '',
	            color = { hex: 'ffcc11' }
	        } = params;


	         switch(textTransform) {
	            case 'uppercase':
	                text = text.toUpperCase();
	            break;
	            case 'lowercase':
	                text = text.toLowerCase();
	            break;
	        }



	        function createText(txt) {
	            const theText = new Text();
	            theText.font = family;        
	            theText.fontSize = fontSize / 2;
	            theText.anchorX = anchorX;
	            theText.anchorY = anchorY;
	            theText.textAlign = textAlign;
	            theText.lineHeight = lineHeight;
	            theText.letterSpacing = letterSpacing;
	            theText.outlineWidth = 0;
	            theText.outlineOpacity = 0;
	            theText.strokeWidth = 0;
	            theText.color = new Color(`#${color.hex}`);

	            theText.text = txt;

	            return theText
	        }


	        return createText(text)
	}






	class TextNode {
	    constructor(content) {
	        this.content = content;
	    }

	    createMesh(program) {
	        const container = new Group$1();
	        

	        const params = this.parentNode.params || {};

	        const {
	            lineSpacing = 0.4,
	            splitLines = false,
	            lineDelim = '|',
	        } = params;



	        let text = this.content || 'default text';
	       
	        
	        //theText.position.z = -2
	        
	        if (splitLines) {
	            text = text.split(lineDelim);
	        }
	        

	        if (!Array.isArray(text)) {
	            // create a group of Toika textnodes
	            text = [text];
	        } 

	        //console.log("TEXT SPLITTING AT LINES", text, splitLines)

	        const nodes = text.map((line, idx) => {
	            
	            const txtnode = createTextNode(line, params);
	            
	            container.add(txtnode);
	            
	            // Update the rendering:
	            //console.log("TEXT NODE", txtnode)

	            txtnode.position.y = -idx * lineSpacing;

	            txtnode.sync();

	            return txtnode
	        });


	        this.tick = (context) => {
	            //console.log("text ticking")
	            
	            nodes.forEach(node => {
	                node.sync();
	            });
	            
	        };
	        return container;
	    }

	    createNode(program) {
	        const mesh = this.createMesh(program);
	        return mesh;
	    }

	    sync() {

	    }

	    node(program, parent) {
	        //console.log("return a mesh with a text node", this, program, parent)
	        if (!this.mesh) {
	            this.mesh = this.createNode(program);
	        }

	        parent.add(this.mesh);

	        return this.mesh;
	    }

	    removeNodes(program, parent) {
	        // dispose everything
	        //console.log("removing nodes", this.mesh, this.mesh.parent, parent)
			if (this.mesh && this.mesh.parent) {
				this.mesh.parent.remove(this.mesh);
			}
			this.mesh = null;
			this.geometry = null;
	    }

	    updateNode(program, parent) {
			this.removeNodes(program, parent);
			return this.node(program, parent)
		}
	}

	/**
	 * Fires when the camera has been transformed by the controls.
	 *
	 * @event OrbitControls#change
	 * @type {Object}
	 */
	const _changeEvent$1 = { type: 'change' };

	/**
	 * Fires when an interaction was initiated.
	 *
	 * @event OrbitControls#start
	 * @type {Object}
	 */
	const _startEvent = { type: 'start' };

	/**
	 * Fires when an interaction has finished.
	 *
	 * @event OrbitControls#end
	 * @type {Object}
	 */
	const _endEvent = { type: 'end' };

	const _ray$4 = new Ray();
	const _plane = new Plane();
	const _TILT_LIMIT = Math.cos( 70 * MathUtils.DEG2RAD );

	const _v = new Vector3();
	const _twoPI = 2 * Math.PI;

	const _STATE = {
		NONE: - 1,
		ROTATE: 0,
		DOLLY: 1,
		PAN: 2,
		TOUCH_ROTATE: 3,
		TOUCH_PAN: 4,
		TOUCH_DOLLY_PAN: 5,
		TOUCH_DOLLY_ROTATE: 6
	};
	const _EPS = 0.000001;


	/**
	 * Orbit controls allow the camera to orbit around a target.
	 *
	 * OrbitControls performs orbiting, dollying (zooming), and panning. Unlike {@link TrackballControls},
	 * it maintains the "up" direction `object.up` (+Y by default).
	 *
	 * - Orbit: Left mouse / touch: one-finger move.
	 * - Zoom: Middle mouse, or mousewheel / touch: two-finger spread or squish.
	 * - Pan: Right mouse, or left mouse + ctrl/meta/shiftKey, or arrow keys / touch: two-finger move.
	 *
	 * ```js
	 * const controls = new OrbitControls( camera, renderer.domElement );
	 *
	 * // controls.update() must be called after any manual changes to the camera's transform
	 * camera.position.set( 0, 20, 100 );
	 * controls.update();
	 *
	 * function animate() {
	 *
	 * 	// required if controls.enableDamping or controls.autoRotate are set to true
	 * 	controls.update();
	 *
	 * 	renderer.render( scene, camera );
	 *
	 * }
	 * ```
	 *
	 * @augments Controls
	 * @three_import import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
	 */
	class OrbitControls extends Controls {

		/**
		 * Constructs a new controls instance.
		 *
		 * @param {Object3D} object - The object that is managed by the controls.
		 * @param {?HTMLDOMElement} domElement - The HTML element used for event listeners.
		 */
		constructor( object, domElement = null ) {

			super( object, domElement );

			this.state = _STATE.NONE;

			/**
			 * The focus point of the controls, the `object` orbits around this.
			 * It can be updated manually at any point to change the focus of the controls.
			 *
			 * @type {Vector3}
			 */
			this.target = new Vector3();

			/**
			 * The focus point of the `minTargetRadius` and `maxTargetRadius` limits.
			 * It can be updated manually at any point to change the center of interest
			 * for the `target`.
			 *
			 * @type {Vector3}
			 */
			this.cursor = new Vector3();

			/**
			 * How far you can dolly in (perspective camera only).
			 *
			 * @type {number}
			 * @default 0
			 */
			this.minDistance = 0;

			/**
			 * How far you can dolly out (perspective camera only).
			 *
			 * @type {number}
			 * @default Infinity
			 */
			this.maxDistance = Infinity;

			/**
			 * How far you can zoom in (orthographic camera only).
			 *
			 * @type {number}
			 * @default 0
			 */
			this.minZoom = 0;

			/**
			 * How far you can zoom out (orthographic camera only).
			 *
			 * @type {number}
			 * @default Infinity
			 */
			this.maxZoom = Infinity;

			/**
			 * How close you can get the target to the 3D `cursor`.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.minTargetRadius = 0;

			/**
			 * How far you can move the target from the 3D `cursor`.
			 *
			 * @type {number}
			 * @default Infinity
			 */
			this.maxTargetRadius = Infinity;

			/**
			 * How far you can orbit vertically, lower limit. Range is `[0, Math.PI]` radians.
			 *
			 * @type {number}
			 * @default 0
			 */
			this.minPolarAngle = 0;

			/**
			 * How far you can orbit vertically, upper limit. Range is `[0, Math.PI]` radians.
			 *
			 * @type {number}
			 * @default Math.PI
			 */
			this.maxPolarAngle = Math.PI;

			/**
			 * How far you can orbit horizontally, lower limit. If set, the interval `[ min, max ]`
			 * must be a sub-interval of `[ - 2 PI, 2 PI ]`, with `( max - min < 2 PI )`.
			 *
			 * @type {number}
			 * @default -Infinity
			 */
			this.minAzimuthAngle = - Infinity;

			/**
			 * How far you can orbit horizontally, upper limit. If set, the interval `[ min, max ]`
			 * must be a sub-interval of `[ - 2 PI, 2 PI ]`, with `( max - min < 2 PI )`.
			 *
			 * @type {number}
			 * @default -Infinity
			 */
			this.maxAzimuthAngle = Infinity;

			/**
			 * Set to `true` to enable damping (inertia), which can be used to give a sense of weight
			 * to the controls. Note that if this is enabled, you must call `update()` in your animation
			 * loop.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.enableDamping = false;

			/**
			 * The damping inertia used if `enableDamping` is set to `true`.
			 *
			 * Note that for this to work, you must call `update()` in your animation loop.
			 *
			 * @type {number}
			 * @default 0.05
			 */
			this.dampingFactor = 0.05;

			/**
			 * Enable or disable zooming (dollying) of the camera.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.enableZoom = true;

			/**
			 * Speed of zooming / dollying.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.zoomSpeed = 1.0;

			/**
			 * Enable or disable horizontal and vertical rotation of the camera.
			 *
			 * Note that it is possible to disable a single axis by setting the min and max of the
			 * `minPolarAngle` or `minAzimuthAngle` to the same value, which will cause the vertical
			 * or horizontal rotation to be fixed at that value.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.enableRotate = true;

			/**
			 * Speed of rotation.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.rotateSpeed = 1.0;

			/**
			 * How fast to rotate the camera when the keyboard is used.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.keyRotateSpeed = 1.0;

			/**
			 * Enable or disable camera panning.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.enablePan = true;

			/**
			 * Speed of panning.
			 *
			 * @type {number}
			 * @default 1
			 */
			this.panSpeed = 1.0;

			/**
			 * Defines how the camera's position is translated when panning. If `true`, the camera pans
			 * in screen space. Otherwise, the camera pans in the plane orthogonal to the camera's up
			 * direction.
			 *
			 * @type {boolean}
			 * @default true
			 */
			this.screenSpacePanning = true;

			/**
			 * How fast to pan the camera when the keyboard is used in
			 * pixels per keypress.
			 *
			 * @type {number}
			 * @default 7
			 */
			this.keyPanSpeed = 7.0;

			/**
			 * Setting this property to `true` allows to zoom to the cursor's position.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.zoomToCursor = false;

			/**
			 * Set to true to automatically rotate around the target
			 *
			 * Note that if this is enabled, you must call `update()` in your animation loop.
			 * If you want the auto-rotate speed to be independent of the frame rate (the refresh
			 * rate of the display), you must pass the time `deltaTime`, in seconds, to `update()`.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.autoRotate = false;

			/**
			 * How fast to rotate around the target if `autoRotate` is `true`. The default  equates to 30 seconds
			 * per orbit at 60fps.
			 *
			 * Note that if `autoRotate` is enabled, you must call `update()` in your animation loop.
			 *
			 * @type {number}
			 * @default 2
			 */
			this.autoRotateSpeed = 2.0;

			/**
			 * This object contains references to the keycodes for controlling camera panning.
			 *
			 * ```js
			 * controls.keys = {
			 * 	LEFT: 'ArrowLeft', //left arrow
			 * 	UP: 'ArrowUp', // up arrow
			 * 	RIGHT: 'ArrowRight', // right arrow
			 * 	BOTTOM: 'ArrowDown' // down arrow
			 * }
			 * ```
			 * @type {Object}
			 */
			this.keys = { LEFT: 'ArrowLeft', UP: 'ArrowUp', RIGHT: 'ArrowRight', BOTTOM: 'ArrowDown' };

			/**
			 * This object contains references to the mouse actions used by the controls.
			 *
			 * ```js
			 * controls.mouseButtons = {
			 * 	LEFT: THREE.MOUSE.ROTATE,
			 * 	MIDDLE: THREE.MOUSE.DOLLY,
			 * 	RIGHT: THREE.MOUSE.PAN
			 * }
			 * ```
			 * @type {Object}
			 */
			this.mouseButtons = { LEFT: MOUSE.ROTATE, MIDDLE: MOUSE.DOLLY, RIGHT: MOUSE.PAN };

			/**
			 * This object contains references to the touch actions used by the controls.
			 *
			 * ```js
			 * controls.mouseButtons = {
			 * 	ONE: THREE.TOUCH.ROTATE,
			 * 	TWO: THREE.TOUCH.DOLLY_PAN
			 * }
			 * ```
			 * @type {Object}
			 */
			this.touches = { ONE: TOUCH.ROTATE, TWO: TOUCH.DOLLY_PAN };

			/**
			 * Used internally by `saveState()` and `reset()`.
			 *
			 * @type {Vector3}
			 */
			this.target0 = this.target.clone();

			/**
			 * Used internally by `saveState()` and `reset()`.
			 *
			 * @type {Vector3}
			 */
			this.position0 = this.object.position.clone();

			/**
			 * Used internally by `saveState()` and `reset()`.
			 *
			 * @type {number}
			 */
			this.zoom0 = this.object.zoom;

			// the target DOM element for key events
			this._domElementKeyEvents = null;

			// internals

			this._lastPosition = new Vector3();
			this._lastQuaternion = new Quaternion();
			this._lastTargetPosition = new Vector3();

			// so camera.up is the orbit axis
			this._quat = new Quaternion().setFromUnitVectors( object.up, new Vector3( 0, 1, 0 ) );
			this._quatInverse = this._quat.clone().invert();

			// current position in spherical coordinates
			this._spherical = new Spherical();
			this._sphericalDelta = new Spherical();

			this._scale = 1;
			this._panOffset = new Vector3();

			this._rotateStart = new Vector2();
			this._rotateEnd = new Vector2();
			this._rotateDelta = new Vector2();

			this._panStart = new Vector2();
			this._panEnd = new Vector2();
			this._panDelta = new Vector2();

			this._dollyStart = new Vector2();
			this._dollyEnd = new Vector2();
			this._dollyDelta = new Vector2();

			this._dollyDirection = new Vector3();
			this._mouse = new Vector2();
			this._performCursorZoom = false;

			this._pointers = [];
			this._pointerPositions = {};

			this._controlActive = false;

			// event listeners

			this._onPointerMove = onPointerMove$1.bind( this );
			this._onPointerDown = onPointerDown$1.bind( this );
			this._onPointerUp = onPointerUp$1.bind( this );
			this._onContextMenu = onContextMenu.bind( this );
			this._onMouseWheel = onMouseWheel.bind( this );
			this._onKeyDown = onKeyDown.bind( this );

			this._onTouchStart = onTouchStart.bind( this );
			this._onTouchMove = onTouchMove.bind( this );

			this._onMouseDown = onMouseDown.bind( this );
			this._onMouseMove = onMouseMove.bind( this );

			this._interceptControlDown = interceptControlDown.bind( this );
			this._interceptControlUp = interceptControlUp.bind( this );

			//

			if ( this.domElement !== null ) {

				this.connect( this.domElement );

			}

			this.update();

		}

		connect( element ) {

			super.connect( element );

			this.domElement.addEventListener( 'pointerdown', this._onPointerDown );
			this.domElement.addEventListener( 'pointercancel', this._onPointerUp );

			this.domElement.addEventListener( 'contextmenu', this._onContextMenu );
			this.domElement.addEventListener( 'wheel', this._onMouseWheel, { passive: false } );

			const document = this.domElement.getRootNode(); // offscreen canvas compatibility
			document.addEventListener( 'keydown', this._interceptControlDown, { passive: true, capture: true } );

			this.domElement.style.touchAction = 'none'; // disable touch scroll

		}

		disconnect() {

			this.domElement.removeEventListener( 'pointerdown', this._onPointerDown );
			this.domElement.removeEventListener( 'pointermove', this._onPointerMove );
			this.domElement.removeEventListener( 'pointerup', this._onPointerUp );
			this.domElement.removeEventListener( 'pointercancel', this._onPointerUp );

			this.domElement.removeEventListener( 'wheel', this._onMouseWheel );
			this.domElement.removeEventListener( 'contextmenu', this._onContextMenu );

			this.stopListenToKeyEvents();

			const document = this.domElement.getRootNode(); // offscreen canvas compatibility
			document.removeEventListener( 'keydown', this._interceptControlDown, { capture: true } );

			this.domElement.style.touchAction = 'auto';

		}

		dispose() {

			this.disconnect();

		}

		/**
		 * Get the current vertical rotation, in radians.
		 *
		 * @return {number} The current vertical rotation, in radians.
		 */
		getPolarAngle() {

			return this._spherical.phi;

		}

		/**
		 * Get the current horizontal rotation, in radians.
		 *
		 * @return {number} The current horizontal rotation, in radians.
		 */
		getAzimuthalAngle() {

			return this._spherical.theta;

		}

		/**
		 * Returns the distance from the camera to the target.
		 *
		 * @return {number} The distance from the camera to the target.
		 */
		getDistance() {

			return this.object.position.distanceTo( this.target );

		}

		/**
		 * Adds key event listeners to the given DOM element.
		 * `window` is a recommended argument for using this method.
		 *
		 * @param {HTMLDOMElement} domElement - The DOM element
		 */
		listenToKeyEvents( domElement ) {

			domElement.addEventListener( 'keydown', this._onKeyDown );
			this._domElementKeyEvents = domElement;

		}

		/**
		 * Removes the key event listener previously defined with `listenToKeyEvents()`.
		 */
		stopListenToKeyEvents() {

			if ( this._domElementKeyEvents !== null ) {

				this._domElementKeyEvents.removeEventListener( 'keydown', this._onKeyDown );
				this._domElementKeyEvents = null;

			}

		}

		/**
		 * Save the current state of the controls. This can later be recovered with `reset()`.
		 */
		saveState() {

			this.target0.copy( this.target );
			this.position0.copy( this.object.position );
			this.zoom0 = this.object.zoom;

		}

		/**
		 * Reset the controls to their state from either the last time the `saveState()`
		 * was called, or the initial state.
		 */
		reset() {

			this.target.copy( this.target0 );
			this.object.position.copy( this.position0 );
			this.object.zoom = this.zoom0;

			this.object.updateProjectionMatrix();
			this.dispatchEvent( _changeEvent$1 );

			this.update();

			this.state = _STATE.NONE;

		}

		update( deltaTime = null ) {

			const position = this.object.position;

			_v.copy( position ).sub( this.target );

			// rotate offset to "y-axis-is-up" space
			_v.applyQuaternion( this._quat );

			// angle from z-axis around y-axis
			this._spherical.setFromVector3( _v );

			if ( this.autoRotate && this.state === _STATE.NONE ) {

				this._rotateLeft( this._getAutoRotationAngle( deltaTime ) );

			}

			if ( this.enableDamping ) {

				this._spherical.theta += this._sphericalDelta.theta * this.dampingFactor;
				this._spherical.phi += this._sphericalDelta.phi * this.dampingFactor;

			} else {

				this._spherical.theta += this._sphericalDelta.theta;
				this._spherical.phi += this._sphericalDelta.phi;

			}

			// restrict theta to be between desired limits

			let min = this.minAzimuthAngle;
			let max = this.maxAzimuthAngle;

			if ( isFinite( min ) && isFinite( max ) ) {

				if ( min < - Math.PI ) min += _twoPI; else if ( min > Math.PI ) min -= _twoPI;

				if ( max < - Math.PI ) max += _twoPI; else if ( max > Math.PI ) max -= _twoPI;

				if ( min <= max ) {

					this._spherical.theta = Math.max( min, Math.min( max, this._spherical.theta ) );

				} else {

					this._spherical.theta = ( this._spherical.theta > ( min + max ) / 2 ) ?
						Math.max( min, this._spherical.theta ) :
						Math.min( max, this._spherical.theta );

				}

			}

			// restrict phi to be between desired limits
			this._spherical.phi = Math.max( this.minPolarAngle, Math.min( this.maxPolarAngle, this._spherical.phi ) );

			this._spherical.makeSafe();


			// move target to panned location

			if ( this.enableDamping === true ) {

				this.target.addScaledVector( this._panOffset, this.dampingFactor );

			} else {

				this.target.add( this._panOffset );

			}

			// Limit the target distance from the cursor to create a sphere around the center of interest
			this.target.sub( this.cursor );
			this.target.clampLength( this.minTargetRadius, this.maxTargetRadius );
			this.target.add( this.cursor );

			let zoomChanged = false;
			// adjust the camera position based on zoom only if we're not zooming to the cursor or if it's an ortho camera
			// we adjust zoom later in these cases
			if ( this.zoomToCursor && this._performCursorZoom || this.object.isOrthographicCamera ) {

				this._spherical.radius = this._clampDistance( this._spherical.radius );

			} else {

				const prevRadius = this._spherical.radius;
				this._spherical.radius = this._clampDistance( this._spherical.radius * this._scale );
				zoomChanged = prevRadius != this._spherical.radius;

			}

			_v.setFromSpherical( this._spherical );

			// rotate offset back to "camera-up-vector-is-up" space
			_v.applyQuaternion( this._quatInverse );

			position.copy( this.target ).add( _v );

			this.object.lookAt( this.target );

			if ( this.enableDamping === true ) {

				this._sphericalDelta.theta *= ( 1 - this.dampingFactor );
				this._sphericalDelta.phi *= ( 1 - this.dampingFactor );

				this._panOffset.multiplyScalar( 1 - this.dampingFactor );

			} else {

				this._sphericalDelta.set( 0, 0, 0 );

				this._panOffset.set( 0, 0, 0 );

			}

			// adjust camera position
			if ( this.zoomToCursor && this._performCursorZoom ) {

				let newRadius = null;
				if ( this.object.isPerspectiveCamera ) {

					// move the camera down the pointer ray
					// this method avoids floating point error
					const prevRadius = _v.length();
					newRadius = this._clampDistance( prevRadius * this._scale );

					const radiusDelta = prevRadius - newRadius;
					this.object.position.addScaledVector( this._dollyDirection, radiusDelta );
					this.object.updateMatrixWorld();

					zoomChanged = !! radiusDelta;

				} else if ( this.object.isOrthographicCamera ) {

					// adjust the ortho camera position based on zoom changes
					const mouseBefore = new Vector3( this._mouse.x, this._mouse.y, 0 );
					mouseBefore.unproject( this.object );

					const prevZoom = this.object.zoom;
					this.object.zoom = Math.max( this.minZoom, Math.min( this.maxZoom, this.object.zoom / this._scale ) );
					this.object.updateProjectionMatrix();

					zoomChanged = prevZoom !== this.object.zoom;

					const mouseAfter = new Vector3( this._mouse.x, this._mouse.y, 0 );
					mouseAfter.unproject( this.object );

					this.object.position.sub( mouseAfter ).add( mouseBefore );
					this.object.updateMatrixWorld();

					newRadius = _v.length();

				} else {

					console.warn( 'WARNING: OrbitControls.js encountered an unknown camera type - zoom to cursor disabled.' );
					this.zoomToCursor = false;

				}

				// handle the placement of the target
				if ( newRadius !== null ) {

					if ( this.screenSpacePanning ) {

						// position the orbit target in front of the new camera position
						this.target.set( 0, 0, - 1 )
							.transformDirection( this.object.matrix )
							.multiplyScalar( newRadius )
							.add( this.object.position );

					} else {

						// get the ray and translation plane to compute target
						_ray$4.origin.copy( this.object.position );
						_ray$4.direction.set( 0, 0, - 1 ).transformDirection( this.object.matrix );

						// if the camera is 20 degrees above the horizon then don't adjust the focus target to avoid
						// extremely large values
						if ( Math.abs( this.object.up.dot( _ray$4.direction ) ) < _TILT_LIMIT ) {

							this.object.lookAt( this.target );

						} else {

							_plane.setFromNormalAndCoplanarPoint( this.object.up, this.target );
							_ray$4.intersectPlane( _plane, this.target );

						}

					}

				}

			} else if ( this.object.isOrthographicCamera ) {

				const prevZoom = this.object.zoom;
				this.object.zoom = Math.max( this.minZoom, Math.min( this.maxZoom, this.object.zoom / this._scale ) );

				if ( prevZoom !== this.object.zoom ) {

					this.object.updateProjectionMatrix();
					zoomChanged = true;

				}

			}

			this._scale = 1;
			this._performCursorZoom = false;

			// update condition is:
			// min(camera displacement, camera rotation in radians)^2 > EPS
			// using small-angle approximation cos(x/2) = 1 - x^2 / 8

			if ( zoomChanged ||
				this._lastPosition.distanceToSquared( this.object.position ) > _EPS ||
				8 * ( 1 - this._lastQuaternion.dot( this.object.quaternion ) ) > _EPS ||
				this._lastTargetPosition.distanceToSquared( this.target ) > _EPS ) {

				this.dispatchEvent( _changeEvent$1 );

				this._lastPosition.copy( this.object.position );
				this._lastQuaternion.copy( this.object.quaternion );
				this._lastTargetPosition.copy( this.target );

				return true;

			}

			return false;

		}

		_getAutoRotationAngle( deltaTime ) {

			if ( deltaTime !== null ) {

				return ( _twoPI / 60 * this.autoRotateSpeed ) * deltaTime;

			} else {

				return _twoPI / 60 / 60 * this.autoRotateSpeed;

			}

		}

		_getZoomScale( delta ) {

			const normalizedDelta = Math.abs( delta * 0.01 );
			return Math.pow( 0.95, this.zoomSpeed * normalizedDelta );

		}

		_rotateLeft( angle ) {

			this._sphericalDelta.theta -= angle;

		}

		_rotateUp( angle ) {

			this._sphericalDelta.phi -= angle;

		}

		_panLeft( distance, objectMatrix ) {

			_v.setFromMatrixColumn( objectMatrix, 0 ); // get X column of objectMatrix
			_v.multiplyScalar( - distance );

			this._panOffset.add( _v );

		}

		_panUp( distance, objectMatrix ) {

			if ( this.screenSpacePanning === true ) {

				_v.setFromMatrixColumn( objectMatrix, 1 );

			} else {

				_v.setFromMatrixColumn( objectMatrix, 0 );
				_v.crossVectors( this.object.up, _v );

			}

			_v.multiplyScalar( distance );

			this._panOffset.add( _v );

		}

		// deltaX and deltaY are in pixels; right and down are positive
		_pan( deltaX, deltaY ) {

			const element = this.domElement;

			if ( this.object.isPerspectiveCamera ) {

				// perspective
				const position = this.object.position;
				_v.copy( position ).sub( this.target );
				let targetDistance = _v.length();

				// half of the fov is center to top of screen
				targetDistance *= Math.tan( ( this.object.fov / 2 ) * Math.PI / 180.0 );

				// we use only clientHeight here so aspect ratio does not distort speed
				this._panLeft( 2 * deltaX * targetDistance / element.clientHeight, this.object.matrix );
				this._panUp( 2 * deltaY * targetDistance / element.clientHeight, this.object.matrix );

			} else if ( this.object.isOrthographicCamera ) {

				// orthographic
				this._panLeft( deltaX * ( this.object.right - this.object.left ) / this.object.zoom / element.clientWidth, this.object.matrix );
				this._panUp( deltaY * ( this.object.top - this.object.bottom ) / this.object.zoom / element.clientHeight, this.object.matrix );

			} else {

				// camera neither orthographic nor perspective
				console.warn( 'WARNING: OrbitControls.js encountered an unknown camera type - pan disabled.' );
				this.enablePan = false;

			}

		}

		_dollyOut( dollyScale ) {

			if ( this.object.isPerspectiveCamera || this.object.isOrthographicCamera ) {

				this._scale /= dollyScale;

			} else {

				console.warn( 'WARNING: OrbitControls.js encountered an unknown camera type - dolly/zoom disabled.' );
				this.enableZoom = false;

			}

		}

		_dollyIn( dollyScale ) {

			if ( this.object.isPerspectiveCamera || this.object.isOrthographicCamera ) {

				this._scale *= dollyScale;

			} else {

				console.warn( 'WARNING: OrbitControls.js encountered an unknown camera type - dolly/zoom disabled.' );
				this.enableZoom = false;

			}

		}

		_updateZoomParameters( x, y ) {

			if ( ! this.zoomToCursor ) {

				return;

			}

			this._performCursorZoom = true;

			const rect = this.domElement.getBoundingClientRect();
			const dx = x - rect.left;
			const dy = y - rect.top;
			const w = rect.width;
			const h = rect.height;

			this._mouse.x = ( dx / w ) * 2 - 1;
			this._mouse.y = - ( dy / h ) * 2 + 1;

			this._dollyDirection.set( this._mouse.x, this._mouse.y, 1 ).unproject( this.object ).sub( this.object.position ).normalize();

		}

		_clampDistance( dist ) {

			return Math.max( this.minDistance, Math.min( this.maxDistance, dist ) );

		}

		//
		// event callbacks - update the object state
		//

		_handleMouseDownRotate( event ) {

			this._rotateStart.set( event.clientX, event.clientY );

		}

		_handleMouseDownDolly( event ) {

			this._updateZoomParameters( event.clientX, event.clientX );
			this._dollyStart.set( event.clientX, event.clientY );

		}

		_handleMouseDownPan( event ) {

			this._panStart.set( event.clientX, event.clientY );

		}

		_handleMouseMoveRotate( event ) {

			this._rotateEnd.set( event.clientX, event.clientY );

			this._rotateDelta.subVectors( this._rotateEnd, this._rotateStart ).multiplyScalar( this.rotateSpeed );

			const element = this.domElement;

			this._rotateLeft( _twoPI * this._rotateDelta.x / element.clientHeight ); // yes, height

			this._rotateUp( _twoPI * this._rotateDelta.y / element.clientHeight );

			this._rotateStart.copy( this._rotateEnd );

			this.update();

		}

		_handleMouseMoveDolly( event ) {

			this._dollyEnd.set( event.clientX, event.clientY );

			this._dollyDelta.subVectors( this._dollyEnd, this._dollyStart );

			if ( this._dollyDelta.y > 0 ) {

				this._dollyOut( this._getZoomScale( this._dollyDelta.y ) );

			} else if ( this._dollyDelta.y < 0 ) {

				this._dollyIn( this._getZoomScale( this._dollyDelta.y ) );

			}

			this._dollyStart.copy( this._dollyEnd );

			this.update();

		}

		_handleMouseMovePan( event ) {

			this._panEnd.set( event.clientX, event.clientY );

			this._panDelta.subVectors( this._panEnd, this._panStart ).multiplyScalar( this.panSpeed );

			this._pan( this._panDelta.x, this._panDelta.y );

			this._panStart.copy( this._panEnd );

			this.update();

		}

		_handleMouseWheel( event ) {

			this._updateZoomParameters( event.clientX, event.clientY );

			if ( event.deltaY < 0 ) {

				this._dollyIn( this._getZoomScale( event.deltaY ) );

			} else if ( event.deltaY > 0 ) {

				this._dollyOut( this._getZoomScale( event.deltaY ) );

			}

			this.update();

		}

		_handleKeyDown( event ) {

			let needsUpdate = false;

			switch ( event.code ) {

				case this.keys.UP:

					if ( event.ctrlKey || event.metaKey || event.shiftKey ) {

						if ( this.enableRotate ) {

							this._rotateUp( _twoPI * this.keyRotateSpeed / this.domElement.clientHeight );

						}

					} else {

						if ( this.enablePan ) {

							this._pan( 0, this.keyPanSpeed );

						}

					}

					needsUpdate = true;
					break;

				case this.keys.BOTTOM:

					if ( event.ctrlKey || event.metaKey || event.shiftKey ) {

						if ( this.enableRotate ) {

							this._rotateUp( - _twoPI * this.keyRotateSpeed / this.domElement.clientHeight );

						}

					} else {

						if ( this.enablePan ) {

							this._pan( 0, - this.keyPanSpeed );

						}

					}

					needsUpdate = true;
					break;

				case this.keys.LEFT:

					if ( event.ctrlKey || event.metaKey || event.shiftKey ) {

						if ( this.enableRotate ) {

							this._rotateLeft( _twoPI * this.keyRotateSpeed / this.domElement.clientHeight );

						}

					} else {

						if ( this.enablePan ) {

							this._pan( this.keyPanSpeed, 0 );

						}

					}

					needsUpdate = true;
					break;

				case this.keys.RIGHT:

					if ( event.ctrlKey || event.metaKey || event.shiftKey ) {

						if ( this.enableRotate ) {

							this._rotateLeft( - _twoPI * this.keyRotateSpeed / this.domElement.clientHeight );

						}

					} else {

						if ( this.enablePan ) {

							this._pan( - this.keyPanSpeed, 0 );

						}

					}

					needsUpdate = true;
					break;

			}

			if ( needsUpdate ) {

				// prevent the browser from scrolling on cursor keys
				event.preventDefault();

				this.update();

			}


		}

		_handleTouchStartRotate( event ) {

			if ( this._pointers.length === 1 ) {

				this._rotateStart.set( event.pageX, event.pageY );

			} else {

				const position = this._getSecondPointerPosition( event );

				const x = 0.5 * ( event.pageX + position.x );
				const y = 0.5 * ( event.pageY + position.y );

				this._rotateStart.set( x, y );

			}

		}

		_handleTouchStartPan( event ) {

			if ( this._pointers.length === 1 ) {

				this._panStart.set( event.pageX, event.pageY );

			} else {

				const position = this._getSecondPointerPosition( event );

				const x = 0.5 * ( event.pageX + position.x );
				const y = 0.5 * ( event.pageY + position.y );

				this._panStart.set( x, y );

			}

		}

		_handleTouchStartDolly( event ) {

			const position = this._getSecondPointerPosition( event );

			const dx = event.pageX - position.x;
			const dy = event.pageY - position.y;

			const distance = Math.sqrt( dx * dx + dy * dy );

			this._dollyStart.set( 0, distance );

		}

		_handleTouchStartDollyPan( event ) {

			if ( this.enableZoom ) this._handleTouchStartDolly( event );

			if ( this.enablePan ) this._handleTouchStartPan( event );

		}

		_handleTouchStartDollyRotate( event ) {

			if ( this.enableZoom ) this._handleTouchStartDolly( event );

			if ( this.enableRotate ) this._handleTouchStartRotate( event );

		}

		_handleTouchMoveRotate( event ) {

			if ( this._pointers.length == 1 ) {

				this._rotateEnd.set( event.pageX, event.pageY );

			} else {

				const position = this._getSecondPointerPosition( event );

				const x = 0.5 * ( event.pageX + position.x );
				const y = 0.5 * ( event.pageY + position.y );

				this._rotateEnd.set( x, y );

			}

			this._rotateDelta.subVectors( this._rotateEnd, this._rotateStart ).multiplyScalar( this.rotateSpeed );

			const element = this.domElement;

			this._rotateLeft( _twoPI * this._rotateDelta.x / element.clientHeight ); // yes, height

			this._rotateUp( _twoPI * this._rotateDelta.y / element.clientHeight );

			this._rotateStart.copy( this._rotateEnd );

		}

		_handleTouchMovePan( event ) {

			if ( this._pointers.length === 1 ) {

				this._panEnd.set( event.pageX, event.pageY );

			} else {

				const position = this._getSecondPointerPosition( event );

				const x = 0.5 * ( event.pageX + position.x );
				const y = 0.5 * ( event.pageY + position.y );

				this._panEnd.set( x, y );

			}

			this._panDelta.subVectors( this._panEnd, this._panStart ).multiplyScalar( this.panSpeed );

			this._pan( this._panDelta.x, this._panDelta.y );

			this._panStart.copy( this._panEnd );

		}

		_handleTouchMoveDolly( event ) {

			const position = this._getSecondPointerPosition( event );

			const dx = event.pageX - position.x;
			const dy = event.pageY - position.y;

			const distance = Math.sqrt( dx * dx + dy * dy );

			this._dollyEnd.set( 0, distance );

			this._dollyDelta.set( 0, Math.pow( this._dollyEnd.y / this._dollyStart.y, this.zoomSpeed ) );

			this._dollyOut( this._dollyDelta.y );

			this._dollyStart.copy( this._dollyEnd );

			const centerX = ( event.pageX + position.x ) * 0.5;
			const centerY = ( event.pageY + position.y ) * 0.5;

			this._updateZoomParameters( centerX, centerY );

		}

		_handleTouchMoveDollyPan( event ) {

			if ( this.enableZoom ) this._handleTouchMoveDolly( event );

			if ( this.enablePan ) this._handleTouchMovePan( event );

		}

		_handleTouchMoveDollyRotate( event ) {

			if ( this.enableZoom ) this._handleTouchMoveDolly( event );

			if ( this.enableRotate ) this._handleTouchMoveRotate( event );

		}

		// pointers

		_addPointer( event ) {

			this._pointers.push( event.pointerId );

		}

		_removePointer( event ) {

			delete this._pointerPositions[ event.pointerId ];

			for ( let i = 0; i < this._pointers.length; i ++ ) {

				if ( this._pointers[ i ] == event.pointerId ) {

					this._pointers.splice( i, 1 );
					return;

				}

			}

		}

		_isTrackingPointer( event ) {

			for ( let i = 0; i < this._pointers.length; i ++ ) {

				if ( this._pointers[ i ] == event.pointerId ) return true;

			}

			return false;

		}

		_trackPointer( event ) {

			let position = this._pointerPositions[ event.pointerId ];

			if ( position === undefined ) {

				position = new Vector2();
				this._pointerPositions[ event.pointerId ] = position;

			}

			position.set( event.pageX, event.pageY );

		}

		_getSecondPointerPosition( event ) {

			const pointerId = ( event.pointerId === this._pointers[ 0 ] ) ? this._pointers[ 1 ] : this._pointers[ 0 ];

			return this._pointerPositions[ pointerId ];

		}

		//

		_customWheelEvent( event ) {

			const mode = event.deltaMode;

			// minimal wheel event altered to meet delta-zoom demand
			const newEvent = {
				clientX: event.clientX,
				clientY: event.clientY,
				deltaY: event.deltaY,
			};

			switch ( mode ) {

				case 1: // LINE_MODE
					newEvent.deltaY *= 16;
					break;

				case 2: // PAGE_MODE
					newEvent.deltaY *= 100;
					break;

			}

			// detect if event was triggered by pinching
			if ( event.ctrlKey && ! this._controlActive ) {

				newEvent.deltaY *= 10;

			}

			return newEvent;

		}

	}

	function onPointerDown$1( event ) {

		if ( this.enabled === false ) return;

		if ( this._pointers.length === 0 ) {

			this.domElement.setPointerCapture( event.pointerId );

			this.domElement.addEventListener( 'pointermove', this._onPointerMove );
			this.domElement.addEventListener( 'pointerup', this._onPointerUp );

		}

		//

		if ( this._isTrackingPointer( event ) ) return;

		//

		this._addPointer( event );

		if ( event.pointerType === 'touch' ) {

			this._onTouchStart( event );

		} else {

			this._onMouseDown( event );

		}

	}

	function onPointerMove$1( event ) {

		if ( this.enabled === false ) return;

		if ( event.pointerType === 'touch' ) {

			this._onTouchMove( event );

		} else {

			this._onMouseMove( event );

		}

	}

	function onPointerUp$1( event ) {

		this._removePointer( event );

		switch ( this._pointers.length ) {

			case 0:

				this.domElement.releasePointerCapture( event.pointerId );

				this.domElement.removeEventListener( 'pointermove', this._onPointerMove );
				this.domElement.removeEventListener( 'pointerup', this._onPointerUp );

				this.dispatchEvent( _endEvent );

				this.state = _STATE.NONE;

				break;

			case 1:

				const pointerId = this._pointers[ 0 ];
				const position = this._pointerPositions[ pointerId ];

				// minimal placeholder event - allows state correction on pointer-up
				this._onTouchStart( { pointerId: pointerId, pageX: position.x, pageY: position.y } );

				break;

		}

	}

	function onMouseDown( event ) {

		let mouseAction;

		switch ( event.button ) {

			case 0:

				mouseAction = this.mouseButtons.LEFT;
				break;

			case 1:

				mouseAction = this.mouseButtons.MIDDLE;
				break;

			case 2:

				mouseAction = this.mouseButtons.RIGHT;
				break;

			default:

				mouseAction = - 1;

		}

		switch ( mouseAction ) {

			case MOUSE.DOLLY:

				if ( this.enableZoom === false ) return;

				this._handleMouseDownDolly( event );

				this.state = _STATE.DOLLY;

				break;

			case MOUSE.ROTATE:

				if ( event.ctrlKey || event.metaKey || event.shiftKey ) {

					if ( this.enablePan === false ) return;

					this._handleMouseDownPan( event );

					this.state = _STATE.PAN;

				} else {

					if ( this.enableRotate === false ) return;

					this._handleMouseDownRotate( event );

					this.state = _STATE.ROTATE;

				}

				break;

			case MOUSE.PAN:

				if ( event.ctrlKey || event.metaKey || event.shiftKey ) {

					if ( this.enableRotate === false ) return;

					this._handleMouseDownRotate( event );

					this.state = _STATE.ROTATE;

				} else {

					if ( this.enablePan === false ) return;

					this._handleMouseDownPan( event );

					this.state = _STATE.PAN;

				}

				break;

			default:

				this.state = _STATE.NONE;

		}

		if ( this.state !== _STATE.NONE ) {

			this.dispatchEvent( _startEvent );

		}

	}

	function onMouseMove( event ) {

		switch ( this.state ) {

			case _STATE.ROTATE:

				if ( this.enableRotate === false ) return;

				this._handleMouseMoveRotate( event );

				break;

			case _STATE.DOLLY:

				if ( this.enableZoom === false ) return;

				this._handleMouseMoveDolly( event );

				break;

			case _STATE.PAN:

				if ( this.enablePan === false ) return;

				this._handleMouseMovePan( event );

				break;

		}

	}

	function onMouseWheel( event ) {

		if ( this.enabled === false || this.enableZoom === false || this.state !== _STATE.NONE ) return;

		event.preventDefault();

		this.dispatchEvent( _startEvent );

		this._handleMouseWheel( this._customWheelEvent( event ) );

		this.dispatchEvent( _endEvent );

	}

	function onKeyDown( event ) {

		if ( this.enabled === false ) return;

		this._handleKeyDown( event );

	}

	function onTouchStart( event ) {

		this._trackPointer( event );

		switch ( this._pointers.length ) {

			case 1:

				switch ( this.touches.ONE ) {

					case TOUCH.ROTATE:

						if ( this.enableRotate === false ) return;

						this._handleTouchStartRotate( event );

						this.state = _STATE.TOUCH_ROTATE;

						break;

					case TOUCH.PAN:

						if ( this.enablePan === false ) return;

						this._handleTouchStartPan( event );

						this.state = _STATE.TOUCH_PAN;

						break;

					default:

						this.state = _STATE.NONE;

				}

				break;

			case 2:

				switch ( this.touches.TWO ) {

					case TOUCH.DOLLY_PAN:

						if ( this.enableZoom === false && this.enablePan === false ) return;

						this._handleTouchStartDollyPan( event );

						this.state = _STATE.TOUCH_DOLLY_PAN;

						break;

					case TOUCH.DOLLY_ROTATE:

						if ( this.enableZoom === false && this.enableRotate === false ) return;

						this._handleTouchStartDollyRotate( event );

						this.state = _STATE.TOUCH_DOLLY_ROTATE;

						break;

					default:

						this.state = _STATE.NONE;

				}

				break;

			default:

				this.state = _STATE.NONE;

		}

		if ( this.state !== _STATE.NONE ) {

			this.dispatchEvent( _startEvent );

		}

	}

	function onTouchMove( event ) {

		this._trackPointer( event );

		switch ( this.state ) {

			case _STATE.TOUCH_ROTATE:

				if ( this.enableRotate === false ) return;

				this._handleTouchMoveRotate( event );

				this.update();

				break;

			case _STATE.TOUCH_PAN:

				if ( this.enablePan === false ) return;

				this._handleTouchMovePan( event );

				this.update();

				break;

			case _STATE.TOUCH_DOLLY_PAN:

				if ( this.enableZoom === false && this.enablePan === false ) return;

				this._handleTouchMoveDollyPan( event );

				this.update();

				break;

			case _STATE.TOUCH_DOLLY_ROTATE:

				if ( this.enableZoom === false && this.enableRotate === false ) return;

				this._handleTouchMoveDollyRotate( event );

				this.update();

				break;

			default:

				this.state = _STATE.NONE;

		}

	}

	function onContextMenu( event ) {

		if ( this.enabled === false ) return;

		event.preventDefault();

	}

	function interceptControlDown( event ) {

		if ( event.key === 'Control' ) {

			this._controlActive = true;

			const document = this.domElement.getRootNode(); // offscreen canvas compatibility

			document.addEventListener( 'keyup', this._interceptControlUp, { passive: true, capture: true } );

		}

	}

	function interceptControlUp( event ) {

		if ( event.key === 'Control' ) {

			this._controlActive = false;

			const document = this.domElement.getRootNode(); // offscreen canvas compatibility

			document.removeEventListener( 'keyup', this._interceptControlUp, { passive: true, capture: true } );

		}

	}

	//import Style from '../../actions/utils/style'

	class Scene$1 extends Shape$1 {
	    constructor(root, canvas, context, entity) {

			super(entity);

			console.log("SCENE INIT", root, canvas, context, entity);

			this.root = root, 
			//this.canvas = canvas
			this.canvas = canvas;
			this.context = context;
			this.entity = entity;
	    }

		get canvas() {
			return this.__canvas;
		}

		set canvas(elem) {
			this.__canvas = elem;
			console.warn("overwriting canvas", elem, this.__canvas);
		}


		createMesh(program) {

			const { renderer, canvas, context, assetManager } = program;

			const { params = {} } = this;

			console.error("CREATING SCENE NODE", params, context);

			let sizes = {
	                    width: window.innerWidth,
	                    height: window.innerHeight
	                };
			let aspect = sizes.width / sizes.height;

			const scene = new Scene({ });
			scene.background = null;

			const stage = new Group$1({ name: 'stage' });

			const frustumSize = 5;
			
			let camera = null;

			if (params.type !== 'orthographic' ) {
				camera = new PerspectiveCamera(50, aspect, 0.1, 1000);
				camera.position.set( 0, 0, 4 );
			} else {
				console.log("CREATED ORTHO CAM");
				camera = new OrthographicCamera(
							(frustumSize * aspect) / -2, // left
							(frustumSize * aspect) / 2, // right
							frustumSize / 2, // top
							frustumSize / -2, // bottom
							0.1, // near
							100 // far
						);
				camera.position.z = 5;
			}

			context.camera = camera;

			function resetCamera() {
				aspect = sizes.width / sizes.height;
				
				if (params.type === 'orthographic' ) {
					
					camera.left = (frustumSize * aspect) / -2;
					camera.right = (frustumSize * aspect) / 2;
					camera.top = frustumSize / 2;
					camera.bottom = frustumSize / -2;
					camera.position.z = 5;

					//console.log("UPDATED ORTHO CAMERA", camera)
				} else {				
					//console.log("UPDATED PERSPECTIVE CAMERA", camera.fov, aspectRatio)
	                camera.aspect = aspect;
				}	

				camera.updateProjectionMatrix();
			}

			scene.add(stage);

			
			const rootNode = this.getChildNodes({ 
				...program, renderer, camera, canvas, 
				context, scene, root: this 
			}, stage);
			


			renderer.preserverDrawingBuffer = true;


			context.scene = scene;
			context.camera = camera;

			//renderer.autoClear = false;

			const tick = (context) => {
				const { time } = context.clock;
				renderer.render(scene, camera);
			};

			this._tick = tick;

			function resizeHandler() {
	                sizes = {
	                    width: window.innerWidth,
	                    height: window.innerHeight
	                };
					resetCamera();
	        }

			console.log(">>>>>>>>>>>>>>>>>>>> CHEARTED CHILD SCENE", scene, stage);

			// Handle window resize
			window.addEventListener('resize', resizeHandler, false);  

			return stage
		}




		// override shape's createNode
		createNode(program, config = {}) {
			// if this is the root
			// we have to return an empty group
			// if not, we should return a new scene
			// object

			console.log("CREATING SCENE", config, config.root);

			if (config.root === true) {
				const group = new Group$1();
				return group
			}


			const childContext = program.context.$new({ name: 'child-scene' });
			const prog = {
				...program,
				context: childContext
			};
			
			return this.createMesh(prog)
		}


		setSize() {

		}

		
		render(program) {
			this.updateNode(program);
		}

		

		tick(context) {
			if (!this.mesh) {
				return
			}

			super.tick(context);
		}

	}

	class Cube extends Shape$1 {
		getGeometry(program) {
			console.log("rendering cube geometry", this.params);
			const cube = new BoxGeometry(this.params.width, this.params.height, this.params.depth, 1, 1, 1);
			return cube
		}

	}

	const _face = new Triangle();
	const _color$1 = new Vector3();
	const _uva = new Vector2(), _uvb = new Vector2(), _uvc = new Vector2();

	/**
	 * Utility class for sampling weighted random points on the surface of a mesh.
	 *
	 * Building the sampler is a one-time O(n) operation. Once built, any number of
	 * random samples may be selected in O(logn) time. Memory usage is O(n).
	 *
	 * References:
	 * - {@link http://www.joesfer.com/?p=84}
	 * - {@link https://stackoverflow.com/a/4322940/1314762}
	 *
	 * ```js
	 * const sampler = new MeshSurfaceSampler( surfaceMesh )
	 * 	.setWeightAttribute( 'color' )
	 * 	.build();
	 *
	 * const mesh = new THREE.InstancedMesh( sampleGeometry, sampleMaterial, 100 );
	 *
	 * const position = new THREE.Vector3();
	 * const matrix = new THREE.Matrix4();
	 *
	 * // Sample randomly from the surface, creating an instance of the sample geometry at each sample point.
	 *
	 * for ( let i = 0; i < 100; i ++ ) {
	 *
	 * 	sampler.sample( position );
	 * 	matrix.makeTranslation( position.x, position.y, position.z );
	 * 	mesh.setMatrixAt( i, matrix );
	 *
	 * }
	 *
	 * scene.add( mesh );
	 * ```
	 *
	 * @three_import import { MeshSurfaceSampler } from 'three/addons/math/MeshSurfaceSampler.js';
	 */
	class MeshSurfaceSampler {

		/**
		 * Constructs a mesh surface sampler.
		 *
		 * @param {Mesh} mesh - Surface mesh from which to sample.
		 */
		constructor( mesh ) {

			this.geometry = mesh.geometry;
			this.randomFunction = Math.random;

			this.indexAttribute = this.geometry.index;
			this.positionAttribute = this.geometry.getAttribute( 'position' );
			this.normalAttribute = this.geometry.getAttribute( 'normal' );
			this.colorAttribute = this.geometry.getAttribute( 'color' );
			this.uvAttribute = this.geometry.getAttribute( 'uv' );
			this.weightAttribute = null;

			this.distribution = null;

		}

		/**
		 * Specifies a vertex attribute to be used as a weight when sampling from the surface.
		 * Faces with higher weights are more likely to be sampled, and those with weights of
		 * zero will not be sampled at all. For vector attributes, only .x is used in sampling.
		 *
		 * If no weight attribute is selected, sampling is randomly distributed by area.
		 *
		 * @param {string} name - The attribute name.
		 * @return {MeshSurfaceSampler} A reference to this sampler.
		 */
		setWeightAttribute( name ) {

			this.weightAttribute = name ? this.geometry.getAttribute( name ) : null;

			return this;

		}

		/**
		 * Processes the input geometry and prepares to return samples. Any configuration of the
		 * geometry or sampler must occur before this method is called. Time complexity is O(n)
		 * for a surface with n faces.
		 *
		 * @return {MeshSurfaceSampler} A reference to this sampler.
		 */
		build() {

			const indexAttribute = this.indexAttribute;
			const positionAttribute = this.positionAttribute;
			const weightAttribute = this.weightAttribute;

			const totalFaces = indexAttribute ? ( indexAttribute.count / 3 ) : ( positionAttribute.count / 3 );
			const faceWeights = new Float32Array( totalFaces );

			// Accumulate weights for each mesh face.

			for ( let i = 0; i < totalFaces; i ++ ) {

				let faceWeight = 1;

				let i0 = 3 * i;
				let i1 = 3 * i + 1;
				let i2 = 3 * i + 2;

				if ( indexAttribute ) {

					i0 = indexAttribute.getX( i0 );
					i1 = indexAttribute.getX( i1 );
					i2 = indexAttribute.getX( i2 );

				}

				if ( weightAttribute ) {

					faceWeight = weightAttribute.getX( i0 )
						+ weightAttribute.getX( i1 )
						+ weightAttribute.getX( i2 );

				}

				_face.a.fromBufferAttribute( positionAttribute, i0 );
				_face.b.fromBufferAttribute( positionAttribute, i1 );
				_face.c.fromBufferAttribute( positionAttribute, i2 );
				faceWeight *= _face.getArea();

				faceWeights[ i ] = faceWeight;

			}

			// Store cumulative total face weights in an array, where weight index
			// corresponds to face index.

			const distribution = new Float32Array( totalFaces );
			let cumulativeTotal = 0;

			for ( let i = 0; i < totalFaces; i ++ ) {

				cumulativeTotal += faceWeights[ i ];
				distribution[ i ] = cumulativeTotal;

			}

			this.distribution = distribution;
			return this;

		}

		/**
		 * Allows to set a custom random number generator. Default is `Math.random()`.
		 *
		 * @param {Function} randomFunction - A random number generator.
		 * @return {MeshSurfaceSampler} A reference to this sampler.
		 */
		setRandomGenerator( randomFunction ) {

			this.randomFunction = randomFunction;
			return this;

		}

		/**
		 * Selects a random point on the surface of the input geometry, returning the
		 * position and optionally the normal vector, color and UV Coordinate at that point.
		 * Time complexity is O(log n) for a surface with n faces.
		 *
		 * @param {Vector3} targetPosition - The target object holding the sampled position.
		 * @param {Vector3} targetNormal - The target object holding the sampled normal.
		 * @param {Color} targetColor - The target object holding the sampled color.
		 * @param {Vector2} targetUV -  The target object holding the sampled uv coordinates.
		 * @return {MeshSurfaceSampler} A reference to this sampler.
		 */
		sample( targetPosition, targetNormal, targetColor, targetUV ) {

			const faceIndex = this._sampleFaceIndex();
			return this._sampleFace( faceIndex, targetPosition, targetNormal, targetColor, targetUV );

		}

		// private

		_sampleFaceIndex() {

			const cumulativeTotal = this.distribution[ this.distribution.length - 1 ];
			return this._binarySearch( this.randomFunction() * cumulativeTotal );

		}

		_binarySearch( x ) {

			const dist = this.distribution;
			let start = 0;
			let end = dist.length - 1;

			let index = - 1;

			while ( start <= end ) {

				const mid = Math.ceil( ( start + end ) / 2 );

				if ( mid === 0 || dist[ mid - 1 ] <= x && dist[ mid ] > x ) {

					index = mid;

					break;

				} else if ( x < dist[ mid ] ) {

					end = mid - 1;

				} else {

					start = mid + 1;

				}

			}

			return index;

		}

		_sampleFace( faceIndex, targetPosition, targetNormal, targetColor, targetUV ) {

			let u = this.randomFunction();
			let v = this.randomFunction();

			if ( u + v > 1 ) {

				u = 1 - u;
				v = 1 - v;

			}

			// get the vertex attribute indices
			const indexAttribute = this.indexAttribute;
			let i0 = faceIndex * 3;
			let i1 = faceIndex * 3 + 1;
			let i2 = faceIndex * 3 + 2;
			if ( indexAttribute ) {

				i0 = indexAttribute.getX( i0 );
				i1 = indexAttribute.getX( i1 );
				i2 = indexAttribute.getX( i2 );

			}

			_face.a.fromBufferAttribute( this.positionAttribute, i0 );
			_face.b.fromBufferAttribute( this.positionAttribute, i1 );
			_face.c.fromBufferAttribute( this.positionAttribute, i2 );

			targetPosition
				.set( 0, 0, 0 )
				.addScaledVector( _face.a, u )
				.addScaledVector( _face.b, v )
				.addScaledVector( _face.c, 1 - ( u + v ) );

			if ( targetNormal !== undefined ) {

				if ( this.normalAttribute !== undefined ) {

					_face.a.fromBufferAttribute( this.normalAttribute, i0 );
					_face.b.fromBufferAttribute( this.normalAttribute, i1 );
					_face.c.fromBufferAttribute( this.normalAttribute, i2 );
					targetNormal.set( 0, 0, 0 ).addScaledVector( _face.a, u ).addScaledVector( _face.b, v ).addScaledVector( _face.c, 1 - ( u + v ) ).normalize();

				} else {

					_face.getNormal( targetNormal );

				}

			}

			if ( targetColor !== undefined && this.colorAttribute !== undefined ) {

				_face.a.fromBufferAttribute( this.colorAttribute, i0 );
				_face.b.fromBufferAttribute( this.colorAttribute, i1 );
				_face.c.fromBufferAttribute( this.colorAttribute, i2 );

				_color$1
					.set( 0, 0, 0 )
					.addScaledVector( _face.a, u )
					.addScaledVector( _face.b, v )
					.addScaledVector( _face.c, 1 - ( u + v ) );

				targetColor.r = _color$1.x;
				targetColor.g = _color$1.y;
				targetColor.b = _color$1.z;

			}

			if ( targetUV !== undefined && this.uvAttribute !== undefined ) {

				_uva.fromBufferAttribute( this.uvAttribute, i0 );
				_uvb.fromBufferAttribute( this.uvAttribute, i1 );
				_uvc.fromBufferAttribute( this.uvAttribute, i2 );
				targetUV.set( 0, 0 ).addScaledVector( _uva, u ).addScaledVector( _uvb, v ).addScaledVector( _uvc, 1 - ( u + v ) );

			}

			return this;

		}

	}

	function surfacescatter(model, params, program) {
	    console.log("SURFACE SCATTER", params);



	    function getMesh(m) {
	        // only scan one level for now
	        if (m.isMesh) {
	            return m
	        }
	        for (let child of m.children) {
	            if (child.isMesh) {
	                return child
	            }
	        }
	    }


	    function resample() {

	        console.log("SAMPLING", model);

	        const mesh = getMesh(model);

	        const vertexCount = mesh.geometry.getAttribute( 'position' ).count;

	        console.info( 'Sampling ' + count + ' points from a surface with ' + vertexCount + ' vertices...' );

	        //

	        console.time( '.build()' );

	        sampler = new MeshSurfaceSampler( mesh )
	            .setWeightAttribute(  null )
	            .build();

	        console.timeEnd( '.build()' );

	        //

	        console.time( '.sample()' );

	        for ( let i = 0; i < count; i ++ ) {

	            ages[ i ] = Math.random();
	            scales[ i ] = scaleCurve( ages[ i ] );

	            resampleParticle( i );

	        }

	        console.timeEnd( '.sample()' );

	        stemMesh.instanceMatrix.needsUpdate = true;
	        blossomMesh.instanceMatrix.needsUpdate = true;

	        console.log(stemMesh, blossomMesh);

	    }

	    
	    
	    
	    const api = {

	        count: 200,
	        distribution: 'random',
	        resample: resample,
	        surfaceColor: 0xFFF784,
	        backgroundColor: 0xE39469,

	    };


	    const {
	        instancesrc = ""
	    } = params;


	    let stemMesh, blossomMesh;
	    let stemGeometry, blossomGeometry;
	    let stemMaterial, blossomMaterial;

	    let sampler;
	    const count = api.count;
	    const ages = new Float32Array( count );
	    const scales = new Float32Array( count );
	    const dummy = new Object3D();

	    const _position = new Vector3();
	    const _normal = new Vector3();
	    const _scale = new Vector3();

	    // let surfaceGeometry = new THREE.BoxGeometry( 10, 10, 10 ).toNonIndexed();
	    //const surfaceGeometry = new THREE.TorusKnotGeometry( 10, 3, 100, 16 ).toNonIndexed();
	    //const surfaceMaterial = new THREE.MeshLambertMaterial( { color: api.surfaceColor, wireframe: false } );
	    //const surface = new THREE.Mesh( surfaceGeometry, surfaceMaterial );

	    // Source: https://gist.github.com/gre/1650294
	    const easeOutCubic = function ( t ) {

	        return ( -- t ) * t * t + 1;

	    };

	    // Scaling curve causes particles to grow quickly, ease gradually into full scale, then
	    // disappear quickly. More of the particle's lifetime is spent around full scale.
	    const scaleCurve = function ( t ) {

	        return Math.abs( easeOutCubic( ( t > 0.5 ? 1 - t : t ) * 2 ) ) / 200;

	    };

	    const group = new Group$1();


	    function resampleParticle( i ) {

	        sampler.sample( _position, _normal );
	        _normal.add( _position );

	        dummy.position.copy( _position );
	        dummy.scale.set( scales[ i ], scales[ i ], scales[ i ] );
	        dummy.lookAt( _normal );
	        dummy.updateMatrix();

	        stemMesh.setMatrixAt( i, dummy.matrix );
	        blossomMesh.setMatrixAt( i, dummy.matrix );

	    }


	    let tick = () => {};


	    const loader = new GLTFLoader(program.assetManager);
	   
	    console.log("instancesrc", instancesrc);

	    loader.load( instancesrc, function ( gltf ) {

	        
	        const _stemMesh = gltf.scene.getObjectByName( 'flower1' );
	        const _blossomMesh = gltf.scene.getObjectByName( 'flower2' );

	        stemGeometry = _stemMesh.geometry.clone();
	        blossomGeometry = _blossomMesh.geometry.clone();

	        console.log("INSTANCE SRC LOADED", gltf, _stemMesh, _blossomMesh);


	        const defaultTransform = new Matrix4()
	            .makeRotationX( Math.PI )
	            .multiply( new Matrix4().makeScale( 7, 7, 7 ) );

	        stemGeometry.applyMatrix4( defaultTransform );
	        blossomGeometry.applyMatrix4( defaultTransform );

	        stemMaterial = _stemMesh.material;
	        blossomMaterial = _blossomMesh.material;

	        stemMaterial = new MeshBasicMaterial({
	            color: "red"
	        });
	        blossomMaterial = new MeshBasicMaterial({
	            color: "#ffffff"
	        });

	        stemMesh = new InstancedMesh( stemGeometry, stemMaterial, count );
	        blossomMesh = new InstancedMesh( blossomGeometry, blossomMaterial, count );

	        group.add( stemMesh );
	        group.add( blossomMesh );

	        // Assign random colors to the blossoms.
	        const color = new Color();
	        const blossomPalette = [ 0xF20587, 0xF2D479, 0xF2C879, 0xF2B077, 0xF24405 ];

	        for ( let i = 0; i < count; i ++ ) {

	            color.setHex( blossomPalette[ Math.floor( Math.random() * blossomPalette.length ) ] );
	            blossomMesh.setColorAt( i, color );

	        }

	        // Instance matrices will be updated every frame.
	        stemMesh.instanceMatrix.setUsage( DynamicDrawUsage );
	        blossomMesh.instanceMatrix.setUsage( DynamicDrawUsage );

	        resample();


	        function updateParticle( i ) {

	            ages[ i ] += 0.005;

	            if ( ages[ i ] >= 1 ) {

	                ages[ i ] = 0.005;
	                scales[ i ] = scaleCurve( ages[ i ] );

	                resampleParticle( i );

	                return;

	            }

	            // Update scale.

	            const prevScale = scales[ i ];
	            scales[ i ] = scaleCurve( ages[ i ] );
	            _scale.set( scales[ i ] / prevScale, scales[ i ] / prevScale, scales[ i ] / prevScale );

	            // Update transform.

	            stemMesh.getMatrixAt( i, dummy.matrix );
	            dummy.matrix.scale( _scale );
	            stemMesh.setMatrixAt( i, dummy.matrix );
	            blossomMesh.setMatrixAt( i, dummy.matrix );

	        }

	        tick = () => {

	            if ( stemMesh && blossomMesh ) {

	                // scene.rotation.x = Math.sin( time / 4 );
	                // scene.rotation.y = Math.sin( time / 2 );

	                for ( let i = 0; i < api.count; i ++ ) {
	                    updateParticle( i );
	                }

	                stemMesh.instanceMatrix.needsUpdate = true;
	                blossomMesh.instanceMatrix.needsUpdate = true;

	                stemMesh.computeBoundingSphere();
	                blossomMesh.computeBoundingSphere();

	            }

	        };


	        


	    } );
	    
	    return {
	        mesh: group,
	        tick: (context) => {
	            tick(context);
	        }
	    }


	    
	}



	var mods = /*#__PURE__*/Object.freeze({
		__proto__: null,
		surfacescatter: surfacescatter
	});

	class Model extends Shape$1 {
	    
		async loadModel(grp, program) {
			console.log("MODEL LOAD", this.params, this.params.meshmod, mods);

			const {
				meshmod = 'none'
			} = this.params;
			

			if (this.data || this.loading) {
				return
			}

			// Instantiate a loader
			//const loader = new DRACOLoader();

			// Specify path to a folder containing WASM/JS decoding libraries.
			//loader.setDecoderPath( '/examples/jsm/libs/draco/' );
			//loader.preload();

			if (this.params.src) {
				this.loading = true;

				const m = await this.loadGLTF(this.params.src, program);
				//console.log("MODEL LOADED SRC", m, this.params.src)

				m.scene.traverse( function ( child ) {
					if ( child.isMesh ) {
						child.castShadow = true;
						child.receiveShadow = true;
						//console.log("MODEL CHILD", child, child.material);
						//child.material = new THREE.MeshStandardMaterial({
						//	color: "#333333"
						//})
					}
				});

				let mesh;

				const modder = mods[meshmod];
				let modifier;
				

				if (modder) {
					modifier = modder(m.scene, this.params, program);
					mesh = modifier.mesh;
				} else {
					mesh = m.scene;
				}

				grp.add(mesh);

				this.loading = false;

				return { 
					modifier,
					mesh: grp
				}
				
				//this.render()
			}
		}

		createMesh(program, parent) {

			//console.log("CREATE MESH", program, this.params)

			//this.removeNodes()
			
			const grp = new Group$1();
			this.applyTransforms(grp);
			let modifier = null;

			this.loadModel(grp, program).then(({modifier: mod}) => {
				
				modifier = mod;
				/*
				if (m.animations && m.animations.length) {
					mixer = new THREE.AnimationMixer(m);
					console.log("HAS ANIMATIONS", m, m.animations)
		
					// Play all animations
					m.animations.forEach( (clip) => {
						const action = mixer.clipAction(clip);
						action.play();
					});
				}
				*/

				//console.log("MODEL LOADED WITH ANIMATIONS", mixer)

			});


			this.tick = (context) => {

				//console.log("modifier", modifier)

				const { time } = context.clock;
				if (modifier) {
					modifier.tick(time);
				}
			};
			

			return grp;		
		}

	}

	//import { SpriteText2D, textAlign } from 'three-text2d'



	class TroikaTextShape extends Shape$1 {
	    createMesh() {
	        // Create:
	        const container = new Group$1();

	        // text is rendered by childnodes
	        // see ./index.js#TextNode 

	        this.applyTransforms(container);


	        this.tick = (context) => {
	            this.childNodes.forEach(child => {
	                child.tick(context);
	            });
	        };


	        return container;
	    }

	} 


	/*
	function createCanvasTexture(options = {}) {

	    const canvas = document.createElement('canvas')
	    const ctx = canvas.getContext('2d')

	    //document.body.appendChild(canvas)

	    options.lineHeight = options.lineHeight || 1;

	    function draw(text) {
	        ctx.font = options.font || '48px serif'

	        let lineHeight = 100; // getFontHeight(options.font);

	        const lines = (text || "")

	        const textWidth = 20;
	        const textHeight = 50;

	        //const textWidth = Math.max.apply(null, lines.map(line => Math.ceil(ctx.measureText(line).width)));
	        //const textHeight = lineHeight + lineHeight * options.lineHeight * (lines.length - 1);

	        // 2 = prevent canvas being 0 size when using empty / null text
	        canvas.width = Math.max(2, THREE.MathUtils.ceilPowerOfTwo(textWidth + (2 * options.horizontalPadding || 0)));
	        canvas.height = Math.max(2, THREE.MathUtils.ceilPowerOfTwo(textHeight + (2 * options.verticalPadding || 0)));

	        const { width, height } = canvas

	        const { horizontalPadding = 0, verticalPadding = 0 } = options

	        //lineHeight = lineHeight * options.lineHeight * i

	        ctx.font = options.font || 'helvetica'
	        ctx.clearRect(0, 0, width, height);

	        ctx.fillStyle = 'yellow';
	        ctx.fillRect(0,0,100,100)
	        
	        const alignX = options.align && options.align.x || 0;

	        const x = textWidth * (0.5 - alignX * 0.5);
	        const y = 0.5 // * ((lineHeight * options.lineHeight || 1) - lineHeight);

	        ctx.fillStyle = 'red';
	        ctx.fillText("Hello world", 10, 50);

	        return canvas

	    }
	    

	    return {
	        getTexture(text) {
	           return draw(text);
	        }
	    }
	}








	class CanvasTextShape extends Shape {
		getGeometry(program) {
			

	        //const viewport = program.renderer.getCurrentViewport()
	        //console.log("viewport", viewport)

	        const aspect = window.innerWidth / window.innerHeight;

			let plane = new THREE.PlaneGeometry(this.params.width, this.params.height, 32);
	       
			return plane
		}

	    // default mesh
	    createMesh(program) {	

	        const container = new THREE.Group()
	        
	        const material = this.getMaterial(program)

	        const sprite = new THREE.Sprite( material )
	        sprite.scale.set(1, 1, 1)
	        // material.map.width, material.map.height

	        //const geometry = this.getGeometry(program)
	        //const material = this.getMaterial(program, geometry)

	        //const mesh = new THREE.Mesh(geometry, material)

	        container.add(sprite);

	        this.applyTransforms(container)

	        //container.position.x = program.camera.left + 0.5;
	        //container.position.y = 0;


	        console.log("Text 2D", this.params)

	        return container;
	    }

	    getMaterial(program, geometry) {
	        const color = new THREE.Color(...this.color)

	        const canvas = createCanvasTexture({

	        });

	        const canvasTex = canvas.getTexture("Some text")

	        const texture = new THREE.Texture(canvasTex);
	        texture.needsUpdate = true;

	        const material = new THREE.SpriteMaterial({ map: texture });

	        
	        return material
	    }


	}





	*/

	/**
	 * A loader for loading fonts.
	 *
	 * You can convert fonts online using [facetype.js]{@link https://gero3.github.io/facetype.js/}.
	 *
	 * ```js
	 * const loader = new FontLoader();
	 * const font = await loader.loadAsync( 'fonts/helvetiker_regular.typeface.json' );
	 * ```
	 *
	 * @augments Loader
	 * @three_import import { FontLoader } from 'three/addons/loaders/FontLoader.js';
	 */
	class FontLoader extends Loader {

		/**
		 * Constructs a new font loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			super( manager );

		}

		/**
		 * Starts loading from the given URL and passes the loaded font
		 * to the `onLoad()` callback.
		 *
		 * @param {string} url - The path/URL of the file to be loaded. This can also be a data URI.
		 * @param {function(Font)} onLoad - Executed when the loading process has been finished.
		 * @param {onProgressCallback} onProgress - Executed while the loading is in progress.
		 * @param {onErrorCallback} onError - Executed when errors occur.
		 */
		load( url, onLoad, onProgress, onError ) {

			const scope = this;

			const loader = new FileLoader( this.manager );
			loader.setPath( this.path );
			loader.setRequestHeader( this.requestHeader );
			loader.setWithCredentials( this.withCredentials );
			loader.load( url, function ( text ) {

				const font = scope.parse( JSON.parse( text ) );

				if ( onLoad ) onLoad( font );

			}, onProgress, onError );

		}

		/**
		 * Parses the given font data and returns the resulting font.
		 *
		 * @param {Object} json - The raw font data as a JSON object.
		 * @return {Font} The font.
		 */
		parse( json ) {

			return new Font( json );

		}

	}

	/**
	 * Class representing a font.
	 */
	class Font {

		/**
		 * Constructs a new font.
		 *
		 * @param {Object} data - The font data as JSON.
		 */
		constructor( data ) {

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isFont = true;

			this.type = 'Font';

			/**
			 * The font data as JSON.
			 *
			 * @type {Object}
			 */
			this.data = data;

		}

		/**
		 * Generates geometry shapes from the given text and size. The result of this method
		 * should be used with {@link ShapeGeometry} to generate the actual geometry data.
		 *
		 * @param {string} text - The text.
		 * @param {number} [size=100] - The text size.
		 * @return {Array<Shape>} An array of shapes representing the text.
		 */
		generateShapes( text, size = 100 ) {

			const shapes = [];
			const paths = createPaths( text, size, this.data );

			for ( let p = 0, pl = paths.length; p < pl; p ++ ) {

				shapes.push( ...paths[ p ].toShapes() );

			}

			return shapes;

		}

	}

	function createPaths( text, size, data ) {

		const chars = Array.from( text );
		const scale = size / data.resolution;
		const line_height = ( data.boundingBox.yMax - data.boundingBox.yMin + data.underlineThickness ) * scale;

		const paths = [];

		let offsetX = 0, offsetY = 0;

		for ( let i = 0; i < chars.length; i ++ ) {

			const char = chars[ i ];

			if ( char === '\n' ) {

				offsetX = 0;
				offsetY -= line_height;

			} else {

				const ret = createPath( char, scale, offsetX, offsetY, data );
				offsetX += ret.offsetX;
				paths.push( ret.path );

			}

		}

		return paths;

	}

	function createPath( char, scale, offsetX, offsetY, data ) {

		const glyph = data.glyphs[ char ] || data.glyphs[ '?' ];

		if ( ! glyph ) {

			console.error( 'THREE.Font: character "' + char + '" does not exists in font family ' + data.familyName + '.' );

			return;

		}

		const path = new ShapePath();

		let x, y, cpx, cpy, cpx1, cpy1, cpx2, cpy2;

		if ( glyph.o ) {

			const outline = glyph._cachedOutline || ( glyph._cachedOutline = glyph.o.split( ' ' ) );

			for ( let i = 0, l = outline.length; i < l; ) {

				const action = outline[ i ++ ];

				switch ( action ) {

					case 'm': // moveTo

						x = outline[ i ++ ] * scale + offsetX;
						y = outline[ i ++ ] * scale + offsetY;

						path.moveTo( x, y );

						break;

					case 'l': // lineTo

						x = outline[ i ++ ] * scale + offsetX;
						y = outline[ i ++ ] * scale + offsetY;

						path.lineTo( x, y );

						break;

					case 'q': // quadraticCurveTo

						cpx = outline[ i ++ ] * scale + offsetX;
						cpy = outline[ i ++ ] * scale + offsetY;
						cpx1 = outline[ i ++ ] * scale + offsetX;
						cpy1 = outline[ i ++ ] * scale + offsetY;

						path.quadraticCurveTo( cpx1, cpy1, cpx, cpy );

						break;

					case 'b': // bezierCurveTo

						cpx = outline[ i ++ ] * scale + offsetX;
						cpy = outline[ i ++ ] * scale + offsetY;
						cpx1 = outline[ i ++ ] * scale + offsetX;
						cpy1 = outline[ i ++ ] * scale + offsetY;
						cpx2 = outline[ i ++ ] * scale + offsetX;
						cpy2 = outline[ i ++ ] * scale + offsetY;

						path.bezierCurveTo( cpx1, cpy1, cpx2, cpy2, cpx, cpy );

						break;

				}

			}

		}

		return { offsetX: glyph.ha * scale, path: path };

	}

	/**
	 * A class for generating text as a single geometry. It is constructed by providing a string of text, and a set of
	 * parameters consisting of a loaded font and extrude settings.
	 *
	 * See the {@link FontLoader} page for additional details.
	 *
	 * `TextGeometry` uses [typeface.json]{@link http://gero3.github.io/facetype.js/} generated fonts.
	 * Some existing fonts can be found located in `/examples/fonts`.
	 *
	 * ```js
	 * const loader = new FontLoader();
	 * const font = await loader.loadAsync( 'fonts/helvetiker_regular.typeface.json' );
	 * const geometry = new TextGeometry( 'Hello three.js!', {
	 * 	font: font,
	 * 	size: 80,
	 * 	depth: 5,
	 * 	curveSegments: 12
	 * } );
	 * ```
	 *
	 * @augments ExtrudeGeometry
	 * @three_import import { TextGeometry } from 'three/addons/geometries/TextGeometry.js';
	 */
	class TextGeometry extends ExtrudeGeometry {

		/**
		 * Constructs a new text geometry.
		 *
		 * @param {string} text - The text that should be transformed into a geometry.
		 * @param {TextGeometry~Options} [parameters] - The text settings.
		 */
		constructor( text, parameters = {} ) {

			const font = parameters.font;

			if ( font === undefined ) {

				super(); // generate default extrude geometry

			} else {

				const shapes = font.generateShapes( text, parameters.size );

				// defaults

				if ( parameters.depth === undefined ) parameters.depth = 50;
				if ( parameters.bevelThickness === undefined ) parameters.bevelThickness = 10;
				if ( parameters.bevelSize === undefined ) parameters.bevelSize = 8;
				if ( parameters.bevelEnabled === undefined ) parameters.bevelEnabled = false;

				super( shapes, parameters );

			}

			this.type = 'TextGeometry';

		}

	}

	const vertexShader = /* glsl */`
    uniform float uTime;
    uniform float uIntensity;
    
    varying vec2 vUv;
    varying float time;
    varying vec4 vPosition;
    

    void main() { 

        vec3 transformed = position;
        transformed.z += sin(position.y + position.x + uTime / 12.0) * 0.25 * uIntensity;
        transformed.x += sin(position.y + position.x + uTime / 12.0) * 0.25 * uIntensity;

        vec4 modelPosition = modelMatrix * vec4(transformed, 1.0);
        vec4 viewPosition = viewMatrix * modelPosition;
        vec4 projectedPosition = projectionMatrix * viewPosition;

        gl_Position = projectedPosition;

        vUv = uv;
        time = uTime;
        vPosition = projectedPosition;

    }   
  `;


	const fragmentShader = /* glsl */`
    varying vec2 vUv;
    varying vec4 vPosition;
    varying float time;

    uniform sampler2D uTexture;
    uniform vec3 uColor;
    uniform float uIntensity;

    void main()	{
        vec2 uv = vUv; 

        uv.x += sin(uv.y + time * 0.5) * 0.15; // uIntensity * 0.15

        vec2 repeat = vec2(8.0, 18.0);
        uv = fract(uv * repeat - vec2(0.0, time * 2.0 + 1.5 * uIntensity));
        
        vec4 image = texture2D(uTexture, uv);
        vec4 color = image;

        //color = mix(image, color, sin(uv.y + uIntensity));
        //gl_FragColor = color; // vec4(vUv, 1.0, 1.0);

        
        gl_FragColor = color;
        #include <tonemapping_fragment>
        #include <colorspace_fragment>
    }
`;




	function createText( message, height, {debug = false} = {} ) {

	    const canvas = document.createElement( 'canvas' );
	    const context = canvas.getContext( '2d' );
	    let metrics = null;
	    const textHeight = 100;
	    context.font = 'normal ' + textHeight + 'px Arial';
	    metrics = context.measureText( message );
	    const textWidth = metrics.width;
	    canvas.width = textWidth;
	    canvas.height = textHeight;
	    context.font = 'normal ' + textHeight + 'px Arial';
	    context.textAlign = 'center';
	    context.textBaseline = 'middle';
	    context.fillStyle = 'red';
	    context.fillText( message, textWidth / 2, textHeight / 2 );

	    if (debug) {
	        document.body.appendChild(canvas);
	        canvas.style.position = 'absolute';
	        canvas.style.top = '0';
	        canvas.style.zIndex = 1000; 
	    }

	    const texture = new Texture( canvas );
	    texture.repeat = UVMapping;
	    //texture.premultiplyAlpha = true;
	    texture.minFilter = LinearFilter;
	    texture.needsUpdate = true;

	    let plane;

	    if (debug) {
	        const material = new MeshBasicMaterial( {
	            color: 0xffffff,
	            side: DoubleSide,
	            map: texture,
	            transparent: true,
	        } );

	        console.log(( height * textWidth ) / textHeight,
	            height);

	        const geometry = new PlaneGeometry(
	            ( height * textWidth ) / textHeight,
	            height
	        );
	        plane = new Mesh( geometry, material );

	    }
	    return {
	        texture, mesh: plane
	    }

	}




	function kineticType(params, program) {
	    const container = new Group$1();

	    const {
	        html = [],
	        content = '',
	        debug = false
	    } = params;

	    const textData = content || (html || [])
	            .map(block => block.text || '').join(' ');

	    // "UNIVERSE"

	    const text = createText(" HONEY N' JOY ", 1, { debug });

	    const geometry = new TorusGeometry(1, 0.6, 64, 100);
	    const innerGeometry = new TorusGeometry(0.9, 0.3, 32, 32);

	    //const material = getMaterial(params, program, geometry)

	    const uniforms = {
	        uTime: new Uniform(0),
	        uTexture: new Uniform(text.texture),
	        uIntensity: new Uniform(6)
	    };

	    const basicMaterial = new MeshStandardMaterial({
	        color: '#8D0700'
	    });

	    const material = new ShaderMaterial({
	        vertexShader,
	        fragmentShader,
	        uniforms,
	        side: DoubleSide,
	        transparent: true,
	        alphaTest: 0.5
	    });

	    const mesh = new Mesh(geometry, material);

	    const meshInner = new Mesh(innerGeometry, basicMaterial);
	    //meshInner.scale.set(0.9, 0.9, 0.9)
	    
	    container.add(mesh);
	    container.add(meshInner);

	    if (debug) {
	        container.add(text.mesh);
	    }

	    function tick(context) {
	        const { analyser } = context;
	        const { time } = context.clock;
	        uniforms.uTime.value = time;

	        uniforms.uIntensity.value = analyser.peaks.avg / 50;

	        //mesh.rotation.y += 0.01;
	    }

	    return {
	        mesh: container, tick
	    }
	}

	function getMaterial(params, program, geometry) {
	    // const color = new THREE.Color(...this.color)

	    const { assetManager } = program;

	    const {
	        color,
	        transparent = true, wireframe = false, map,
	    } = params;

	    const uniforms = {
	        uTime: new Uniform(0),
	        uMin: new Uniform(0),
	        uMax: new Uniform(0),
	        uColor: { value: color }
	    };

	    if (map) {

	        const textureLoader = new TextureLoader(assetManager);
	        const texture = textureLoader.load(map, function(tex) {
	            // console.log("Text3D: texture loaded")
	            // 
	            // uniforms.uTextureSize.value.x = 
	        });
	        uniforms.uTexture = new Uniform(texture);
	        uniforms.uTextureSize = new Uniform(new Vector2(512, 512));
	    }
	    
	    let material;


	    {
	            material = new MeshStandardMaterial({
	            color,
	            wireframe,
	            transparent,
	            side: FrontSide,
	            //fragmentShader: fragment,
	            //vertexShader: vertex,
	            //uniforms,                    
	        });
	    }

	    const tick = (context) => {
	        const { time } = context.clock;

	        uniforms.uTime.value = time;
	        uniforms.uMin.value = geometry.boundingBox.min;
	        uniforms.uMax.value = geometry.boundingBox.min;

	    };

	    return {
	        material, tick
	    }
	}







	function basicText3D(params, program, parent) {


	        const container = new Group$1();

	        const { assetManager } = program;

	        //const geometry = this.getGeometry(program)
	        

	        //const mesh = new THREE.Mesh(geometry, material)

	        const fontLoader = new FontLoader(assetManager);

	        // font json file, use facetype.js

	        const {
	            family: fontFamilyJson,
	            html = [{ text: "TEXT" }],
	            size = 5,
	            depth = 0.02,
	            bevelThickness = 0.001,
	            bevelSize = 0.001,
	            bevelOffset = 0,
	            bevelSegments = 5,
	            content = "",
	            animation = null
	        } = params;

	        
	        const textData = content || (html || [])
	            .map(block => block.text || '').join(' ');

	        //console.log("LOADING FONT FILE LOADED",this.params, fontFamilyJson, textData )

	        //fetch(fontFamilyJson).then(async (resp) => {
	        //    const json = await resp.json()
	            //console.log("FONT FILE LOADED", json)
	        //})

	        let mesh;
	        let geometry;
	        let mat;

	        fontLoader.load(fontFamilyJson, (font) => {
	            //console.log("FONT FILE LOADED",font, textData)

	            const textGeometry = new TextGeometry(
	                textData,
	                {
	                    font,
	                    size: size / 100,
	                    depth,
	                    curveSegments: 12,
	                    bevelEnabled: true,
	                    bevelThickness,
	                    bevelSize,
	                    bevelOffset,
	                    bevelSegments
	                }
	            );

	            textGeometry.center();
	            textGeometry.computeBoundingBox();

	            //console.log("textGeometry", content, textGeometry)

	            geometry = textGeometry;

	            mat = getMaterial(params, program, geometry);
	            
	            const text = new Mesh(textGeometry, mat.material);
	            mesh = text;

	            /*

	            if (enableAnimation) {
	                mod = textAlongPath(text, this.params, program)
	                mesh = mod.mesh
	            } else {
	                mesh = text
	            }
	                */
	            
	            container.add(mesh);

	        });

	        const tick = (context) => {
	            // console.log("font  3d tick", mesh)
	            if (mat)
	                mat.tick(context);
	        };

	        return {
	            mesh: container, tick
	        }
	}











	const TextGenerators = {
	    basic: basicText3D,
	    kinetic: kineticType,
	};


	class Text3D extends Shape$1 {
		getGeometry(program) {
			
		}

	    // default mesh
	    createMesh(program) {	
	        const container = new Group$1();	
	        
	        const color = new Color(...this.color);

	        const {
	            type = 'basic'
	        } = this.params;

	        console.log("TEXT 3D", this.params);

	        const text = (TextGenerators[type] || TextGenerators.basic)({
	            ...this.params,
	            color,
	        }, program);

	        container.add(text.mesh);
	        
	        this.applyTransforms(container);
	            
	        const tick = (context) => {
	            text.tick(context);
	        };

	        this.tick = tick;

	        return container;
	    }


	    getMaterial(program, geometry) {
	        
	    }

	    get children() {
	        return []
	    }


	}

	// Helper for passes that need to fill the viewport with a single quad.

	const _camera = new OrthographicCamera( - 1, 1, 1, - 1, 0, 1 );

	// https://github.com/mrdoob/three.js/pull/21358

	class FullscreenTriangleGeometry extends BufferGeometry {

		constructor() {

			super();

			this.setAttribute( 'position', new Float32BufferAttribute( [ - 1, 3, 0, - 1, - 1, 0, 3, - 1, 0 ], 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( [ 0, 2, 0, 0, 2, 0 ], 2 ) );

		}

	}

	const _geometry = new FullscreenTriangleGeometry();


	/**
	 * This module is a helper for passes which need to render a full
	 * screen effect which is quite common in context of post processing.
	 *
	 * The intended usage is to reuse a single full screen quad for rendering
	 * subsequent passes by just reassigning the `material` reference.
	 *
	 * This module can only be used with {@link WebGLRenderer}.
	 *
	 * @augments Mesh
	 * @three_import import { FullScreenQuad } from 'three/addons/postprocessing/Pass.js';
	 */
	class FullScreenQuad {

		/**
		 * Constructs a new full screen quad.
		 *
		 * @param {?Material} material - The material to render te full screen quad with.
		 */
		constructor( material ) {

			this._mesh = new Mesh( _geometry, material );

		}

		/**
		 * Frees the GPU-related resources allocated by this instance. Call this
		 * method whenever the instance is no longer used in your app.
		 */
		dispose() {

			this._mesh.geometry.dispose();

		}

		/**
		 * Renders the full screen quad.
		 *
		 * @param {WebGLRenderer} renderer - The renderer.
		 */
		render( renderer ) {

			renderer.render( this._mesh, _camera );

		}

		/**
		 * The quad's material.
		 *
		 * @type {?Material}
		 */
		get material() {

			return this._mesh.material;

		}

		set material( value ) {

			this._mesh.material = value;

		}

	}

	/**
	 * GPUComputationRenderer, based on SimulationRenderer by @zz85.
	 *
	 * The GPUComputationRenderer uses the concept of variables. These variables are RGBA float textures that hold 4 floats
	 * for each compute element (texel).
	 *
	 * Each variable has a fragment shader that defines the computation made to obtain the variable in question.
	 * You can use as many variables you need, and make dependencies so you can use textures of other variables in the shader
	 * (the sampler uniforms are added automatically) Most of the variables will need themselves as dependency.
	 *
	 * The renderer has actually two render targets per variable, to make ping-pong. Textures from the current frame are used
	 * as inputs to render the textures of the next frame.
	 *
	 * The render targets of the variables can be used as input textures for your visualization shaders.
	 *
	 * Variable names should be valid identifiers and should not collide with THREE GLSL used identifiers.
	 * a common approach could be to use 'texture' prefixing the variable name; i.e texturePosition, textureVelocity...
	 *
	 * The size of the computation (sizeX * sizeY) is defined as 'resolution' automatically in the shader. For example:
	 * ```
	 * #DEFINE resolution vec2( 1024.0, 1024.0 )
	 * ```
	 * Basic use:
	 * ```js
	 * // Initialization...
	 *
	 * // Create computation renderer
	 * const gpuCompute = new GPUComputationRenderer( 1024, 1024, renderer );
	 *
	 * // Create initial state float textures
	 * const pos0 = gpuCompute.createTexture();
	 * const vel0 = gpuCompute.createTexture();
	 * // and fill in here the texture data...
	 *
	 * // Add texture variables
	 * const velVar = gpuCompute.addVariable( "textureVelocity", fragmentShaderVel, vel0 );
	 * const posVar = gpuCompute.addVariable( "texturePosition", fragmentShaderPos, pos0 );
	 *
	 * // Add variable dependencies
	 * gpuCompute.setVariableDependencies( velVar, [ velVar, posVar ] );
	 * gpuCompute.setVariableDependencies( posVar, [ velVar, posVar ] );
	 *
	 * // Add custom uniforms
	 * velVar.material.uniforms.time = { value: 0.0 };
	 *
	 * // Check for completeness
	 * const error = gpuCompute.init();
	 * if ( error !== null ) {
	 *		console.error( error );
	  * }
	 *
	 * // In each frame...
	 *
	 * // Compute!
	 * gpuCompute.compute();
	 *
	 * // Update texture uniforms in your visualization materials with the gpu renderer output
	 * myMaterial.uniforms.myTexture.value = gpuCompute.getCurrentRenderTarget( posVar ).texture;
	 *
	 * // Do your rendering
	 * renderer.render( myScene, myCamera );
	 * ```
	 *
	 * Also, you can use utility functions to create ShaderMaterial and perform computations (rendering between textures)
	 * Note that the shaders can have multiple input textures.
	 *
	 * ```js
	 * const myFilter1 = gpuCompute.createShaderMaterial( myFilterFragmentShader1, { theTexture: { value: null } } );
	 * const myFilter2 = gpuCompute.createShaderMaterial( myFilterFragmentShader2, { theTexture: { value: null } } );
	 *
	 * const inputTexture = gpuCompute.createTexture();
	 *
	 * // Fill in here inputTexture...
	 *
	 * myFilter1.uniforms.theTexture.value = inputTexture;
	 *
	 * const myRenderTarget = gpuCompute.createRenderTarget();
	 * myFilter2.uniforms.theTexture.value = myRenderTarget.texture;
	 *
	 * const outputRenderTarget = gpuCompute.createRenderTarget();
	 *
	 * // Now use the output texture where you want:
	 * myMaterial.uniforms.map.value = outputRenderTarget.texture;
	 *
	 * // And compute each frame, before rendering to screen:
	 * gpuCompute.doRenderTarget( myFilter1, myRenderTarget );
	 * gpuCompute.doRenderTarget( myFilter2, outputRenderTarget );
	 * ```
	 *
	 * @three_import import { GPUComputationRenderer } from 'three/addons/misc/GPUComputationRenderer.js';
	 */
	class GPUComputationRenderer {

		/**
		 * Constructs a new GPU computation renderer.
		 *
		 * @param {number} sizeX - Computation problem size is always 2d: sizeX * sizeY elements.
	 	 * @param {number} sizeY - Computation problem size is always 2d: sizeX * sizeY elements.
	 	 * @param {WebGLRenderer} renderer - The renderer.
		 */
		constructor( sizeX, sizeY, renderer ) {

			this.variables = [];

			this.currentTextureIndex = 0;

			let dataType = FloatType;

			const passThruUniforms = {
				passThruTexture: { value: null }
			};

			const passThruShader = createShaderMaterial( getPassThroughFragmentShader(), passThruUniforms );

			const quad = new FullScreenQuad( passThruShader );

			/**
			 * Sets the data type of the internal textures.
			 *
			 * @param {(FloatType|HalfFloatType)} type - The type to set.
			 * @return {GPUComputationRenderer} A reference to this renderer.
			 */
			this.setDataType = function ( type ) {

				dataType = type;
				return this;

			};

			/**
			 * Adds a compute variable to the renderer.
			 *
			 * @param {string} variableName - The variable name.
			 * @param {string} computeFragmentShader - The compute (fragment) shader source.
			 * @param {Texture} initialValueTexture - The initial value texture.
			 * @return {Object} The compute variable.
			 */
			this.addVariable = function ( variableName, computeFragmentShader, initialValueTexture ) {

				const material = this.createShaderMaterial( computeFragmentShader );

				const variable = {
					name: variableName,
					initialValueTexture: initialValueTexture,
					material: material,
					dependencies: null,
					renderTargets: [],
					wrapS: null,
					wrapT: null,
					minFilter: NearestFilter,
					magFilter: NearestFilter
				};

				this.variables.push( variable );

				return variable;

			};

			/**
			 * Sets variable dependencies.
			 *
			 * @param {Object} variable - The compute variable.
			 * @param {Array<Object>} dependencies - Other compute variables that represents the dependencies.
			 */
			this.setVariableDependencies = function ( variable, dependencies ) {

				variable.dependencies = dependencies;

			};

			/**
			 * Initializes the renderer.
			 *
			 * @return {?string} Returns `null` if no errors are detected. Otherwise returns the error message.
			 */
			this.init = function () {

				if ( renderer.capabilities.maxVertexTextures === 0 ) {

					return 'No support for vertex shader textures.';

				}

				for ( let i = 0; i < this.variables.length; i ++ ) {

					const variable = this.variables[ i ];

					// Creates rendertargets and initialize them with input texture
					variable.renderTargets[ 0 ] = this.createRenderTarget( sizeX, sizeY, variable.wrapS, variable.wrapT, variable.minFilter, variable.magFilter );
					variable.renderTargets[ 1 ] = this.createRenderTarget( sizeX, sizeY, variable.wrapS, variable.wrapT, variable.minFilter, variable.magFilter );
					this.renderTexture( variable.initialValueTexture, variable.renderTargets[ 0 ] );
					this.renderTexture( variable.initialValueTexture, variable.renderTargets[ 1 ] );

					// Adds dependencies uniforms to the ShaderMaterial
					const material = variable.material;
					const uniforms = material.uniforms;

					if ( variable.dependencies !== null ) {

						for ( let d = 0; d < variable.dependencies.length; d ++ ) {

							const depVar = variable.dependencies[ d ];

							if ( depVar.name !== variable.name ) {

								// Checks if variable exists
								let found = false;

								for ( let j = 0; j < this.variables.length; j ++ ) {

									if ( depVar.name === this.variables[ j ].name ) {

										found = true;
										break;

									}

								}

								if ( ! found ) {

									return 'Variable dependency not found. Variable=' + variable.name + ', dependency=' + depVar.name;

								}

							}

							uniforms[ depVar.name ] = { value: null };

							material.fragmentShader = '\nuniform sampler2D ' + depVar.name + ';\n' + material.fragmentShader;

						}

					}

				}

				this.currentTextureIndex = 0;

				return null;

			};

			/**
			 * Executes the compute. This method is usually called in the animation loop.
			 */
			this.compute = function () {

				const currentTextureIndex = this.currentTextureIndex;
				const nextTextureIndex = this.currentTextureIndex === 0 ? 1 : 0;

				for ( let i = 0, il = this.variables.length; i < il; i ++ ) {

					const variable = this.variables[ i ];

					// Sets texture dependencies uniforms
					if ( variable.dependencies !== null ) {

						const uniforms = variable.material.uniforms;

						for ( let d = 0, dl = variable.dependencies.length; d < dl; d ++ ) {

							const depVar = variable.dependencies[ d ];

							uniforms[ depVar.name ].value = depVar.renderTargets[ currentTextureIndex ].texture;

						}

					}

					// Performs the computation for this variable
					this.doRenderTarget( variable.material, variable.renderTargets[ nextTextureIndex ] );

				}

				this.currentTextureIndex = nextTextureIndex;

			};

			/**
			 * Returns the current render target for the given compute variable.
			 *
			 * @param {Object} variable - The compute variable.
			 * @return {WebGLRenderTarget} The current render target.
			 */
			this.getCurrentRenderTarget = function ( variable ) {

				return variable.renderTargets[ this.currentTextureIndex ];

			};

			/**
			 * Returns the alternate render target for the given compute variable.
			 *
			 * @param {Object} variable - The compute variable.
			 * @return {WebGLRenderTarget} The alternate render target.
			 */
			this.getAlternateRenderTarget = function ( variable ) {

				return variable.renderTargets[ this.currentTextureIndex === 0 ? 1 : 0 ];

			};

			/**
			 * Frees all internal resources. Call this method if you don't need the
			 * renderer anymore.
			 */
			this.dispose = function () {

				quad.dispose();

				const variables = this.variables;

				for ( let i = 0; i < variables.length; i ++ ) {

					const variable = variables[ i ];

					if ( variable.initialValueTexture ) variable.initialValueTexture.dispose();

					const renderTargets = variable.renderTargets;

					for ( let j = 0; j < renderTargets.length; j ++ ) {

						const renderTarget = renderTargets[ j ];
						renderTarget.dispose();

					}

				}

			};

			function addResolutionDefine( materialShader ) {

				materialShader.defines.resolution = 'vec2( ' + sizeX.toFixed( 1 ) + ', ' + sizeY.toFixed( 1 ) + ' )';

			}

			/**
			 * Adds a resolution defined for the given material shader.
			 *
			 * @param {Object} materialShader - The material shader.
			 */
			this.addResolutionDefine = addResolutionDefine;


			// The following functions can be used to compute things manually

			function createShaderMaterial( computeFragmentShader, uniforms ) {

				uniforms = uniforms || {};

				const material = new ShaderMaterial( {
					name: 'GPUComputationShader',
					uniforms: uniforms,
					vertexShader: getPassThroughVertexShader(),
					fragmentShader: computeFragmentShader
				} );

				addResolutionDefine( material );

				return material;

			}

			this.createShaderMaterial = createShaderMaterial;

			/**
			 * Creates a new render target from the given parameters.
			 *
			 * @param {number} sizeXTexture - The width of the render target.
			 * @param {number} sizeYTexture - The height of the render target.
			 * @param {number} wrapS - The wrapS value.
			 * @param {number} wrapT - The wrapS value.
			 * @param {number} minFilter - The minFilter value.
			 * @param {number} magFilter - The magFilter value.
			 * @return {WebGLRenderTarget} The new render target.
			 */
			this.createRenderTarget = function ( sizeXTexture, sizeYTexture, wrapS, wrapT, minFilter, magFilter ) {

				sizeXTexture = sizeXTexture || sizeX;
				sizeYTexture = sizeYTexture || sizeY;

				wrapS = wrapS || ClampToEdgeWrapping;
				wrapT = wrapT || ClampToEdgeWrapping;

				minFilter = minFilter || NearestFilter;
				magFilter = magFilter || NearestFilter;

				const renderTarget = new WebGLRenderTarget( sizeXTexture, sizeYTexture, {
					wrapS: wrapS,
					wrapT: wrapT,
					minFilter: minFilter,
					magFilter: magFilter,
					format: RGBAFormat,
					type: dataType,
					depthBuffer: false
				} );

				return renderTarget;

			};

			/**
			 * Creates a new data texture.
			 *
			 * @return {DataTexture} The new data texture.
			 */
			this.createTexture = function () {

				const data = new Float32Array( sizeX * sizeY * 4 );
				const texture = new DataTexture( data, sizeX, sizeY, RGBAFormat, FloatType );
				texture.needsUpdate = true;
				return texture;

			};

			/**
			 * Renders the given texture into the given render target.
			 *
			 * @param {Texture} input - The input.
			 * @param {WebGLRenderTarget} output - The output.
			 */
			this.renderTexture = function ( input, output ) {

				passThruUniforms.passThruTexture.value = input;

				this.doRenderTarget( passThruShader, output );

				passThruUniforms.passThruTexture.value = null;

			};


			/**
			 * Renders the given material into the given render target
			 * with a full-screen pass.
			 *
			 * @param {Material} material - The material.
			 * @param {WebGLRenderTarget} output - The output.
			 */
			this.doRenderTarget = function ( material, output ) {

				const currentRenderTarget = renderer.getRenderTarget();

				const currentXrEnabled = renderer.xr.enabled;
				const currentShadowAutoUpdate = renderer.shadowMap.autoUpdate;

				renderer.xr.enabled = false; // Avoid camera modification
				renderer.shadowMap.autoUpdate = false; // Avoid re-computing shadows
				quad.material = material;
				renderer.setRenderTarget( output );
				quad.render( renderer );
				quad.material = passThruShader;

				renderer.xr.enabled = currentXrEnabled;
				renderer.shadowMap.autoUpdate = currentShadowAutoUpdate;

				renderer.setRenderTarget( currentRenderTarget );

			};

			// Shaders

			function getPassThroughVertexShader() {

				return	'void main()	{\n' +
						'\n' +
						'	gl_Position = vec4( position, 1.0 );\n' +
						'\n' +
						'}\n';

			}

			function getPassThroughFragmentShader() {

				return	'uniform sampler2D passThruTexture;\n' +
						'\n' +
						'void main() {\n' +
						'\n' +
						'	vec2 uv = gl_FragCoord.xy / resolution.xy;\n' +
						'\n' +
						'	gl_FragColor = texture2D( passThruTexture, uv );\n' +
						'\n' +
						'}\n';

			}

		}

	}

	const simplexNoise4d = /* glsl */`
//	Simplex 4D Noise 
//	by Ian McEwan, Ashima Arts
//
vec4 permute(vec4 x){return mod(((x*34.0)+1.0)*x, 289.0);}
float permute(float x){return floor(mod(((x*34.0)+1.0)*x, 289.0));}
vec4 taylorInvSqrt(vec4 r){return 1.79284291400159 - 0.85373472095314 * r;}
float taylorInvSqrt(float r){return 1.79284291400159 - 0.85373472095314 * r;}

vec4 grad4(float j, vec4 ip){
  const vec4 ones = vec4(1.0, 1.0, 1.0, -1.0);
  vec4 p,s;

  p.xyz = floor( fract (vec3(j) * ip.xyz) * 7.0) * ip.z - 1.0;
  p.w = 1.5 - dot(abs(p.xyz), ones.xyz);
  s = vec4(lessThan(p, vec4(0.0)));
  p.xyz = p.xyz + (s.xyz*2.0 - 1.0) * s.www; 

  return p;
}

float simplexNoise4d(vec4 v){
  const vec2  C = vec2( 0.138196601125010504,  // (5 - sqrt(5))/20  G4
                        0.309016994374947451); // (sqrt(5) - 1)/4   F4
// First corner
  vec4 i  = floor(v + dot(v, C.yyyy) );
  vec4 x0 = v -   i + dot(i, C.xxxx);

// Other corners

// Rank sorting originally contributed by Bill Licea-Kane, AMD (formerly ATI)
  vec4 i0;

  vec3 isX = step( x0.yzw, x0.xxx );
  vec3 isYZ = step( x0.zww, x0.yyz );
//  i0.x = dot( isX, vec3( 1.0 ) );
  i0.x = isX.x + isX.y + isX.z;
  i0.yzw = 1.0 - isX;

//  i0.y += dot( isYZ.xy, vec2( 1.0 ) );
  i0.y += isYZ.x + isYZ.y;
  i0.zw += 1.0 - isYZ.xy;

  i0.z += isYZ.z;
  i0.w += 1.0 - isYZ.z;

  // i0 now contains the unique values 0,1,2,3 in each channel
  vec4 i3 = clamp( i0, 0.0, 1.0 );
  vec4 i2 = clamp( i0-1.0, 0.0, 1.0 );
  vec4 i1 = clamp( i0-2.0, 0.0, 1.0 );

  //  x0 = x0 - 0.0 + 0.0 * C 
  vec4 x1 = x0 - i1 + 1.0 * C.xxxx;
  vec4 x2 = x0 - i2 + 2.0 * C.xxxx;
  vec4 x3 = x0 - i3 + 3.0 * C.xxxx;
  vec4 x4 = x0 - 1.0 + 4.0 * C.xxxx;

// Permutations
  i = mod(i, 289.0); 
  float j0 = permute( permute( permute( permute(i.w) + i.z) + i.y) + i.x);
  vec4 j1 = permute( permute( permute( permute (
             i.w + vec4(i1.w, i2.w, i3.w, 1.0 ))
           + i.z + vec4(i1.z, i2.z, i3.z, 1.0 ))
           + i.y + vec4(i1.y, i2.y, i3.y, 1.0 ))
           + i.x + vec4(i1.x, i2.x, i3.x, 1.0 ));
// Gradients
// ( 7*7*6 points uniformly over a cube, mapped onto a 4-octahedron.)
// 7*7*6 = 294, which is close to the ring size 17*17 = 289.

  vec4 ip = vec4(1.0/294.0, 1.0/49.0, 1.0/7.0, 0.0) ;

  vec4 p0 = grad4(j0,   ip);
  vec4 p1 = grad4(j1.x, ip);
  vec4 p2 = grad4(j1.y, ip);
  vec4 p3 = grad4(j1.z, ip);
  vec4 p4 = grad4(j1.w, ip);

// Normalise gradients
  vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));
  p0 *= norm.x;
  p1 *= norm.y;
  p2 *= norm.z;
  p3 *= norm.w;
  p4 *= taylorInvSqrt(dot(p4,p4));

// Mix contributions from the five corners
  vec3 m0 = max(0.6 - vec3(dot(x0,x0), dot(x1,x1), dot(x2,x2)), 0.0);
  vec2 m1 = max(0.6 - vec2(dot(x3,x3), dot(x4,x4)            ), 0.0);
  m0 = m0 * m0;
  m1 = m1 * m1;
  return 49.0 * ( dot(m0*m0, vec3( dot( p0, x0 ), dot( p1, x1 ), dot( p2, x2 )))
               + dot(m1*m1, vec2( dot( p3, x3 ), dot( p4, x4 ) ) ) ) ;

}
`;

	function particleMaterial() {

	    const vertex = /* glsl */`
       

        uniform float uTime;
        uniform sampler2D uParticlesTexture;
        uniform float uSize;
        uniform vec2 uResolution;

        attribute vec2 aParticlesUv;
        attribute float aSize;
        attribute vec3 aColor;

        varying vec2 vUv;
        varying vec3 vColor;

        void main() {
            vec4 particle = texture(uParticlesTexture, aParticlesUv);

    //        vec4 pos = projectionMatrix * modelViewMatrix * vec4(particle.xyz, 1.0);
            // Final position
            vec4 modelPosition = modelMatrix * vec4(particle.xyz, 1.0);
            vec4 viewPosition = viewMatrix * modelPosition;
            vec4 projectedPosition = projectionMatrix * viewPosition;
            gl_Position = projectedPosition;

            vColor = particle.xyz;

            vUv = uv;

            // Point size
            float sizeIn = smoothstep(0.0, 0.1, particle.a);
            float sizeOut = 1.0 - smoothstep(0.7, 1.0, particle.a);
            float size = min(sizeIn, sizeOut);

            gl_PointSize = size * aSize * uSize * uResolution.y;
            gl_PointSize *= (1.0 / - viewPosition.z);
            
            //gl_PointSize *= 2.0;

            //gl_PointSize = size * aSize * uSize * uResolution.y;

            //gl_PointSize = uSize * uResolution.y;
            
        }   
    `;


	    const fragment = /* glsl */`
        varying vec2 vUv;
        uniform float uTime;
        uniform sampler2D uParticlesTexture;

        uniform vec2 uResolution;
        varying vec3 vColor;
        
        // uParticles && resolution is provided by gpgpu compute

        void main() {

            //vec4 particle = texture(uParticlesTexture, aParticlesUv);

            //vec2 uv = gl_FragCoord.xy / resolution.xy; 
            //vec4 particle = texture(uParticlesTexture, uv);

            float r = smoothstep(0.0, 1.0, sin(uTime * 0.5));
            float g = smoothstep(0.0, 1.0, sin(uTime * 0.5));
            float b = smoothstep(0.0, 1.0, sin(uTime * 0.2));

            //vec3 fColor = mix(vColor, vec3(r, g, b), abs(sin(uTime)));
            vec3 fColor = vec3(r, g, b);

            gl_FragColor = vec4(fColor, 1.0);
        }
       
    `;

	    const uniforms = {
	        uSize: new Uniform(0.01),
	        uResolution: new Uniform(new Vector2(
	            512, 512
	        )),
	        uTime: new Uniform(0),
	        uParticlesTexture: new Uniform(),
	    };


	    const tick = (context) => {
	        uniforms.uTime.value = context.clock.time;
	    };

	    return { vertex, fragment, uniforms, tick }
	}








	// for the texture itself
	function particleShader() {
	    const fragment = /* glsl */`
         ${simplexNoise4d}

        uniform float uTime;
        uniform float uDeltaTime;
        uniform sampler2D uBase;
        uniform float uFlowFieldStrength;
        uniform float uFlowFieldFrequency;
        uniform float uFlowFieldInfluence;

        varying vec2 vUv;
        // uParticles && resolution is provided by gpgpu compute

        void main() {

            float time = uTime * 0.2;
        
            vec2 uv = gl_FragCoord.xy / resolution.xy; 
            vec4 particle = texture(uParticles, uv);
            vec4 base = texture(uBase, uv);

            float strength = simplexNoise4d(vec4(base.xyz * 0.84, time + 2.0));
            strength = smoothstep(- 0.2, 1.0, strength);

            if (particle.a >= 1.0) {
                particle.a = mod(particle.a, 1.0);
                particle.xyz = base.xyz;
            } else {
                float influence = (uFlowFieldInfluence - 0.5) * (- 2.0);
                strength = smoothstep(influence, 1.0, strength);

                vec3 flowField = vec3(
                    simplexNoise4d(vec4(particle.xyz * uFlowFieldFrequency + 0.0, time)),
                    simplexNoise4d(vec4(particle.xyz * uFlowFieldFrequency + 1.0, time)),
                    simplexNoise4d(vec4(particle.xyz * uFlowFieldFrequency + 2.0, time))
                );

                flowField = normalize(flowField);
                particle.xyz += flowField * (uDeltaTime + 0.1) * strength * uFlowFieldStrength;

                // decay
                particle.a += (uDeltaTime + 0.1) * 0.4;
            } 

            gl_FragColor = vec4(particle);
        }
       
    `;
	    return fragment
	}


	async function createParticles(baseGeometry, material, params, program) {

	    const { renderer } = program;

	        //const baseGeometry = this.getGeometry(program)
	        //const material = this.getMaterial(program)

	        const modelUrl = null; // params.particles?.src

	        console.log("PARTICLE params", params, modelUrl);

	        let modelGeometry;

	        {
	            modelGeometry = new SphereGeometry(2, 2096, 4096);
	            baseGeometry.instance = modelGeometry;   
	            baseGeometry.count = modelGeometry.attributes.position.count; 
	        }
	        

	        /**
	         * GPU Compute
	         */
	        // Setup
	        const gpgpu = {};
	        gpgpu.size = Math.ceil(Math.sqrt(baseGeometry.count));
	        gpgpu.computation = new GPUComputationRenderer(gpgpu.size, gpgpu.size, renderer);

	        // Base particles
	        const baseParticlesTexture = gpgpu.computation.createTexture();
	        //console.log("baseParticlesTexture", baseParticlesTexture)

	        for (let i = 0; i< baseGeometry.count; i++) {
	            const i3 = i * 3;
	            const i4 = i * 4;

	            // position based on geometry
	            baseParticlesTexture.image.data[i4 + 0] 
	                = baseGeometry.instance.attributes.position.array[i3 + 0];

	            baseParticlesTexture.image.data[i4 + 1] 
	                = baseGeometry.instance.attributes.position.array[i3 + 1];

	            baseParticlesTexture.image.data[i4 + 2] 
	                = baseGeometry.instance.attributes.position.array[i3 + 2];
	            
	            baseParticlesTexture.image.data[i4 + 3] = Math.random();
	            
	        }

	        //console.log(baseParticlesTexture.image.data)

	        const gpgpuParticlesShader = particleShader();

	        // Particles variable
	        // Particles variable
	        gpgpu.particlesVariable = gpgpu.computation.addVariable('uParticles', gpgpuParticlesShader, baseParticlesTexture);
	        gpgpu.computation.setVariableDependencies(gpgpu.particlesVariable, [ gpgpu.particlesVariable ]);

	        // uniforms
	            //time
	        gpgpu.particlesVariable.material.uniforms.uTime = new Uniform(0);
	            // delta time
	        gpgpu.particlesVariable.material.uniforms.uDeltaTime = new Uniform(0);
	            // original positions
	        gpgpu.particlesVariable.material.uniforms.uFlowFieldInfluence = new Uniform(0.24);
	        gpgpu.particlesVariable.material.uniforms.uFlowFieldStrength = new Uniform(2.2);
	        gpgpu.particlesVariable.material.uniforms.uFlowFieldFrequency = new Uniform(1.75);

	        gpgpu.particlesVariable.material.uniforms.uBase = new Uniform(baseParticlesTexture);


	        
	        // init
	        gpgpu.computation.init();

	        const renderTarget = gpgpu.computation.getCurrentRenderTarget(gpgpu.particlesVariable);


	        //console.log("renderTarget", renderTarget)

	        gpgpu.debug = new Mesh(
	            new PlaneGeometry(3, 3),
	            new MeshBasicMaterial({
	               map: renderTarget.texture,
	            })
	        );
	        gpgpu.debug.position.x = 3;

	        const particles = { material };

	        const particlesUvArray = new Float32Array(baseGeometry.count * 2);
	        const sizesArray = new Float32Array(baseGeometry.count);

	        console.log(" gpgpu.size",  gpgpu.size);

	        
	        for (let y = 0; y < gpgpu.size; y++) {
	            for (let x = 0; x < gpgpu.size; x++) {
	                const i = (y * gpgpu.size) + x;
	                
	                const i2 = i * 2;

	                const uvX = (x + 0.5) / gpgpu.size;
	                const uvY = (y + 0.5) / gpgpu.size;

	                particlesUvArray[i2 + 0] = uvX;
	                particlesUvArray[i2 + 1] = uvY;

	                // Size
	                sizesArray[i] = Math.random();
	            }
	        }

	        console.log("particlesUuArray", particlesUvArray);

	        particles.geometry = new BufferGeometry();
	        particles.geometry.setDrawRange(0, baseGeometry.count);
	        particles.geometry.setAttribute('aParticlesUv', new BufferAttribute(particlesUvArray, 2));
	        //particles.geometry.setAttribute('aColor', baseGeometry.instance.attributes.color)
	        
	        particles.geometry.setAttribute('aSize', new BufferAttribute(sizesArray, 1));

	        particles.points = new Points(particles.geometry, particles.material);

	        const tick = (context) => {
	            //console.log("ggpu tick")
	            gpgpu.particlesVariable.material.uniforms.uTime = context.clock.time;
	            gpgpu.particlesVariable.material.uniforms.uDeltaTime = context.clock.delta;

	            gpgpu.computation.compute();
	            
	            particles.material.uniforms.uParticlesTexture.value = 
	                gpgpu.computation.getCurrentRenderTarget(gpgpu.particlesVariable).texture;
	        };
	        
	        return {
	            particles, gpgpu, tick
	        }


	}










	class GPGPUParticles extends Shape$1 {
	    
	    getMaterial(program) {
	        const { vertex, fragment, uniforms, tick } = particleMaterial();
	        const material =  new ShaderMaterial({
	            color: 'purple',
	            vertexShader: vertex,
	            fragmentShader: fragment,
	            //wireframe: true,
	            transparent: true,
	            uniforms
	        });

	        console.log("GPGPU Particles", material);

	        return { material, uniforms, tick };
	    }


	    getGeometry() {
	        const baseGeometry = {};
	        baseGeometry.instance = new SphereGeometry(2);
	        baseGeometry.count = baseGeometry.instance.attributes.position.count;

	        return baseGeometry;

	        
	    }

		createMesh(program) {	
	        const { params } = this;
	        const geometry = this.getGeometry(program);
	        const mat = this.getMaterial(program);

	        const container = new Group$1();

	        let ticker;

	        createParticles(geometry, mat.material, params, program).then(({particles, gpgpu, tick }) => {
	            console.log("particles.points", particles.points);
	            container.add(particles.points);
	            //container.add(gpgpu.debug)
	            ticker = tick;
	        });

	        this.tick = (context) => {
	            if (ticker) {
	                ticker(context);
	            }
	            mat.tick(context);
	        };

	        return container;
	    }

	}

	function toColor(clr) {
	    // { h: 14, s: 12, l: 40, a: 1, hex: 'ffffff' }
	    return new Color(`#${clr.hex}`);
	}


	const ambient = (params = {}) => {
	    const {
	        keycolor = { hex: 'red' },
	        intensity = 5
	    } = params || {};

	    const lightColor = toColor(keycolor);

	   return new  AmbientLight(lightColor, intensity)
	};



	const directional = (params = {}) => {
	    const {
	        keycolor = { hex: 'red' },
	        intensity = 5
	    } = params || {};

	    const lightColor = toColor(keycolor);

	    const light = new  DirectionalLight(lightColor, intensity);

	    light.castShadow = true;
	    light.shadow.mapSize.width = 512;
	    light.shadow.mapSize.height = 512;

	   return light
	};

	const hemisphere = (params = {}) => {
	    const {
	        keycolor = { hex: 'red' },
	        seccolor = { hex: 'blue' },
	        intensity = 5
	    } = params || {};

	    const skycolor = toColor(keycolor);
	    const groundColor = toColor(seccolor);

	   return new HemisphereLight(lightColor, skycolor, intensity );
	};


	const point = (params = {}) => {
	    const {
	        keycolor = { hex: 'red' },
	        intensity = 5,
	        distance = 40,
	        decay = 4
	    } = params || {};

	    const lightColor = toColor(keycolor);

	   return new PointLight( lightColor, intensity, distance, decay );
	};

	const LIGHTS = {
	    ambient,
	    directional,
	    hemisphere,
	    point,
	    //'area': THREE.RectAreaLight,
	    //'spot': SpotLight
	};



	class Light$1 extends Shape$1 {
		getGeometry(program) {
			
		}

	    // default mesh
	    createMesh(program) {	

	        const {
	            type = 'directional',
			} = this.params || {};

	        // console.log("LIGHT", scene, this.params);
	        
	        const lightgroup = new Group$1();
	        //const lightColor = new THREE.Color(`#${keycolor.hex}`);

	        const createLight = LIGHTS[type] || LIGHTS.directional;

	        const light = createLight(this.params);

	        //const light1 = new THREE.DirectionalLight(lightColor, intensity || 15);
	        //light1.position.set(1,1,0);
	        //
	        
	        lightgroup.add(light);

	        //const ambient = new THREE.AmbientLight(color, 2); // soft white light
	        //lightgroup.add( ambient );

	        this.applyTransforms(lightgroup);

	        return lightgroup

	    }

	    getMaterial(program, geometry) {
	        
	    }

	    tick(context) {
	        //console.log("lockscreen tick", context)
	    }


	}

	class Group$2 extends Shape$1 {
		

	    // default mesh
	    createMesh(program) {	

	        const container = new Group$1();

	        const { context } = program;

	        const { loader } = this.params;

	        if (loader === 'default') {
	            const preloader = context.assetManager;
	            container.visible = false;
	            preloader.addEvent('onComplete', () => {
	                console.log("PRELOADING COMPLETE");
	                container.visible = true;
	            });
	        }

	        // console.log("CREATING MESH FOR GROUP", this.params)

	        this._tick = (context) => { 
	        };

	        this.applyTransforms(container);

	        return container;
	        
	    } 

	}

	class Plane$1 extends Shape$1 {
		getGeometry(program) {

	        const {
	            width = 1,
	            height = 1,
	            widthSegments = 1,
	            heightSegments = 1,
	        } = this.params;

			const geometry = new PlaneGeometry(width, 
					height, widthSegments, heightSegments);

			return geometry
		}

	    createMesh(program) {

	        const {
	            width = 1,
	            height = 1,
	        } = this.params;

	            const container = new Group$1();
	            const geometry = this.getGeometry(program);

	            const material = this.getMaterial(program);
	        
	            // console.log("PLANE::::: CREATING MESH", this.params)

	            const mesh = new Mesh(geometry, material);
	            // mesh.castShadow = true;
	            //mesh.receiveShadow = true;

	    
	            this.applyTransforms(mesh);

	            this.tick = (context) => {
	                
	            };
	    
	            return mesh;
	    }

	    getMaterial(program) {
	        //const color = new THREE.Color(...this.color)

	        const { assetManager } = program;

	        const {
	            map,
	            displacement,
	            normal,
	            displacementScale = 0.6,
	            displacementBias = 0,
	            color: baseColor,
	            emissiveColor, // color
	            
	            emissiveIntensity = 1
	        } = this.params;

	        const textureLoader = new TextureLoader(assetManager);
	        
	        let texture;
	        let displacementMap;
	        let normalMap;
	        let emissive;
	        let color;

	        if (baseColor) {
	            color = new Color(`#${baseColor.hex}`);
	        }

	        if (emissiveColor) {
	            emissive = new Color(`#${emissiveColor.hex}`);
	        }

	        const options = {
	            color,
	            wireframe: false,
	            side: DoubleSide,
	            //fragmentShader,
	            //vertexShader,
	            //uniforms,
	            normalScale: new Vector2(1, 1),
	            displacementScale,
	            displacementBias,
	            transparent: true,
	            alphaTest: 0.001,
	            //depthTest: false,
	            //depthWrite: false,
	            //emissive            
	        };

	        
	        if (map) {
	            texture = textureLoader.load(map, function() {
	                //console.log("PLANE: texture loaded")
	                //map.colorSpace = THREE.SRGBColorSpace;
	            });
	            options.map = texture;

	        }
	        if (displacement) {
	            displacementMap = textureLoader.load(displacement, function() {
	                //console.log("PLANE: displacement loaded", displacement)
	            });
	            options.displacementMap = displacementMap;
	            

	        }
	        if (normal) {
	            normalMap = textureLoader.load(normal, function() {
	                //console.log("PLANE: normalMap loaded")
	            });
	            options.normalMap = normalMap;
	        }
	        
	        
	        
	        
	        const material = new MeshStandardMaterial(options);

	        return material
	    }
		

	}

	const cnoise = /* glsl */`
//	Classic Perlin 3D Noise 
//	by Stefan Gustavson
//
vec4 permute(vec4 x){ return mod(((x*34.0)+1.0)*x, 289.0); }
vec4 taylorInvSqrt(vec4 r){ return 1.79284291400159 - 0.85373472095314 * r; }
vec3 fade(vec3 t) { return t*t*t*(t*(t*6.0-15.0)+10.0); }

float cnoise(vec3 P)
{
    vec3 Pi0 = floor(P); // Integer part for indexing
    vec3 Pi1 = Pi0 + vec3(1.0); // Integer part + 1
    Pi0 = mod(Pi0, 289.0);
    Pi1 = mod(Pi1, 289.0);
    vec3 Pf0 = fract(P); // Fractional part for interpolation
    vec3 Pf1 = Pf0 - vec3(1.0); // Fractional part - 1.0
    vec4 ix = vec4(Pi0.x, Pi1.x, Pi0.x, Pi1.x);
    vec4 iy = vec4(Pi0.yy, Pi1.yy);
    vec4 iz0 = Pi0.zzzz;
    vec4 iz1 = Pi1.zzzz;

    vec4 ixy = permute(permute(ix) + iy);
    vec4 ixy0 = permute(ixy + iz0);
    vec4 ixy1 = permute(ixy + iz1);

    vec4 gx0 = ixy0 / 7.0;
    vec4 gy0 = fract(floor(gx0) / 7.0) - 0.5;
    gx0 = fract(gx0);
    vec4 gz0 = vec4(0.5) - abs(gx0) - abs(gy0);
    vec4 sz0 = step(gz0, vec4(0.0));
    gx0 -= sz0 * (step(0.0, gx0) - 0.5);
    gy0 -= sz0 * (step(0.0, gy0) - 0.5);

    vec4 gx1 = ixy1 / 7.0;
    vec4 gy1 = fract(floor(gx1) / 7.0) - 0.5;
    gx1 = fract(gx1);
    vec4 gz1 = vec4(0.5) - abs(gx1) - abs(gy1);
    vec4 sz1 = step(gz1, vec4(0.0));
    gx1 -= sz1 * (step(0.0, gx1) - 0.5);
    gy1 -= sz1 * (step(0.0, gy1) - 0.5);

    vec3 g000 = vec3(gx0.x,gy0.x,gz0.x);
    vec3 g100 = vec3(gx0.y,gy0.y,gz0.y);
    vec3 g010 = vec3(gx0.z,gy0.z,gz0.z);
    vec3 g110 = vec3(gx0.w,gy0.w,gz0.w);
    vec3 g001 = vec3(gx1.x,gy1.x,gz1.x);
    vec3 g101 = vec3(gx1.y,gy1.y,gz1.y);
    vec3 g011 = vec3(gx1.z,gy1.z,gz1.z);
    vec3 g111 = vec3(gx1.w,gy1.w,gz1.w);

    vec4 norm0 = taylorInvSqrt(vec4(dot(g000, g000), dot(g010, g010), dot(g100, g100), dot(g110, g110)));
    g000 *= norm0.x;
    g010 *= norm0.y;
    g100 *= norm0.z;
    g110 *= norm0.w;
    vec4 norm1 = taylorInvSqrt(vec4(dot(g001, g001), dot(g011, g011), dot(g101, g101), dot(g111, g111)));
    g001 *= norm1.x;
    g011 *= norm1.y;
    g101 *= norm1.z;
    g111 *= norm1.w;

    float n000 = dot(g000, Pf0);
    float n100 = dot(g100, vec3(Pf1.x, Pf0.yz));
    float n010 = dot(g010, vec3(Pf0.x, Pf1.y, Pf0.z));
    float n110 = dot(g110, vec3(Pf1.xy, Pf0.z));
    float n001 = dot(g001, vec3(Pf0.xy, Pf1.z));
    float n101 = dot(g101, vec3(Pf1.x, Pf0.y, Pf1.z));
    float n011 = dot(g011, vec3(Pf0.x, Pf1.yz));
    float n111 = dot(g111, Pf1);

    vec3 fade_xyz = fade(Pf0);
    vec4 n_z = mix(vec4(n000, n100, n010, n110), vec4(n001, n101, n011, n111), fade_xyz.z);
    vec2 n_yz = mix(n_z.xy, n_z.zw, fade_xyz.y);
    float n_xyz = mix(n_yz.x, n_yz.y, fade_xyz.x); 
    
    return 2.2 * n_xyz;
}
`;




	const vertexShader$1 = /* glsl */`
    uniform vec2 uPlaneResolution;
    uniform vec2 uTextureSize;
    varying vec2 vUv;

    void main() { 
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
    }   
  `;

	const fragmentShader$1 = /* glsl */`
    varying vec2 vUv;

    uniform float uTime;
    uniform sampler2D uTexture;
    uniform vec2 uPlaneResolution;
    uniform vec2 uTextureSize;

    uniform vec3 uColorStart;
    uniform vec3 uColorEnd;

    ${cnoise}

    

    void main()	{

        
        // Displace the UV
        vec2 displacedUv = vUv + cnoise(vec3(vUv * 5.0, uTime * 0.9));

        // Perlin noise
        float strength = cnoise(vec3(displacedUv * 5.0, uTime * 0.9));

        // Outer glow
        float outerGlow = distance(vUv, vec2(0.5)) * 4.0 - 1.8;
        strength += outerGlow;

        // Apply cool step
        //strength += step(-0.2, strength) * 0.8;

        // // Clamp the value from 0 to 1
        // strength = clamp(strength, 0.0, 1.0);

        // Final color
        vec3 color = mix(uColorStart, uColorEnd, strength);

        gl_FragColor = vec4(color, strength );


        #include <tonemapping_fragment>
        #include <colorspace_fragment>
    }
`;



	function portalMaterial(params, program) {

	    const {
	        innercolor = { hex: 'ff0000' },
	        outercolor =  { hex: '0000ff' }
	    } = params;

	    const uniforms = {
	        uTime: new Uniform(0),
	        uColorStart: new Uniform(new Color(
	            `#${innercolor.hex}`
	        ) ),
	        uColorEnd: new Uniform(new Color(
	            `#${outercolor.hex}`
	        ) ),        
	    };


	    const material = new ShaderMaterial({
	        vertexShader: vertexShader$1,
	        fragmentShader: fragmentShader$1,
	        transparent: true,
	        alphaTest: 0.5,
	        uniforms
	    });

	    function tick(context) {
	        uniforms.uTime.value = context.clock.time;

	    }

	    return {
	        material, tick
	    }
	}






	class GenericMesh extends Shape$1 {
		getGeometry(program) {

	        const {
	            width = 1,
	            height = 1,
	            depth = 1,
	            widthSegments = 1,
	            heightSegments = 1,
	            depthSegments = 1,
	            geometry = "cube",
	            arc = Math.PI * 2
	        } = this.params;

	        let geo;

	        switch(geometry) {
	            case 'cube':
	                geo = new BoxGeometry( width, height, depth, widthSegments, heightSegments, depthSegments ); 
	            break;
	            case 'circle':
	                geo = new CircleGeometry( width, widthSegments ); 
	            break;
	            case 'plane':
	                geo = new PlaneGeometry( width, height, widthSegments, heightSegments ); 
	            break;
	            case 'sphere':
	                geo = new SphereGeometry( width, widthSegments, heightSegments ); 
	            break;
	            case 'torus':
	                geo = new TorusGeometry( width, height, widthSegments, heightSegments, arc ); 
	            break;
	            default:
	                 geo = new PlaneGeometry( width, height, widthSegments, heightSegments ); 
	            break;
	        }

			return geo
		}

	    createMesh(program) {

	        const {
	            width = 1,
	            height = 1,
	            shader = "",
	        } = this.params;


	            const container = new Group$1();
	            const geometry = this.getGeometry(program);

	            const { material, tick } = this.getMaterial(program);

	            
	            
	        
	            console.log(">>>>>>>>>>>>>>> MESH::::: CREATING MESH", this.params);

	            const mesh = new Mesh(geometry, material);
	            // mesh.castShadow = true;
	            //mesh.receiveShadow = true;


	            this.applyTransforms(mesh);

	            this.tick = (context) => {
	                tick(context);
	            };
	    
	            return mesh;
	    }


	    getMaterial(program) {


	        const {
	            width = 1,
	            height = 1,
	            shader = "",
	        } = this.params;

	        let material;
	        let tick;

	        switch(shader) {
	                case 'basic':
	                    material = new MeshStandardMaterial({
	                        color: "#ffffff"
	                    });
	                    tick = (context) => {

	                    };
	                    return {
	                            material, tick
	                        }
	                default:
	                    return portalMaterial(this.params)
	            }
	            
	    }








	    __getMaterial(program) {
	        //const color = new THREE.Color(...this.color)

	        const { assetManager } = program;

	        const {
	            map,
	            displacement,
	            normal,
	            displacementScale = 0.6,
	            displacementBias = 0,
	            color: baseColor,
	            emissiveColor, // color
	            
	            emissiveIntensity = 1
	        } = this.params;

	        const textureLoader = new TextureLoader(assetManager);
	        
	        let texture;
	        let displacementMap;
	        let normalMap;
	        let emissive;
	        let color;

	        if (baseColor) {
	            color = new Color(`#${baseColor.hex}`);
	        }

	        if (emissiveColor) {
	            emissive = new Color(`#${emissiveColor.hex}`);
	        }

	        const options = {
	            color,
	            wireframe: false,
	            side: DoubleSide,
	            //fragmentShader,
	            //vertexShader,
	            //uniforms,
	            normalScale: new Vector2(1, 1),
	            displacementScale,
	            displacementBias,
	            transparent: true,
	            alphaTest: 0.001,
	            //depthTest: false,
	            //depthWrite: false,
	            //emissive            
	        };

	        
	        if (map) {
	            texture = textureLoader.load(map, function() {
	                //console.log("PLANE: texture loaded")
	                //map.colorSpace = THREE.SRGBColorSpace;
	            });
	            options.map = texture;

	        }
	        if (displacement) {
	            displacementMap = textureLoader.load(displacement, function() {
	                //console.log("PLANE: displacement loaded", displacement)
	            });
	            options.displacementMap = displacementMap;
	            

	        }
	        if (normal) {
	            normalMap = textureLoader.load(normal, function() {
	                //console.log("PLANE: normalMap loaded")
	            });
	            options.normalMap = normalMap;
	        }
	        
	        
	        const material = new MeshStandardMaterial(options);

	        return material
	    }
		

	}

	function randomPointsInSphere(numPoints, radius) {
	    const points = [];
	    while (points.length < numPoints) {
	        // Generate random coordinates (x, y, z) within the bounding cube
	        // -radius to +radius for each dimension
	        const x = (Math.random() * 2 - 1) * radius;
	        const y = (Math.random() * 2 - 1) * radius;
	        const z = (Math.random() * 2 - 1) * radius;

	        // Check if the point is inside the sphere
	        if (x * x + y * y + z * z <= radius * radius) {
	            points.push(new Vector3(x, y, z));
	        }
	    }
	    return points;
	}



	function createLeaves(params, program) {

	    const {
	        count = 200,
	        leafCount = 10,
	        height = 0.3,
	        width = 0.3,
	        radius = 8,
	        bbox,
	        leafsrc = ''
	    } = params;


	    const {
	        assetManager
	    } = program;


	    const geometry = new SphereGeometry(
	        width, 4, 4, 4
	    );

	    const textureLoader = new TextureLoader(assetManager);
	    const texture = textureLoader.load(leafsrc, function() {
	                //console.log("PLANE: texture loaded")
	                //map.colorSpace = THREE.SRGBColorSpace;
	            });


	    const material = new MeshStandardMaterial({
	        //color: 0x00ff00, 
	        // green stem
	        //color: 'red',
	        map: texture,
	        emissive: new Color('red'),
	        emissiveIntensity: 0.1,
	        side: DoubleSide,
	        transparent: true,
	        alphaTest: 0.5,
	        //depthTest: false,
	    });

	    const container = new Group$1();

	    const dummy = new Object3D();
	    
	    //const createFlower = flowerGenerator(params, program)

	    let mesh;

	    function createInstances() {

	        mesh = new InstancedMesh(geometry, material, count * leafCount);
	        const points = randomPointsInSphere(count * leafCount, bbox.max.z * 2);

	        for (let i = 0; i < count * leafCount; i++) {

	                const point = points[i];

	                dummy.position.x = point.x;
	                dummy.position.y = point.y + bbox.max.y;
	                dummy.position.z = point.z; 

	                dummy.rotation.x = Math.PI/2 * Math.random();
	                //dummy.rotation.y = Math.PI/2 * Math.random()
	                //dummy.rotation.z = Math.PI/2 * Math.random()

	                dummy.scale.x = Math.random();
	                dummy.scale.y = Math.random();
	                dummy.scale.z = Math.random();

	                dummy.updateMatrix();
	                mesh.setMatrixAt(i, dummy.matrix);

	                const mmax = (bbox.max.x + 4);

	                const color = new Color(((dummy.position.x / (bbox.max.z * 2))) * 0xFFFFFF);
	                mesh.setColorAt(i, color);

	            
	            
	            
	        }

	        container.add(mesh);
	    }


	    createInstances();

	    
	    const matrix = new Matrix4();

	    const tick = (context) => {
	        if (!mesh) {
	            return;
	        }
	        const { analyser } = context;
	        const { time } = context.clock;


	        for (let i = 0; i<count; i++) { 

	            const d = analyser.data[i];
	            const p = analyser.peaks[i];

	            mesh.getMatrixAt(i, matrix);
	            matrix.decompose(dummy.position, dummy.rotation, dummy.scale);

	            //dummy.position.z = (i + 1) / 10 * Math.sin(time) * 2
	            
	            // stems
	            const scale = 0.01 + d / 100;

	            dummy.position.y = 0.18 + (scale / 2);
	            dummy.scale.set(1, scale, 1);
	            dummy.updateMatrix();

	            mesh.setMatrixAt(i, dummy.matrix);
	        }

	        mesh.instanceMatrix.needsUpdate = true;
	    };

	    return {
	        mesh: container, tick
	    };

	}






	class Tree extends Shape$1 {
	    
		async loadModel(grp, program) {
			console.log("TREE LOAD", this.params);

			const {
	            color1 = {},
	            color2 = {},
	            trunksrc = '',
			} = this.params;
			

			if (this.data || this.loading) {
				return
			}

			// Instantiate a loader
			//const loader = new DRACOLoader();

			// Specify path to a folder containing WASM/JS decoding libraries.
			//loader.setDecoderPath( '/examples/jsm/libs/draco/' );
			//loader.preload();

			if (trunksrc) {
				this.loading = true;

				const m = await this.loadGLTF(trunksrc, program);
				//console.log("MODEL LOADED SRC", m, this.params.src)

	            let bbox;

				m.scene.traverse( function ( child ) {
					if ( child.isMesh ) {
						child.castShadow = true;
						child.receiveShadow = true;
	                    
	                    bbox = child.geometry.boundingBox;
	                    
					}
				});

				let mesh;
				mesh = m.scene;

				grp.add(mesh);

				this.loading = false;

				return {
					mesh: grp, bbox
				}
				
				//this.render()
			}
		}

		createMesh(program, parent) {

			console.log("CREATE TREE", program, this.params);

			//this.removeNodes()
			
			const grp = new Group$1();
			this.applyTransforms(grp);


	       
		

			this.loadModel(grp, program).then(({ bbox}) => {

				const leaves = createLeaves({
	                bbox,
	                ...this.params
	            }, program);
	             grp.add(leaves.mesh);

			});


			this.tick = (context) => {
				const { time } = context.clock;
				
			};
			

			return grp;		
		}

	}

	const _registry = new Map();

	function registry(name) {
		var filters = _registry.get(name);
		if (!filters) {
			filters = new Map();
			_registry.set(name, filters);
		}
		return filters
	}


	// acts as a node in itself
	class NodeGroup {
		static register(name, klass) {
			registry(this.name).set(name, klass);
		}
		static get(name) {
			return registry(this.name).get(name)
		}
		static has(name) {
			return registry(this.name).has(name)
		}
		static all() {
			return registry(this.name)
		}

		constructor(conf, elem, parent) {

			console.log("nodegroup init", conf, elem, parent);

			this.conf = conf;
			this.elem = elem;
			this.parent = parent;

			this.nodes = (this.conf.nodes || []).reduce((acc, nc) => {
				var klass = this.constructor.get(nc.fname);
				if (!klass && nc.fname == 'custom') {
					console.log("gound custom node", nc.klass);
				}
				if (klass) {
					acc.set(nc.id, new klass(nc, elem, this));
				}
				return acc
			}, new Map() );

			const nodes = Array.from(this.nodes.values());
			this.first = nodes[0];
			this.last = nodes[nodes.length - 1];

			console.log("created nodes", nodes);

			this.each = f => nodes.forEach(f);
			this.map = f => nodes.map(f);

		}

		init(gl) {
			console.log("initializing nodes", this.nodes, this);
			this.map( node => node.init(gl) );
			this.connect();
		}

		connect() {
			const nodes = this.conf.nodes || [];

			const getLead = (inp) => {
				console.log("get lead", inp);

				if (inp.id == 'src') {
					return this
				}
				return this.nodes.get(inp.id)
			};

			nodes.forEach(({ id, ins }) => {
				const node = this.nodes.get(id);
				if (node) {
					if (!ins.length) {
						ins = [{ id: 'src', i: 'in' }];
					}
					var inputs = ins.map(getLead);
					node.connect(inputs);
				}
			});
			var dests = this.conf.dests || [];

			if (!dests.length) {
				dests = this.last ? [{ name: 'texture', value: { id: this.last.id } }] : [];
			}

			if (!dests[0]) {
				throw new Error("Atleast one destination must be provided")
			}

			/*
			this.dests = new Map(dests.map(({ name, value }) => {
				const { id } = value || {}
				const node = id && this.nodes.get(id)
				return node ? [ name, node ] : false
			}).filter(Boolean))
			*/

			this.dests = dests.map(({ id }) => {
				const node = id && this.nodes.get(id);
				return node ? [ id, node ] : false
			}).filter(Boolean).reduce((acc, [id, node]) => {
				acc[id] = node;
				return acc
			}, {});

			console.log("this.dests", this.dests);

		}

		destroy() {

		}

	}

	class Node {

		constructor(conf, elem) {
			this.conf = conf;
			this.elem = elem;
			this.uniforms = new Map();
		}

		get config() {
			return this.conf.props.config
		}

		get id() {
			return this.conf.id
		}
		get name() {
			return this.conf.fname
		}
		get nodeName() {
			return `${this.id}_${this.name}`
		}

		init(gl) {
			console.log("init node", this);
			this.reset = () => {

			};
			this.reset();
		}

		connect() {
			console.log("connecting node", this);
		}

		async process() {

		}

	}

	class Custom extends Node {

		constructor(conf, elem) {
			super(conf, elem);
			console.log("create custom node", this);
		}

		init(gl) {
			console.log("init custom node", this);
		}




		/**
		 * async process - description
		 *
		 * @param  {texture} destination texture
		 * @return {image}             image
		 */
		async process(destination) {

		}




	}

	class Loader$1 extends Node {

		constructor(conf, elem) {
			super(conf, elem);
			console.log("create loader node", this);
		}

		init(gl) {

			if (this.src === this.config.src) ;

			this.texture = new Texture$1(gl);

			this.promise = null;
			this.image = null;
			this.src = this.config.src;
			this.reset = () => {

			};
			this.load(this.config.src);

			const name = `t${this.nodeName}`;

			this.uniforms.set(name, {
				value: this.texture,
				type: 'sampler2D',
				name
			});

			this.vertex = ``;
			this.fragment = `vec4 ${this.nodeName}() {
			vec4 tex = texture2D(t${this.nodeName}, vUv);
			return(tex);
		}`;

		}

		load(src) {
			const image = new Image();
			image.onload = () => {
				this.texture.image = image;
			};
			image.setAttribute('crossorigin', 'anonymous');
			image.src = src;
		}






	}

	class Materials extends NodeGroup {




	}


	Materials.register('custom', Custom);
	Materials.register('loader', Loader$1);

	var nodes = {
		material: Materials
	};

	/**
	 * anime.js - ESM
	 * @version v4.0.2
	 * @author Julian Garnier
	 * @license MIT
	 * @copyright (c) 2025 Julian Garnier
	 * @see https://animejs.com
	 */

	/**
	 * @typedef {Object} DefaultsParams
	 * @property {Number|String} [id]
	 * @property {PercentageKeyframes|DurationKeyframes} [keyframes]
	 * @property {EasingParam} [playbackEase]
	 * @property {Number} [playbackRate]
	 * @property {Number} [frameRate]
	 * @property {Number|Boolean} [loop]
	 * @property {Boolean} [reversed]
	 * @property {Boolean} [alternate]
	 * @property {Boolean|ScrollObserver} [autoplay]
	 * @property {Number|FunctionValue} [duration]
	 * @property {Number|FunctionValue} [delay]
	 * @property {Number} [loopDelay]
	 * @property {EasingParam} [ease]
	 * @property {'none'|'replace'|'blend'|compositionTypes} [composition]
	 * @property {(v: any) => any} [modifier]
	 * @property {(tickable: Tickable) => void} [onBegin]
	 * @property {(tickable: Tickable) => void} [onBeforeUpdate]
	 * @property {(tickable: Tickable) => void} [onUpdate]
	 * @property {(tickable: Tickable) => void} [onLoop]
	 * @property {(tickable: Tickable) => void} [onPause]
	 * @property {(tickable: Tickable) => void} [onComplete]
	 * @property {(renderable: Renderable) => void} [onRender]
	 */

	/** @typedef {JSAnimation|Timeline} Renderable */
	/** @typedef {Timer|Renderable} Tickable */
	/** @typedef {Timer&JSAnimation&Timeline} CallbackArgument */
	/** @typedef {Animatable|Tickable|Draggable|ScrollObserver|Scope} Revertible */

	/**
	 * @typedef {Object} DraggableAxisParam
	 * @property {String} [mapTo]
	 * @property {TweenModifier} [modifier]
	 * @property {TweenComposition} [composition]
	 * @property {Number|Array<Number>|((draggable: Draggable) => Number|Array<Number>)} [snap]
	 */

	/**
	 * @typedef {Object} DraggableCursorParams
	 * @property {String} [onHover]
	 * @property {String} [onGrab]
	 */

	/**
	 * @typedef {Object} DraggableParams
	 * @property {DOMTargetSelector} [trigger]
	 * @property {DOMTargetSelector|Array<Number>|((draggable: Draggable) => DOMTargetSelector|Array<Number>)} [container]
	 * @property {Boolean|DraggableAxisParam} [x]
	 * @property {Boolean|DraggableAxisParam} [y]
	 * @property {TweenModifier} [modifier]
	 * @property {Number|Array<Number>|((draggable: Draggable) => Number|Array<Number>)} [snap]
	 * @property {Number|Array<Number>|((draggable: Draggable) => Number|Array<Number>)} [containerPadding]
	 * @property {Number|((draggable: Draggable) => Number)} [containerFriction]
	 * @property {Number|((draggable: Draggable) => Number)} [releaseContainerFriction]
	 * @property {Number|((draggable: Draggable) => Number)} [dragSpeed]
	 * @property {Number|((draggable: Draggable) => Number)} [scrollSpeed]
	 * @property {Number|((draggable: Draggable) => Number)} [scrollThreshold]
	 * @property {Number|((draggable: Draggable) => Number)} [minVelocity]
	 * @property {Number|((draggable: Draggable) => Number)} [maxVelocity]
	 * @property {Number|((draggable: Draggable) => Number)} [velocityMultiplier]
	 * @property {Number} [releaseMass]
	 * @property {Number} [releaseStiffness]
	 * @property {Number} [releaseDamping]
	 * @property {Boolean} [releaseDamping]
	 * @property {EasingParam} [releaseEase]
	 * @property {Boolean|DraggableCursorParams|((draggable: Draggable) => Boolean|DraggableCursorParams)} [cursor]
	 * @property {Callback<Draggable>} [onGrab]
	 * @property {Callback<Draggable>} [onDrag]
	 * @property {Callback<Draggable>} [onRelease]
	 * @property {Callback<Draggable>} [onUpdate]
	 * @property {Callback<Draggable>} [onSettle]
	 * @property {Callback<Draggable>} [onSnap]
	 * @property {Callback<Draggable>} [onResize]
	 * @property {Callback<Draggable>} [onAfterResize]
	 */

	/**
	 * @typedef {SVGGeometryElement & {
	 *   setAttribute(name: 'draw', value: `${number} ${number}`): void;
	 *   draw: `${number} ${number}`;
	 * }} DrawableSVGGeometry
	 */

	/**
	 * @callback EasingFunction
	 * @param {Number} time
	 * @return {Number}
	 */

	/**
	 * @typedef {('linear'|'linear(x1, x2 25%, x3)'|'in'|'out'|'inOut'|'inQuad'|'outQuad'|'inOutQuad'|'inCubic'|'outCubic'|'inOutCubic'|'inQuart'|'outQuart'|'inOutQuart'|'inQuint'|'outQuint'|'inOutQuint'|'inSine'|'outSine'|'inOutSine'|'inCirc'|'outCirc'|'inOutCirc'|'inExpo'|'outExpo'|'inOutExpo'|'inBounce'|'outBounce'|'inOutBounce'|'inBack'|'outBack'|'inOutBack'|'inElastic'|'outElastic'|'inOutElastic'|'irregular'|'cubicBezier'|'steps'|'in(p = 1.675)'|'out(p = 1.675)'|'inOut(p = 1.675)'|'inBack(overshoot = 1.70158)'|'outBack(overshoot = 1.70158)'|'inOutBack(overshoot = 1.70158)'|'inElastic(amplitude = 1, period = .3)'|'outElastic(amplitude = 1, period = .3)'|'inOutElastic(amplitude = 1, period = .3)'|'irregular(length = 10, randomness = 1)'|'cubicBezier(x1, y1, x2, y2)'|'steps(steps = 10)')} EaseStringParamNames
	 */

	// A hack to get both ease names suggestions AND allow any strings
	// https://github.com/microsoft/TypeScript/issues/29729#issuecomment-460346421
	/** @typedef {(String & {})|EaseStringParamNames|EasingFunction|Spring} EasingParam */

	/** @typedef {HTMLElement|SVGElement} DOMTarget */
	/** @typedef {Record<String, any>} JSTarget */
	/** @typedef {DOMTarget|JSTarget} Target */
	/** @typedef {Target|NodeList|String} TargetSelector */
	/** @typedef {DOMTarget|NodeList|String} DOMTargetSelector */
	/** @typedef {Array.<DOMTargetSelector>|DOMTargetSelector} DOMTargetsParam */
	/** @typedef {Array.<DOMTarget>} DOMTargetsArray */
	/** @typedef {Array.<JSTarget>|JSTarget} JSTargetsParam */
	/** @typedef {Array.<JSTarget>} JSTargetsArray */
	/** @typedef {Array.<TargetSelector>|TargetSelector} TargetsParam */
	/** @typedef {Array.<Target>} TargetsArray */

	/**
	 * @callback FunctionValue
	 * @param {Target} target - The animated target
	 * @param {Number} index - The target index
	 * @param {Number} length - The total number of animated targets
	 * @return {Number|String|TweenObjectValue|Array.<Number|String|TweenObjectValue>}
	 */

	/**
	 * @callback TweenModifier
	 * @param {Number} value - The animated value
	 * @return {Number|String}
	 */

	/** @typedef {[Number, Number, Number, Number]} ColorArray */

	/**
	 * @template T
	 * @callback Callback
	 * @param {T} self - Returns itself
	 * @param {PointerEvent} [e]
	 * @return {*}
	 */

	/**
	 * @template {object} T
	 * @typedef {Object} TickableCallbacks
	 * @property {Callback<T>} [onBegin]
	 * @property {Callback<T>} [onBeforeUpdate]
	 * @property {Callback<T>} [onUpdate]
	 * @property {Callback<T>} [onLoop]
	 * @property {Callback<T>} [onPause]
	 * @property {Callback<T>} [onComplete]
	 */

	/**
	 * @template {object} T
	 * @typedef {Object} RenderableCallbacks
	 * @property {Callback<T>} [onRender]
	 */

	/**
	 * @typedef {Object} Tween
	 * @property {Number} id
	 * @property {JSAnimation} parent
	 * @property {String} property
	 * @property {Target} target
	 * @property {String|Number} _value
	 * @property {Function|null} _func
	 * @property {EasingFunction} _ease
	 * @property {Array.<Number>} _fromNumbers
	 * @property {Array.<Number>} _toNumbers
	 * @property {Array.<String>} _strings
	 * @property {Number} _fromNumber
	 * @property {Number} _toNumber
	 * @property {Array.<Number>} _numbers
	 * @property {Number} _number
	 * @property {String} _unit
	 * @property {TweenModifier} _modifier
	 * @property {Number} _currentTime
	 * @property {Number} _delay
	 * @property {Number} _updateDuration
	 * @property {Number} _startTime
	 * @property {Number} _changeDuration
	 * @property {Number} _absoluteStartTime
	 * @property {tweenTypes} _tweenType
	 * @property {valueTypes} _valueType
	 * @property {Number} _composition
	 * @property {Number} _isOverlapped
	 * @property {Number} _isOverridden
	 * @property {Number} _renderTransforms
	 * @property {Tween} _prevRep
	 * @property {Tween} _nextRep
	 * @property {Tween} _prevAdd
	 * @property {Tween} _nextAdd
	 * @property {Tween} _prev
	 * @property {Tween} _next
	 */

	/**
	 * @typedef TweenDecomposedValue
	 * @property {Number} t - Type
	 * @property {Number} n - Single number value
	 * @property {String} u - Value unit
	 * @property {String} o - Value operator
	 * @property {Array.<Number>} d - Array of Numbers (in case of complex value type)
	 * @property {Array.<String>} s - Strings (in case of complex value type)
	 */

	/** @typedef {{_head: null|Tween, _tail: null|Tween}} TweenPropertySiblings */
	/** @typedef {Record<String, TweenPropertySiblings>} TweenLookups */
	/** @typedef {WeakMap.<Target, TweenLookups>} TweenReplaceLookups */
	/** @typedef {Map.<Target, TweenLookups>} TweenAdditiveLookups */

	/**
	 * @typedef {Object} TimerOptions
	 * @property {Number|String} [id]
	 * @property {TweenParamValue} [duration]
	 * @property {TweenParamValue} [delay]
	 * @property {Number} [loopDelay]
	 * @property {Boolean} [reversed]
	 * @property {Boolean} [alternate]
	 * @property {Boolean|Number} [loop]
	 * @property {Boolean|ScrollObserver} [autoplay]
	 * @property {Number} [frameRate]
	 * @property {Number} [playbackRate]
	 */

	/**

	/**
	 * @typedef {TimerOptions & TickableCallbacks<Timer>} TimerParams
	 */

	/**
	 * @typedef {Number|String|FunctionValue} TweenParamValue
	 */

	/**
	 * @typedef {TweenParamValue|[TweenParamValue, TweenParamValue]} TweenPropValue
	 */

	/**
	 * @typedef {(String & {})|'none'|'replace'|'blend'|compositionTypes} TweenComposition
	 */

	/**
	 * @typedef {Object} TweenParamsOptions
	 * @property {TweenParamValue} [duration]
	 * @property {TweenParamValue} [delay]
	 * @property {EasingParam} [ease]
	 * @property {TweenModifier} [modifier]
	 * @property {TweenComposition} [composition]
	 */

	/**
	 * @typedef {Object} TweenValues
	 * @property {TweenParamValue} [from]
	 * @property {TweenPropValue} [to]
	 * @property {TweenPropValue} [fromTo]
	 */

	/**
	 * @typedef {TweenParamsOptions & TweenValues} TweenKeyValue
	 */

	/**
	 * @typedef {Array.<TweenKeyValue|TweenPropValue>} ArraySyntaxValue
	 */

	/**
	 * @typedef {TweenParamValue|ArraySyntaxValue|TweenKeyValue} TweenOptions
	 */

	/**
	 * @typedef {Partial<{to: TweenParamValue|Array.<TweenParamValue>; from: TweenParamValue|Array.<TweenParamValue>; fromTo: TweenParamValue|Array.<TweenParamValue>;}>} TweenObjectValue
	 */

	/**
	 * @typedef {Object} PercentageKeyframeOptions
	 * @property {EasingParam} [ease]
	 */

	/**
	 * @typedef {Record<String, TweenParamValue>} PercentageKeyframeParams
	 */

	/**
	 * @typedef {Record<String, PercentageKeyframeParams & PercentageKeyframeOptions>} PercentageKeyframes
	 */

	/**
	 * @typedef {Array<Record<String, TweenOptions | TweenModifier | boolean> & TweenParamsOptions>} DurationKeyframes
	 */

	/**
	 * @typedef {Object} AnimationOptions
	 * @property {PercentageKeyframes|DurationKeyframes} [keyframes]
	 * @property {EasingParam} [playbackEase]
	 */

	// TODO: Currently setting TweenModifier to the intersected Record<> makes the FunctionValue type target param any if only one parameter is set
	/**
	 * @typedef {Record<String, TweenOptions | Callback<JSAnimation> | TweenModifier | boolean | PercentageKeyframes | DurationKeyframes | ScrollObserver> & TimerOptions & AnimationOptions & TweenParamsOptions & TickableCallbacks<JSAnimation> & RenderableCallbacks<JSAnimation>} AnimationParams
	 */

	/**
	 * @typedef {Object} TimelineOptions
	 * @property {DefaultsParams} [defaults]
	 * @property {EasingParam} [playbackEase]
	 */

	/**
	 * @typedef {TimerOptions & TimelineOptions & TickableCallbacks<Timeline> & RenderableCallbacks<Timeline>} TimelineParams
	 */

	/**
	 * @callback AnimatablePropertySetter
	 * @param  {Number|Array.<Number>} to
	 * @param  {Number} [duration]
	 * @param  {EasingParam} [ease]
	 * @return {AnimatableObject}
	 */

	/**
	 * @callback AnimatablePropertyGetter
	 * @return {Number|Array.<Number>}
	 */

	/**
	 * @typedef {AnimatablePropertySetter & AnimatablePropertyGetter} AnimatableProperty
	 */

	/**
	 * @typedef {Animatable & Record<String, AnimatableProperty>} AnimatableObject
	 */

	/**
	 * @typedef {Object} AnimatablePropertyParamsOptions
	 * @property {String} [unit]
	 * @property {TweenParamValue} [duration]
	 * @property {EasingParam} [ease]
	 * @property {TweenModifier} [modifier]
	 * @property {TweenComposition} [composition]
	 */

	/**
	 * @typedef {Record<String, TweenParamValue | EasingParam | TweenModifier | TweenComposition | AnimatablePropertyParamsOptions> & AnimatablePropertyParamsOptions} AnimatableParams
	 */


	// Environments

	// TODO: Do we need to check if we're running inside a worker ?
	const isBrowser = typeof window !== 'undefined';

	/** @type {Object|Null} */
	const win = isBrowser ? window : null;

	/** @type {Document} */
	const doc = isBrowser ? document : null;

	// Enums

	/** @enum {Number} */
	const tweenTypes = {
	  OBJECT: 0,
	  ATTRIBUTE: 1,
	  CSS: 2,
	  TRANSFORM: 3,
	  CSS_VAR: 4,
	};

	/** @enum {Number} */
	const valueTypes = {
	  NUMBER: 0,
	  UNIT: 1,
	  COLOR: 2,
	  COMPLEX: 3,
	};

	/** @enum {Number} */
	const tickModes = {
	  NONE: 0,
	  AUTO: 1,
	  FORCE: 2,
	};

	/** @enum {Number} */
	const compositionTypes = {
	  replace: 0,
	  none: 1,
	  blend: 2,
	};

	// Cache symbols

	const isRegisteredTargetSymbol = Symbol();
	const isDomSymbol = Symbol();
	const isSvgSymbol = Symbol();
	const transformsSymbol = Symbol();
	const proxyTargetSymbol = Symbol();

	// Numbers

	const minValue = 1e-11;
	const maxValue = 1e12;
	const K = 1e3;
	const maxFps = 120;

	// Strings

	const emptyString = '';
	const shortTransforms = new Map();

	shortTransforms.set('x', 'translateX');
	shortTransforms.set('y', 'translateY');
	shortTransforms.set('z', 'translateZ');

	const validTransforms = [
	  'translateX',
	  'translateY',
	  'translateZ',
	  'rotate',
	  'rotateX',
	  'rotateY',
	  'rotateZ',
	  'scale',
	  'scaleX',
	  'scaleY',
	  'scaleZ',
	  'skew',
	  'skewX',
	  'skewY',
	  'perspective',
	  'matrix',
	  'matrix3d',
	];

	const transformsFragmentStrings = validTransforms.reduce((a, v) => ({...a, [v]: v + '('}), {});

	// Functions

	/** @return {void} */
	const noop = () => {};

	// Regex

	const hexTestRgx = /(^#([\da-f]{3}){1,2}$)|(^#([\da-f]{4}){1,2}$)/i;
	const rgbExecRgx = /rgb\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)/i;
	const rgbaExecRgx = /rgba\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(-?\d+|-?\d*.\d+)\s*\)/i;
	const hslExecRgx = /hsl\(\s*(-?\d+|-?\d*.\d+)\s*,\s*(-?\d+|-?\d*.\d+)%\s*,\s*(-?\d+|-?\d*.\d+)%\s*\)/i;
	const hslaExecRgx = /hsla\(\s*(-?\d+|-?\d*.\d+)\s*,\s*(-?\d+|-?\d*.\d+)%\s*,\s*(-?\d+|-?\d*.\d+)%\s*,\s*(-?\d+|-?\d*.\d+)\s*\)/i;
	// export const digitWithExponentRgx = /[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?/g;
	const digitWithExponentRgx = /[-+]?\d*\.?\d+(?:e[-+]?\d)?/gi;
	// export const unitsExecRgx = /^([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)+([a-z]+|%)$/i;
	const unitsExecRgx = /^([-+]?\d*\.?\d+(?:e[-+]?\d+)?)([a-z]+|%)$/i;
	const lowerCaseRgx = /([a-z])([A-Z])/g;
	const transformsExecRgx = /(\w+)(\([^)]+\)+)/g; // Match inline transforms with cacl() values, returns the value wrapped in ()




	/** @type {DefaultsParams} */
	const defaults = {
	  id: null,
	  keyframes: null,
	  playbackEase: null,
	  playbackRate: 1,
	  frameRate: maxFps,
	  loop: 0,
	  reversed: false,
	  alternate: false,
	  autoplay: true,
	  duration: K,
	  delay: 0,
	  loopDelay: 0,
	  ease: 'out(2)',
	  composition: compositionTypes.replace,
	  modifier: v => v,
	  onBegin: noop,
	  onBeforeUpdate: noop,
	  onUpdate: noop,
	  onLoop: noop,
	  onPause: noop,
	  onComplete: noop,
	  onRender: noop,
	};

	const globals = {
	  /** @type {DefaultsParams} */
	  defaults,
	  /** @type {Document|DOMTarget} */
	  root: doc,
	  /** @type {Scope} */
	  scope: null,
	  /** @type {Number} */
	  precision: 4,
	  /** @type {Number} */
	  timeScale: 1,
	  /** @type {Number} */
	  tickThreshold: 200,
	};

	const globalVersions = { version: '4.0.2', engine: null };

	if (isBrowser) {
	  if (!win.AnimeJS) win.AnimeJS = [];
	  win.AnimeJS.push(globalVersions);
	}

	// Strings

	/**
	 * @param  {String} str
	 * @return {String}
	 */
	const toLowerCase = str => str.replace(lowerCaseRgx, '$1-$2').toLowerCase();

	/**
	 * Prioritize this method instead of regex when possible
	 * @param  {String} str
	 * @param  {String} sub
	 * @return {Boolean}
	 */
	const stringStartsWith = (str, sub) => str.indexOf(sub) === 0;

	// Time
	// Note: Date.now is used instead of performance.now since it is precise enough for timings calculations, performs slightly faster and works in Node.js environement.
	const now$2 = Date.now;

	// Types checkers

	const isArr = Array.isArray;
	/**@param {any} a @return {a is Record<String, any>} */
	const isObj = a => a && a.constructor === Object;
	/**@param {any} a @return {a is Number} */
	const isNum = a => typeof a === 'number' && !isNaN(a);
	/**@param {any} a @return {a is String} */
	const isStr = a => typeof a === 'string';
	/**@param {any} a @return {a is Function} */
	const isFnc = a => typeof a === 'function';
	/**@param {any} a @return {a is undefined} */
	const isUnd = a => typeof a === 'undefined';
	/**@param {any} a @return {a is null | undefined} */
	const isNil = a => isUnd(a) || a === null;
	/**@param {any} a @return {a is SVGElement} */
	const isSvg = a => isBrowser && a instanceof SVGElement;
	/**@param {any} a @return {Boolean} */
	const isHex = a => hexTestRgx.test(a);
	/**@param {any} a @return {Boolean} */
	const isRgb = a => stringStartsWith(a, 'rgb');
	/**@param {any} a @return {Boolean} */
	const isHsl = a => stringStartsWith(a, 'hsl');
	/**@param {any} a @return {Boolean} */
	const isCol = a => isHex(a) || isRgb(a) || isHsl(a);
	/**@param {any} a @return {Boolean} */
	const isKey = a => !globals.defaults.hasOwnProperty(a);

	// Number

	/**
	 * @param  {Number|String} str
	 * @return {Number}
	 */
	const parseNumber = str => isStr(str) ?
	  parseFloat(/** @type {String} */(str)) :
	  /** @type {Number} */(str);

	// Math

	const pow = Math.pow;
	const sqrt = Math.sqrt;
	const sin = Math.sin;
	const cos = Math.cos;
	const abs = Math.abs;
	const ceil = Math.ceil;
	const floor = Math.floor;
	const asin = Math.asin;
	const PI = Math.PI;
	const _round = Math.round;

	/**
	 * @param  {Number} v
	 * @param  {Number} min
	 * @param  {Number} max
	 * @return {Number}
	 */
	const clamp$1 = (v, min, max) => v < min ? min : v > max ? max : v;

	const powCache = {};

	/**
	 * @param  {Number} v
	 * @param  {Number} decimalLength
	 * @return {Number}
	 */
	const round = (v, decimalLength) => {
	  if (decimalLength < 0) return v;
	  if (!decimalLength) return _round(v);
	  let p = powCache[decimalLength];
	  if (!p) p = powCache[decimalLength] = 10 ** decimalLength;
	  return _round(v * p) / p;
	};

	/**
	 * @param  {Number} start
	 * @param  {Number} end
	 * @param  {Number} progress
	 * @return {Number}
	 */
	const interpolate = (start, end, progress) => start + (end - start) * progress;

	/**
	 * @param  {Number} v
	 * @return {Number}
	 */
	const clampInfinity = v => v === Infinity ? maxValue : v === -Infinity ? -1e12 : v;

	/**
	 * @param  {Number} v
	 * @return {Number}
	 */
	const normalizeTime = v => v <= minValue ? minValue : clampInfinity(round(v, 11));

	// Arrays

	/**
	 * @template T
	 * @param {T[]} a
	 * @return {T[]}
	 */
	const cloneArray = a => isArr(a) ? [ ...a ] : a;

	// Objects

	/**
	 * @template T
	 * @template U
	 * @param {T} o1
	 * @param {U} o2
	 * @return {T & U}
	 */
	const mergeObjects = (o1, o2) => {
	  const merged = /** @type {T & U} */({ ...o1 });
	  for (let p in o2) {
	    const o1p = /** @type {T & U} */(o1)[p];
	    merged[p] = isUnd(o1p) ? /** @type {T & U} */(o2)[p] : o1p;
	  }  return merged;
	};

	// Linked lists

	/**
	 * @param {Object} parent
	 * @param {Function} callback
	 * @param {Boolean} [reverse]
	 * @param {String} [prevProp]
	 * @param {String} [nextProp]
	 * @return {void}
	 */
	const forEachChildren = (parent, callback, reverse, prevProp = '_prev', nextProp = '_next') => {
	  let next = parent._head;
	  let adjustedNextProp = nextProp;
	  if (reverse) {
	    next = parent._tail;
	    adjustedNextProp = prevProp;
	  }
	  while (next) {
	    const currentNext = next[adjustedNextProp];
	    callback(next);
	    next = currentNext;
	  }
	};

	/**
	 * @param  {Object} parent
	 * @param  {Object} child
	 * @param  {String} [prevProp]
	 * @param  {String} [nextProp]
	 * @return {void}
	 */
	const removeChild = (parent, child, prevProp = '_prev', nextProp = '_next') => {
	  const prev = child[prevProp];
	  const next = child[nextProp];
	  prev ? prev[nextProp] = next : parent._head = next;
	  next ? next[prevProp] = prev : parent._tail = prev;
	  child[prevProp] = null;
	  child[nextProp] = null;
	};

	/**
	 * @param  {Object} parent
	 * @param  {Object} child
	 * @param  {Function} [sortMethod]
	 * @param  {String} prevProp
	 * @param  {String} nextProp
	 * @return {void}
	 */
	const addChild = (parent, child, sortMethod, prevProp = '_prev', nextProp = '_next') => {
	  let prev = parent._tail;
	  while (prev && sortMethod && sortMethod(prev, child)) prev = prev[prevProp];
	  const next = prev ? prev[nextProp] : parent._head;
	  prev ? prev[nextProp] = child : parent._head = child;
	  next ? next[prevProp] = child : parent._tail = child;
	  child[prevProp] = prev;
	  child[nextProp] = next;
	};

	/*
	 * Base class to control framerate and playback rate.
	 * Inherited by Engine, Timer, Animation and Timeline.
	 */
	class Clock$1 {

	  /** @param {Number} [initTime] */
	  constructor(initTime = 0) {
	    /** @type {Number} */
	    this.deltaTime = 0;
	    /** @type {Number} */
	    this._currentTime = initTime;
	    /** @type {Number} */
	    this._elapsedTime = initTime;
	    /** @type {Number} */
	    this._startTime = initTime;
	    /** @type {Number} */
	    this._lastTime = initTime;
	    /** @type {Number} */
	    this._scheduledTime = 0;
	    /** @type {Number} */
	    this._frameDuration = round(K / maxFps, 0);
	    /** @type {Number} */
	    this._fps = maxFps;
	    /** @type {Number} */
	    this._speed = 1;
	    /** @type {Boolean} */
	    this._hasChildren = false;
	    /** @type {Tickable|Tween} */
	    this._head = null;
	    /** @type {Tickable|Tween} */
	    this._tail = null;
	  }

	  get fps() {
	    return this._fps;
	  }

	  set fps(frameRate) {
	    const previousFrameDuration = this._frameDuration;
	    const fr = +frameRate;
	    const fps = fr < minValue ? minValue : fr;
	    const frameDuration = round(K / fps, 0);
	    this._fps = fps;
	    this._frameDuration = frameDuration;
	    this._scheduledTime += frameDuration - previousFrameDuration;
	  }

	  get speed() {
	    return this._speed;
	  }

	  set speed(playbackRate) {
	    const pbr = +playbackRate;
	    this._speed = pbr < minValue ? minValue : pbr;
	  }

	  /**
	   * @param  {Number} time
	   * @return {tickModes}
	   */
	  requestTick(time) {
	    const scheduledTime = this._scheduledTime;
	    const elapsedTime = this._elapsedTime;
	    this._elapsedTime += (time - elapsedTime);
	    // If the elapsed time is lower than the scheduled time
	    // this means not enough time has passed to hit one frameDuration
	    // so skip that frame
	    if (elapsedTime < scheduledTime) return tickModes.NONE;
	    const frameDuration = this._frameDuration;
	    const frameDelta = elapsedTime - scheduledTime;
	    // Ensures that _scheduledTime progresses in steps of at least 1 frameDuration.
	    // Skips ahead if the actual elapsed time is higher.
	    this._scheduledTime += frameDelta < frameDuration ? frameDuration : frameDelta;
	    return tickModes.AUTO;
	  }

	  /**
	   * @param  {Number} time
	   * @return {Number}
	   */
	  computeDeltaTime(time) {
	    const delta = time - this._lastTime;
	    this.deltaTime = delta;
	    this._lastTime = time;
	    return delta;
	  }

	}




	/**
	 * @param  {Tickable} tickable
	 * @param  {Number} time
	 * @param  {Number} muteCallbacks
	 * @param  {Number} internalRender
	 * @param  {tickModes} tickMode
	 * @return {Number}
	 */
	const render = (tickable, time, muteCallbacks, internalRender, tickMode) => {

	  const parent = tickable.parent;
	  const duration = tickable.duration;
	  const completed = tickable.completed;
	  const iterationDuration = tickable.iterationDuration;
	  const iterationCount = tickable.iterationCount;
	  const _currentIteration = tickable._currentIteration;
	  const _loopDelay = tickable._loopDelay;
	  const _reversed = tickable._reversed;
	  const _alternate = tickable._alternate;
	  const _hasChildren = tickable._hasChildren;
	  const tickableDelay = tickable._delay;
	  const tickablePrevAbsoluteTime = tickable._currentTime; // TODO: rename ._currentTime to ._absoluteCurrentTime

	  const tickableEndTime = tickableDelay + iterationDuration;
	  const tickableAbsoluteTime = time - tickableDelay;
	  const tickablePrevTime = clamp$1(tickablePrevAbsoluteTime, -tickableDelay, duration);
	  const tickableCurrentTime = clamp$1(tickableAbsoluteTime, -tickableDelay, duration);
	  const deltaTime = tickableAbsoluteTime - tickablePrevAbsoluteTime;
	  const isCurrentTimeAboveZero = tickableCurrentTime > 0;
	  const isCurrentTimeEqualOrAboveDuration = tickableCurrentTime >= duration;
	  const isSetter = duration <= minValue;
	  const forcedTick = tickMode === tickModes.FORCE;

	  let isOdd = 0;
	  let iterationElapsedTime = tickableAbsoluteTime;
	  // Render checks
	  // Used to also check if the children have rendered in order to trigger the onRender callback on the parent timer
	  let hasRendered = 0;

	  // Execute the "expensive" iterations calculations only when necessary
	  if (iterationCount > 1) {
	    // bitwise NOT operator seems to be generally faster than Math.floor() across browsers
	    const currentIteration = ~~(tickableCurrentTime / (iterationDuration + (isCurrentTimeEqualOrAboveDuration ? 0 : _loopDelay)));
	    tickable._currentIteration = clamp$1(currentIteration, 0, iterationCount);
	    // Prevent the iteration count to go above the max iterations when reaching the end of the animation
	    if (isCurrentTimeEqualOrAboveDuration) tickable._currentIteration--;
	    isOdd = tickable._currentIteration % 2;
	    iterationElapsedTime = tickableCurrentTime % (iterationDuration + _loopDelay) || 0;
	  }

	  // Checks if exactly one of _reversed and (_alternate && isOdd) is true
	  const isReversed = _reversed ^ (_alternate && isOdd);
	  const _ease = /** @type {Renderable} */(tickable)._ease;
	  let iterationTime = isCurrentTimeEqualOrAboveDuration ? isReversed ? 0 : duration : isReversed ? iterationDuration - iterationElapsedTime : iterationElapsedTime;
	  if (_ease) iterationTime = iterationDuration * _ease(iterationTime / iterationDuration) || 0;
	  const isRunningBackwards = (parent ? parent.backwards : tickableAbsoluteTime < tickablePrevAbsoluteTime) ? !isReversed : !!isReversed;

	  tickable._currentTime = tickableAbsoluteTime;
	  tickable._iterationTime = iterationTime;
	  tickable.backwards = isRunningBackwards;

	  if (isCurrentTimeAboveZero && !tickable.began) {
	    tickable.began = true;
	    if (!muteCallbacks && !(parent && (isRunningBackwards || !parent.began))) {
	      tickable.onBegin(/** @type {CallbackArgument} */(tickable));
	    }
	  } else if (tickableAbsoluteTime <= 0) {
	    tickable.began = false;
	  }

	  // Only triggers onLoop for tickable without children, otherwise call the the onLoop callback in the tick function
	  // Make sure to trigger the onLoop before rendering to allow .refresh() to pickup the current values
	  if (!muteCallbacks && !_hasChildren && isCurrentTimeAboveZero && tickable._currentIteration !== _currentIteration) {
	    tickable.onLoop(/** @type {CallbackArgument} */(tickable));
	  }

	  if (
	    forcedTick ||
	    tickMode === tickModes.AUTO && (
	      time >= tickableDelay && time <= tickableEndTime || // Normal render
	      time <= tickableDelay && tickablePrevTime > tickableDelay || // Playhead is before the animation start time so make sure the animation is at its initial state
	      time >= tickableEndTime && tickablePrevTime !== duration // Playhead is after the animation end time so make sure the animation is at its end state
	    ) ||
	    iterationTime >= tickableEndTime && tickablePrevTime !== duration ||
	    iterationTime <= tickableDelay && tickablePrevTime > 0 ||
	    time <= tickablePrevTime && tickablePrevTime === duration && completed || // Force a render if a seek occurs on an completed animation
	    isCurrentTimeEqualOrAboveDuration && !completed && isSetter // This prevents 0 duration tickables to be skipped
	  ) {

	    if (isCurrentTimeAboveZero) {
	      // Trigger onUpdate callback before rendering
	      tickable.computeDeltaTime(tickablePrevTime);
	      if (!muteCallbacks) tickable.onBeforeUpdate(/** @type {CallbackArgument} */(tickable));
	    }

	    // Start tweens rendering
	    if (!_hasChildren) {

	      // Time has jumped more than globals.tickThreshold so consider this tick manual
	      const forcedRender = forcedTick || (isRunningBackwards ? deltaTime * -1 : deltaTime) >= globals.tickThreshold;
	      const absoluteTime = tickable._offset + (parent ? parent._offset : 0) + tickableDelay + iterationTime;

	      // Only Animation can have tweens, Timer returns undefined
	      let tween = /** @type {Tween} */(/** @type {JSAnimation} */(tickable)._head);
	      let tweenTarget;
	      let tweenStyle;
	      let tweenTargetTransforms;
	      let tweenTargetTransformsProperties;
	      let tweenTransformsNeedUpdate = 0;

	      while (tween) {

	        const tweenComposition = tween._composition;
	        const tweenCurrentTime = tween._currentTime;
	        const tweenChangeDuration = tween._changeDuration;
	        const tweenAbsEndTime = tween._absoluteStartTime + tween._changeDuration;
	        const tweenNextRep = tween._nextRep;
	        const tweenPrevRep = tween._prevRep;
	        const tweenHasComposition = tweenComposition !== compositionTypes.none;

	        if ((forcedRender || (
	            (tweenCurrentTime !== tweenChangeDuration || absoluteTime <= tweenAbsEndTime + (tweenNextRep ? tweenNextRep._delay : 0)) &&
	            (tweenCurrentTime !== 0 || absoluteTime >= tween._absoluteStartTime)
	          )) && (!tweenHasComposition || (
	            !tween._isOverridden &&
	            (!tween._isOverlapped || absoluteTime <= tweenAbsEndTime) &&
	            (!tweenNextRep || (tweenNextRep._isOverridden || absoluteTime <= tweenNextRep._absoluteStartTime)) &&
	            (!tweenPrevRep || (tweenPrevRep._isOverridden || (absoluteTime >= (tweenPrevRep._absoluteStartTime + tweenPrevRep._changeDuration) + tween._delay)))
	          ))
	        ) {

	          const tweenNewTime = tween._currentTime = clamp$1(iterationTime - tween._startTime, 0, tweenChangeDuration);
	          const tweenProgress = tween._ease(tweenNewTime / tween._updateDuration);
	          const tweenModifier = tween._modifier;
	          const tweenValueType = tween._valueType;
	          const tweenType = tween._tweenType;
	          const tweenIsObject = tweenType === tweenTypes.OBJECT;
	          const tweenIsNumber = tweenValueType === valueTypes.NUMBER;
	          // Only round the in-between frames values if the final value is a string
	          const tweenPrecision = (tweenIsNumber && tweenIsObject) || tweenProgress === 0 || tweenProgress === 1 ? -1 : globals.precision;

	          // Recompose tween value
	          /** @type {String|Number} */
	          let value;
	          /** @type {Number} */
	          let number;

	          if (tweenIsNumber) {
	            value = number = /** @type {Number} */(tweenModifier(round(interpolate(tween._fromNumber, tween._toNumber,  tweenProgress), tweenPrecision )));
	          } else if (tweenValueType === valueTypes.UNIT) {
	            // Rounding the values speed up string composition
	            number = /** @type {Number} */(tweenModifier(round(interpolate(tween._fromNumber, tween._toNumber,  tweenProgress), tweenPrecision)));
	            value = `${number}${tween._unit}`;
	          } else if (tweenValueType === valueTypes.COLOR) {
	            const fn = tween._fromNumbers;
	            const tn = tween._toNumbers;
	            const r = round(clamp$1(/** @type {Number} */(tweenModifier(interpolate(fn[0], tn[0], tweenProgress))), 0, 255), 0);
	            const g = round(clamp$1(/** @type {Number} */(tweenModifier(interpolate(fn[1], tn[1], tweenProgress))), 0, 255), 0);
	            const b = round(clamp$1(/** @type {Number} */(tweenModifier(interpolate(fn[2], tn[2], tweenProgress))), 0, 255), 0);
	            const a = clamp$1(/** @type {Number} */(tweenModifier(round(interpolate(fn[3], tn[3], tweenProgress), tweenPrecision))), 0, 1);
	            value = `rgba(${r},${g},${b},${a})`;
	            if (tweenHasComposition) {
	              const ns = tween._numbers;
	              ns[0] = r;
	              ns[1] = g;
	              ns[2] = b;
	              ns[3] = a;
	            }
	          } else if (tweenValueType === valueTypes.COMPLEX) {
	            value = tween._strings[0];
	            for (let j = 0, l = tween._toNumbers.length; j < l; j++) {
	              const n = /** @type {Number} */(tweenModifier(round(interpolate(tween._fromNumbers[j], tween._toNumbers[j], tweenProgress), tweenPrecision)));
	              const s = tween._strings[j + 1];
	              value += `${s ? n + s : n}`;
	              if (tweenHasComposition) {
	                tween._numbers[j] = n;
	              }
	            }
	          }

	          // For additive tweens and Animatables
	          if (tweenHasComposition) {
	            tween._number = number;
	          }

	          if (!internalRender && tweenComposition !== compositionTypes.blend) {

	            const tweenProperty = tween.property;
	            tweenTarget = tween.target;

	            if (tweenIsObject) {
	              tweenTarget[tweenProperty] = value;
	            } else if (tweenType === tweenTypes.ATTRIBUTE) {
	              /** @type {DOMTarget} */(tweenTarget).setAttribute(tweenProperty, /** @type {String} */(value));
	            } else {
	              tweenStyle = /** @type {DOMTarget} */(tweenTarget).style;
	              if (tweenType === tweenTypes.TRANSFORM) {
	                if (tweenTarget !== tweenTargetTransforms) {
	                  tweenTargetTransforms = tweenTarget;
	                  // NOTE: Referencing the cachedTransforms in the tween property directly can be a little bit faster but appears to increase memory usage.
	                  tweenTargetTransformsProperties = tweenTarget[transformsSymbol];
	                }
	                tweenTargetTransformsProperties[tweenProperty] = value;
	                tweenTransformsNeedUpdate = 1;
	              } else if (tweenType === tweenTypes.CSS) {
	                tweenStyle[tweenProperty] = value;
	              } else if (tweenType === tweenTypes.CSS_VAR) {
	                tweenStyle.setProperty(tweenProperty,/** @type {String} */(value));
	              }
	            }

	            if (isCurrentTimeAboveZero) hasRendered = 1;

	          } else {
	            // Used for composing timeline tweens without having to do a real render
	            tween._value = value;
	          }

	        }

	        // NOTE: Possible improvement: Use translate(x,y) / translate3d(x,y,z) syntax
	        // to reduce memory usage on string composition
	        if (tweenTransformsNeedUpdate && tween._renderTransforms) {
	          let str = emptyString;
	          for (let key in tweenTargetTransformsProperties) {
	            str += `${transformsFragmentStrings[key]}${tweenTargetTransformsProperties[key]}) `;
	          }
	          tweenStyle.transform = str;
	          tweenTransformsNeedUpdate = 0;
	        }

	        tween = tween._next;
	      }

	      if (!muteCallbacks && hasRendered) {
	        /** @type {JSAnimation} */(tickable).onRender(/** @type {JSAnimation} */(tickable));
	      }
	    }

	    if (!muteCallbacks && isCurrentTimeAboveZero) {
	      tickable.onUpdate(/** @type {CallbackArgument} */(tickable));
	    }

	  }

	  // End tweens rendering

	  // Handle setters on timeline differently and allow re-trigering the onComplete callback when seeking backwards
	  if (parent && isSetter) {
	    if (!muteCallbacks && (
	      (parent.began && !isRunningBackwards && tickableAbsoluteTime >= duration && !completed) ||
	      (isRunningBackwards && tickableAbsoluteTime <= minValue && completed)
	    )) {
	      tickable.onComplete(/** @type {CallbackArgument} */(tickable));
	      tickable.completed = !isRunningBackwards;
	    }
	  // If currentTime is both above 0 and at least equals to duration, handles normal onComplete or infinite loops
	  } else if (isCurrentTimeAboveZero && isCurrentTimeEqualOrAboveDuration) {
	    if (iterationCount === Infinity) {
	      // Offset the tickable _startTime with its duration to reset _currentTime to 0 and continue the infinite timer
	      tickable._startTime += tickable.duration;
	    } else if (tickable._currentIteration >= iterationCount - 1) {
	      // By setting paused to true, we tell the engine loop to not render this tickable and removes it from the list on the next tick
	      tickable.paused = true;
	      if (!completed && !_hasChildren) {
	        // If the tickable has children, triggers onComplete() only when all children have completed in the tick function
	        tickable.completed = true;
	        if (!muteCallbacks && !(parent && (isRunningBackwards || !parent.began))) {
	          tickable.onComplete(/** @type {CallbackArgument} */(tickable));
	          tickable._resolve(/** @type {CallbackArgument} */(tickable));
	        }
	      }
	    }
	  // Otherwise set the completed flag to false
	  } else {
	    tickable.completed = false;
	  }

	  // NOTE: hasRendered * direction (negative for backwards) this way we can remove the tickable.backwards property completly ?
	  return hasRendered;
	};

	/**
	 * @param  {Tickable} tickable
	 * @param  {Number} time
	 * @param  {Number} muteCallbacks
	 * @param  {Number} internalRender
	 * @param  {Number} tickMode
	 * @return {void}
	 */
	const tick = (tickable, time, muteCallbacks, internalRender, tickMode) => {
	  const _currentIteration = tickable._currentIteration;
	  render(tickable, time, muteCallbacks, internalRender, tickMode);
	  if (tickable._hasChildren) {
	    const tl = /** @type {Timeline} */(tickable);
	    const tlIsRunningBackwards = tl.backwards;
	    const tlChildrenTime = internalRender ? time : tl._iterationTime;
	    const tlCildrenTickTime = now$2();

	    let tlChildrenHasRendered = 0;
	    let tlChildrenHaveCompleted = true;

	    // If the timeline has looped forward, we need to manually triggers children skipped callbacks
	    if (!internalRender && tl._currentIteration !== _currentIteration) {
	      const tlIterationDuration = tl.iterationDuration;
	      forEachChildren(tl, (/** @type {JSAnimation} */child) => {
	        if (!tlIsRunningBackwards) {
	          // Force an internal render to trigger the callbacks if the child has not completed on loop
	          if (!child.completed && !child.backwards && child._currentTime < child.iterationDuration) {
	            render(child, tlIterationDuration, muteCallbacks, 1, tickModes.FORCE);
	          }
	          // Reset their began and completed flags to allow retrigering callbacks on the next iteration
	          child.began = false;
	          child.completed = false;
	        } else {
	          const childDuration = child.duration;
	          const childStartTime = child._offset + child._delay;
	          const childEndTime = childStartTime + childDuration;
	          // Triggers the onComplete callback on reverse for children on the edges of the timeline
	          if (!muteCallbacks && childDuration <= minValue && (!childStartTime || childEndTime === tlIterationDuration)) {
	            child.onComplete(child);
	          }
	        }
	      });
	      if (!muteCallbacks) tl.onLoop(/** @type {CallbackArgument} */(tl));
	    }

	    forEachChildren(tl, (/** @type {JSAnimation} */child) => {
	      const childTime = round((tlChildrenTime - child._offset) * child._speed, 12); // Rounding is needed when using seconds
	      const childTickMode = child._fps < tl._fps ? child.requestTick(tlCildrenTickTime) : tickMode;
	      tlChildrenHasRendered += render(child, childTime, muteCallbacks, internalRender, childTickMode);
	      if (!child.completed && tlChildrenHaveCompleted) tlChildrenHaveCompleted = false;
	    }, tlIsRunningBackwards);

	    // Renders on timeline are triggered by its children so it needs to be set after rendering the children
	    if (!muteCallbacks && tlChildrenHasRendered) tl.onRender(/** @type {CallbackArgument} */(tl));

	    // Triggers the timeline onComplete() once all chindren all completed and the current time has reached the end
	    if (tlChildrenHaveCompleted && tl._currentTime >= tl.duration) {
	      // Make sure the paused flag is false in case it has been skipped in the render function
	      tl.paused = true;
	      if (!tl.completed) {
	        tl.completed = true;
	        if (!muteCallbacks) {
	          tl.onComplete(/** @type {CallbackArgument} */(tl));
	          tl._resolve(/** @type {CallbackArgument} */(tl));
	        }
	      }
	    }
	  }
	};




	const additive = {
	  animation: null,
	  update: noop,
	};

	/**
	 * @typedef AdditiveAnimation
	 * @property {Number} duration
	 * @property {Number} _offset
	 * @property {Number} _delay
	 * @property {Tween} _head
	 * @property {Tween} _tail
	 */

	/**
	 * @param  {TweenAdditiveLookups} lookups
	 * @return {AdditiveAnimation}
	 */
	const addAdditiveAnimation = lookups => {
	  let animation = additive.animation;
	  if (!animation) {
	    animation = {
	      duration: minValue,
	      computeDeltaTime: noop,
	      _offset: 0,
	      _delay: 0,
	      _head: null,
	      _tail: null,
	    };
	    additive.animation = animation;
	    additive.update = () => {
	      lookups.forEach(propertyAnimation => {
	        for (let propertyName in propertyAnimation) {
	          const tweens = propertyAnimation[propertyName];
	          const lookupTween = tweens._head;
	          if (lookupTween) {
	            const valueType = lookupTween._valueType;
	            const additiveValues = valueType === valueTypes.COMPLEX || valueType === valueTypes.COLOR ? cloneArray(lookupTween._fromNumbers) : null;
	            let additiveValue = lookupTween._fromNumber;
	            let tween = tweens._tail;
	            while (tween && tween !== lookupTween) {
	              if (additiveValues) {
	                for (let i = 0, l = tween._numbers.length; i < l; i++) additiveValues[i] += tween._numbers[i];
	              } else {
	                additiveValue += tween._number;
	              }
	              tween = tween._prevAdd;
	            }
	            lookupTween._toNumber = additiveValue;
	            lookupTween._toNumbers = additiveValues;
	          }
	        }
	      });
	      // TODO: Avoid polymorphism here, idealy the additive animation should be a regular animation with a higher priority in the render loop
	      render(animation, 1, 1, 0, tickModes.FORCE);
	    };
	  }
	  return animation;
	};

	const engineTickMethod = isBrowser ? requestAnimationFrame : setImmediate;
	const engineCancelMethod = isBrowser ? cancelAnimationFrame : clearImmediate;

	class Engine extends Clock$1 {

	  /** @param {Number} [initTime] */
	  constructor(initTime) {
	    super(initTime);
	    this.useDefaultMainLoop = true;
	    this.pauseOnDocumentHidden = true;
	    /** @type {DefaultsParams} */
	    this.defaults = defaults;
	    this.paused = isBrowser && doc.hidden ? true  : false;
	    /** @type {Number|NodeJS.Immediate} */
	    this.reqId = null;
	  }

	  update() {
	    const time = this._currentTime = now$2();
	    if (this.requestTick(time)) {
	      this.computeDeltaTime(time);
	      const engineSpeed = this._speed;
	      const engineFps = this._fps;
	      let activeTickable = /** @type {Tickable} */(this._head);
	      while (activeTickable) {
	        const nextTickable = activeTickable._next;
	        if (!activeTickable.paused) {
	          tick(
	            activeTickable,
	            (time - activeTickable._startTime) * activeTickable._speed * engineSpeed,
	            0, // !muteCallbacks
	            0, // !internalRender
	            activeTickable._fps < engineFps ? activeTickable.requestTick(time) : tickModes.AUTO
	          );
	        } else {
	          removeChild(this, activeTickable);
	          this._hasChildren = !!this._tail;
	          activeTickable._running = false;
	          if (activeTickable.completed && !activeTickable._cancelled) {
	            activeTickable.cancel();
	          }
	        }
	        activeTickable = nextTickable;
	      }
	      additive.update();
	    }
	  }

	  wake() {
	    if (this.useDefaultMainLoop && !this.reqId && !this.paused) {
	      this.reqId = engineTickMethod(tickEngine);
	    }
	    return this;
	  }

	  pause() {
	    this.paused = true;
	    return killEngine();
	  }

	  resume() {
	    if (!this.paused) return;
	    this.paused = false;
	    forEachChildren(this, (/** @type {Tickable} */child) => child.resetTime());
	    return this.wake();
	  }

	  // Getter and setter for speed
	  get speed() {
	    return this._speed * (globals.timeScale === 1 ? 1 : K);
	  }

	  set speed(playbackRate) {
	    this._speed = playbackRate * globals.timeScale;
	    forEachChildren(this, (/** @type {Tickable} */child) => child.speed = child._speed);
	  }

	  // Getter and setter for timeUnit
	  get timeUnit() {
	    return globals.timeScale === 1 ? 'ms' : 's';
	  };

	  set timeUnit(unit) {
	    const secondsScale = 0.001;
	    const isSecond = unit === 's';
	    const newScale = isSecond ? secondsScale : 1;
	    if (globals.timeScale !== newScale) {
	      globals.timeScale = newScale;
	      globals.tickThreshold = 200 * newScale;
	      const scaleFactor = isSecond ? secondsScale : K;
	      /** @type {Number} */
	      (this.defaults.duration) *= scaleFactor;
	      this._speed *= scaleFactor;
	    }
	  }

	  // Getter and setter for precision
	  get precision() {
	    return globals.precision;
	  }

	  set precision(precision) {
	    globals.precision = precision;
	  }

	}
	const engine = /*#__PURE__*/(() => {
	  const engine = new Engine(now$2());
	  if (isBrowser) {
	    globalVersions.engine = engine;
	    doc.addEventListener('visibilitychange', () => {
	      if (!engine.pauseOnDocumentHidden) return;
	      doc.hidden ? engine.pause() : engine.resume();
	    });
	  }
	  return engine;
	})();


	const tickEngine = () => {
	  if (engine._head) {
	    engine.reqId = engineTickMethod(tickEngine);
	    engine.update();
	  } else {
	    engine.reqId = 0;
	  }
	};

	const killEngine = () => {
	  engineCancelMethod(/** @type {NodeJS.Immediate & Number} */(engine.reqId));
	  engine.reqId = 0;
	  return engine;
	};




	/**
	 * @param  {DOMTarget} target
	 * @param  {String} propName
	 * @param  {Object} animationInlineStyles
	 * @return {String}
	 */
	const parseInlineTransforms = (target, propName, animationInlineStyles) => {
	  const inlineTransforms = target.style.transform;
	  let inlinedStylesPropertyValue;
	  if (inlineTransforms) {
	    const cachedTransforms = target[transformsSymbol];
	    let t; while (t = transformsExecRgx.exec(inlineTransforms)) {
	      const inlinePropertyName = t[1];
	      // const inlinePropertyValue = t[2];
	      const inlinePropertyValue = t[2].slice(1, -1);
	      cachedTransforms[inlinePropertyName] = inlinePropertyValue;
	      if (inlinePropertyName === propName) {
	        inlinedStylesPropertyValue = inlinePropertyValue;
	        // Store the new parsed inline styles if animationInlineStyles is provided
	        if (animationInlineStyles) {
	          animationInlineStyles[propName] = inlinePropertyValue;
	        }
	      }
	    }
	  }
	  return inlineTransforms && !isUnd(inlinedStylesPropertyValue) ? inlinedStylesPropertyValue :
	    stringStartsWith(propName, 'scale') ? '1' :
	    stringStartsWith(propName, 'rotate') || stringStartsWith(propName, 'skew') ? '0deg' : '0px';
	};




	/**
	 * @param  {DOMTargetsParam|TargetsParam} v
	 * @return {NodeList|HTMLCollection}
	 */
	function getNodeList(v) {
	  const n = isStr(v) ? globals.root.querySelectorAll(v) : v;
	  if (n instanceof NodeList || n instanceof HTMLCollection) return n;
	}

	/**
	 * @overload
	 * @param  {DOMTargetsParam} targets
	 * @return {DOMTargetsArray}
	 *
	 * @overload
	 * @param  {JSTargetsParam} targets
	 * @return {JSTargetsArray}
	 *
	 * @overload
	 * @param  {TargetsParam} targets
	 * @return {TargetsArray}
	 *
	 * @param  {DOMTargetsParam|JSTargetsParam|TargetsParam} targets
	 */
	function parseTargets(targets) {
	  if (isNil(targets)) return /** @type {TargetsArray} */([]);
	  if (isArr(targets)) {
	    const flattened = targets.flat(Infinity);
	    /** @type {TargetsArray} */
	    const parsed = [];
	    for (let i = 0, l = flattened.length; i < l; i++) {
	      const item = flattened[i];
	      if (!isNil(item)) {
	        const nodeList = getNodeList(item);
	        if (nodeList) {
	          for (let j = 0, jl = nodeList.length; j < jl; j++) {
	            const subItem = nodeList[j];
	            if (!isNil(subItem)) {
	              let isDuplicate = false;
	              for (let k = 0, kl = parsed.length; k < kl; k++) {
	                if (parsed[k] === subItem) {
	                  isDuplicate = true;
	                  break;
	                }
	              }
	              if (!isDuplicate) {
	                parsed.push(subItem);
	              }
	            }
	          }
	        } else {
	          let isDuplicate = false;
	          for (let j = 0, jl = parsed.length; j < jl; j++) {
	            if (parsed[j] === item) {
	              isDuplicate = true;
	              break;
	            }
	          }
	          if (!isDuplicate) {
	            parsed.push(item);
	          }
	        }
	      }
	    }
	    return parsed;
	  }
	  if (!isBrowser) return /** @type {JSTargetsArray} */([targets]);
	  const nodeList = getNodeList(targets);
	  if (nodeList) return /** @type {DOMTargetsArray} */(Array.from(nodeList));
	  return /** @type {TargetsArray} */([targets]);
	}

	/**
	 * @overload
	 * @param  {DOMTargetsParam} targets
	 * @return {DOMTargetsArray}
	 *
	 * @overload
	 * @param  {JSTargetsParam} targets
	 * @return {JSTargetsArray}
	 *
	 * @overload
	 * @param  {TargetsParam} targets
	 * @return {TargetsArray}
	 *
	 * @param  {DOMTargetsParam|JSTargetsParam|TargetsParam} targets
	 */
	function registerTargets(targets) {
	  const parsedTargetsArray = parseTargets(targets);
	  const parsedTargetsLength = parsedTargetsArray.length;
	  if (parsedTargetsLength) {
	    for (let i = 0; i < parsedTargetsLength; i++) {
	      const target = parsedTargetsArray[i];
	      if (!target[isRegisteredTargetSymbol]) {
	        target[isRegisteredTargetSymbol] = true;
	        const isSvgType = isSvg(target);
	        const isDom = /** @type {DOMTarget} */(target).nodeType || isSvgType;
	        if (isDom) {
	          target[isDomSymbol] = true;
	          target[isSvgSymbol] = isSvgType;
	          target[transformsSymbol] = {};
	        }
	      }
	    }
	  }
	  return parsedTargetsArray;
	}

	// Check for valid SVG attribute

	const cssReservedProperties = ['opacity', 'rotate', 'overflow', 'color'];

	/**
	 * @param  {Target} el
	 * @param  {String} propertyName
	 * @return {Boolean}
	 */
	const isValidSVGAttribute = (el, propertyName) => {
	  // Return early and use CSS opacity animation instead (already better default values (opacity: 1 instead of 0)) and rotate should be considered a transform
	  if (cssReservedProperties.includes(propertyName)) return false;
	  if (el.getAttribute(propertyName) || propertyName in el) {
	    if (propertyName === 'scale') { // Scale
	      const elParentNode = /** @type {SVGGeometryElement} */(/** @type {DOMTarget} */(el).parentNode);
	      // Only consider scale as a valid SVG attribute on filter element
	      return elParentNode && elParentNode.tagName === 'filter';
	    }
	    return true;
	  }
	};




	/**
	 * RGB / RGBA Color value string -> RGBA values array
	 * @param  {String} rgbValue
	 * @return {ColorArray}
	 */
	const rgbToRgba = rgbValue => {
	  const rgba = rgbExecRgx.exec(rgbValue) || rgbaExecRgx.exec(rgbValue);
	  const a = !isUnd(rgba[4]) ? +rgba[4] : 1;
	  return [
	    +rgba[1],
	    +rgba[2],
	    +rgba[3],
	    a
	  ]
	};

	/**
	 * HEX3 / HEX3A / HEX6 / HEX6A Color value string -> RGBA values array
	 * @param  {String} hexValue
	 * @return {ColorArray}
	 */
	const hexToRgba = hexValue => {
	  const hexLength = hexValue.length;
	  const isShort = hexLength === 4 || hexLength === 5;
	  return [
	    +('0x' + hexValue[1] + hexValue[isShort ? 1 : 2]),
	    +('0x' + hexValue[isShort ? 2 : 3] + hexValue[isShort ? 2 : 4]),
	    +('0x' + hexValue[isShort ? 3 : 5] + hexValue[isShort ? 3 : 6]),
	    ((hexLength === 5 || hexLength === 9) ? +(+('0x' + hexValue[isShort ? 4 : 7] + hexValue[isShort ? 4 : 8]) / 255).toFixed(3) : 1)
	  ]
	};

	/**
	 * @param  {Number} p
	 * @param  {Number} q
	 * @param  {Number} t
	 * @return {Number}
	 */
	const hue2rgb$1 = (p, q, t) => {
	  if (t < 0) t += 1;
	  if (t > 1) t -= 1;
	  return t < 1 / 6 ? p + (q - p) * 6 * t :
	         t < 1 / 2 ? q :
	         t < 2 / 3 ? p + (q - p) * (2 / 3 - t) * 6 :
	         p;
	};

	/**
	 * HSL / HSLA Color value string -> RGBA values array
	 * @param  {String} hslValue
	 * @return {ColorArray}
	 */
	const hslToRgba = hslValue => {
	  const hsla = hslExecRgx.exec(hslValue) || hslaExecRgx.exec(hslValue);
	  const h = +hsla[1] / 360;
	  const s = +hsla[2] / 100;
	  const l = +hsla[3] / 100;
	  const a = !isUnd(hsla[4]) ? +hsla[4] : 1;
	  let r, g, b;
	  if (s === 0) {
	    r = g = b = l;
	  } else {
	    const q = l < .5 ? l * (1 + s) : l + s - l * s;
	    const p = 2 * l - q;
	    r = round(hue2rgb$1(p, q, h + 1 / 3) * 255, 0);
	    g = round(hue2rgb$1(p, q, h) * 255, 0);
	    b = round(hue2rgb$1(p, q, h - 1 / 3) * 255, 0);
	  }
	  return [r, g, b, a];
	};

	/**
	 * All in one color converter that converts a color string value into an array of RGBA values
	 * @param  {String} colorString
	 * @return {ColorArray}
	 */
	const convertColorStringValuesToRgbaArray = colorString => {
	  return isRgb(colorString) ? rgbToRgba(colorString) :
	         isHex(colorString) ? hexToRgba(colorString) :
	         isHsl(colorString) ? hslToRgba(colorString) :
	         [0, 0, 0, 1];
	};




	/**
	 * @template T, D
	 * @param {T|undefined} targetValue
	 * @param {D} defaultValue
	 * @return {T|D}
	 */
	const setValue = (targetValue, defaultValue) => {
	  return isUnd(targetValue) ? defaultValue : targetValue;
	};

	/**
	 * @param  {TweenPropValue} value
	 * @param  {Target} target
	 * @param  {Number} index
	 * @param  {Number} total
	 * @param  {Object} [store]
	 * @return {any}
	 */
	const getFunctionValue = (value, target, index, total, store) => {
	  if (isFnc(value)) {
	    const func = () => {
	      const computed = /** @type {Function} */(value)(target, index, total);
	      // Fallback to 0 if the function returns undefined / NaN / null / false / 0
	      return !isNaN(+computed) ? +computed : computed || 0;
	    };
	    if (store) {
	      store.func = func;
	    }
	    return func();
	  } else {
	    return value;
	  }
	};

	/**
	 * @param  {Target} target
	 * @param  {String} prop
	 * @return {tweenTypes}
	 */
	const getTweenType = (target, prop) => {
	  return !target[isDomSymbol] ? tweenTypes.OBJECT :
	    // Handle SVG attributes
	    target[isSvgSymbol] && isValidSVGAttribute(target, prop) ? tweenTypes.ATTRIBUTE :
	    // Handle CSS Transform properties differently than CSS to allow individual animations
	    validTransforms.includes(prop) || shortTransforms.get(prop) ? tweenTypes.TRANSFORM :
	    // CSS variables
	    stringStartsWith(prop, '--') ? tweenTypes.CSS_VAR :
	    // All other CSS properties
	    prop in /** @type {DOMTarget} */(target).style ? tweenTypes.CSS :
	    // Handle other DOM Attributes
	    prop in target ? tweenTypes.OBJECT :
	    tweenTypes.ATTRIBUTE;
	};

	/**
	 * @param  {DOMTarget} target
	 * @param  {String} propName
	 * @param  {Object} animationInlineStyles
	 * @return {String}
	 */
	const getCSSValue = (target, propName, animationInlineStyles) => {
	  const inlineStyles = target.style[propName];
	  if (inlineStyles && animationInlineStyles) {
	    animationInlineStyles[propName] = inlineStyles;
	  }
	  const value = inlineStyles || getComputedStyle(target[proxyTargetSymbol] || target).getPropertyValue(propName);
	  return value === 'auto' ? '0' : value;
	};

	/**
	 * @param {Target} target
	 * @param {String} propName
	 * @param {tweenTypes} [tweenType]
	 * @param {Object|void} [animationInlineStyles]
	 * @return {String|Number}
	 */
	const getOriginalAnimatableValue = (target, propName, tweenType, animationInlineStyles) => {
	  const type = !isUnd(tweenType) ? tweenType : getTweenType(target, propName);
	  return type === tweenTypes.OBJECT ? target[propName] || 0 :
	         type === tweenTypes.ATTRIBUTE ? /** @type {DOMTarget} */(target).getAttribute(propName) :
	         type === tweenTypes.TRANSFORM ? parseInlineTransforms(/** @type {DOMTarget} */(target), propName, animationInlineStyles) :
	         type === tweenTypes.CSS_VAR ? getCSSValue(/** @type {DOMTarget} */(target), propName, animationInlineStyles).trimStart() :
	         getCSSValue(/** @type {DOMTarget} */(target), propName, animationInlineStyles);
	};

	/**
	 * @param  {Number} x
	 * @param  {Number} y
	 * @param  {String} operator
	 * @return {Number}
	 */
	const getRelativeValue = (x, y, operator) => {
	  return operator === '-' ? x - y :
	         operator === '+' ? x + y :
	         x * y;
	};

	/** @return {TweenDecomposedValue} */
	const createDecomposedValueTargetObject = () => {
	  return {
	    /** @type {valueTypes} */
	    t: valueTypes.NUMBER,
	    n: 0,
	    u: null,
	    o: null,
	    d: null,
	    s: null,
	  }
	};

	/**
	 * @param  {String|Number} rawValue
	 * @param  {TweenDecomposedValue} targetObject
	 * @return {TweenDecomposedValue}
	 */
	const decomposeRawValue = (rawValue, targetObject) => {
	  /** @type {valueTypes} */
	  targetObject.t = valueTypes.NUMBER;
	  targetObject.n = 0;
	  targetObject.u = null;
	  targetObject.o = null;
	  targetObject.d = null;
	  targetObject.s = null;
	  if (!rawValue) return targetObject;
	  const num = +rawValue;
	  if (!isNaN(num)) {
	    // It's a number
	    targetObject.n = num;
	    return targetObject;
	  } else {
	    // let str = /** @type {String} */(rawValue).trim();
	    let str = /** @type {String} */(rawValue);
	    // Parsing operators (+=, -=, *=) manually is much faster than using regex here
	    if (str[1] === '=') {
	      targetObject.o = str[0];
	      str = str.slice(2);
	    }
	    // Skip exec regex if the value type is complex or color to avoid long regex backtracking
	    const unitMatch = str.includes(' ') ? false : unitsExecRgx.exec(str);
	    if (unitMatch) {
	      // Has a number and a unit
	      targetObject.t = valueTypes.UNIT;
	      targetObject.n = +unitMatch[1];
	      targetObject.u = unitMatch[2];
	      return targetObject;
	    } else if (targetObject.o) {
	      // Has an operator (+=, -=, *=)
	      targetObject.n = +str;
	      return targetObject;
	    } else if (isCol(str)) {
	      // Is a color
	      targetObject.t = valueTypes.COLOR;
	      targetObject.d = convertColorStringValuesToRgbaArray(str);
	      return targetObject;
	    } else {
	      // Is a more complex string (generally svg coords, calc() or filters CSS values)
	      const matchedNumbers = str.match(digitWithExponentRgx);
	      targetObject.t = valueTypes.COMPLEX;
	      targetObject.d = matchedNumbers ? matchedNumbers.map(Number) : [];
	      targetObject.s = str.split(digitWithExponentRgx) || [];
	      return targetObject;
	    }
	  }
	};

	/**
	 * @param  {Tween} tween
	 * @param  {TweenDecomposedValue} targetObject
	 * @return {TweenDecomposedValue}
	 */
	const decomposeTweenValue = (tween, targetObject) => {
	  targetObject.t = tween._valueType;
	  targetObject.n = tween._toNumber;
	  targetObject.u = tween._unit;
	  targetObject.o = null;
	  targetObject.d = cloneArray(tween._toNumbers);
	  targetObject.s = cloneArray(tween._strings);
	  return targetObject;
	};

	const decomposedOriginalValue = createDecomposedValueTargetObject();




	const lookups = {
	  /** @type {TweenReplaceLookups} */
	  _rep: new WeakMap(),
	  /** @type {TweenAdditiveLookups} */
	  _add: new Map(),
	};

	/**
	 * @param  {Target} target
	 * @param  {String} property
	 * @param  {String} lookup
	 * @return {TweenPropertySiblings}
	 */
	const getTweenSiblings = (target, property, lookup = '_rep') => {
	  const lookupMap = lookups[lookup];
	  let targetLookup = lookupMap.get(target);
	  if (!targetLookup) {
	    targetLookup = {};
	    lookupMap.set(target, targetLookup);
	  }
	  return targetLookup[property] ? targetLookup[property] : targetLookup[property] = {
	    _head: null,
	    _tail: null,
	  }
	};

	/**
	 * @param  {Tween} p
	 * @param  {Tween} c
	 * @return {Number|Boolean}
	 */
	const addTweenSortMethod = (p, c) => {
	  return p._isOverridden || p._absoluteStartTime > c._absoluteStartTime;
	};

	/**
	 * @param {Tween} tween
	 */
	const overrideTween = tween => {
	  tween._isOverlapped = 1;
	  tween._isOverridden = 1;
	  tween._changeDuration = minValue;
	  tween._currentTime = minValue;
	};

	/**
	 * @param  {Tween} tween
	 * @param  {TweenPropertySiblings} siblings
	 * @return {Tween}
	 */
	const composeTween = (tween, siblings) => {

	  const tweenCompositionType = tween._composition;

	  // Handle replaced tweens

	  if (tweenCompositionType === compositionTypes.replace) {

	    const tweenAbsStartTime = tween._absoluteStartTime;

	    addChild(siblings, tween, addTweenSortMethod, '_prevRep', '_nextRep');

	    const prevSibling = tween._prevRep;

	    // Update the previous siblings for composition replace tweens

	    if (prevSibling) {

	      const prevParent = prevSibling.parent;
	      const prevAbsEndTime = prevSibling._absoluteStartTime + prevSibling._changeDuration;

	      // Handle looped animations tween

	      if (
	        // Check if the previous tween is from a different animation
	        tween.parent.id !== prevParent.id &&
	        // Check if the animation has loops
	        prevParent.iterationCount> 1 &&
	        // Check if _absoluteChangeEndTime of last loop overlaps the current tween
	        prevAbsEndTime + (prevParent.duration - prevParent.iterationDuration) > tweenAbsStartTime
	      ) {

	        // TODO: Find a way to only override the iterations overlapping with the tween
	        overrideTween(prevSibling);

	        let prevPrevSibling = prevSibling._prevRep;

	        // If the tween was part of a set of keyframes, override its siblings
	        while (prevPrevSibling && prevPrevSibling.parent.id === prevParent.id) {
	          overrideTween(prevPrevSibling);
	          prevPrevSibling = prevPrevSibling._prevRep;
	        }

	      }

	      const absoluteUpdateStartTime = tweenAbsStartTime - tween._delay;

	      if (prevAbsEndTime > absoluteUpdateStartTime) {

	        const prevChangeStartTime = prevSibling._startTime;
	        const prevTLOffset = prevAbsEndTime - (prevChangeStartTime + prevSibling._updateDuration);

	        prevSibling._changeDuration = absoluteUpdateStartTime - prevTLOffset - prevChangeStartTime;
	        prevSibling._currentTime = prevSibling._changeDuration;
	        prevSibling._isOverlapped = 1;

	        if (prevSibling._changeDuration < minValue) {
	          overrideTween(prevSibling);
	        }
	      }

	      // Pause (and cancel) the parent if it only contains overlapped tweens

	      let pausePrevParentAnimation = true;

	      forEachChildren(prevParent, (/** @type Tween */t) => {
	        if (!t._isOverlapped) pausePrevParentAnimation = false;
	      });

	      if (pausePrevParentAnimation) {
	        const prevParentTL = prevParent.parent;
	        if (prevParentTL) {
	          let pausePrevParentTL = true;
	          forEachChildren(prevParentTL, (/** @type JSAnimation */a) => {
	            if (a !== prevParent) {
	              forEachChildren(a, (/** @type Tween */t) => {
	                if (!t._isOverlapped) pausePrevParentTL = false;
	              });
	            }
	          });
	          if (pausePrevParentTL) {
	            prevParentTL.cancel();
	          }
	        } else {
	          prevParent.cancel();
	          // Previously, calling .cancel() on a timeline child would affect the render order of other children
	          // Worked around this by marking it as .completed and using .pause() for safe removal in the engine loop
	          // This is no longer needed since timeline tween composition is now handled separatly
	          // Keeping this here for reference
	          // prevParent.completed = true;
	          // prevParent.pause();
	        }
	      }

	    }

	    // let nextSibling = tween._nextRep;

	    // // All the next siblings are automatically overridden

	    // if (nextSibling && nextSibling._absoluteStartTime >= tweenAbsStartTime) {
	    //   while (nextSibling) {
	    //     overrideTween(nextSibling);
	    //     nextSibling = nextSibling._nextRep;
	    //   }
	    // }

	    // if (nextSibling && nextSibling._absoluteStartTime < tweenAbsStartTime) {
	    //   while (nextSibling) {
	    //     overrideTween(nextSibling);
	    //     console.log(tween.id, nextSibling.id);
	    //     nextSibling = nextSibling._nextRep;
	    //   }
	    // }

	  // Handle additive tweens composition

	  } else if (tweenCompositionType === compositionTypes.blend) {

	    const additiveTweenSiblings = getTweenSiblings(tween.target, tween.property, '_add');
	    const additiveAnimation = addAdditiveAnimation(lookups._add);

	    let lookupTween = additiveTweenSiblings._head;

	    if (!lookupTween) {
	      lookupTween = { ...tween };
	      lookupTween._composition = compositionTypes.replace;
	      lookupTween._updateDuration = minValue;
	      lookupTween._startTime = 0;
	      lookupTween._numbers = cloneArray(tween._fromNumbers);
	      lookupTween._number = 0;
	      lookupTween._next = null;
	      lookupTween._prev = null;
	      addChild(additiveTweenSiblings, lookupTween);
	      addChild(additiveAnimation, lookupTween);
	    }

	    // Convert the values of TO to FROM and set TO to 0

	    const toNumber = tween._toNumber;
	    tween._fromNumber = lookupTween._fromNumber - toNumber;
	    tween._toNumber = 0;
	    tween._numbers = cloneArray(tween._fromNumbers);
	    tween._number = 0;
	    lookupTween._fromNumber = toNumber;

	    if (tween._toNumbers) {
	      const toNumbers = cloneArray(tween._toNumbers);
	      if (toNumbers) {
	        toNumbers.forEach((value, i) => {
	          tween._fromNumbers[i] = lookupTween._fromNumbers[i] - value;
	          tween._toNumbers[i] = 0;
	        });
	      }
	      lookupTween._fromNumbers = toNumbers;
	    }

	    addChild(additiveTweenSiblings, tween, null, '_prevAdd', '_nextAdd');

	  }

	  return tween;

	};

	/**
	 * @param  {Tween} tween
	 * @return {Tween}
	 */
	const removeTweenSliblings = tween => {
	  const tweenComposition = tween._composition;
	  if (tweenComposition !== compositionTypes.none) {
	    const tweenTarget = tween.target;
	    const tweenProperty = tween.property;
	    const replaceTweensLookup = lookups._rep;
	    const replaceTargetProps = replaceTweensLookup.get(tweenTarget);
	    const tweenReplaceSiblings = replaceTargetProps[tweenProperty];
	    removeChild(tweenReplaceSiblings, tween, '_prevRep', '_nextRep');
	    if (tweenComposition === compositionTypes.blend) {
	      const addTweensLookup = lookups._add;
	      const addTargetProps = addTweensLookup.get(tweenTarget);
	      if (!addTargetProps) return;
	      const additiveTweenSiblings = addTargetProps[tweenProperty];
	      const additiveAnimation = additive.animation;
	      removeChild(additiveTweenSiblings, tween, '_prevAdd', '_nextAdd');
	      // If only one tween is left in the additive lookup, it's the tween lookup
	      const lookupTween = additiveTweenSiblings._head;
	      if (lookupTween && lookupTween === additiveTweenSiblings._tail) {
	        removeChild(additiveTweenSiblings, lookupTween, '_prevAdd', '_nextAdd');
	        removeChild(additiveAnimation, lookupTween);
	        let shouldClean = true;
	        for (let prop in addTargetProps) {
	          if (addTargetProps[prop]._head) {
	            shouldClean = false;
	            break;
	          }
	        }
	        if (shouldClean) {
	          addTweensLookup.delete(tweenTarget);
	        }
	      }
	    }
	  }
	  return tween;
	};




	/**
	 * @param  {Timer} timer
	 * @return {Timer}
	 */
	const resetTimerProperties = timer => {
	  timer.paused = true;
	  timer.began = false;
	  timer.completed = false;
	  return timer;
	};

	/**
	 * @param  {Timer} timer
	 * @return {Timer}
	 */
	const reviveTimer = timer => {
	  if (!timer._cancelled) return timer;
	  if (timer._hasChildren) {
	    forEachChildren(timer, reviveTimer);
	  } else {
	    forEachChildren(timer, (/** @type {Tween} tween*/tween) => {
	      if (tween._composition !== compositionTypes.none) {
	        composeTween(tween, getTweenSiblings(tween.target, tween.property));
	      }
	    });
	  }
	  timer._cancelled = 0;
	  return timer;
	};

	let timerId = 0;

	/**
	 * Base class used to create Timers, Animations and Timelines
	 */
	class Timer extends Clock$1 {
	  /**
	   * @param {TimerParams} [parameters]
	   * @param {Timeline} [parent]
	   * @param {Number} [parentPosition]
	   */
	  constructor(parameters = {}, parent = null, parentPosition = 0) {

	    super(0);

	    const {
	      id,
	      delay,
	      duration,
	      reversed,
	      alternate,
	      loop,
	      loopDelay,
	      autoplay,
	      frameRate,
	      playbackRate,
	      onComplete,
	      onLoop,
	      onPause,
	      onBegin,
	      onBeforeUpdate,
	      onUpdate,
	    } = parameters;

	    const timerInitTime = parent ? 0 : engine._elapsedTime;
	    const timerDefaults = parent ? parent.defaults : globals.defaults;
	    const timerDelay = /** @type {Number} */(isFnc(delay) || isUnd(delay) ? timerDefaults.delay : +delay);
	    const timerDuration = isFnc(duration) || isUnd(duration) ? Infinity : +duration;
	    const timerLoop = setValue(loop, timerDefaults.loop);
	    const timerLoopDelay = setValue(loopDelay, timerDefaults.loopDelay);
	    const timerIterationCount = timerLoop === true ||
	                                timerLoop === Infinity ||
	                                /** @type {Number} */(timerLoop) < 0 ? Infinity :
	                                /** @type {Number} */(timerLoop) + 1;

	    let offsetPosition = 0;

	    if (parent) {
	      offsetPosition = parentPosition;
	    } else {
	      let startTime = now$2();
	      // Make sure to tick the engine once if suspended to avoid big gaps with the following offsetPosition calculation
	      if (engine.paused) {
	        engine.requestTick(startTime);
	        startTime = engine._elapsedTime;
	      }
	      offsetPosition = startTime - engine._startTime;
	    }

	    // Timer's parameters
	    this.id = !isUnd(id) ? id : ++timerId;
	    /** @type {Timeline} */
	    this.parent = parent;
	    // Total duration of the timer
	    this.duration = clampInfinity(((timerDuration + timerLoopDelay) * timerIterationCount) - timerLoopDelay) || minValue;
	    /** @type {Boolean} */
	    this.backwards = false;
	    /** @type {Boolean} */
	    this.paused = true;
	    /** @type {Boolean} */
	    this.began = false;
	    /** @type {Boolean} */
	    this.completed = false;
	    /** @type {Callback<this>} */
	    this.onBegin = onBegin || timerDefaults.onBegin;
	    /** @type {Callback<this>} */
	    this.onBeforeUpdate = onBeforeUpdate || timerDefaults.onBeforeUpdate;
	    /** @type {Callback<this>} */
	    this.onUpdate = onUpdate || timerDefaults.onUpdate;
	    /** @type {Callback<this>} */
	    this.onLoop = onLoop || timerDefaults.onLoop;
	    /** @type {Callback<this>} */
	    this.onPause = onPause || timerDefaults.onPause;
	    /** @type {Callback<this>} */
	    this.onComplete = onComplete || timerDefaults.onComplete;
	    /** @type {Number} */
	    this.iterationDuration = timerDuration; // Duration of one loop
	    /** @type {Number} */
	    this.iterationCount = timerIterationCount; // Number of loops
	    /** @type {Boolean|ScrollObserver} */
	    this._autoplay = parent ? false : setValue(autoplay, timerDefaults.autoplay);
	    /** @type {Number} */
	    this._offset = offsetPosition;
	    /** @type {Number} */
	    this._delay = timerDelay;
	    /** @type {Number} */
	    this._loopDelay = timerLoopDelay;
	    /** @type {Number} */
	    this._iterationTime = 0;
	    /** @type {Number} */
	    this._currentIteration = 0; // Current loop index
	    /** @type {Function} */
	    this._resolve = noop; // Used by .then()
	    /** @type {Boolean} */
	    this._running = false;
	    /** @type {Number} */
	    this._reversed = +setValue(reversed, timerDefaults.reversed);
	    /** @type {Number} */
	    this._reverse = this._reversed;
	    /** @type {Number} */
	    this._cancelled = 0;
	    /** @type {Boolean} */
	    this._alternate = setValue(alternate, timerDefaults.alternate);
	    /** @type {Renderable} */
	    this._prev = null;
	    /** @type {Renderable} */
	    this._next = null;

	    // Clock's parameters
	    /** @type {Number} */
	    this._elapsedTime = timerInitTime;
	    /** @type {Number} */
	    this._startTime = timerInitTime;
	    /** @type {Number} */
	    this._lastTime = timerInitTime;
	    /** @type {Number} */
	    this._fps = setValue(frameRate, timerDefaults.frameRate);
	    /** @type {Number} */
	    this._speed = setValue(playbackRate, timerDefaults.playbackRate);
	  }

	  get cancelled() {
	    return !!this._cancelled;
	  }

	  /** @param {Boolean} cancelled  */
	  set cancelled(cancelled) {
	    cancelled ? this.cancel() : this.reset(1).play();
	  }

	  get currentTime() {
	    return clamp$1(round(this._currentTime, globals.precision), -this._delay, this.duration);
	  }

	  /** @param {Number} time  */
	  set currentTime(time) {
	    const paused = this.paused;
	    // Pausing the timer is necessary to avoid time jumps on a running instance
	    this.pause().seek(+time);
	    if (!paused) this.resume();
	  }

	  get iterationCurrentTime() {
	    return round(this._iterationTime, globals.precision);
	  }

	  /** @param {Number} time  */
	  set iterationCurrentTime(time) {
	    this.currentTime = (this.iterationDuration * this._currentIteration) + time;
	  }

	  get progress() {
	    return clamp$1(round(this._currentTime / this.duration, 5), 0, 1);
	  }

	  /** @param {Number} progress  */
	  set progress(progress) {
	    this.currentTime = this.duration * progress;
	  }

	  get iterationProgress() {
	    return clamp$1(round(this._iterationTime / this.iterationDuration, 5), 0, 1);
	  }

	  /** @param {Number} progress  */
	  set iterationProgress(progress) {
	    const iterationDuration = this.iterationDuration;
	    this.currentTime = (iterationDuration * this._currentIteration) + (iterationDuration * progress);
	  }

	  get currentIteration() {
	    return this._currentIteration;
	  }

	  /** @param {Number} iterationCount  */
	  set currentIteration(iterationCount) {
	    this.currentTime = (this.iterationDuration * clamp$1(+iterationCount, 0, this.iterationCount - 1));
	  }

	  get reversed() {
	    return !!this._reversed;
	  }

	  /** @param {Boolean} reverse  */
	  set reversed(reverse) {
	    reverse ? this.reverse() : this.play();
	  }

	  get speed() {
	    return super.speed;
	  }

	  /** @param {Number} playbackRate  */
	  set speed(playbackRate) {
	    super.speed = playbackRate;
	    this.resetTime();
	  }

	  /**
	   * @param  {Number} internalRender
	   * @return {this}
	   */
	  reset(internalRender = 0) {
	    // If cancelled, revive the timer before rendering in order to have propertly composed tweens siblings
	    reviveTimer(this);
	    if (this._reversed && !this._reverse) this.reversed = false;
	    // Rendering before updating the completed flag to prevent skips and to make sure the properties are not overridden
	    // Setting the iterationTime at the end to force the rendering to happend backwards, otherwise calling .reset() on Timelines might not render children in the right order
	    // NOTE: This is only required for Timelines and might be better to move to the Timeline class?
	    this._iterationTime = this.iterationDuration;
	    // Set tickMode to tickModes.FORCE to force rendering
	    tick(this, 0, 1, internalRender, tickModes.FORCE);
	    // Reset timer properties after revive / render to make sure the props are not updated again
	    resetTimerProperties(this);
	    // Also reset children properties
	    if (this._hasChildren) {
	      forEachChildren(this, resetTimerProperties);
	    }
	    return this;
	  }

	  /**
	   * @param  {Number} internalRender
	   * @return {this}
	   */
	  init(internalRender = 0) {
	    this.fps = this._fps;
	    this.speed = this._speed;
	    // Manually calling .init() on timelines should render all children intial state
	    // Forces all children to render once then render to 0 when reseted
	    if (!internalRender && this._hasChildren) {
	      tick(this, this.duration, 1, internalRender, tickModes.FORCE);
	    }
	    this.reset(internalRender);
	    // Make sure to set autoplay to false to child timers so it doesn't attempt to autoplay / link
	    const autoplay = this._autoplay;
	    if (autoplay === true) {
	      this.resume();
	    } else if (autoplay && !isUnd(/** @type {ScrollObserver} */(autoplay).linked)) {
	      /** @type {ScrollObserver} */(autoplay).link(this);
	    }
	    return this;
	  }

	  /** @return {this} */
	  resetTime() {
	    const timeScale = 1 / (this._speed * engine._speed);
	    this._startTime = now$2() - (this._currentTime + this._delay) * timeScale;
	    return this;
	  }

	  /** @return {this} */
	  pause() {
	    if (this.paused) return this;
	    this.paused = true;
	    this.onPause(this);
	    return this;
	  }

	  /** @return {this} */
	  resume() {
	    if (!this.paused) return this;
	    this.paused = false;
	    // We can safely imediatly render a timer that has no duration and no children
	    if (this.duration <= minValue && !this._hasChildren) {
	      tick(this, minValue, 0, 0, tickModes.FORCE);
	    } else {
	      if (!this._running) {
	        addChild(engine, this);
	        engine._hasChildren = true;
	        this._running = true;
	      }
	      this.resetTime();
	      // Forces the timer to advance by at least one frame when the next tick occurs
	      this._startTime -= 12;
	      engine.wake();
	    }
	    return this;
	  }

	  /** @return {this} */
	  restart() {
	    return this.reset(0).resume();
	  }

	  /**
	   * @param  {Number} time
	   * @param  {Boolean|Number} [muteCallbacks]
	   * @param  {Boolean|Number} [internalRender]
	   * @return {this}
	   */
	  seek(time, muteCallbacks = 0, internalRender = 0) {
	    // Recompose the tween siblings in case the timer has been cancelled
	    reviveTimer(this);
	    // If you seek a completed animation, otherwise the next play will starts at 0
	    this.completed = false;
	    const isPaused = this.paused;
	    this.paused = true;
	    // timer, time, muteCallbacks, internalRender, tickMode
	    tick(this, time + this._delay, ~~muteCallbacks, ~~internalRender, tickModes.AUTO);
	    return isPaused ? this : this.resume();
	  }

	  /** @return {this} */
	  alternate() {
	    const reversed = this._reversed;
	    const count = this.iterationCount;
	    const duration = this.iterationDuration;
	    // Calculate the maximum iterations possible given the iteration duration
	    const iterations = count === Infinity ? floor(maxValue / duration) : count;
	    this._reversed = +(this._alternate && !(iterations % 2) ? reversed : !reversed);
	    if (count === Infinity) {
	      // Handle infinite loops to loop on themself
	      this.iterationProgress = this._reversed ? 1 - this.iterationProgress : this.iterationProgress;
	    } else {
	      this.seek((duration * iterations) - this._currentTime);
	    }
	    this.resetTime();
	    return this;
	  }

	  /** @return {this} */
	  play() {
	    if (this._reversed) this.alternate();
	    return this.resume();
	  }

	  /** @return {this} */
	  reverse() {
	    if (!this._reversed) this.alternate();
	    return this.resume();
	  }

	  // TODO: Move all the animation / tweens / children related code to Animation / Timeline

	  /** @return {this} */
	  cancel() {
	    if (this._hasChildren) {
	      forEachChildren(this, (/** @type {Renderable} */child) => child.cancel(), true);
	    } else {
	      forEachChildren(this, removeTweenSliblings);
	    }
	    this._cancelled = 1;
	    // Pausing the timer removes it from the engine
	    return this.pause();
	  }

	  /**
	   * @param  {Number} newDuration
	   * @return {this}
	   */
	  stretch(newDuration) {
	    const currentDuration = this.duration;
	    const normlizedDuration = normalizeTime(newDuration);
	    if (currentDuration === normlizedDuration) return this;
	    const timeScale = newDuration / currentDuration;
	    const isSetter = newDuration <= minValue;
	    this.duration = isSetter ? minValue : normlizedDuration;
	    this.iterationDuration = isSetter ? minValue : normalizeTime(this.iterationDuration * timeScale);
	    this._offset *= timeScale;
	    this._delay *= timeScale;
	    this._loopDelay *= timeScale;
	    return this;
	  }

	 /**
	   * Cancels the timer by seeking it back to 0 and reverting the attached scroller if necessary
	   * @return {this}
	   */
	  revert() {
	    tick(this, 0, 1, 0, tickModes.AUTO);
	    const ap = /** @type {ScrollObserver} */(this._autoplay);
	    if (ap && ap.linked && ap.linked === this) ap.revert();
	    return this.cancel();
	  }

	 /**
	   * Imediatly completes the timer, cancels it and triggers the onComplete callback
	   * @return {this}
	   */
	  complete() {
	    return this.seek(this.duration).cancel();
	  }

	  /**
	   * @param  {Callback<this>} [callback]
	   * @return {Promise}
	   */
	  then(callback = noop) {
	    const then = this.then;
	    const onResolve = () => {
	      // this.then = null prevents infinite recursion if returned by an async function
	      // https://github.com/juliangarnierorg/anime-beta/issues/26
	      this.then = null;
	      callback(this);
	      this.then = then;
	      this._resolve = noop;
	    };
	    return new Promise(r => {
	      this._resolve = () => r(onResolve());
	      // Make sure to resolve imediatly if the timer has already completed
	      if (this.completed) this._resolve();
	      return this;
	    });
	  }

	}




	/** @type {EasingFunction} */
	const none = t => t;

	// Cubic Bezier solver adapted from https://github.com/gre/bezier-ease © Gaëtan Renaudeau

	/**
	 * @param  {Number} aT
	 * @param  {Number} aA1
	 * @param  {Number} aA2
	 * @return {Number}
	 */
	const calcBezier = (aT, aA1, aA2) => (((1 - 3 * aA2 + 3 * aA1) * aT + (3 * aA2 - 6 * aA1)) * aT + (3 * aA1)) * aT;

	/**
	 * @param  {Number} aX
	 * @param  {Number} mX1
	 * @param  {Number} mX2
	 * @return {Number}
	 */
	const binarySubdivide = (aX, mX1, mX2) => {
	  let aA = 0, aB = 1, currentX, currentT, i = 0;
	  do {
	    currentT = aA + (aB - aA) / 2;
	    currentX = calcBezier(currentT, mX1, mX2) - aX;
	    if (currentX > 0) {
	      aB = currentT;
	    } else {
	      aA = currentT;
	    }
	  } while (abs(currentX) > .0000001 && ++i < 100);
	  return currentT;
	};

	/**
	 * @param  {Number} [mX1]
	 * @param  {Number} [mY1]
	 * @param  {Number} [mX2]
	 * @param  {Number} [mY2]
	 * @return {EasingFunction}
	 */

	const cubicBezier = (mX1 = 0.5, mY1 = 0.0, mX2 = 0.5, mY2 = 1.0) => (mX1 === mY1 && mX2 === mY2) ? none :
	  t => t === 0 || t === 1 ? t :
	  calcBezier(binarySubdivide(t, mX1, mX2), mY1, mY2);

	/**
	 * Steps ease implementation https://developer.mozilla.org/fr/docs/Web/CSS/transition-timing-function
	 * Only covers 'end' and 'start' jumpterms
	 * @param  {Number} steps
	 * @param  {Boolean} [fromStart]
	 * @return {EasingFunction}
	 */
	const steps = (steps = 10, fromStart) => {
	  const roundMethod = fromStart ? ceil : floor;
	  return t => roundMethod(clamp$1(t, 0, 1) * steps) * (1 / steps);
	};

	/**
	 * Without parameters, the linear function creates a non-eased transition.
	 * Parameters, if used, creates a piecewise linear easing by interpolating linearly between the specified points.
	 * @param  {...String|Number} [args] - Points
	 * @return {EasingFunction}
	 */
	const linear = (...args) => {
	  const argsLength = args.length;
	  if (!argsLength) return none;
	  const totalPoints = argsLength - 1;
	  const firstArg = args[0];
	  const lastArg = args[totalPoints];
	  const xPoints = [0];
	  const yPoints = [parseNumber(firstArg)];
	  for (let i = 1; i < totalPoints; i++) {
	    const arg = args[i];
	    const splitValue = isStr(arg) ?
	    /** @type {String} */(arg).trim().split(' ') :
	    [arg];
	    const value = splitValue[0];
	    const percent = splitValue[1];
	    xPoints.push(!isUnd(percent) ? parseNumber(percent) / 100 : i / totalPoints);
	    yPoints.push(parseNumber(value));
	  }
	  yPoints.push(parseNumber(lastArg));
	  xPoints.push(1);
	  return function easeLinear(t) {
	    for (let i = 1, l = xPoints.length; i < l; i++) {
	      const currentX = xPoints[i];
	      if (t <= currentX) {
	        const prevX = xPoints[i - 1];
	        const prevY = yPoints[i - 1];
	        return prevY + (yPoints[i] - prevY) * (t - prevX) / (currentX - prevX);
	      }
	    }
	    return yPoints[yPoints.length - 1];
	  }
	};

	/**
	 * Generate random steps
	 * @param  {Number} [length] - The number of steps
	 * @param  {Number} [randomness] - How strong the randomness is
	 * @return {EasingFunction}
	 */
	const irregular = (length = 10, randomness = 1) => {
	  const values = [0];
	  const total = length - 1;
	  for (let i = 1; i < total; i++) {
	    const previousValue = values[i - 1];
	    const spacing = i / total;
	    const segmentEnd = (i + 1) / total;
	    const randomVariation = spacing + (segmentEnd - spacing) * Math.random();
	    // Mix the even spacing and random variation based on the randomness parameter
	    const randomValue = spacing * (1 - randomness) + randomVariation * randomness;
	    values.push(clamp$1(randomValue, previousValue, 1));
	  }
	  values.push(1);
	  return linear(...values);
	};

	// Easing functions adapted from http://www.robertpenner.com/ease © Robert Penner

	/**
	 * @callback PowerEasing
	 * @param {Number|String} [power=1.675]
	 * @return {EasingFunction}
	 */

	/**
	 * @callback BackEasing
	 * @param {Number|String} [overshoot=1.70158]
	 * @return {EasingFunction}
	 */

	/**
	 * @callback ElasticEasing
	 * @param {Number|String} [amplitude=1]
	 * @param {Number|String} [period=.3]
	 * @return {EasingFunction}
	 */

	/**
	 * @callback EaseFactory
	 * @param {Number|String} [paramA]
	 * @param {Number|String} [paramB]
	 * @return {EasingFunction|Number}
	 */

	/** @typedef {PowerEasing|BackEasing|ElasticEasing} EasesFactory */

	const halfPI = PI / 2;
	const doublePI = PI * 2;
	/** @type {PowerEasing} */
	const easeInPower = (p = 1.68) => t => pow(t, +p);

	/** @type {Record<String, EasesFactory|EasingFunction>} */
	const easeInFunctions = {
	  [emptyString]: easeInPower,
	  Quad: easeInPower(2),
	  Cubic: easeInPower(3),
	  Quart: easeInPower(4),
	  Quint: easeInPower(5),
	  /** @type {EasingFunction} */
	  Sine: t => 1 - cos(t * halfPI),
	  /** @type {EasingFunction} */
	  Circ: t => 1 - sqrt(1 - t * t),
	  /** @type {EasingFunction} */
	  Expo: t => t ? pow(2, 10 * t - 10) : 0,
	  /** @type {EasingFunction} */
	  Bounce: t => {
	    let pow2, b = 4;
	    while (t < ((pow2 = pow(2, --b)) - 1) / 11);
	    return 1 / pow(4, 3 - b) - 7.5625 * pow((pow2 * 3 - 2) / 22 - t, 2);
	  },
	  /** @type {BackEasing} */
	  Back: (overshoot = 1.70158) => t => (+overshoot + 1) * t * t * t - +overshoot * t * t,
	  /** @type {ElasticEasing} */
	  Elastic: (amplitude = 1, period = .3) => {
	    const a = clamp$1(+amplitude, 1, 10);
	    const p = clamp$1(+period, minValue, 2);
	    const s = (p / doublePI) * asin(1 / a);
	    const e = doublePI / p;
	    return t => t === 0 || t === 1 ? t : -a * pow(2, -10 * (1 - t)) * sin(((1 - t) - s) * e);
	  }
	};

	/**
	 * @callback EaseType
	 * @param {EasingFunction} Ease
	 * @return {EasingFunction}
	 */

	/** @type {Record<String, EaseType>} */
	const easeTypes = {
	  in: easeIn => t => easeIn(t),
	  out: easeIn => t => 1 - easeIn(1 - t),
	  inOut: easeIn => t => t < .5 ? easeIn(t * 2) / 2 : 1 - easeIn(t * -2 + 2) / 2,
	  outIn: easeIn => t => t < .5 ? (1 - easeIn(1 - t * 2)) / 2 : (easeIn(t * 2 - 1) + 1) / 2,
	};

	/**
	 * @param  {String} string
	 * @param  {Record<String, EasesFactory|EasingFunction>} easesFunctions
	 * @param  {Object} easesLookups
	 * @return {EasingFunction}
	 */
	const parseEaseString = (string, easesFunctions, easesLookups) => {
	  if (easesLookups[string]) return easesLookups[string];
	  if (string.indexOf('(') <= -1) {
	    const hasParams = easeTypes[string] || string.includes('Back') || string.includes('Elastic');
	    const parsedFn = /** @type {EasingFunction} */(hasParams ? /** @type {EasesFactory} */(easesFunctions[string])() : easesFunctions[string]);
	    return parsedFn ? easesLookups[string] = parsedFn : none;
	  } else {
	    const split = string.slice(0, -1).split('(');
	    const parsedFn = /** @type {EasesFactory} */(easesFunctions[split[0]]);
	    return parsedFn ? easesLookups[string] = parsedFn(...split[1].split(',')) : none;
	  }
	};

	/**
	 * @typedef  {Object} EasesFunctions
	 * @property {typeof linear} linear
	 * @property {typeof irregular} irregular
	 * @property {typeof steps} steps
	 * @property {typeof cubicBezier} cubicBezier
	 * @property {PowerEasing} in
	 * @property {PowerEasing} out
	 * @property {PowerEasing} inOut
	 * @property {PowerEasing} outIn
	 * @property {EasingFunction} inQuad
	 * @property {EasingFunction} outQuad
	 * @property {EasingFunction} inOutQuad
	 * @property {EasingFunction} outInQuad
	 * @property {EasingFunction} inCubic
	 * @property {EasingFunction} outCubic
	 * @property {EasingFunction} inOutCubic
	 * @property {EasingFunction} outInCubic
	 * @property {EasingFunction} inQuart
	 * @property {EasingFunction} outQuart
	 * @property {EasingFunction} inOutQuart
	 * @property {EasingFunction} outInQuart
	 * @property {EasingFunction} inQuint
	 * @property {EasingFunction} outQuint
	 * @property {EasingFunction} inOutQuint
	 * @property {EasingFunction} outInQuint
	 * @property {EasingFunction} inSine
	 * @property {EasingFunction} outSine
	 * @property {EasingFunction} inOutSine
	 * @property {EasingFunction} outInSine
	 * @property {EasingFunction} inCirc
	 * @property {EasingFunction} outCirc
	 * @property {EasingFunction} inOutCirc
	 * @property {EasingFunction} outInCirc
	 * @property {EasingFunction} inExpo
	 * @property {EasingFunction} outExpo
	 * @property {EasingFunction} inOutExpo
	 * @property {EasingFunction} outInExpo
	 * @property {EasingFunction} inBounce
	 * @property {EasingFunction} outBounce
	 * @property {EasingFunction} inOutBounce
	 * @property {EasingFunction} outInBounce
	 * @property {BackEasing} inBack
	 * @property {BackEasing} outBack
	 * @property {BackEasing} inOutBack
	 * @property {BackEasing} outInBack
	 * @property {ElasticEasing} inElastic
	 * @property {ElasticEasing} outElastic
	 * @property {ElasticEasing} inOutElastic
	 * @property {ElasticEasing} outInElastic
	 */

	const eases = (/*#__PURE__*/ (() => {
	  const list = { linear, irregular, steps, cubicBezier };
	  for (let type in easeTypes) {
	    for (let name in easeInFunctions) {
	      const easeIn = easeInFunctions[name];
	      const easeType = easeTypes[type];
	      list[type + name] = /** @type {EasesFactory|EasingFunction} */(
	        name === emptyString || name === 'Back' || name === 'Elastic' ?
	        (a, b) => easeType(/** @type {EasesFactory} */(easeIn)(a, b)) :
	        easeType(/** @type {EasingFunction} */(easeIn))
	      );
	    }
	  }
	  return /** @type {EasesFunctions} */(list);
	})());

	/** @type {Record<String, EasingFunction>} */
	const JSEasesLookups = { linear: none };

	/**
	 * @param  {EasingParam} ease
	 * @return {EasingFunction}
	 */
	const parseEasings = ease => isFnc(ease) ? ease :
	  isStr(ease) ? parseEaseString(/** @type {String} */(ease), eases, JSEasesLookups) :
	  none;




	const propertyNamesCache = {};

	/**
	 * @param  {String} propertyName
	 * @param  {Target} target
	 * @param  {tweenTypes} tweenType
	 * @return {String}
	 */
	const sanitizePropertyName = (propertyName, target, tweenType) => {
	  if (tweenType === tweenTypes.TRANSFORM) {
	    const t = shortTransforms.get(propertyName);
	    return t ? t : propertyName;
	  } else if (
	    tweenType === tweenTypes.CSS ||
	    // Handle special cases where properties like "strokeDashoffset" needs to be set as "stroke-dashoffset"
	    // but properties like "baseFrequency" should stay in lowerCamelCase
	    (tweenType === tweenTypes.ATTRIBUTE && (isSvg(target) && propertyName in /** @type {DOMTarget} */(target).style))
	  ) {
	    const cachedPropertyName = propertyNamesCache[propertyName];
	    if (cachedPropertyName) {
	      return cachedPropertyName;
	    } else {
	      const lowerCaseName = propertyName ? toLowerCase(propertyName) : propertyName;
	      propertyNamesCache[propertyName] = lowerCaseName;
	      return lowerCaseName;
	    }
	  } else {
	    return propertyName;
	  }
	};




	const angleUnitsMap = { 'deg': 1, 'rad': 180 / PI, 'turn': 360 };
	const convertedValuesCache = {};

	/**
	 * @param  {DOMTarget} el
	 * @param  {TweenDecomposedValue} decomposedValue
	 * @param  {String} unit
	 * @param  {Boolean} [force]
	 * @return {TweenDecomposedValue}
	 */
	const convertValueUnit = (el, decomposedValue, unit, force = false) => {
	  const currentUnit = decomposedValue.u;
	  const currentNumber = decomposedValue.n;
	  if (decomposedValue.t === valueTypes.UNIT && currentUnit === unit) { // TODO: Check if checking against the same unit string is necessary
	    return decomposedValue;
	  }
	  const cachedKey = currentNumber + currentUnit + unit;
	  const cached = convertedValuesCache[cachedKey];
	  if (!isUnd(cached) && !force) {
	    decomposedValue.n = cached;
	  } else {
	    let convertedValue;
	    if (currentUnit in angleUnitsMap) {
	      convertedValue = currentNumber * angleUnitsMap[currentUnit] / angleUnitsMap[unit];
	    } else {
	      const baseline = 100;
	      const tempEl = /** @type {DOMTarget} */(el.cloneNode());
	      const parentNode = el.parentNode;
	      const parentEl = (parentNode && (parentNode !== doc)) ? parentNode : doc.body;
	      parentEl.appendChild(tempEl);
	      const elStyle = tempEl.style;
	      elStyle.width = baseline + currentUnit;
	      const currentUnitWidth = /** @type {HTMLElement} */(tempEl).offsetWidth || baseline;
	      elStyle.width = baseline + unit;
	      const newUnitWidth = /** @type {HTMLElement} */(tempEl).offsetWidth || baseline;
	      const factor = currentUnitWidth / newUnitWidth;
	      parentEl.removeChild(tempEl);
	      convertedValue = factor * currentNumber;
	    }
	    decomposedValue.n = convertedValue;
	    convertedValuesCache[cachedKey] = convertedValue;
	  }
	  decomposedValue.t === valueTypes.UNIT;
	  decomposedValue.u = unit;
	  return decomposedValue;
	};




	/**
	 * @template {Renderable} T
	 * @param {T} renderable
	 * @return {T}
	 */
	const cleanInlineStyles = renderable => {
	  // Allow cleanInlineStyles() to be called on timelines
	  if (renderable._hasChildren) {
	    forEachChildren(renderable, cleanInlineStyles, true);
	  } else {
	    const animation = /** @type {JSAnimation} */(renderable);
	    animation.pause();
	    forEachChildren(animation, (/** @type {Tween} */tween) => {
	      const tweenProperty = tween.property;
	      const tweenTarget = tween.target;
	      if (tweenTarget[isDomSymbol]) {
	        const targetStyle = /** @type {DOMTarget} */(tweenTarget).style;
	        const originalInlinedValue = animation._inlineStyles[tweenProperty];
	        if (tween._tweenType === tweenTypes.TRANSFORM) {
	          const cachedTransforms = tweenTarget[transformsSymbol];
	          if (isUnd(originalInlinedValue) || originalInlinedValue === emptyString) {
	            delete cachedTransforms[tweenProperty];
	          } else {
	            cachedTransforms[tweenProperty] = originalInlinedValue;
	          }
	          if (tween._renderTransforms) {
	            if (!Object.keys(cachedTransforms).length) {
	              targetStyle.removeProperty('transform');
	            } else {
	              let str = emptyString;
	              for (let key in cachedTransforms) {
	                str += transformsFragmentStrings[key] + cachedTransforms[key] + ') ';
	              }
	              targetStyle.transform = str;
	            }
	          }
	        } else {
	          if (isUnd(originalInlinedValue) || originalInlinedValue === emptyString) {
	            targetStyle.removeProperty(tweenProperty);
	          } else {
	            targetStyle[tweenProperty] = originalInlinedValue;
	          }
	        }
	        if (animation._tail === tween) {
	          animation.targets.forEach(t => {
	            if (t.getAttribute && t.getAttribute('style') === emptyString) {
	              t.removeAttribute('style');
	            }          });
	        }
	      }
	    });
	  }
	  return renderable;
	};

	// Defines decomposed values target objects only once and mutate their properties later to avoid GC
	// TODO: Maybe move the objects creation to values.js and use the decompose function to create the base object
	const fromTargetObject = createDecomposedValueTargetObject();
	const toTargetObject = createDecomposedValueTargetObject();
	const toFunctionStore = { func: null };
	const keyframesTargetArray = [null];
	const fastSetValuesArray = [null, null];
	/** @type {TweenKeyValue} */
	const keyObjectTarget = { to: null };

	let tweenId = 0;
	let keyframes;
	/** @type {TweenParamsOptions & TweenValues} */
	let key;

	/**
	 * @param {DurationKeyframes | PercentageKeyframes} keyframes
	 * @param {AnimationParams} parameters
	 * @return {AnimationParams}
	 */
	const generateKeyframes = (keyframes, parameters) => {
	  /** @type {AnimationParams} */
	  const properties = {};
	  if (isArr(keyframes)) {
	    const propertyNames = [].concat(.../** @type {DurationKeyframes} */(keyframes).map(key => Object.keys(key))).filter(isKey);
	    for (let i = 0, l = propertyNames.length; i < l; i++) {
	      const propName = propertyNames[i];
	      const propArray = /** @type {DurationKeyframes} */(keyframes).map(key => {
	        /** @type {TweenKeyValue} */
	        const newKey = {};
	        for (let p in key) {
	          const keyValue = /** @type {TweenPropValue} */(key[p]);
	          if (isKey(p)) {
	            if (p === propName) {
	              newKey.to = keyValue;
	            }
	          } else {
	            newKey[p] = keyValue;
	          }
	        }
	        return newKey;
	      });
	      properties[propName] = /** @type {ArraySyntaxValue} */(propArray);
	    }

	  } else {
	    const totalDuration = /** @type {Number} */(setValue(parameters.duration, globals.defaults.duration));
	    const keys = Object.keys(keyframes)
	    .map(key => { return {o: parseFloat(key) / 100, p: keyframes[key]} })
	    .sort((a, b) => a.o - b.o);
	    keys.forEach(key => {
	      const offset = key.o;
	      const prop = key.p;
	      for (let name in prop) {
	        if (isKey(name)) {
	          let propArray = /** @type {Array} */(properties[name]);
	          if (!propArray) propArray = properties[name] = [];
	          const duration = offset * totalDuration;
	          let length = propArray.length;
	          let prevKey = propArray[length - 1];
	          const keyObj = { to: prop[name] };
	          let durProgress = 0;
	          for (let i = 0; i < length; i++) {
	            durProgress += propArray[i].duration;
	          }
	          if (length === 1) {
	            keyObj.from = prevKey.to;
	          }
	          if (prop.ease) {
	            keyObj.ease = prop.ease;
	          }
	          keyObj.duration = duration - (length ? durProgress : 0);
	          propArray.push(keyObj);
	        }
	      }
	      return key;
	    });

	    for (let name in properties) {
	      const propArray = /** @type {Array} */(properties[name]);
	      let prevEase;
	      // let durProgress = 0
	      for (let i = 0, l = propArray.length; i < l; i++) {
	        const prop = propArray[i];
	        // Emulate WAPPI easing parameter position
	        const currentEase = prop.ease;
	        prop.ease = prevEase ? prevEase : undefined;
	        prevEase = currentEase;
	        // durProgress += prop.duration;
	        // if (i === l - 1 && durProgress !== totalDuration) {
	        //   propArray.push({ from: prop.to, ease: prop.ease, duration: totalDuration - durProgress })
	        // }
	      }
	      if (!propArray[0].duration) {
	        propArray.shift();
	      }
	    }

	  }

	  return properties;
	};

	class JSAnimation extends Timer {
	  /**
	   * @param {TargetsParam} targets
	   * @param {AnimationParams} parameters
	   * @param {Timeline} [parent]
	   * @param {Number} [parentPosition]
	   * @param {Boolean} [fastSet=false]
	   * @param {Number} [index=0]
	   * @param {Number} [length=0]
	   */
	  constructor(
	    targets,
	    parameters,
	    parent,
	    parentPosition,
	    fastSet = false,
	    index = 0,
	    length = 0
	  ) {

	    super(/** @type {TimerParams&AnimationParams} */(parameters), parent, parentPosition);

	    const parsedTargets = registerTargets(targets);
	    const targetsLength = parsedTargets.length;

	    // If the parameters object contains a "keyframes" property, convert all the keyframes values to regular properties

	    const kfParams = /** @type {AnimationParams} */(parameters).keyframes;
	    const params = /** @type {AnimationParams} */(kfParams ? mergeObjects(generateKeyframes(/** @type {DurationKeyframes} */(kfParams), parameters), parameters) : parameters);

	    const {
	      delay,
	      duration,
	      ease,
	      playbackEase,
	      modifier,
	      composition,
	      onRender,
	    } = params;

	    const animDefaults = parent ? parent.defaults : globals.defaults;
	    const animaPlaybackEase = setValue(playbackEase, animDefaults.playbackEase);
	    const animEase = animaPlaybackEase ? parseEasings(animaPlaybackEase) : null;
	    const hasSpring = !isUnd(ease) && !isUnd(/** @type {Spring} */(ease).ease);
	    const tEasing = hasSpring ? /** @type {Spring} */(ease).ease : setValue(ease, animEase ? 'linear' : animDefaults.ease);
	    const tDuration = hasSpring ? /** @type {Spring} */(ease).duration : setValue(duration, animDefaults.duration);
	    const tDelay = setValue(delay, animDefaults.delay);
	    const tModifier = modifier || animDefaults.modifier;
	    // If no composition is defined and the targets length is high (>= 1000) set the composition to 'none' (0) for faster tween creation
	    const tComposition = isUnd(composition) && targetsLength >= K ? compositionTypes.none : !isUnd(composition) ? composition : animDefaults.composition;
	    // TODO: Do not create an empty object until we know the animation will generate inline styles
	    const animInlineStyles = {};
	    // const absoluteOffsetTime = this._offset;
	    const absoluteOffsetTime = this._offset + (parent ? parent._offset : 0);

	    let iterationDuration = NaN;
	    let iterationDelay = NaN;
	    let animationAnimationLength = 0;
	    let shouldTriggerRender = 0;

	    for (let targetIndex = 0; targetIndex < targetsLength; targetIndex++) {

	      const target = parsedTargets[targetIndex];
	      const ti = index || targetIndex;
	      const tl = length || targetsLength;

	      let lastTransformGroupIndex = NaN;
	      let lastTransformGroupLength = NaN;

	      for (let p in params) {

	        if (isKey(p)) {

	          const tweenType = getTweenType(target, p);

	          const propName = sanitizePropertyName(p, target, tweenType);

	          let propValue = params[p];

	          const isPropValueArray = isArr(propValue);

	          if (fastSet && !isPropValueArray) {
	            fastSetValuesArray[0] = propValue;
	            fastSetValuesArray[1] = propValue;
	            propValue = fastSetValuesArray;
	          }

	          // TODO: Allow nested keyframes inside ObjectValue value (prop: { to: [.5, 1, .75, 2, 3] })
	          // Normalize property values to valid keyframe syntax:
	          // [x, y] to [{to: [x, y]}] or {to: x} to [{to: x}] or keep keys syntax [{}, {}, {}...]
	          // const keyframes = isArr(propValue) ? propValue.length === 2 && !isObj(propValue[0]) ? [{ to: propValue }] : propValue : [propValue];
	          if (isPropValueArray) {
	            const arrayLength = /** @type {Array} */(propValue).length;
	            const isNotObjectValue = !isObj(propValue[0]);
	            // Convert [x, y] to [{to: [x, y]}]
	            if (arrayLength === 2 && isNotObjectValue) {
	              keyObjectTarget.to = /** @type {TweenParamValue} */(/** @type {unknown} */(propValue));
	              keyframesTargetArray[0] = keyObjectTarget;
	              keyframes = keyframesTargetArray;
	            // Convert [x, y, z] to [[x, y], z]
	            } else if (arrayLength > 2 && isNotObjectValue) {
	              keyframes = [];
	              /** @type {Array.<Number>} */(propValue).forEach((v, i) => {
	                if (!i) {
	                  fastSetValuesArray[0] = v;
	                } else if (i === 1) {
	                  fastSetValuesArray[1] = v;
	                  keyframes.push(fastSetValuesArray);
	                } else {
	                  keyframes.push(v);
	                }
	              });
	            } else {
	              keyframes = /** @type {Array.<TweenKeyValue>} */(propValue);
	            }
	          } else {
	            keyframesTargetArray[0] = propValue;
	            keyframes = keyframesTargetArray;
	          }

	          let siblings = null;
	          let prevTween = null;
	          let firstTweenChangeStartTime = NaN;
	          let lastTweenChangeEndTime = 0;
	          let tweenIndex = 0;

	          for (let l = keyframes.length; tweenIndex < l; tweenIndex++) {

	            const keyframe = keyframes[tweenIndex];

	            if (isObj(keyframe)) {
	              key = keyframe;
	            } else {
	              keyObjectTarget.to = /** @type {TweenParamValue} */(keyframe);
	              key = keyObjectTarget;
	            }

	            toFunctionStore.func = null;

	            const computedToValue = getFunctionValue(key.to, target, ti, tl, toFunctionStore);

	            let tweenToValue;
	            // Allows function based values to return an object syntax value ({to: v})
	            if (isObj(computedToValue) && !isUnd(computedToValue.to)) {
	              key = computedToValue;
	              tweenToValue = computedToValue.to;
	            } else {
	              tweenToValue = computedToValue;
	            }
	            const tweenFromValue = getFunctionValue(key.from, target, ti, tl);
	            const keyEasing = key.ease;
	            const hasSpring = !isUnd(keyEasing) && !isUnd(/** @type {Spring} */(keyEasing).ease);
	            // Easing are treated differently and don't accept function based value to prevent having to pass a function wrapper that returns an other function all the time
	            const tweenEasing = hasSpring ? /** @type {Spring} */(keyEasing).ease : keyEasing || tEasing;
	            // Calculate default individual keyframe duration by dividing the tl of keyframes
	            const tweenDuration = hasSpring ? /** @type {Spring} */(keyEasing).duration : getFunctionValue(setValue(key.duration, (l > 1 ? getFunctionValue(tDuration, target, ti, tl) / l : tDuration)), target, ti, tl);
	            // Default delay value should only be applied to the first tween
	            const tweenDelay = getFunctionValue(setValue(key.delay, (!tweenIndex ? tDelay : 0)), target, ti, tl);
	            const computedComposition = getFunctionValue(setValue(key.composition, tComposition), target, ti, tl);
	            const tweenComposition = isNum(computedComposition) ? computedComposition : compositionTypes[computedComposition];
	            // Modifiers are treated differently and don't accept function based value to prevent having to pass a function wrapper
	            const tweenModifier = key.modifier || tModifier;
	            const hasFromvalue = !isUnd(tweenFromValue);
	            const hasToValue = !isUnd(tweenToValue);
	            const isFromToArray = isArr(tweenToValue);
	            const isFromToValue = isFromToArray || (hasFromvalue && hasToValue);
	            const tweenStartTime = prevTween ? lastTweenChangeEndTime + tweenDelay : tweenDelay;
	            const absoluteStartTime = absoluteOffsetTime + tweenStartTime;

	            // Force a onRender callback if the animation contains at least one from value and autoplay is set to false
	            if (!shouldTriggerRender && (hasFromvalue || isFromToArray)) shouldTriggerRender = 1;

	            let prevSibling = prevTween;

	            if (tweenComposition !== compositionTypes.none) {
	              if (!siblings) siblings = getTweenSiblings(target, propName);
	              let nextSibling = siblings._head;
	              // Iterate trough all the next siblings until we find a sibling with an equal or inferior start time
	              while (nextSibling && !nextSibling._isOverridden && nextSibling._absoluteStartTime <= absoluteStartTime) {
	                prevSibling = nextSibling;
	                nextSibling = nextSibling._nextRep;
	                // Overrides all the next siblings if the next sibling starts at the same time of after as the new tween start time
	                if (nextSibling && nextSibling._absoluteStartTime >= absoluteStartTime) {
	                  while (nextSibling) {
	                    overrideTween(nextSibling);
	                    // This will ends both the current while loop and the upper one once all the next sibllings have been overriden
	                    nextSibling = nextSibling._nextRep;
	                  }
	                }
	              }
	            }

	            // Decompose values
	            if (isFromToValue) {
	              decomposeRawValue(isFromToArray ? getFunctionValue(tweenToValue[0], target, ti, tl) : tweenFromValue, fromTargetObject);
	              decomposeRawValue(isFromToArray ? getFunctionValue(tweenToValue[1], target, ti, tl, toFunctionStore) : tweenToValue, toTargetObject);
	              if (fromTargetObject.t === valueTypes.NUMBER) {
	                if (prevSibling) {
	                  if (prevSibling._valueType === valueTypes.UNIT) {
	                    fromTargetObject.t = valueTypes.UNIT;
	                    fromTargetObject.u = prevSibling._unit;
	                  }
	                } else {
	                  decomposeRawValue(
	                    getOriginalAnimatableValue(target, propName, tweenType, animInlineStyles),
	                    decomposedOriginalValue
	                  );
	                  if (decomposedOriginalValue.t === valueTypes.UNIT) {
	                    fromTargetObject.t = valueTypes.UNIT;
	                    fromTargetObject.u = decomposedOriginalValue.u;
	                  }
	                }
	              }
	            } else {
	              if (hasToValue) {
	                decomposeRawValue(tweenToValue, toTargetObject);
	              } else {
	                if (prevTween) {
	                  decomposeTweenValue(prevTween, toTargetObject);
	                } else {
	                  // No need to get and parse the original value if the tween is part of a timeline and has a previous sibling part of the same timeline
	                  decomposeRawValue(parent && prevSibling && prevSibling.parent.parent === parent ? prevSibling._value :
	                  getOriginalAnimatableValue(target, propName, tweenType, animInlineStyles), toTargetObject);
	                }
	              }
	              if (hasFromvalue) {
	                decomposeRawValue(tweenFromValue, fromTargetObject);
	              } else {
	                if (prevTween) {
	                  decomposeTweenValue(prevTween, fromTargetObject);
	                } else {
	                  decomposeRawValue(parent && prevSibling && prevSibling.parent.parent === parent ? prevSibling._value :
	                  // No need to get and parse the original value if the tween is part of a timeline and has a previous sibling part of the same timeline
	                  getOriginalAnimatableValue(target, propName, tweenType, animInlineStyles), fromTargetObject);
	                }
	              }
	            }

	            // Apply operators
	            if (fromTargetObject.o) {
	              fromTargetObject.n = getRelativeValue(
	                !prevSibling ? decomposeRawValue(
	                  getOriginalAnimatableValue(target, propName, tweenType, animInlineStyles),
	                  decomposedOriginalValue
	                ).n : prevSibling._toNumber,
	                fromTargetObject.n,
	                fromTargetObject.o
	              );
	            }

	            if (toTargetObject.o) {
	              toTargetObject.n = getRelativeValue(fromTargetObject.n, toTargetObject.n, toTargetObject.o);
	            }

	            // Values omogenisation in cases of type difference between "from" and "to"
	            if (fromTargetObject.t !== toTargetObject.t) {
	              if (fromTargetObject.t === valueTypes.COMPLEX || toTargetObject.t === valueTypes.COMPLEX) {
	                const complexValue = fromTargetObject.t === valueTypes.COMPLEX ? fromTargetObject : toTargetObject;
	                const notComplexValue = fromTargetObject.t === valueTypes.COMPLEX ? toTargetObject : fromTargetObject;
	                notComplexValue.t = valueTypes.COMPLEX;
	                notComplexValue.s = cloneArray(complexValue.s);
	                notComplexValue.d = complexValue.d.map(() => notComplexValue.n);
	              } else if (fromTargetObject.t === valueTypes.UNIT || toTargetObject.t === valueTypes.UNIT) {
	                const unitValue = fromTargetObject.t === valueTypes.UNIT ? fromTargetObject : toTargetObject;
	                const notUnitValue = fromTargetObject.t === valueTypes.UNIT ? toTargetObject : fromTargetObject;
	                notUnitValue.t = valueTypes.UNIT;
	                notUnitValue.u = unitValue.u;
	              } else if (fromTargetObject.t === valueTypes.COLOR || toTargetObject.t === valueTypes.COLOR) {
	                const colorValue = fromTargetObject.t === valueTypes.COLOR ? fromTargetObject : toTargetObject;
	                const notColorValue = fromTargetObject.t === valueTypes.COLOR ? toTargetObject : fromTargetObject;
	                notColorValue.t = valueTypes.COLOR;
	                notColorValue.s = colorValue.s;
	                notColorValue.d = [0, 0, 0, 1];
	              }
	            }

	            // Unit conversion
	            if (fromTargetObject.u !== toTargetObject.u) {
	              let valueToConvert = toTargetObject.u ? fromTargetObject : toTargetObject;
	              valueToConvert = convertValueUnit(/** @type {DOMTarget} */(target), valueToConvert, toTargetObject.u ? toTargetObject.u : fromTargetObject.u, false);
	              // TODO:
	              // convertValueUnit(target, to.u ? from : to, to.u ? to.u : from.u);
	            }

	            // Fill in non existing complex values
	            if (toTargetObject.d && fromTargetObject.d && (toTargetObject.d.length !== fromTargetObject.d.length)) {
	              const longestValue = fromTargetObject.d.length > toTargetObject.d.length ? fromTargetObject : toTargetObject;
	              const shortestValue = longestValue === fromTargetObject ? toTargetObject : fromTargetObject;
	              // TODO: Check if n should be used instead of 0 for default complex values
	              shortestValue.d = longestValue.d.map((_, i) => isUnd(shortestValue.d[i]) ? 0 : shortestValue.d[i]);
	              shortestValue.s = cloneArray(longestValue.s);
	            }

	            // Tween factory

	            // Rounding is necessary here to minimize floating point errors
	            const tweenUpdateDuration = round(+tweenDuration || minValue, 12);

	            /** @type {Tween} */
	            const tween = {
	              parent: this,
	              id: tweenId++,
	              property: propName,
	              target: target,
	              _value: null,
	              _func: toFunctionStore.func,
	              _ease: parseEasings(tweenEasing),
	              _fromNumbers: cloneArray(fromTargetObject.d),
	              _toNumbers: cloneArray(toTargetObject.d),
	              _strings: cloneArray(toTargetObject.s),
	              _fromNumber: fromTargetObject.n,
	              _toNumber: toTargetObject.n,
	              _numbers: cloneArray(fromTargetObject.d), // For additive tween and animatables
	              _number: fromTargetObject.n, // For additive tween and animatables
	              _unit: toTargetObject.u,
	              _modifier: tweenModifier,
	              _currentTime: 0,
	              _startTime: tweenStartTime,
	              _delay: +tweenDelay,
	              _updateDuration: tweenUpdateDuration,
	              _changeDuration: tweenUpdateDuration,
	              _absoluteStartTime: absoluteStartTime,
	              // NOTE: Investigate bit packing to stores ENUM / BOOL
	              _tweenType: tweenType,
	              _valueType: toTargetObject.t,
	              _composition: tweenComposition,
	              _isOverlapped: 0,
	              _isOverridden: 0,
	              _renderTransforms: 0,
	              _prevRep: null, // For replaced tween
	              _nextRep: null, // For replaced tween
	              _prevAdd: null, // For additive tween
	              _nextAdd: null, // For additive tween
	              _prev: null,
	              _next: null,
	            };

	            if (tweenComposition !== compositionTypes.none) {
	              composeTween(tween, siblings);
	            }

	            if (isNaN(firstTweenChangeStartTime)) {
	              firstTweenChangeStartTime = tween._startTime;
	            }
	            // Rounding is necessary here to minimize floating point errors
	            lastTweenChangeEndTime = round(tweenStartTime + tweenUpdateDuration, 12);
	            prevTween = tween;
	            animationAnimationLength++;

	            addChild(this, tween);

	          }

	          // Update animation timings with the added tweens properties

	          if (isNaN(iterationDelay) || firstTweenChangeStartTime < iterationDelay) {
	            iterationDelay = firstTweenChangeStartTime;
	          }

	          if (isNaN(iterationDuration) || lastTweenChangeEndTime > iterationDuration) {
	            iterationDuration = lastTweenChangeEndTime;
	          }

	          // TODO: Find a way to inline tween._renderTransforms = 1 here
	          if (tweenType === tweenTypes.TRANSFORM) {
	            lastTransformGroupIndex = animationAnimationLength - tweenIndex;
	            lastTransformGroupLength = animationAnimationLength;
	          }

	        }

	      }

	      // Set _renderTransforms to last transform property to correctly render the transforms list
	      if (!isNaN(lastTransformGroupIndex)) {
	        let i = 0;
	        forEachChildren(this, (/** @type {Tween} */tween) => {
	          if (i >= lastTransformGroupIndex && i < lastTransformGroupLength) {
	            tween._renderTransforms = 1;
	            if (tween._composition === compositionTypes.blend) {
	              forEachChildren(additive.animation, (/** @type {Tween} */additiveTween) => {
	                if (additiveTween.id === tween.id) {
	                  additiveTween._renderTransforms = 1;
	                }
	              });
	            }
	          }
	          i++;
	        });
	      }

	    }

	    if (!targetsLength) {
	      console.warn(`No target found. Make sure the element you're trying to animate is accessible before creating your animation.`);
	    }

	    if (iterationDelay) {
	      forEachChildren(this, (/** @type {Tween} */tween) => {
	        // If (startTime - delay) equals 0, this means the tween is at the begining of the animation so we need to trim the delay too
	        if (!(tween._startTime - tween._delay)) {
	          tween._delay -= iterationDelay;
	        }
	        tween._startTime -= iterationDelay;
	      });
	      iterationDuration -= iterationDelay;
	    } else {
	      iterationDelay = 0;
	    }

	    // Prevents iterationDuration to be NaN if no valid animatable props have been provided
	    // Prevents _iterationCount to be NaN if no valid animatable props have been provided
	    if (!iterationDuration) {
	      iterationDuration = minValue;
	      this.iterationCount = 0;
	    }
	    /** @type {TargetsArray} */
	    this.targets = parsedTargets;
	    /** @type {Number} */
	    this.duration = iterationDuration === minValue ? minValue : clampInfinity(((iterationDuration + this._loopDelay) * this.iterationCount) - this._loopDelay) || minValue;
	    /** @type {Callback<this>} */
	    this.onRender = onRender || animDefaults.onRender;
	    /** @type {EasingFunction} */
	    this._ease = animEase;
	    /** @type {Number} */
	    this._delay = iterationDelay;
	    // NOTE: I'm keeping delay values separated from offsets in timelines because delays can override previous tweens and it could be confusing to debug a timeline with overridden tweens and no associated visible delays.
	    // this._delay = parent ? 0 : iterationDelay;
	    // this._offset += parent ? iterationDelay : 0;
	    /** @type {Number} */
	    this.iterationDuration = iterationDuration;
	    /** @type {{}} */
	    this._inlineStyles = animInlineStyles;

	    if (!this._autoplay && shouldTriggerRender) this.onRender(this);
	  }

	  /**
	   * @param  {Number} newDuration
	   * @return {this}
	   */
	  stretch(newDuration) {
	    const currentDuration = this.duration;
	    if (currentDuration === normalizeTime(newDuration)) return this;
	    const timeScale = newDuration / currentDuration;
	    // NOTE: Find a better way to handle the stretch of an animation after stretch = 0
	    forEachChildren(this, (/** @type {Tween} */tween) => {
	      // Rounding is necessary here to minimize floating point errors
	      tween._updateDuration = normalizeTime(tween._updateDuration * timeScale);
	      tween._changeDuration = normalizeTime(tween._changeDuration * timeScale);
	      tween._currentTime *= timeScale;
	      tween._startTime *= timeScale;
	      tween._absoluteStartTime *= timeScale;
	    });
	    return super.stretch(newDuration);
	  }

	  /**
	   * @return {this}
	   */
	  refresh() {
	    forEachChildren(this, (/** @type {Tween} */tween) => {
	      const ogValue = getOriginalAnimatableValue(tween.target, tween.property, tween._tweenType);
	      decomposeRawValue(ogValue, decomposedOriginalValue);
	      tween._fromNumbers = cloneArray(decomposedOriginalValue.d);
	      tween._fromNumber = decomposedOriginalValue.n;
	      if (tween._func) {
	        decomposeRawValue(tween._func(), toTargetObject);
	        tween._toNumbers = cloneArray(toTargetObject.d);
	        tween._strings = cloneArray(toTargetObject.s);
	        tween._toNumber = toTargetObject.n;
	      }
	    });
	    return this;
	  }

	  /**
	   * Cancel the animation and revert all the values affected by this animation to their original state
	   * @return {this}
	   */
	  revert() {
	    super.revert();
	    return cleanInlineStyles(this);
	  }

	  /**
	   * @param  {Callback<this>} [callback]
	   * @return {Promise}
	   */
	  then(callback) {
	    return super.then(callback);
	  }

	}

	/**
	 * @param {TargetsParam} targets
	 * @param {AnimationParams} parameters
	 * @return {JSAnimation}
	 */
	const animate = (targets, parameters) => new JSAnimation(targets, parameters, null, 0, false).init();

	/**
	 * @typedef {String|Number|Array<String>|Array<Number>} WAAPITweenValue
	 */

	/**
	 * @callback WAAPIFunctionvalue
	 * @param {DOMTarget} target - The animated target
	 * @param {Number} index - The target index
	 * @param {Number} length - The total number of animated targets
	 * @return {WAAPITweenValue}
	 */

	/**
	 * @typedef {WAAPITweenValue|WAAPIFunctionvalue|Array<String|Number|WAAPIFunctionvalue>} WAAPIKeyframeValue
	 */

	/**
	 * @typedef {(animation: WAAPIAnimation) => void} WAAPICallback
	 */

	/**
	 * @typedef {Object} WAAPITweenOptions
	 * @property {WAAPIKeyframeValue} [to]
	 * @property {WAAPIKeyframeValue} [from]
	 * @property {Number|WAAPIFunctionvalue} [duration]
	 * @property {Number|WAAPIFunctionvalue} [delay]
	 * @property {EasingParam} [ease]
	 * @property {CompositeOperation} [composition]
	 */

	/**
	 * @typedef {Object} WAAPIAnimationOptions
	 * @property {Number|Boolean} [loop]
	 * @property {Boolean} [Reversed]
	 * @property {Boolean} [Alternate]
	 * @property {Boolean|ScrollObserver} [autoplay]
	 * @property {Number} [playbackRate]
	 * @property {Number|WAAPIFunctionvalue} [duration]
	 * @property {Number|WAAPIFunctionvalue} [delay]
	 * @property {EasingParam} [ease]
	 * @property {CompositeOperation} [composition]
	 * @property {WAAPICallback} [onComplete]
	 */

	/**
	 * @typedef {Record<String, WAAPIKeyframeValue | WAAPIAnimationOptions | Boolean | ScrollObserver | WAAPICallback | EasingParam | WAAPITweenOptions> & WAAPIAnimationOptions} WAAPIAnimationParams
	 */

	const transformsShorthands = ['x', 'y', 'z'];

	const validIndividualTransforms = [...transformsShorthands, ...validTransforms.filter(t => ['X', 'Y', 'Z'].some(axis => t.endsWith(axis)))];

	// Setting it to true in case CSS.registerProperty is not supported will automatically skip the registration and fallback to no animation
	let transformsPropertiesRegistered = isBrowser && (isUnd(CSS) || !Object.hasOwnProperty.call(CSS, 'registerProperty'));

	// color: 0x0E2323,
	// specularColor: 0xffffff,
	// attenuationColor: new THREE.Color(0xffffff),
	// _transmission: 1,
	/*
	anisotropicBlur: 0.1,
	        ior: 1.5,
	        
	        attenuationDistance: 1,
	        specularIntensity: 1,
	        
	        envMapIntensity: 1,
	        lightIntensity: 2,
	        exposure: 1,
	        chromaticAberration: 0.02,
	        transparent: true,
	        backside: false

	        */

	function glassButton() {


	    const params = {
	        color: 0x0E2323,
	        metalness: 0,
	        roughness: 0.2,
	        //transmission: 1,
	        //ior: 1.5,
	        //reflectivity: 0.5,
	        //thickness: 2.5,
	        //envMapIntensity: 1.5,
	        //clearcoat: 1,
	        //clearcoatRoughness: 0.1,
	        normalScale: 0.3,
	        //clearcoatNormalScale: 0.2,
	        //normalRepeat: 3,
	        
	    };

	    

	    //const geometry = roundedRectange(0.5, 1) // new THREE.PlaneGeometry(1,1,1);

	    const geometry = new CapsuleGeometry( 0.2, 2.4, 16, 32 ); 

	    const material = new MeshStandardMaterial(params);

	    const mesh = new Mesh(geometry, material);

	    mesh.rotation.z = Math.PI * 0.5;

	    const tick = (context) => {

	    };


	    return {
	        mesh, material, tick
	    }
	}

	const perlin3d = /*wgsl */`

// Classic Perlin 3D Noise 
// by Stefan Gustavson
//
vec4 permute(vec4 x)
{
    return mod(((x*34.0)+1.0)*x, 289.0);
}
vec4 taylorInvSqrt(vec4 r)
{
    return 1.79284291400159 - 0.85373472095314 * r;
}
vec3 fade(vec3 t)
{
    return t*t*t*(t*(t*6.0-15.0)+10.0);
}

float cnoise(vec3 P)
{
    vec3 Pi0 = floor(P); // Integer part for indexing
    vec3 Pi1 = Pi0 + vec3(1.0); // Integer part + 1
    Pi0 = mod(Pi0, 289.0);
    Pi1 = mod(Pi1, 289.0);
    vec3 Pf0 = fract(P); // Fractional part for interpolation
    vec3 Pf1 = Pf0 - vec3(1.0); // Fractional part - 1.0
    vec4 ix = vec4(Pi0.x, Pi1.x, Pi0.x, Pi1.x);
    vec4 iy = vec4(Pi0.yy, Pi1.yy);
    vec4 iz0 = Pi0.zzzz;
    vec4 iz1 = Pi1.zzzz;

    vec4 ixy = permute(permute(ix) + iy);
    vec4 ixy0 = permute(ixy + iz0);
    vec4 ixy1 = permute(ixy + iz1);

    vec4 gx0 = ixy0 / 7.0;
    vec4 gy0 = fract(floor(gx0) / 7.0) - 0.5;
    gx0 = fract(gx0);
    vec4 gz0 = vec4(0.5) - abs(gx0) - abs(gy0);
    vec4 sz0 = step(gz0, vec4(0.0));
    gx0 -= sz0 * (step(0.0, gx0) - 0.5);
    gy0 -= sz0 * (step(0.0, gy0) - 0.5);

    vec4 gx1 = ixy1 / 7.0;
    vec4 gy1 = fract(floor(gx1) / 7.0) - 0.5;
    gx1 = fract(gx1);
    vec4 gz1 = vec4(0.5) - abs(gx1) - abs(gy1);
    vec4 sz1 = step(gz1, vec4(0.0));
    gx1 -= sz1 * (step(0.0, gx1) - 0.5);
    gy1 -= sz1 * (step(0.0, gy1) - 0.5);

    vec3 g000 = vec3(gx0.x,gy0.x,gz0.x);
    vec3 g100 = vec3(gx0.y,gy0.y,gz0.y);
    vec3 g010 = vec3(gx0.z,gy0.z,gz0.z);
    vec3 g110 = vec3(gx0.w,gy0.w,gz0.w);
    vec3 g001 = vec3(gx1.x,gy1.x,gz1.x);
    vec3 g101 = vec3(gx1.y,gy1.y,gz1.y);
    vec3 g011 = vec3(gx1.z,gy1.z,gz1.z);
    vec3 g111 = vec3(gx1.w,gy1.w,gz1.w);

    vec4 norm0 = taylorInvSqrt(vec4(dot(g000, g000), dot(g010, g010), dot(g100, g100), dot(g110, g110)));
    g000 *= norm0.x;
    g010 *= norm0.y;
    g100 *= norm0.z;
    g110 *= norm0.w;
    vec4 norm1 = taylorInvSqrt(vec4(dot(g001, g001), dot(g011, g011), dot(g101, g101), dot(g111, g111)));
    g001 *= norm1.x;
    g011 *= norm1.y;
    g101 *= norm1.z;
    g111 *= norm1.w;

    float n000 = dot(g000, Pf0);
    float n100 = dot(g100, vec3(Pf1.x, Pf0.yz));
    float n010 = dot(g010, vec3(Pf0.x, Pf1.y, Pf0.z));
    float n110 = dot(g110, vec3(Pf1.xy, Pf0.z));
    float n001 = dot(g001, vec3(Pf0.xy, Pf1.z));
    float n101 = dot(g101, vec3(Pf1.x, Pf0.y, Pf1.z));
    float n011 = dot(g011, vec3(Pf0.x, Pf1.yz));
    float n111 = dot(g111, Pf1);

    vec3 fade_xyz = fade(Pf0);
    vec4 n_z = mix(vec4(n000, n100, n010, n110), vec4(n001, n101, n011, n111), fade_xyz.z);
    vec2 n_yz = mix(n_z.xy, n_z.zw, fade_xyz.y);
    float n_xyz = mix(n_yz.x, n_yz.y, fade_xyz.x); 
    return 2.2 * n_xyz;
}
    `;




	const simplexNoise4d$1 = /* glsl */`
//	Simplex 4D Noise 
//	by Ian McEwan, Ashima Arts
//
vec4 permute(vec4 x){return mod(((x*34.0)+1.0)*x, 289.0);}
float permute(float x){return floor(mod(((x*34.0)+1.0)*x, 289.0));}
vec4 taylorInvSqrt(vec4 r){return 1.79284291400159 - 0.85373472095314 * r;}
float taylorInvSqrt(float r){return 1.79284291400159 - 0.85373472095314 * r;}

vec4 grad4(float j, vec4 ip){
  const vec4 ones = vec4(1.0, 1.0, 1.0, -1.0);
  vec4 p,s;

  p.xyz = floor( fract (vec3(j) * ip.xyz) * 7.0) * ip.z - 1.0;
  p.w = 1.5 - dot(abs(p.xyz), ones.xyz);
  s = vec4(lessThan(p, vec4(0.0)));
  p.xyz = p.xyz + (s.xyz*2.0 - 1.0) * s.www; 

  return p;
}

float simplexNoise4d(vec4 v){
  const vec2  C = vec2( 0.138196601125010504,  // (5 - sqrt(5))/20  G4
                        0.309016994374947451); // (sqrt(5) - 1)/4   F4
// First corner
  vec4 i  = floor(v + dot(v, C.yyyy) );
  vec4 x0 = v -   i + dot(i, C.xxxx);

// Other corners

// Rank sorting originally contributed by Bill Licea-Kane, AMD (formerly ATI)
  vec4 i0;

  vec3 isX = step( x0.yzw, x0.xxx );
  vec3 isYZ = step( x0.zww, x0.yyz );
//  i0.x = dot( isX, vec3( 1.0 ) );
  i0.x = isX.x + isX.y + isX.z;
  i0.yzw = 1.0 - isX;

//  i0.y += dot( isYZ.xy, vec2( 1.0 ) );
  i0.y += isYZ.x + isYZ.y;
  i0.zw += 1.0 - isYZ.xy;

  i0.z += isYZ.z;
  i0.w += 1.0 - isYZ.z;

  // i0 now contains the unique values 0,1,2,3 in each channel
  vec4 i3 = clamp( i0, 0.0, 1.0 );
  vec4 i2 = clamp( i0-1.0, 0.0, 1.0 );
  vec4 i1 = clamp( i0-2.0, 0.0, 1.0 );

  //  x0 = x0 - 0.0 + 0.0 * C 
  vec4 x1 = x0 - i1 + 1.0 * C.xxxx;
  vec4 x2 = x0 - i2 + 2.0 * C.xxxx;
  vec4 x3 = x0 - i3 + 3.0 * C.xxxx;
  vec4 x4 = x0 - 1.0 + 4.0 * C.xxxx;

// Permutations
  i = mod(i, 289.0); 
  float j0 = permute( permute( permute( permute(i.w) + i.z) + i.y) + i.x);
  vec4 j1 = permute( permute( permute( permute (
             i.w + vec4(i1.w, i2.w, i3.w, 1.0 ))
           + i.z + vec4(i1.z, i2.z, i3.z, 1.0 ))
           + i.y + vec4(i1.y, i2.y, i3.y, 1.0 ))
           + i.x + vec4(i1.x, i2.x, i3.x, 1.0 ));
// Gradients
// ( 7*7*6 points uniformly over a cube, mapped onto a 4-octahedron.)
// 7*7*6 = 294, which is close to the ring size 17*17 = 289.

  vec4 ip = vec4(1.0/294.0, 1.0/49.0, 1.0/7.0, 0.0) ;

  vec4 p0 = grad4(j0,   ip);
  vec4 p1 = grad4(j1.x, ip);
  vec4 p2 = grad4(j1.y, ip);
  vec4 p3 = grad4(j1.z, ip);
  vec4 p4 = grad4(j1.w, ip);

// Normalise gradients
  vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));
  p0 *= norm.x;
  p1 *= norm.y;
  p2 *= norm.z;
  p3 *= norm.w;
  p4 *= taylorInvSqrt(dot(p4,p4));

// Mix contributions from the five corners
  vec3 m0 = max(0.6 - vec3(dot(x0,x0), dot(x1,x1), dot(x2,x2)), 0.0);
  vec2 m1 = max(0.6 - vec2(dot(x3,x3), dot(x4,x4)            ), 0.0);
  m0 = m0 * m0;
  m1 = m1 * m1;
  return 49.0 * ( dot(m0*m0, vec3( dot( p0, x0 ), dot( p1, x1 ), dot( p2, x2 )))
               + dot(m1*m1, vec2( dot( p3, x3 ), dot( p4, x4 ) ) ) ) ;

}
`;



	const simplexNoise2d = /* glsl */`

// Simplex 2D noise
//
vec3 permute(vec3 x) { return mod(((x*44.0)+1.0)*x, 299.0); }

float simplexNoise2d(vec2 v)
{
    const vec4 C = vec4(0.211324865405187, 0.366025403784439,
            -0.577350269189626, 0.024390243902439);
    vec2 i  = floor(v + dot(v, C.yy) );
    vec2 x0 = v -   i + dot(i, C.xx);
    vec2 i1;
    i1 = (x0.x > x0.y) ? vec2(1.0, 0.0) : vec2(0.0, 1.0);
    vec4 x12 = x0.xyxy + C.xxzz;
    x12.xy -= i1;
    i = mod(i, 299.0);
    vec3 p = permute( permute( i.y + vec3(0.0, i1.y, 1.0 ))
    + i.x + vec3(0.0, i1.x, 1.0 ));
    vec3 m = max(0.5 - vec3(dot(x0,x0), dot(x12.xy,x12.xy),
    dot(x12.zw,x12.zw)), 0.0);
    m = m*m ;
    m = m*m ;
    vec3 x = 2.0 * fract(p * C.www) - 1.0;
    vec3 h = abs(x) - 0.5;
    vec3 ox = floor(x + 0.5);
    vec3 a0 = x - ox;
    m *= 1.79284291400159 - 0.85373472095314 * ( a0*a0 + h*h );
    vec3 g;
    g.x  = a0.x  * x0.x  + h.x  * x0.y;
    g.yz = a0.yz * x12.xz + h.yz * x12.yw;
    return 130.0 * dot(m, g);
}

`;

	const defs = `
#define PI 3.1415926535897932384626433832795
`;

	const utils = /* wgsl */`

float random(vec2 st) {
            return fract(sin(dot(st.xy, vec2(12.9898,78.233))) * 43758.5453123);
}

vec2 rotate(vec2 uv, float rotation, vec2 mid)
{
    return vec2(
      cos(rotation) * (uv.x - mid.x) + sin(rotation) * (uv.y - mid.y) + mid.x,
      cos(rotation) * (uv.y - mid.y) - sin(rotation) * (uv.x - mid.x) + mid.y
    );
}

float wavify(vec2 vUv, float frequency) {
        float angle = atan(vUv.x - 0.5, vUv.y - 0.5);
        angle /= PI * 2.0;
        angle += 0.5;
        float sinAngle = sin(angle * frequency) * 0.02;
        return sinAngle;
}

float circle(vec2 vUv, float radius, float strokeWidth) {
        // draw a circle
        float circle = abs(distance(vUv, vec2(0.5, 0.5)) - radius);
        circle = 1.0 - step(strokeWidth, circle); 
        return circle;
}
// 50.0
// repeatingRadial(vUv, 50.0, 0.5, 0.5);
float repeatingRadial(vec2 vUv, float frequency, float cx, float cy) {
    float angle = atan(vUv.x - cx, vUv.y - cy);
    angle /= PI * 2.0;
    angle += 0.5;
    angle = sin(angle * frequency);

    return angle;
}
// repeatingConical
float repeatingConical(vec2 vUv, float frequency, float cx, float cy) {

        float angle = atan(vUv.x - cx, vUv.y - cy);
        angle /= PI * 2.0;
        angle += 0.5;
        angle *= frequency;
        angle = mod(angle, 1.0);

        return angle;
}
// conicalGradient(vUv, 0.5, 0.5, PI * 2.0);
float conicalGradient(vec2 vUv, float cx, float cy, float a) {
    float angle = atan(vUv.x - cx, vUv.y - cy);
    angle = angle / a; // PI * 2.0;
    angle += 0.5;

    return angle;
}
float radialGradient(vec2 vUv, float cx, float cy, float a) {
    float angle = atan(vUv.x - cx, vUv.y - cy);
    return angle / a;
}

`;

	function galaxyParticles(params, program) {
	    const { count = 2000, gui } = params;
	    const { renderer } = program; 


	    const vertexShader = /* wgsl */`

                // modelMatrix 
                // viewMatrix 
                // projectionMatrix

                uniform float uTime;
                uniform float uSize;
                uniform float uSizePow;

                attribute float aScale;
                attribute vec3 aRandomness;

                varying vec2 vUv;

                varying vec3 vColor;

                void main() {
                    vec4 modelPosition = modelMatrix * vec4(position, 1.0);

                    // spin
                    float angle = atan(modelPosition.x, modelPosition.z);
                    //float distanceToCenter = length(modelPosition.xz); // vec3(0.0)
                    float distanceToCenter = length(modelPosition.xz);
                    // inner particles rotate faster
                    float angleOffset = (1.0 / distanceToCenter) * uTime * 0.2;
                    angle += angleOffset;

                    //modelPosition.x = cos(angle) * distanceToCenter;
                    //modelPosition.z = sin(angle) * distanceToCenter;

                    modelPosition.xyz += aRandomness;
                    //modelPosition.y += sin(uTime + aRandomness.z * 1.0) * 0.3;
                    
                    vec4 viewPosition = viewMatrix * modelPosition;
                    vec4 projectedPosition = projectionMatrix * viewPosition;

                    gl_Position = projectedPosition;

                    float size = abs(uSize);

                    gl_PointSize = uSize * aScale; // * (1.0 /  viewPosition.z);
                    gl_PointSize *= (1.0 / - viewPosition.z);

                    vColor = color;

                    //vUv = uv;

                }
        `;


	    const fragmentShader = /* wgsl */`
                ${defs}
                ${utils}

                varying vec2 vUv;
                varying vec3 vColor;

                uniform float uSizePow;
                uniform float uRadiusInner;
                uniform float uRadiusOuter;
                uniform int uParticleType;
                

                void main() {
                    
                    vec4 fragColor = vec4(gl_PointCoord, 1.0, 1.0);
                    // get the distance from (0.5,0.5) center
                    float strength = distance(gl_PointCoord, vec2(0.5));  
                    
                    strength = 1.0 - strength;
                    strength = pow(strength, uSizePow);
                    // power
                    float alpha = smoothstep(uRadiusInner, uRadiusOuter, strength);
                    alpha = pow(alpha, uSizePow);
                    
                    //float alpha2 = smoothstep(0.0, 1.0, strength);
                    
                    //strength = smoothstep(0.7, 1.0, pow(strength, 10.0));

                    //alpha = alpha * alpha2;
                    
                    vec3 color = mix(vec3(0.0), vColor, alpha);
                    //vec3 color2 = mix(vec3(0.0), vColor, alpha2);

                    gl_FragColor = vec4(color, alpha); //vec4(color, alpha);


                    
                }
        `;



	    const geometry = new BufferGeometry();
	    const positions = new Float32Array(count*3);
	    const initialPositions = new Float32Array(count*3);
	    const colors = new Float32Array(count*3);
	    const randomness = new Float32Array(count*3);
	    const scales = new Float32Array(count * 1);


	    const innerColor = new Color(params.innerColor);
	    const outerColor = new Color(params.outerColor);

	    const {branches = 3, spin = 0.4, radius = 2.5, 
	        randomnessPow = 2, randomness: randomnessFreq = 0.5,
	        innerRadius = 0, outerRadius = 1, particleType = 'disc',
	        blending = 'normal' } = params;

	    
	    const type = PARTICLE_TYPES[particleType] || PARTICLE_TYPES.disc;    
	    const blendMode = BLENDMODES[blending] || BLENDMODES.normal;


	    for (let i = 0; i < count; i++) {
	        let i3 = i * 3;

	        const rad = Math.random() * radius;
	        let bAngle = (i % branches) / branches; // [0, 0.3333, 0.6666], 
	        bAngle *= Math.PI * 2;

	        const spinAngle = rad * spin;

	        //const randX = Math.pow(Math.random(), params.randomnessPow) * randSign()
	        //const randY =  Math.pow(Math.random(), params.randomnessPow) * randSign()
	        //const randZ =  Math.pow(Math.random(), params.randomnessPow) * randSign()

	        const randX = Math.pow(Math.random(), randomnessPow) * (Math.random() < 0.5 ? 1 : - 1) * randomnessFreq * rad;
	        const randY = Math.pow(Math.random(), randomnessPow) * (Math.random() < 0.5 ? 1 : - 1) * randomnessFreq * rad;
	        const randZ = Math.pow(Math.random(), randomnessPow) * (Math.random() < 0.5 ? 1 : - 1) * randomnessFreq * rad;

	        positions[i3+0] = Math.cos(bAngle + spinAngle) * rad ;
	        positions[i3+1] = 0 ; 
	        positions[i3+2] = Math.sin(bAngle + spinAngle) * rad ;

	        randomness[i3    ] = randX;
	        randomness[i3 + 1] = randY;
	        randomness[i3 + 2] = randZ;

	        initialPositions[i3] = positions[i3];
	        initialPositions[i3+1] = positions[i3+1];
	        initialPositions[i3+2] = positions[i3+2];

	        const mixedColor = innerColor.clone();
	        mixedColor.lerp(outerColor, rad / radius);

	        colors[i3] = mixedColor.r;
	        colors[i3+1] = mixedColor.g;
	        colors[i3+2] = mixedColor.b;

	        scales[i] = Math.random() * 10;
	    }



	    geometry.setAttribute('position', new BufferAttribute(positions, 3));
	    geometry.setAttribute('color', new BufferAttribute(colors, 3));
	    geometry.setAttribute('aScale', new BufferAttribute(scales, 1));
	    geometry.setAttribute('aRandomness', new BufferAttribute(randomness, 3));


	    const uniforms = {
	            uSize: { value: (params.size || 1) * renderer.getPixelRatio() }, //
	            uSizePow: new Uniform(params.sizePow || 2),
	            uRadiusInner: new Uniform(innerRadius),
	            uRadiusOuter: new Uniform(outerRadius),
	            uParticleType: new Uniform(type),
	            uTime: { value: 0 },

	        };

	    

	    const material = new ShaderMaterial({
	        //size: params.size,
	        //sizeAttenuation: params.sizeAttenuation,
	        
	        //blending: params.blending,
	        //randomness: params.randomness,
	        transparent: true,
	        alphaTest: 0.001,
	        depthTest: false,
	        depthWrite: false,
	        vertexColors: true,
	        blending: blendMode,
	        fragmentShader, 
	        vertexShader,
	        uniforms,
	    });

	    console.log("renderer.getPixelRatio()", renderer.getPixelRatio(), window.devicePixelRatio);

	    const mesh = new Points(geometry, material);

	    const tick = (context) => {
	        uniforms.uTime.value = context.clock.time * 2;
	    };

	    return { geometry, mesh, material, tick }
	}

	const vertex$m = /* glsl */`
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;
varying vec2 vUv;

void main() { 
    vUv = uv;
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}   
`;

	const fragment$m = /* glsl */`
varying vec2 vUv;

uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;


vec2 calcUV(vec2 uv, vec2 texureSize, vec2 planesize){
	// vec2 tempUV = (uv - vec2(.5)) * 2.;
	vec2 tempUV = uv - vec2(.5);

	float planeAspect = uPlaneResolution.x / uPlaneResolution.y;
	float texAspect = uTextureSize.x / uTextureSize.y;

	if (planeAspect < texAspect) {
		tempUV = tempUV * vec2(planeAspect / texAspect, 1.);
	} else {
		tempUV = tempUV * vec2(1., texAspect/planeAspect);
	}

	tempUV += vec2(0.5);
	return tempUV;
}


void main()	{

	vec2 scaledUV = calcUV(vUv, uTextureSize, uPlaneResolution);

	vec4 image = texture2D(uTexture, scaledUV);
    gl_FragColor = image; // vec4(vUv, 1.0, 1.0);

    //gl_FragColor =  vec4(vUv, 1.0, 1.0);
    #include <tonemapping_fragment>
    #include <colorspace_fragment>

}
`;



	function SmokeMaterial(params, program) {

	    console.log("SmokeMaterial params", params);

	    const displacementMapUrl = params.displacement;

	    const vertex = /* glsl */`
        varying vec2 vUv;
        varying float time;

        uniform float uTime;
        uniform sampler2D uPerlinTex;
        uniform vec2 uCursor;
        uniform float uRandom;
        uniform float uFrequency;
        uniform float uVolume;

        vec2 rotate2D(vec2 value, float angle)
        {
            float s = sin(angle);
            float c = cos(angle);
            mat2 m = mat2(c, s, -s, c);
            return m * value;
        }

        void main() {

            float twistFreq = 0.03;
            float twistAmp = 6.0;

            float twistXWave = 0.05;
            float twistYWave = 0.007;
            
            float twistMapSize = 0.2;

            float windStrength = 40.0 ;
            float windPower = 0.125;


            vUv = uv;

            vec3 newPosition = position;

            time = (uTime + (uRandom * 37.0)) * uFrequency ;

            float twistPerlin = texture(uPerlinTex,
                 vec2(0.1 + uv.x * twistMapSize - time * twistXWave, 
                        0.1 + uv.y * twistMapSize - time * twistYWave)
            ).r;

            twistPerlin = smoothstep(0.3, 0.8, twistPerlin) ;
        
            float angle = (twistPerlin + (uTime * twistFreq)) * twistAmp ;
            newPosition.xz = rotate2D(newPosition.xz, angle);


            vec2 windOffset = vec2(
                texture(uPerlinTex, vec2(0.25, time * 0.003)).r - 0.5 + uCursor.x,
                texture(uPerlinTex, vec2(0.75, time * 0.003)).r - 0.5 + uCursor.y
            );

                    // Wind
            //vec2 windOffset = vec2(
            //    texture(uPerlinTex, vec2(0.25, uTime * 0.003)).r - 0.5,
            //    texture(uPerlinTex, vec2(0.75, uTime * 0.003)).r - 0.5
            //);
            windOffset *= uCursor.x + pow(uv.y, 2.0) * sin(time) * windStrength; // uv.y will start from the bottom
            newPosition.xz += windOffset;

            //newPosition.y += uCursor.y;
            

            // Twist
            // float angle = position.y;
            newPosition.xz = rotate2D(newPosition.xz, angle);
            //newPosition.z += uCursor.y;
            //newPosition.y *= uCursor.x;

            //newPosition = position;

            // position
            gl_Position = projectionMatrix * modelViewMatrix * vec4(newPosition, 1.0);
        }
    `;

	    const fragment = /* glsl */`

        uniform float uTime;
        uniform sampler2D uPerlinTex;
        uniform float uColorMixFactor;
        uniform vec3 uColor;
        uniform vec2 uCursor;
        uniform float uVolume;
        //uniform float uTime;

        varying float time;
        varying vec2 vUv;

       void main() {
            vec2 scaledUv = vUv;
            scaledUv.x *= 0.52;
            scaledUv.y *= 0.52;

            scaledUv.y -= time * 0.2;

            vec4 vertexPosition = vec4(gl_PointCoord, 1.0, 1.0);

            float lum = texture(uPerlinTex, scaledUv).r; // red channel
            lum = smoothstep(0.4, 1.0, lum);

            //lum = 1.0;
            lum *= smoothstep(0.0, 0.1, vUv.x);
            lum *= smoothstep(1.0, 0.9, vUv.x);
            lum *= smoothstep(0.0, 0.1, vUv.y);
            lum *= smoothstep(1.0, 0.9, vUv.y);


            float x = abs(sin(vUv.x + time * 0.3));
            float y = abs(cos(vUv.y + time * 0.6));
            float z = abs(smoothstep(0.0, 1.0, sin(time) * 0.6));

            float x2 = abs(sin(vUv.x + time * 0.4));
            float y2 = abs(cos(vUv.y + time * 0.7));
            float z2 = abs(smoothstep(0.0, 1.0, sin(time) * 0.7));

            vec3 mixedColor = mix(vec3(x,y,z), uColor, uColorMixFactor);

            mixedColor = mix(mixedColor, vec3(x2,y2,z2), vertexPosition.z);
            //mixedColor = mix(mixedColor, vec3(x2,y2,z2), vertexPosition.z);

            //lum = smoothstep(0.0, 0.5, lum);

            gl_FragColor =  vec4(mixedColor, lum);
       }
    `;

	    console.log("smoked material", params);

	    const textureLoader2 = new TextureLoader();
	    const displaceTexture = textureLoader2.load(displacementMapUrl, function() {
	            console.log("displaceTexture loaded", displacementMapUrl, displaceTexture);
	        });

	    displaceTexture.wrapS = MirroredRepeatWrapping;
	    displaceTexture.wrapT = MirroredRepeatWrapping;


	    const uniforms = {
	            uTime: { value: new Uniform(0) },
	            uVolume: { value: new Uniform(0) },
	            uColor: { value: new Color("#A7D0F9") },
	            uCursor: { value: new Vector2(0, 0) },
	            uColorMixFactor: { value: 0 },
	            uRandom: { value: Math.random() },
	            uFrequency: { value: 1 },
	            //uTexture: { value: texture },
	            uPerlinTex: { value: displaceTexture },
	            uTextureSize: {value: new Vector2(1024, 1024)},
	            uPlaneResolution: {value: new Vector2(1.4, 1)}
	        };



	    let material = new ShaderMaterial({
	            wireframe: false,
	            transparent: true,
	            depthTest: false,
	            //side: THREE.DoubleSide,
	            fragmentShader: fragment,
	            vertexShader: vertex,
	            uniforms,    
	    });

	    const tick = (context) => {

	        //console.log('scroll', context.scroll);
	        
	        //uniforms.uTime.value = context.scroll.progress * 10;

	        uniforms.uTime.value = context.clock.time;

	        uniforms.uCursor.value.x = context.cursor.x;
	        uniforms.uCursor.value.y = context.cursor.y;

	        //uniforms.uColorMixFactor.value = context.mouse.y;

	        //console.log(context.cursor.x)
	    };


	    return { material, tick, uniforms }
	}










	class LockScreen extends Shape$1 {

	    constructor(...args) {
	        super(...args);
	    }

		getGeometry(program) {
			
	        const aspect = window.innerWidth / window.innerHeight;

	        console.log(aspect);

			let plane = new PlaneGeometry(aspect * 4, 1 * 4, 32, 32);
	        
			return plane
		}

	    // default mesh
	    createMesh(program) {		
	        const geometry = this.getGeometry(program);
	        const material = this.getMaterial(program, geometry);

	        const container = new Group$1();

	        //const mesh = new THREE.Mesh(geometry, material)
	        //container.add(mesh)

	        const bg = this.createBackground(program);
	        container.add(bg);

	        


	        //const button = glassButton();
	        //button.mesh.position.z = 2;
	    
	        //container.add(button.mesh);
	    


	        return container;
	    }



	    createBackground(program) {
	        let geometry = new PlaneGeometry(1, 1, 512, 512);
	        geometry.scale(8, 10, 1);
	        geometry.computeVertexNormals();

	        const bgMaterial = SmokeMaterial(this.params);

	        const container = new Group$1();

	        const mesh = new Mesh(geometry, bgMaterial.material);

	        let geometry2 = new PlaneGeometry(1, 1, 512, 512);
	        geometry2.scale(4, 16, 1);
	        geometry2.rotateY(Math.PI);

	        const bgMaterial2 = SmokeMaterial(this.params);

	       // const mesh2 = new THREE.Mesh(geometry2, bgMaterial.material)
	        const mesh3 = new Mesh(geometry2, bgMaterial2.material);

	        // this.bgMaterial = bgMaterial;

	        container.add(mesh);
	        //container.add(mesh2);
	        container.add(mesh3);

	        mesh3.position.x = 0;
	        mesh3.rotation.y = Math.PI / 2;

	    
	        const aObj = { x: 0 };

	        const tl = animate(aObj, {
	            z: 100,
	            ease: 'out(4)',
	            duration: 11500,
	            autoplay: false, 
	            onUpdate: () => {
	                //console.log("animating model x", aObj.x)
	                mesh.rotation.y = aObj.z / 100 * -Math.PI;
	                //mesh3.rotation.z = aObj.x / 100 * -Math.PI;

	                //bgMaterial.uniforms.uFrequency.value = aObj.x / 100;
	                //bgMaterial2.uniforms.uFrequency.value = aObj.x / 100;
	            }
	        });




	        this.updateMaterials = (context) => {
	            bgMaterial.tick(context);
	            //bgMaterial2.tick(context)

	            bgMaterial2.uniforms.uVolume.value = context.analyser.data.average;


	            tl.seek(context.scroll.progress * 1500);
	        };
	        
	        return container;
	    }




	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);
	        const texFile = this.params.materials?.map;
	        const displacementMapUrl = this.params.materials?.displacement;

	        const textureLoader = new TextureLoader();
	        const texture = textureLoader.load(texFile, function() {
	            console.log("texture loaded", texFile);
	        });
	        const textureLoader2 = new TextureLoader();
	        const displaceTexture = textureLoader2.load(displacementMapUrl, function() {
	            console.log("displaceTexture loaded", displacementMapUrl);
	        });

	        const uniforms = {
	            uTime: new Uniform(0),
	            uVolume: new Uniform(0),
	            uTexture: { value: texture },
	            uDisplacement: { value: displaceTexture },
	            uTextureSize: {value: new Vector2(1024, 1024)},
	            uPlaneResolution: {value: new Vector2(1.4, 1)}
	        };
	        
	        const material = new ShaderMaterial({
	            color,
	            wireframe: false,
	            
	            side: DoubleSide,
	            fragmentShader: fragment$m,
	            vertexShader: vertex$m,
	            uniforms,    
	        });

	        return material
	    }

	    tick(context) {
	        if (context) {
	            if (this.updateMaterials) {
	                //this.bgMaterial.tick(context)
	                this.updateMaterials(context);
	            }
	            //console.log("lockscreen tick", context.clock.time)
	        }
	        
	    }


	}

	function circle() {
	    return /* glsl */`
        float circle(vec2 uv, vec2 center, float radius) {
            float d = length(uv - center) - radius;
            //d = step(0., d);
            d = smoothstep(0.0, radius, d);
            return d;
        }
    `
	}


	// line segment
	function line() {
	    return /* glsl */`
        float line(vec2 p, vec2 a, vec2 b, float thickness) {
            vec2 pa = p - a;
            vec2 ba = b - a;

            float h = clamp( dot(pa, ba) / dot(ba, ba), 0.0, 1.0 );
            float l = length(pa - (ba * h));

            return smoothstep(0.0, thickness, l);
        }
    `
	}

	function rsquare() {

	    return /* glsl */`
        float rsquare(vec2 uv, vec2 center, float size, float thickness) {

            float l = line(uv, vec2(0.1, 0.1), vec2(0.5, 0.5), 0.05);

            return l;

//            float strength = step(size, max(abs(uv.x - center.x - thickness/2.0), abs(uv.y - center.y)));
//            strength *= 1.0 - step(size + thickness, max(abs(uv.x - center.x - thickness/2.0), abs(uv.y - center.y)));
//            return strength;
        }    
    `

	}


	function dots() {
	    return /* glsl */`
        float dots(vec2 uv, float thickness, float lineCount) {
            float strength = step(1.0 - thickness, mod(uv.x * lineCount, 1.0));
            strength *= step(1.0 - thickness, mod(uv.y * lineCount, 1.0));
            return strength;
        }
    `
	}


	function square() {

	    return /* glsl */`
        float square(vec2 uv, vec2 center, float size, float thickness) {
            float strength = step(size, max(abs(uv.x - center.x - thickness/2.0), abs(uv.y - center.y)));
            strength *= 1.0 - step(size + thickness, max(abs(uv.x - center.x - thickness/2.0), abs(uv.y - center.y)));
            return strength;
        }    
    `

	}

	const vertexShader$2 = /* glsl */`
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;

varying vec2 vUv;
varying vec4 vPos;


void main() { 
    vUv = uv;
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);

    vPos = gl_Position;
}   
  `;








	const uiShader = /* glsl */`
${defs}

const int count = 100;

const vec3 red = vec3(1.0, 0.0, 0.0);
const vec3 blue = vec3(0.0, 0.0, 1.0);

uniform sampler2D uTexture;
uniform vec2 uTextureSize;

uniform float uTime;
uniform vec2 uResolution;

uniform vec3 uBaseColor;
uniform vec3 uBarColor;
uniform vec3 uPeakColor;

varying vec2 vUv;
varying vec4 vPos;

${dots()}
${circle()}
${line()}
${square()}
${rsquare()}

float SMOOTH(float r, float R) {
    return 1.0 - smoothstep(R-1.0, R+1.0, r);
}

void main()	{

    vec2 uv = vUv;
    vec2 center = vec2(0.5, 0.5);
    vec2 leftBottom = vec2(0.01, 0.1);

    float time = uTime * 1.0;

    float border = 0.005;
    float bg = dots(uv + vec2(0.04 * time, 0.04), 0.08, 11.0) ; // grid
    bg += square(uv, vec2(0.5 - border / 2.0, 0.5), 0.5 - border / 2.0, border); // outerbox
    
    // meters
    float lines = 1.;
    lines *= line(uv, vec2(0.0, 0.210 ), vec2(1.0, 0.210), 0.002); // line above meters
    lines *= line(uv, vec2(0.0, 0.175 ), vec2(1.0, 0.175), 0.002); // line below meters
	
    // 
    vec3 finalColor = vec3(0.0);

    finalColor += vec3(1. - lines) * uBaseColor;
    finalColor += bg * uBaseColor;

    float alpha = finalColor.r + finalColor.g + finalColor.b;
    if (alpha > 0.0) {
        alpha = 1.0;
    }
    
    gl_FragColor =  vec4(finalColor, alpha);
    #include <tonemapping_fragment>
    #include <colorspace_fragment>
}
`;





	const spectrumShader = /* glsl */`
${defs}

const int count = 100;

const vec3 red = vec3(1.0, 0.0, 0.0);
const vec3 blue = vec3(0.0, 0.0, 1.0);

uniform float uTime;
uniform vec2 uResolution;

uniform float uPeaks[count];
uniform float uData[count];

uniform float uPeaksTimeData[count / 2];

uniform float uAvg;
uniform float uPeakAvg;

uniform float uParticleSize;
uniform float uHeight;

uniform vec3 uBaseColor;
uniform vec3 uBarColor;
uniform vec3 uPeakColor;

varying vec2 vUv;
varying vec4 vPos;

${circle()}
${line()}


void main()	{
    vec2 uv = vUv;
    vec2 center = vec2(0.5, 0.5);
    float avg = uAvg * 2.0;
    float pavg = uPeakAvg * 2.0;

    float time = uTime * 1.0;

    // float d = circle(uv, vec2(0.7, 0.7), 0.03);

    float radius = uParticleSize;
    
    float data = 1.;
    float peak = 1.;
    float peakTime = 1.;
    
    for(int i = 0; i<count; i++) {

        float p = uPeaks[i];
        float a = uData[i];

        float d = circle(uv, vec2(float(i) / float(count), p * uHeight), radius);
        float aD = circle(uv, vec2(float(i) / float(count), a * uHeight), radius);

        data *= aD;
        peak *= d;
    }

    for(int i = 0; i<count / 2; i++) {
        float pT = uPeaksTimeData[i];
        float c = circle(uv, vec2(float(i) / float(count / 2), pT * 0.3 + 0.22), radius * 1.1);
        peakTime *= c;
    }

    for(int i = 0; i<count / 4; i++) {
        float a = uData[i];
        float aD = circle(uv, vec2(float(i) / float(count / 4), 0.22 - (a * uHeight + 0.1)), radius * 2.0);
        peakTime *= aD;
    }

    // meters
    float redlines = 1.;
    float bluelines = 1.;
    
    redlines *= line(uv, vec2(0.0, 0.200), vec2(pavg, 0.200), 0.005);
    bluelines *= line(uv, vec2(0.0, 0.185), vec2(avg, 0.185), 0.005);
	
    // 
    vec3 finalColor = vec3(0.0);
    finalColor = vec3(1. - data) * uBarColor;
    finalColor += vec3(1. - peak) * uPeakColor;

    finalColor += vec3(1. - peak) * uPeakColor;

    finalColor += vec3(1. - redlines) * uPeakColor;
    finalColor += vec3(1. - bluelines) * uBarColor;

    finalColor += vec3(1. - peakTime) * uBarColor;

    float alpha = finalColor.r + finalColor.g + finalColor.b;

    gl_FragColor =  vec4(finalColor, alpha);
    #include <tonemapping_fragment>
    #include <colorspace_fragment>
}
`;





	function spectrum(params, program) {

	    const { context} = program;

	    const { 
	            width = 1,
	            height = 1,
	            texture: gradient = [
	                { image: { stops: [
	                    { color: { hex: '777777' } },
	                    { color: { hex: '999999' } },
	                    { color: { hex: '333333' } }
	                ] } }
	            ] 
	        } = params;


	    const colorStops = gradient[0]?.image?.stops.map((stop) => {
	        const hex = stop.color.hex || 'FFFFFF';
	        return new Color(`#${hex}`);
	    });

	    const peaksOverTime = Array(50).fill(0).map((k, i) => Math.random());

	    const geometry = new PlaneGeometry(1, 1, 1);
	    const uniforms = {
	            uTime: { value: 0 },
	            uData: new Uniform(context.analyser.data),
	            uPeaks: new Uniform(context.analyser.peaks),
	            uPeakAvg: new Uniform(context.analyser.peaks.avg),
	            uAvg: new Uniform(context.analyser.data.avg),

	            uPeaksTimeData: new Uniform(peaksOverTime),

	            uParticleSize: new Uniform(0.002),
	            uHeight: new Uniform(0.003),
	            uPeakColor: new Uniform(colorStops[0]),
	            uBarColor: new Uniform(colorStops[1]),

	            uResolution: { value: new Vector2(width, height) },
	            uTextureSize: { value: new Vector2(100, 100) },
	        };
	        
	        const material = new ShaderMaterial({
	                    
	                    fragmentShader: spectrumShader,
	                    vertexShader: vertexShader$2,
	                    uniforms,
	                    depthTest: true,
	                    depthWrite: false,
	                    transparent: true,
	                    
	        });

	    const mesh = new Mesh(geometry, material);

	    const tick = (context) => {
	        const { time } = context.clock;
	        const { analyser } = context;
	        uniforms.uTime.value = time;
	        uniforms.uPeakAvg.value = analyser.peaks.avg / 100;
	        uniforms.uAvg.value = analyser.data.avg / 100;

	        const pt = uniforms.uPeaksTimeData.value;
	        pt.shift();
	        pt.push(analyser.data.avg / 100);

	    };

	    return {
	        mesh, geometry, material, tick
	    }

	}












	class ShipUI extends Shape$1 {
		getGeometry(program) {
			let plane = new PlaneGeometry(this.params.width, this.params.height, 32);
	       
			return plane
		}

	    // default mesh
	    createMesh(program) {
	        const container = new Group$1();
	        
	        console.log("SHUP UI", this.params);

	        const geometry = this.getGeometry(program);
	        const {material, uniforms} = this.getMaterial(program, geometry);

	        const mesh = new Mesh(geometry, material);


	        const spectr = spectrum(this.params, program);
	        container.add(spectr.mesh);
	        
	        container.add(mesh);


	        this.applyTransforms(container);

	//        mesh.position.x = 0;
	//        mesh.position.y = program.camera.bottom + 0.5;

	        this.tick = (context) => {

	            const { time } = context.clock;

	                uniforms.uTime.value = time;
	                //uniforms.uPeakAvg.value = analyser.peaks.avg / 100; //  get the height from config
	                //uniforms.uAvg.value = analyser.data.avg / 100;

	                spectr.tick(context);

	                //console.log("context.analyser.data.avg", analyser.data.avg, analyser.peaks.avg)
	                //console.log("lockscreen tick", context)
	            };


	        return container;
	    }

	    getMaterial(program, geometry) {

	        const { context } = program;

	        // TODO: grab all gradients in the params
	        // draw them to a canvas texture
	        const { 
	            width = 1,
	            height = 1,
	            texture: gradient = [
	                { image: { stops: [
	                    { color: { hex: '777777' } },
	                    { color: { hex: '999999' } },
	                    { color: { hex: '333333' } }
	                ] } }
	            ] 
	        } = this.params;

	        const colorStops = gradient[0]?.image?.stops.map((stop) => {
	            const hex = stop.color.hex || 'FFFFFF';
	            return new Color(`#${hex}`);
	        });



	        const color = new Color(...this.color);
	        const texFile = this.params.map;

	        const textureLoader = new TextureLoader();
	        const texture = textureLoader.load(texFile, function() {
	            // console.log("EVBAR: texture loaded")
	        });

	        const uniforms = {
	            uTexture: { value: texture },
	            uTime: { value: 0 },
	            uData: new Uniform(context.analyser.data),
	            uPeaks: new Uniform(context.analyser.peaks),
	            uPeakAvg: new Uniform(context.analyser.peaks.avg),
	            uAvg: new Uniform(context.analyser.data.avg),

	            uParticleSize: new Uniform(0.002),
	            uHeight: new Uniform(0.003),
	            uBaseColor: new Uniform(color),
	            uPeakColor: new Uniform(colorStops[0]),
	            uBarColor: new Uniform(colorStops[1]),

	            uResolution: { value: new Vector2(width, height) },
	            uTextureSize: { value: new Vector2(100, 100) },
	        };
	        
	        const material = new ShaderMaterial({
	                    color,
	                    wireframe: false,
	                    side: DoubleSide,
	                    fragmentShader: uiShader,
	                    vertexShader: vertexShader$2,
	                    uniforms,
	                    transparent: true,
	                    depthTest: true,
	                    depthWrite: false,
	                    //blending: THREE.NoBlending,
	                    
	            });

	        return {material, uniforms}
	    }

	   

	}

	const vertexShader$3 = /* wgsl */`
uniform float uTime;
uniform float uBigWavesElevation;
uniform vec2 uBigWavesFrequency;
uniform float uBigWavesSpeed;

uniform float uSmallWavesElevation;
uniform float uSmallWavesFrequency;
uniform float uSmallWavesSpeed;
uniform float uSmallIterations;

varying float vElevation;

// Classic Perlin 3D Noise 
// by Stefan Gustavson
//
vec4 permute(vec4 x)
{
    return mod(((x*34.0)+1.0)*x, 289.0);
}
vec4 taylorInvSqrt(vec4 r)
{
    return 1.79284291400159 - 0.85373472095314 * r;
}
vec3 fade(vec3 t)
{
    return t*t*t*(t*(t*6.0-15.0)+10.0);
}

float cnoise(vec3 P)
{
    vec3 Pi0 = floor(P); // Integer part for indexing
    vec3 Pi1 = Pi0 + vec3(1.0); // Integer part + 1
    Pi0 = mod(Pi0, 289.0);
    Pi1 = mod(Pi1, 289.0);
    vec3 Pf0 = fract(P); // Fractional part for interpolation
    vec3 Pf1 = Pf0 - vec3(1.0); // Fractional part - 1.0
    vec4 ix = vec4(Pi0.x, Pi1.x, Pi0.x, Pi1.x);
    vec4 iy = vec4(Pi0.yy, Pi1.yy);
    vec4 iz0 = Pi0.zzzz;
    vec4 iz1 = Pi1.zzzz;

    vec4 ixy = permute(permute(ix) + iy);
    vec4 ixy0 = permute(ixy + iz0);
    vec4 ixy1 = permute(ixy + iz1);

    vec4 gx0 = ixy0 / 7.0;
    vec4 gy0 = fract(floor(gx0) / 7.0) - 0.5;
    gx0 = fract(gx0);
    vec4 gz0 = vec4(0.5) - abs(gx0) - abs(gy0);
    vec4 sz0 = step(gz0, vec4(0.0));
    gx0 -= sz0 * (step(0.0, gx0) - 0.5);
    gy0 -= sz0 * (step(0.0, gy0) - 0.5);

    vec4 gx1 = ixy1 / 7.0;
    vec4 gy1 = fract(floor(gx1) / 7.0) - 0.5;
    gx1 = fract(gx1);
    vec4 gz1 = vec4(0.5) - abs(gx1) - abs(gy1);
    vec4 sz1 = step(gz1, vec4(0.0));
    gx1 -= sz1 * (step(0.0, gx1) - 0.5);
    gy1 -= sz1 * (step(0.0, gy1) - 0.5);

    vec3 g000 = vec3(gx0.x,gy0.x,gz0.x);
    vec3 g100 = vec3(gx0.y,gy0.y,gz0.y);
    vec3 g010 = vec3(gx0.z,gy0.z,gz0.z);
    vec3 g110 = vec3(gx0.w,gy0.w,gz0.w);
    vec3 g001 = vec3(gx1.x,gy1.x,gz1.x);
    vec3 g101 = vec3(gx1.y,gy1.y,gz1.y);
    vec3 g011 = vec3(gx1.z,gy1.z,gz1.z);
    vec3 g111 = vec3(gx1.w,gy1.w,gz1.w);

    vec4 norm0 = taylorInvSqrt(vec4(dot(g000, g000), dot(g010, g010), dot(g100, g100), dot(g110, g110)));
    g000 *= norm0.x;
    g010 *= norm0.y;
    g100 *= norm0.z;
    g110 *= norm0.w;
    vec4 norm1 = taylorInvSqrt(vec4(dot(g001, g001), dot(g011, g011), dot(g101, g101), dot(g111, g111)));
    g001 *= norm1.x;
    g011 *= norm1.y;
    g101 *= norm1.z;
    g111 *= norm1.w;

    float n000 = dot(g000, Pf0);
    float n100 = dot(g100, vec3(Pf1.x, Pf0.yz));
    float n010 = dot(g010, vec3(Pf0.x, Pf1.y, Pf0.z));
    float n110 = dot(g110, vec3(Pf1.xy, Pf0.z));
    float n001 = dot(g001, vec3(Pf0.xy, Pf1.z));
    float n101 = dot(g101, vec3(Pf1.x, Pf0.y, Pf1.z));
    float n011 = dot(g011, vec3(Pf0.x, Pf1.yz));
    float n111 = dot(g111, Pf1);

    vec3 fade_xyz = fade(Pf0);
    vec4 n_z = mix(vec4(n000, n100, n010, n110), vec4(n001, n101, n011, n111), fade_xyz.z);
    vec2 n_yz = mix(n_z.xy, n_z.zw, fade_xyz.y);
    float n_xyz = mix(n_yz.x, n_yz.y, fade_xyz.x); 
    return 2.2 * n_xyz;
}

void main()
{
    vec4 modelPosition = modelMatrix * vec4(position, 1.0);

    // Elevation
    float elevation = sin(modelPosition.x * uBigWavesFrequency.x + uTime * uBigWavesSpeed) *
                      sin(modelPosition.y * uBigWavesFrequency.y + uTime * uBigWavesSpeed) *
                      uBigWavesElevation;

    for(float i = 1.0; i <= uSmallIterations; i++)
    {
        elevation -= abs(cnoise(vec3(modelPosition.xy * uSmallWavesFrequency * i, uTime * uSmallWavesSpeed)) * uSmallWavesElevation / i);
    }
    
    modelPosition.z += elevation;

    vec4 viewPosition = viewMatrix * modelPosition;
    vec4 projectedPosition = projectionMatrix * viewPosition;
    gl_Position = projectedPosition;

    vElevation = elevation;
}
`;



	const fragmentShader$2 = /* wgsl */`
uniform vec3 uDepthColor;
uniform vec3 uSurfaceColor;
uniform float uColorOffset;
uniform float uColorMultiplier;

varying float vElevation;

void main()
{
    float mixStrength = (vElevation + uColorOffset) * uColorMultiplier;
    vec3 color = mix(uDepthColor, uSurfaceColor, mixStrength);
    
    gl_FragColor = vec4(color, 1.0);
    #include <colorspace_fragment>
}
`;




	function ragingSea(params, program) {

	    console.log("ragingSea params", params);

	    const {
	        width = 2, 
	        height = 2,
	        widthSegments = 1024,
	        heightSegments = 1024,

	        innercolor = {
	            hex: 'A7D0F9'
	        },
	        outercolor = {
	            hex: 'C7DEF9'
	        }

	    } = params;



	    const uniforms = {
	            uTime: new Uniform(0),
	            
	            uElevation: new Uniform(0.8),
	            uFrequency: new Uniform(new Vector2(2.2, 1.4)),
	            uSpeed: new Uniform(new Vector2(0.5, 0.7)),

	            uSurfaceColor: new Uniform(new Color(`#${outercolor.hex}`)),
	            uDepthColor: new Uniform(new Color(`#${innercolor.hex}`)),

	            uColorMultiplier: new Uniform(5),
	            uColorOffset: new Uniform(0.08),

	            uResolution: new Uniform(new Vector2(14, 14)),
	        
	            uBigWavesElevation: { value: 0.2 },
	            uBigWavesFrequency: { value: new Vector2(1, 3.5) },
	            uBigWavesSpeed: { value: 1.75 },

	            uSmallWavesElevation: { value: 0.15 },
	            uSmallWavesFrequency: { value: 3 },
	            uSmallWavesSpeed: { value: 0.2 },
	            uSmallIterations: { value: 4 },
	            
	    };


	    const geometry = new PlaneGeometry(width, height, widthSegments, heightSegments);
	    //geometry.scale(1, 1, 1)

	    const material = new ShaderMaterial({
	            //wireframe: params.materialRendering === 'wireframe',
	            transparent: false,
	            wireframe: false,
	            //side: THREE.DoubleSide,
	            fragmentShader: fragmentShader$2,
	           
	            vertexShader: vertexShader$3,
	            //depthTest: false,
	            uniforms,
	    });


	    const mesh = new Mesh(geometry, material);

	    const tick = (context) => {

	        const { clock, cursor } = context;
	        uniforms.uTime.value = clock.time;
	    };


	    return { mesh, geometry, material, tick, uniforms }
	}

	const vertex$n = /* glsl */`
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;
varying vec2 vUv;

void main() { 
    vUv = uv;
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}   
  `;

	const fragment$n = /* glsl */`
varying vec2 vUv;

uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;


vec2 calcUV(vec2 uv, vec2 texureSize, vec2 planesize){
	// vec2 tempUV = (uv - vec2(.5)) * 2.;
	vec2 tempUV = uv - vec2(.5);

	float planeAspect = uPlaneResolution.x / uPlaneResolution.y;
	float texAspect = uTextureSize.x / uTextureSize.y;

	if (planeAspect < texAspect) {
		tempUV = tempUV * vec2(planeAspect / texAspect, 1.);
	} else {
		tempUV = tempUV * vec2(1., texAspect/planeAspect);
	}

	tempUV += vec2(0.5);
	return tempUV;
}


void main()	{

	//vec2 scaledUV = calcUV(vUv, uTextureSize, uPlaneResolution);

    vec2 tempUV = (vUv - 0.5) * uTextureSize + 0.5;

	vec4 image = texture2D(uTexture, tempUV);
    gl_FragColor = image; // vec4(image, 1.0);

    //gl_FragColor =  vec4(vUv, 1.0, 1.0);
    #include <tonemapping_fragment>
    #include <colorspace_fragment>

}
`;



	function createCanvas$1(program, params) {

	    const { context } = program;

	    const { width, height } = program.canvas;

	    const elem = document.createElement('canvas');
	    elem.classList.add("iscanvas");
	    elem.width = 512;
	    elem.height = 512;
	    elem.style.position = 'fixed';
	    elem.style.top = "0px";
	    elem.style.left = "0px";
	    elem.style.zIndex = 200;
	    //elem.style.background = "transparent";

	    //document.body.appendChild(elem)
	    const canvas = new Canvas(elem, { ratio: window.devicePixelRatio });
	    //canvas.setSize(width/2, height/2)

	    const { name = "BisonOutlined", face = {} } = params;

	    const familyName = params['font-family'];

	    const font = new FontFace(name, `url(${face.url})`, {
	        style: "normal",
	        weight: "100",
	    });

	    function maybeCall(prop) {
	        return typeof prop === 'function' ? prop(context) : prop
	    }
	   
	    function drawText(blocks) {

	        canvas.clear();
	        //canvas.ctx.fillStyle = 'yellow';
	        //canvas.ctx.fillRect(0,0,width,height)

	        blocks.forEach(({ text, props }) => {
	            //console.log("drawing block")
	            const txt = maybeCall(text);
	            const position = {};
	            position.x = maybeCall(props.position.x); 
	            position.y = maybeCall(props.position.y); 

	            props.position = position;

	            canvas.drawText(txt, props);
	        });
	    }


	    return {
	        canvas,
	        element: canvas.elem,
	        font,
	        draw: drawText,
	        async load() {
	            // load fonts
	            try {
	                await font.load();
	                document.fonts.add(font);                
	                // load other stuff 

	                console.log("FONTS LOADED",font );

	                return {
	                    canvas,
	                    element: canvas.elem,
	                    font,
	                    draw: drawText
	                }

	            } catch(e) {
	                console.error("FONT LOADING FAILED", e);
	            }   
	            
	        
	        },
	        
	    }

	    //console.log("new canvas created", canvas, context, params)
	}






	function intensityGraphMaterial(program) {

	    const vertex = /* glsl */`
        varying vec2 vUv;

        void main() { 
            vUv = uv;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }   
    `;

	    const fragment = /* glsl */`
        varying vec2 vUv;

        uniform float uTime;
        uniform sampler2D uTexture;

        void main()	{
            vec2 wavedUv = vec2(
                vUv.x + sin(vUv.y * 30.0 + uTime) * 0.1,
                vUv.y + sin(vUv.x * 30.0 + uTime) * 0.1
            );
            float strength = 1.0 - step(0.01, abs(distance(wavedUv, vec2(0.5)) - 0.25));

            gl_FragColor = vec4(vec3(strength), strength );

            //gl_FragColor =  vec4(vUv, 1.0, 1.0);
            #include <tonemapping_fragment>
            #include <colorspace_fragment>
        }
    `;


	    const uniforms = {
	        uTime: {value: 0},
	        //uTexture: { value: texture },
	    };
	    
	    const material = new ShaderMaterial({
	            wireframe: false,
	            transparent: true,
	            side: DoubleSide,
	            fragmentShader: fragment,
	            vertexShader: vertex,
	            uniforms,
	    });

	   

	    return {
	        material,
	        tick(context) {
	            uniforms.uTime.value = context.clock.time;
	        }
	    }
	}











	function roundedPlane(w, h) {

	    const thickness = 0.075;    
	    const outerWidth = w;
	    const outerHeight = h;

	    // Create the outer rectangle shape
	    const outerShape = new Shape();
	    outerShape.moveTo(-outerWidth / 2, -outerHeight / 2);
	    outerShape.lineTo(outerWidth / 2, -outerHeight / 2);
	    outerShape.lineTo(outerWidth / 2, outerHeight / 2);
	    outerShape.lineTo(-outerWidth / 2, outerHeight / 2);
	    outerShape.lineTo(-outerWidth / 2, -outerHeight / 2); // Close the path

	    // Create the rounded rectangle hole path
	    const holePath = new Path();

	    const holeWidth = w - thickness;
	    const holeHeight = h - thickness;
	    const holeRadius = 0.1;
	    const hx = -holeWidth / 2;
	    const hy = -holeHeight / 2;

	    // Hole dimensions and radius

	    

	    /*
	    holePath.moveTo(hx, hy + holeRadius);
	    holePath.lineTo(hx, hy + holeHeight - holeRadius);
	    holePath.quadraticCurveTo(hx, hy + holeHeight, hx + holeRadius, hy + holeHeight);
	    holePath.lineTo(hx + holeWidth - holeRadius, hy + holeHeight);
	    holePath.quadraticCurveTo(hx + holeWidth, hy + holeHeight, hx + holeWidth, hy + holeHeight - holeRadius);
	    holePath.lineTo(hx + holeWidth, hy + holeRadius);
	    holePath.quadraticCurveTo(hx + holeWidth, hy, hx + holeWidth - holeRadius, hy);
	    holePath.lineTo(hx + holeRadius, hy);
	    holePath.quadraticCurveTo(hx, hy, hx, hy + holeRadius);
	    */

	    const bottomRightNotch = {
	        height: 0.2,
	        width: 1.2,
	        offset: 0.1,
	    };
	    
	    holePath.moveTo(hx, hy + holeRadius);
	    holePath.lineTo(hx, hy + holeHeight - holeRadius);
	    holePath.quadraticCurveTo(hx, hy + holeHeight, hx + holeRadius, hy + holeHeight);
	    holePath.lineTo(hx + holeWidth - holeRadius, hy + holeHeight);
	    holePath.quadraticCurveTo(hx + holeWidth, hy + holeHeight, hx + holeWidth, hy + holeHeight - holeRadius);
	    
	    // ui right edge
	    // top
	    holePath.lineTo(hx + holeWidth, hy + holeRadius + bottomRightNotch.height);
	    // bottom
	    holePath.quadraticCurveTo(hx + holeWidth, hy + holeRadius + (bottomRightNotch.height - holeRadius), 
	        hx + holeWidth - holeRadius, hy + holeRadius + (bottomRightNotch.height - holeRadius));
	    
	    // ui left edge
	    //top
	    holePath.lineTo(hx + holeWidth - bottomRightNotch.width + holeRadius,
	         hy + holeRadius + (bottomRightNotch.height - holeRadius));
	    holePath.quadraticCurveTo(hx + holeWidth - bottomRightNotch.width, hy + holeRadius + (bottomRightNotch.height - holeRadius), 
	        hx + holeWidth - bottomRightNotch.width  - bottomRightNotch.offset / 2, hy + holeRadius + (bottomRightNotch.height - holeRadius * 2));
	    

	    holePath.lineTo(hx + holeWidth  - bottomRightNotch.width - bottomRightNotch.offset / 2, hy + holeRadius);
	    holePath.quadraticCurveTo(hx + holeWidth - bottomRightNotch.width  - bottomRightNotch.offset, hy, 
	            hx + holeWidth - holeRadius - bottomRightNotch.width - bottomRightNotch.offset, hy);

	    //holePath.lineTo(hx + holeWidth, hy + holeRadius);
	    //holePath.quadraticCurveTo(hx + holeWidth, hy, hx + holeWidth - holeRadius, hy);
	    holePath.lineTo(hx + holeRadius, hy);
	    holePath.quadraticCurveTo(hx, hy, hx, hy + holeRadius);
	    

	    // Add the hole to the outer shape
	    outerShape.holes.push(holePath);
	    
	    let geometry = new ShapeGeometry( outerShape );

	    return geometry
	}




	function shipBorder(params, program) {


	    const vertex = /* glsl */`
        uniform vec2 uPlaneResolution;
        uniform vec2 uTextureSize;
        varying vec2 vUv;

        void main() { 
            vUv = uv;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }   
    `;

	    const fragment = /* glsl */`
        varying vec2 vUv;

        uniform sampler2D uTexture;
        uniform vec2 uPlaneResolution;
        uniform vec2 uTextureSize;


        vec2 calcUV(vec2 uv, vec2 texureSize, vec2 planesize){
            // vec2 tempUV = (uv - vec2(.5)) * 2.;
            vec2 tempUV = uv - vec2(.5);

            float planeAspect = uPlaneResolution.x / uPlaneResolution.y;
            float texAspect = uTextureSize.x / uTextureSize.y;

            if (planeAspect < texAspect) {
                tempUV = tempUV * vec2(planeAspect / texAspect, 1.);
            } else {
                tempUV = tempUV * vec2(1., texAspect/planeAspect);
            }

            tempUV += vec2(0.5);
            return tempUV;
        }


        void main()	{

            //vec2 scaledUV = calcUV(vUv, uTextureSize, uPlaneResolution);

            // vec2 tempUV = (vUv - 0.5) * uTextureSize + 0.5;

            // vec4 image = texture2D(uTexture, tempUV);
            // gl_FragColor = image; // vec4(image, 1.0);


            gl_FragColor = vec4(1.0, 1.0, 1.0, 1.0);
            //gl_FragColor =  vec4(vUv, 1.0, 1.0);
            #include <tonemapping_fragment>
            #include <colorspace_fragment>

        }
    `;




	    const uniforms = {
	        uTime: { value: 0 },
	        //uTexture: { value: texture },
	    };
	    

	    const material = new ShaderMaterial({                
	        wireframe: false,
	        transparent: true,
	        side: DoubleSide,
	        fragmentShader: fragment,
	        vertexShader: vertex,
	        uniforms,                
	    });


	    // TODO: get all the required info from camera or context
	    const frustumSize = 5;
	    const aspect = window.innerWidth / window.innerHeight;

	    // console.log("SHIP BORDER", renderer, camera, camera.fov, camera.aspect)

	    const container = new Group$1();

	    const geometry = roundedPlane(frustumSize * aspect, frustumSize);
	    const mesh = new Mesh(geometry, material);
	    container.add(mesh);

	    // TODO, figure out a way to hook these up to the 
	    // common resize handler in site or context
	    function resizeHandler() {
	        const aspect = window.innerWidth / window.innerHeight;
	        mesh.geometry.dispose();
	        mesh.geometry = roundedPlane(frustumSize * aspect, frustumSize);
	    }
	    window.addEventListener('resize', resizeHandler, false);  


	    return {
	        material, mesh: container, geometry,
	        tick(context) {
	            uniforms.uTime.value = context.clock.time;
	        }
	    }


	}



	function shipLogo(params, program) {

	    const { context } = program;

	    const logo = context.files.honeyvv.files.find(f => f.name === 'harmony-logo.png');

	    const evvlogo = context.files.honeyvv.files.find(f => f.name === 'evv-logo.png');
	    const avplogo = context.files.honeyvv.files.find(f => f.name === 'avp-logo.png');

	    const textureLoader = new TextureLoader();
	    const  texture = textureLoader.load(logo.url, function(map) {
	        //console.log("PLANE: texture loaded", texture)
	        map.colorSpace = SRGBColorSpace;
	    });

	    const  evvTexture = textureLoader.load(evvlogo.url, function(map) {
	        //console.log("PLANE: texture loaded", texture)
	        map.colorSpace = SRGBColorSpace;
	    });

	    const  avpTexture = textureLoader.load(avplogo.url, function(map) {
	        //console.log("PLANE: texture loaded", texture)
	        map.colorSpace = SRGBColorSpace;
	    });


	    const geometry = new PlaneGeometry(1.2, 1.2, 1);
	    const material = new MeshBasicMaterial({
	        map: texture,
	        transparent: true,
	        //depthTest: false,
	    });
	    const mesh = new Mesh(geometry, material);

	    const evv_geometry = new PlaneGeometry(1, 0.24, 1);
	    const evv_material = new MeshBasicMaterial({
	        map: evvTexture,
	        transparent: true
	    });
	    const evv_mesh = new Mesh(evv_geometry, evv_material);
	    evv_mesh.position.y = -1.8;


	    const avp_geometry = new PlaneGeometry(0.4, 0.4, 1);
	    const avp_material = new MeshBasicMaterial({
	        map: avpTexture,
	        transparent: true
	    });

	    const avp_mesh = new Mesh(avp_geometry, avp_material);
	    avp_mesh.position.y = -1.8;
	    avp_mesh.position.x = -0.8;

	    const group = new Group$1();

	    group.add(mesh);
	    group.add(evv_mesh);
	    group.add(avp_mesh);

	    return {
	        mesh: group
	    }

	}






	class ShipHud extends Shape$1 {
		getGeometry(program) {

			let plane = new PlaneGeometry(1, 1, 4);
	       
			return plane
		}

	    // default mesh
	    createMesh(program) {	
	        const { renderer } = program;	
	        const geometry = this.getGeometry(program);
	        const mat1 = this.getMaterial(program, geometry);
	        
	        const mesh = new Mesh(geometry, mat1.material);
	        mesh.name = 'hud';

	        const container = new Group$1();
	        container.name = 'shiphud';
	        const uiLayer = new Group$1();
	        

	        
	        //
	        uiLayer.position.x = program.camera.right - 1.5;
	        uiLayer.position.y = program.camera.bottom + 0.1;

	        //mesh.position.x = program.camera.right - 1.5;
	        //mesh.position.y = program.camera.bottom + 1.5;

	        mesh.scale.set(2, 2, 1);

	        const logo = shipLogo(this.params, program);
	        uiLayer.add(logo.mesh);

	        //logo.mesh.position.x = program.camera.right - 0.5;
	        //logo.mesh.position.y = program.camera.bottom + 1.5;

	        logo.mesh.position.y = 0.5;
	        logo.mesh.position.x = 0.5;
	        logo.mesh.scale.set(0.6, 0.6, 0.6);
	        

	        //const intensityGraph = this.drawIntensityGraph(program)
	        //container.add(intensityGraph.mesh)

	        const spectrumParams = {
	            "width": 1,
	            "height": 1,
	            "color": {
	                "h": 189,
	                "s": 54.17000000000001,
	                "l": 47.74,
	                "a": 1,
	                "hex": "38A8BC"
	            },
	            "texture": [
	                {
	                    "image": {
	                        "angle": 0,
	                        "x": 0,
	                        "y": 0,
	                        "cx": 50,
	                        "cy": 50,
	                        "radius": "farthest-corner",
	                        "shape": "circle",
	                        "stops": [
	                            {
	                                "color": {
	                                    "h": 0,
	                                    "s": 100,
	                                    "l": 66.09,
	                                    "a": 1,
	                                    "hex": "FF5252"
	                                },
	                                "at": 0
	                            },
	                            {
	                                "color": {
	                                    "h": 191,
	                                    "s": 94.34000000000002,
	                                    "l": 51.849999999999994,
	                                    "a": 1,
	                                    "hex": "10CEF8"
	                                },
	                                "at": 51.57
	                            },
	                            {
	                                "color": {
	                                    "h": 190.90909090909093,
	                                    "s": 83.32000000000001,
	                                    "l": 27.71,
	                                    "a": 1,
	                                    "hex": "0C6C82"
	                                },
	                                "at": 90.45
	                            }
	                        ],
	                        "blend": "normal",
	                        "type": "linear",
	                        "opacity": 100,
	                    },
	                    "params": {}
	                }
	            ]
	        };



	        const spectr = spectrum({
	            ...this.params,
	            ...spectrumParams
	        }, program);
	        container.add(spectr.mesh);

	        spectr.mesh.position.x = -0.11;
	        spectr.mesh.position.y = 0.2;


	        const border = shipBorder(this.params);
	        container.add(border.mesh);

	        console.log("SHIPHUD", program, program.camera);

	        uiLayer.add(mesh);
	        uiLayer.add(spectr.mesh);
	        
	        container.add(uiLayer);
	        uiLayer.position.z = 2;
	        

	        this.applyTransforms(container);

	        this.tick = (context) => {
	             if (renderer.xr.isPresenting) {
	                // in an immersive VR session.\
	                border.mesh.visible = false;

	                uiLayer.position.y = -0.5;
	                uiLayer.position.x = 3; //program.camera.right + 0.1;
	            } else {
	                // not in an immersive VR session.
	                border.mesh.visible = true;

	                uiLayer.position.x = program.camera.right - 1.0;
	                uiLayer.position.y = program.camera.bottom + 0.7;
	            } 

	            spectr.tick(context);
	            mat1.tick(context);
	            //intensityGraph.tick(context)
	        };

	        return container;
	    }





	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);

	        console.log("SHIPHUD::::::::::::::: Getmaterial", this, this.params, this.entity);
	        const texFile = this.params.map;

	        const canvas = createCanvas$1(program, this.params);

	       
	        const canvasTex = new CanvasTexture(canvas.element);
	        canvasTex.wrapS = RepeatWrapping;
	        canvasTex.wrapT = RepeatWrapping;
	        
	        let fontName = canvas.font.family;

	        let textBlocks = [];

	        function paint() {
	            //console.log("canvas paint", textBlocks)
	            
	            canvas.draw(textBlocks);
	            canvasTex.needsUpdate=true;
	        }


	        canvas.load().then((canvas) => {
	            fontName = canvas.font.family;
	            
	            const { width, height } = canvas.canvas;

	            const blackText = "#cccccc";
	            const blueText = `#1B61EE`;
	            const greenText = '#00BE7B';

	            textBlocks = [
	                {
	                    text: "0", 
	                    props: {
	                        font: `18px "${fontName}"`,
	                        textAlign: "left",
	                        color: blueText,
	                        position: {
	                            x: 80, y: height/2 -4
	                        }
	                    }
	                },
	                {
	                    text: "m l y ", 
	                    props: {
	                        font: `8px "${fontName}"`,
	                        textAlign: "left",
	                        color: blueText,
	                        position: {
	                            x: 80, y: height/2 + 6
	                        }
	                    }
	                },
	                {
	                    text: "E . 3 6 9", 
	                    props: {
	                        font: `8px "${fontName}"`,
	                        textAlign: "left",
	                        color: blackText,
	                        position: {
	                            x: 30, y: height/2 - 10
	                        }
	                    }
	                },
	                {
	                    text: "4 0 9 6 P", 
	                    props: {
	                        font: `4px "${fontName}"`,
	                        textAlign: "left",
	                        color: blackText,
	                        position: {
	                            x: 30, y: height/2 - 5
	                        }
	                    }
	                },
	                {
	                    text: "I N T N S T Y", 
	                    props: {
	                        font: `4px "${fontName}"`,
	                        textAlign: "right",
	                        color: blackText,
	                        position: {
	                            x: 30, y: height/2 + 5
	                        }
	                    }
	                },
	                {
	                    text: "20%", 
	                    props: {
	                        font: `18px "${fontName}"`,
	                        textAlign: "right",
	                        color: blackText,
	                        position: {
	                            x: 30, y: height/2 - 10
	                        }
	                    }
	                },
	                {
	                    text: "H E A R T", 
	                    props: {
	                        font: `4px "${fontName}"`,
	                        textAlign: "right",
	                        color: blackText,
	                        position: {
	                            x: 30, y: height/2 - 20
	                        }
	                    }
	                },
	                {
	                    text: "7 2 ", 
	                    props: {
	                        font: `18px "${fontName}"`,
	                        textAlign: "right",
	                        color: blackText,
	                        position: {
	                            x: 30, y: height/2 - 35
	                        }
	                    }
	                },
	                {
	                    text: "S L O W  C H A R G I N G", 
	                    props: {
	                        font: `4px "${fontName}"`,
	                        textAlign: "left",
	                        color: blackText,
	                        position: {
	                            x: 125, y: height/2 - 15
	                        }
	                    }
	                },
	                {
	                    text: "1 4 0 0 K W", 
	                    props: {
	                        font: `9px "${fontName}"`,
	                        textAlign: "left",
	                        color: greenText,
	                        position: {
	                            x: 125, y: height/2 - 5
	                        }
	                    }
	                },
	                {
	                    text: (context) => {
	                        return (2028 * Math.random()) + ""
	                    }, 
	                    props: {
	                        font: `4px "${fontName}"`,
	                        textAlign: "right",
	                        position: {
	                            x: 40, y: 20
	                        }
	                    }
	                }
	            ];

	            paint();
	        });

	        const textureLoader = new TextureLoader();
	        
	        /*
	        const texture1 = textureLoader.load(texFile, function() {
	            console.log("SHIPHUD: texture loaded")
	        })
	        */

	        
	        const texture = canvasTex;

	        //texture.magFilter = THREE.NearestFilter
	        texture.generateMipmaps = false;
	        //texture.minFilter = THREE.NearestFilter

	        const uniforms = {
	            time: new Uniform(0),
	            uTime: new Uniform(0),
	            uTexture: new Uniform(texture),
	            uTextureSize: new Uniform(new Vector2(1, 1)),
	            uPlaneResolution: new Uniform(new Vector2(2, 2))
	        };

	        
	        const material = new ShaderMaterial({
	                //color,
	                wireframe: false,
	                transparent: true,
	                alphaTest: 0.5,
	                side: FrontSide,
	                //depthTest: false,
	                vertexShader: vertex$n,
	                fragmentShader: fragment$n,
	                //blending: THREE.NormalBlending,
	                uniforms,
	                
	            });

	        return {
	            material,
	            tick(context) {
	                const { time } = context.clock;
	                const { analyser } = context;

	                
	                if (textBlocks && textBlocks.length) {
	                    // should be the average of the audio 
	                    // Math.round(Math.abs(Math.sin(time/10)) * 100) +
	                    const avg = analyser.peaks.avg;
	                    const sum = analyser.peaks.sum;
	                    const intnsty = textBlocks[5];
	                    intnsty.text =  Math.round(avg) + ' %';

	                    const charge = textBlocks[9];
	                    charge.text =  Math.round(sum * 10) + ' K W';

	                }
	                paint();
	                //console.log("shiphud tick", context)
	                 //uniforms.uTexture.value.needsUpdate = true
	            }
	        }
	    }

	    drawIntensityGraph(program) {
	        const geometry = new PlaneGeometry(1, 1, 1);
	        const mat = intensityGraphMaterial();

	        const mesh = new Mesh(geometry, mat.material);
	        mesh.name = 'intensitygraph';

	        return {
	            geometry,
	            mesh,
	            material: mat.material,
	            tick(context) {
	                mat.tick(context);
	            }
	        };
	    }

	    


	}

	const vertex$o = /* glsl */`
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;
varying vec2 vUv;

void main() { 
    vUv = uv;
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}   
  `;

	const fragment$o = /* glsl */`
varying vec2 vUv;

uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;


vec2 calcUV(vec2 uv, vec2 texureSize, vec2 planesize){
	// vec2 tempUV = (uv - vec2(.5)) * 2.;
	vec2 tempUV = uv - vec2(.5);

	float planeAspect = uPlaneResolution.x / uPlaneResolution.y;
	float texAspect = uTextureSize.x / uTextureSize.y;

	if (planeAspect < texAspect) {
		tempUV = tempUV * vec2(planeAspect / texAspect, 1.);
	} else {
		tempUV = tempUV * vec2(1., texAspect/planeAspect);
	}

	tempUV += vec2(0.5);
	return tempUV;
}


void main()	{

	vec2 scaledUV = vUv; //calcUV(vUv, uTextureSize, uPlaneResolution);

	vec4 image = texture2D(uTexture, scaledUV);
    gl_FragColor = image; // vec4(vUv, 1.0, 1.0);

    
    //gl_FragColor =  vec4(vUv, 1.0, 1.0);
    #include <tonemapping_fragment>
    #include <colorspace_fragment>

}
`;




	class EVBottomBar extends Shape$1 {
		getGeometry(program) {

			let plane = new PlaneGeometry(this.params.width, this.params.height, 32);
	       
			return plane
		}

	    // default mesh
	    createMesh(program) {		
	        const geometry = this.getGeometry(program);
	        const material = this.getMaterial(program, geometry);

	        const mesh = new Mesh(geometry, material);

	        const container = new Group$1();
	        container.add(mesh);

	        mesh.position.x = 0;
	        mesh.position.y = program.camera.bottom + 0.5;

	        return container;
	    }

	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);
	        const texFile = this.params.map;

	        const textureLoader = new TextureLoader();
	        const texture = textureLoader.load(texFile, function() {
	            console.log("EVBAR: texture loaded");
	        });

	        const uniforms = {
	            time: {value: 0},
	            uTexture: { value: texture },
	            uTextureSize: {value: new Vector2(1024, 1024)},
	            uPlaneResolution: {value: new Vector2(1.4, 1)}
	        };
	        
	        const material = new ShaderMaterial({
	                    color,
	                    wireframe: false,
	                    side: DoubleSide,
	                    fragmentShader: fragment$o,
	                    vertexShader: vertex$o,
	                    uniforms,
	                    
	            });

	        return material
	    }

	    tick(context) {
	        //console.log("lockscreen tick", context)
	    }


	}

	const vertex$p = /* glsl */`
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;
varying vec2 vUv;

void main() { 
    vUv = uv;
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}   
  `;

	const fragment$p = /* glsl */`
varying vec2 vUv;

uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;


vec2 calcUV(vec2 uv, vec2 texureSize, vec2 planesize){
	// vec2 tempUV = (uv - vec2(.5)) * 2.;
	vec2 tempUV = uv - vec2(.5);

	float planeAspect = uPlaneResolution.x / uPlaneResolution.y;
	float texAspect = uTextureSize.x / uTextureSize.y;

	if (planeAspect < texAspect) {
		tempUV = tempUV * vec2(planeAspect / texAspect, 1.);
	} else {
		tempUV = tempUV * vec2(1., texAspect/planeAspect);
	}

	tempUV += vec2(0.5);
	return tempUV;
}


void main()	{

	vec2 scaledUV = vUv; //calcUV(vUv, uTextureSize, uPlaneResolution);

	vec4 image = texture2D(uTexture, scaledUV);
    gl_FragColor = image; // vec4(vUv, 1.0, 1.0);

    
    //gl_FragColor =  vec4(vUv, 1.0, 1.0);
    #include <tonemapping_fragment>
    #include <colorspace_fragment>

}
`;













	class EVStatusBar extends Shape$1 {
		getGeometry(program) {

			let plane = new PlaneGeometry(this.params.width, this.params.height, 32);
	       
	        
			return plane
		}

	    // default mesh
	    createMesh(program) {		
	        const geometry = this.getGeometry(program);
	        const material = this.getMaterial(program, geometry);

	        const mesh = new Mesh(geometry, material);

	        const container = new Group$1();
	        container.add(mesh);

	        mesh.position.x = program.camera.right - 0.5;
	        mesh.position.y = program.camera.top - 0.5;

	        return container;
	    }


	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);
	        const texFile = this.params.map;

	        const textureLoader = new TextureLoader();
	        const texture = textureLoader.load(texFile, function() {
	            console.log("EVSTATUS: texture loaded");
	        });

	        const uniforms = {
	            time: {value: 0},
	            uTexture: {value: texture },
	            uTextureSize: {value: new Vector2(1024, 1024)},
	            uPlaneResolution: {value: new Vector2(1.4, 1)}
	        };
	        
	        const material = new ShaderMaterial({
	                    color,
	                    wireframe: false,
	                    side: DoubleSide,
	                    fragmentShader: fragment$p,
	                    vertexShader: vertex$p,
	                    uniforms,
	            });

	        return material
	    }

	    tick(context) {
	        //console.log("lockscreen tick", context)
	    }


	}

	const vertex$q = /* glsl */`
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;
varying vec2 vUv;

void main() { 
    vUv = uv;
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}   
  `;

	const fragment$q = /* glsl */`
varying vec2 vUv;

uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;


vec2 calcUV(vec2 uv, vec2 texureSize, vec2 planesize){
	// vec2 tempUV = (uv - vec2(.5)) * 2.;
	vec2 tempUV = uv - vec2(.5);

	float planeAspect = uPlaneResolution.x / uPlaneResolution.y;
	float texAspect = uTextureSize.x / uTextureSize.y;

	if (planeAspect < texAspect) {
		tempUV = tempUV * vec2(planeAspect / texAspect, 1.);
	} else {
		tempUV = tempUV * vec2(1., texAspect/planeAspect);
	}

	tempUV += vec2(0.5);
	return tempUV;
}


void main()	{

	vec2 scaledUV = vUv; //calcUV(vUv, uTextureSize, uPlaneResolution);

	vec4 image = texture2D(uTexture, scaledUV);
    gl_FragColor = image; // vec4(vUv, 1.0, 1.0);

    
    //gl_FragColor =  vec4(vUv, 1.0, 1.0);
    #include <tonemapping_fragment>
    #include <colorspace_fragment>

}
`;




	class EVBottomBar$1 extends Shape$1 {
		getGeometry(program) {
			console.log("ISLAND: geometry", this.params, program);

			let plane = new PlaneGeometry(this.params.width, this.params.height, 32);
	       
			return plane
		}

	    // default mesh
	    createMesh(program) {		
	        const geometry = this.getGeometry(program);
	        const material = this.getMaterial(program, geometry);

	        const mesh = new Mesh(geometry, material);

	        const container = new Group$1();
	        container.add(mesh);

	        mesh.position.x = 0;
	        mesh.position.y = program.camera.top - 0.5;

	        return container;
	    }

	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);
	        const texFile = this.params.map;

	        const textureLoader = new TextureLoader();
	        const texture = textureLoader.load(texFile, function() {
	            console.log("ISLAND: texture loaded");
	        });

	        const uniforms = {
	            time: {value: 0},
	            uTexture: { value: texture },
	            uTextureSize: {value: new Vector2(1024, 1024)},
	            uPlaneResolution: {value: new Vector2(1.4, 1)}
	        };
	        
	        const material = new ShaderMaterial({
	                    color,
	                    wireframe: false,
	                    side: DoubleSide,
	                    fragmentShader: fragment$q,
	                    vertexShader: vertex$q,
	                    uniforms,
	                    
	            });

	        return material
	    }

	    tick(context) {
	        //console.log("lockscreen tick", context)
	    }


	}

	var __defProp = Object.defineProperty;
	var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
	var __publicField = (obj, key, value) => {
	  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
	  return value;
	};
	function memcpy(src, srcOffset, dst, dstOffset, length) {
	  let i;
	  src = src.subarray || src.slice ? src : src.buffer;
	  dst = dst.subarray || dst.slice ? dst : dst.buffer;
	  src = srcOffset ? src.subarray ? src.subarray(srcOffset, length && srcOffset + length) : src.slice(srcOffset, length && srcOffset + length) : src;
	  if (dst.set) {
	    dst.set(src, dstOffset);
	  } else {
	    for (i = 0; i < src.length; i++)
	      dst[i + dstOffset] = src[i];
	  }
	  return dst;
	}
	function convertPoints(points) {
	  if (points instanceof Float32Array)
	    return points;
	  if (points instanceof BufferGeometry)
	    return points.getAttribute("position").array;
	  return points.map((p) => {
	    const isArray = Array.isArray(p);
	    return p instanceof Vector3 ? [p.x, p.y, p.z] : p instanceof Vector2 ? [p.x, p.y, 0] : isArray && p.length === 3 ? [p[0], p[1], p[2]] : isArray && p.length === 2 ? [p[0], p[1], 0] : p;
	  }).flat();
	}
	class MeshLineGeometry extends BufferGeometry {
	  constructor() {
	    super();
	    __publicField(this, "type", "MeshLine");
	    __publicField(this, "isMeshLine", true);
	    __publicField(this, "positions", []);
	    __publicField(this, "previous", []);
	    __publicField(this, "next", []);
	    __publicField(this, "side", []);
	    __publicField(this, "width", []);
	    __publicField(this, "indices_array", []);
	    __publicField(this, "uvs", []);
	    __publicField(this, "counters", []);
	    __publicField(this, "widthCallback", null);
	    __publicField(this, "_attributes");
	    __publicField(this, "_points", []);
	    __publicField(this, "points");
	    __publicField(this, "matrixWorld", new Matrix4());
	    Object.defineProperties(this, {
	      points: {
	        enumerable: true,
	        get() {
	          return this._points;
	        },
	        set(value) {
	          this.setPoints(value, this.widthCallback);
	        }
	      }
	    });
	  }
	  setMatrixWorld(matrixWorld) {
	    this.matrixWorld = matrixWorld;
	  }
	  setPoints(points, wcb) {
	    points = convertPoints(points);
	    this._points = points;
	    this.widthCallback = wcb != null ? wcb : null;
	    this.positions = [];
	    this.counters = [];
	    if (points.length && points[0] instanceof Vector3) {
	      for (let j = 0; j < points.length; j++) {
	        const p = points[j];
	        const c = j / (points.length - 1);
	        this.positions.push(p.x, p.y, p.z);
	        this.positions.push(p.x, p.y, p.z);
	        this.counters.push(c);
	        this.counters.push(c);
	      }
	    } else {
	      for (let j = 0; j < points.length; j += 3) {
	        const c = j / (points.length - 1);
	        this.positions.push(points[j], points[j + 1], points[j + 2]);
	        this.positions.push(points[j], points[j + 1], points[j + 2]);
	        this.counters.push(c);
	        this.counters.push(c);
	      }
	    }
	    this.process();
	  }
	  compareV3(a, b) {
	    const aa = a * 6;
	    const ab = b * 6;
	    return this.positions[aa] === this.positions[ab] && this.positions[aa + 1] === this.positions[ab + 1] && this.positions[aa + 2] === this.positions[ab + 2];
	  }
	  copyV3(a) {
	    const aa = a * 6;
	    return [this.positions[aa], this.positions[aa + 1], this.positions[aa + 2]];
	  }
	  process() {
	    const l = this.positions.length / 6;
	    this.previous = [];
	    this.next = [];
	    this.side = [];
	    this.width = [];
	    this.indices_array = [];
	    this.uvs = [];
	    let w;
	    let v;
	    if (this.compareV3(0, l - 1)) {
	      v = this.copyV3(l - 2);
	    } else {
	      v = this.copyV3(0);
	    }
	    this.previous.push(v[0], v[1], v[2]);
	    this.previous.push(v[0], v[1], v[2]);
	    for (let j = 0; j < l; j++) {
	      this.side.push(1);
	      this.side.push(-1);
	      if (this.widthCallback)
	        w = this.widthCallback(j / (l - 1));
	      else
	        w = 1;
	      this.width.push(w);
	      this.width.push(w);
	      this.uvs.push(j / (l - 1), 0);
	      this.uvs.push(j / (l - 1), 1);
	      if (j < l - 1) {
	        v = this.copyV3(j);
	        this.previous.push(v[0], v[1], v[2]);
	        this.previous.push(v[0], v[1], v[2]);
	        const n = j * 2;
	        this.indices_array.push(n, n + 1, n + 2);
	        this.indices_array.push(n + 2, n + 1, n + 3);
	      }
	      if (j > 0) {
	        v = this.copyV3(j);
	        this.next.push(v[0], v[1], v[2]);
	        this.next.push(v[0], v[1], v[2]);
	      }
	    }
	    if (this.compareV3(l - 1, 0)) {
	      v = this.copyV3(1);
	    } else {
	      v = this.copyV3(l - 1);
	    }
	    this.next.push(v[0], v[1], v[2]);
	    this.next.push(v[0], v[1], v[2]);
	    if (!this._attributes || this._attributes.position.count !== this.counters.length) {
	      this._attributes = {
	        position: new BufferAttribute(new Float32Array(this.positions), 3),
	        previous: new BufferAttribute(new Float32Array(this.previous), 3),
	        next: new BufferAttribute(new Float32Array(this.next), 3),
	        side: new BufferAttribute(new Float32Array(this.side), 1),
	        width: new BufferAttribute(new Float32Array(this.width), 1),
	        uv: new BufferAttribute(new Float32Array(this.uvs), 2),
	        index: new BufferAttribute(new Uint16Array(this.indices_array), 1),
	        counters: new BufferAttribute(new Float32Array(this.counters), 1)
	      };
	    } else {
	      this._attributes.position.copyArray(new Float32Array(this.positions));
	      this._attributes.position.needsUpdate = true;
	      this._attributes.previous.copyArray(new Float32Array(this.previous));
	      this._attributes.previous.needsUpdate = true;
	      this._attributes.next.copyArray(new Float32Array(this.next));
	      this._attributes.next.needsUpdate = true;
	      this._attributes.side.copyArray(new Float32Array(this.side));
	      this._attributes.side.needsUpdate = true;
	      this._attributes.width.copyArray(new Float32Array(this.width));
	      this._attributes.width.needsUpdate = true;
	      this._attributes.uv.copyArray(new Float32Array(this.uvs));
	      this._attributes.uv.needsUpdate = true;
	      this._attributes.index.copyArray(new Uint16Array(this.indices_array));
	      this._attributes.index.needsUpdate = true;
	    }
	    this.setAttribute("position", this._attributes.position);
	    this.setAttribute("previous", this._attributes.previous);
	    this.setAttribute("next", this._attributes.next);
	    this.setAttribute("side", this._attributes.side);
	    this.setAttribute("width", this._attributes.width);
	    this.setAttribute("uv", this._attributes.uv);
	    this.setAttribute("counters", this._attributes.counters);
	    this.setAttribute("position", this._attributes.position);
	    this.setAttribute("previous", this._attributes.previous);
	    this.setAttribute("next", this._attributes.next);
	    this.setAttribute("side", this._attributes.side);
	    this.setAttribute("width", this._attributes.width);
	    this.setAttribute("uv", this._attributes.uv);
	    this.setAttribute("counters", this._attributes.counters);
	    this.setIndex(this._attributes.index);
	    this.computeBoundingSphere();
	    this.computeBoundingBox();
	  }
	  advance({ x, y, z }) {
	    const positions = this._attributes.position.array;
	    const previous = this._attributes.previous.array;
	    const next = this._attributes.next.array;
	    const l = positions.length;
	    memcpy(positions, 0, previous, 0, l);
	    memcpy(positions, 6, positions, 0, l - 6);
	    positions[l - 6] = x;
	    positions[l - 5] = y;
	    positions[l - 4] = z;
	    positions[l - 3] = x;
	    positions[l - 2] = y;
	    positions[l - 1] = z;
	    memcpy(positions, 6, next, 0, l - 6);
	    next[l - 6] = x;
	    next[l - 5] = y;
	    next[l - 4] = z;
	    next[l - 3] = x;
	    next[l - 2] = y;
	    next[l - 1] = z;
	    this._attributes.position.needsUpdate = true;
	    this._attributes.previous.needsUpdate = true;
	    this._attributes.next.needsUpdate = true;
	  }
	}
	const vertexShader$4 = `
  #include <common>
  #include <logdepthbuf_pars_vertex>
  #include <fog_pars_vertex>
  #include <clipping_planes_pars_vertex>

  attribute vec3 previous;
  attribute vec3 next;
  attribute float side;
  attribute float width;
  attribute float counters;
  
  uniform vec2 resolution;
  uniform float lineWidth;
  uniform vec3 color;
  uniform float opacity;
  uniform float sizeAttenuation;
  
  varying vec2 vUV;
  varying vec4 vColor;
  varying float vCounters;
  
  vec2 fix(vec4 i, float aspect) {
    vec2 res = i.xy / i.w;
    res.x *= aspect;
    return res;
  }
  
  void main() {
    float aspect = resolution.x / resolution.y;
    vColor = vec4(color, opacity);
    vUV = uv;
    vCounters = counters;
  
    mat4 m = projectionMatrix * modelViewMatrix;
    vec4 finalPosition = m * vec4(position, 1.0) * aspect;
    vec4 prevPos = m * vec4(previous, 1.0);
    vec4 nextPos = m * vec4(next, 1.0);
  
    vec2 currentP = fix(finalPosition, aspect);
    vec2 prevP = fix(prevPos, aspect);
    vec2 nextP = fix(nextPos, aspect);
  
    float w = lineWidth * width;
  
    vec2 dir;
    if (nextP == currentP) dir = normalize(currentP - prevP);
    else if (prevP == currentP) dir = normalize(nextP - currentP);
    else {
      vec2 dir1 = normalize(currentP - prevP);
      vec2 dir2 = normalize(nextP - currentP);
      dir = normalize(dir1 + dir2);
  
      vec2 perp = vec2(-dir1.y, dir1.x);
      vec2 miter = vec2(-dir.y, dir.x);
      //w = clamp(w / dot(miter, perp), 0., 4. * lineWidth * width);
    }
  
    //vec2 normal = (cross(vec3(dir, 0.), vec3(0., 0., 1.))).xy;
    vec4 normal = vec4(-dir.y, dir.x, 0., 1.);
    normal.xy *= .5 * w;
    //normal *= projectionMatrix;
    if (sizeAttenuation == 0.) {
      normal.xy *= finalPosition.w;
      normal.xy /= (vec4(resolution, 0., 1.) * projectionMatrix).xy * aspect;
    }
  
    finalPosition.xy += normal.xy * side;
    gl_Position = finalPosition;
    #include <logdepthbuf_vertex>
    #include <fog_vertex>
    vec4 mvPosition = modelViewMatrix * vec4(position, 1.0);
    #include <clipping_planes_vertex>
    #include <fog_vertex>
  }
`;
	const version = /* @__PURE__ */ (() => parseInt(REVISION.replace(/\D+/g, "")))();
	const colorspace_fragment$1 = version >= 154 ? "colorspace_fragment" : "encodings_fragment";
	const fragmentShader$3 = `
  #include <fog_pars_fragment>
  #include <logdepthbuf_pars_fragment>
  #include <clipping_planes_pars_fragment>
  
  uniform sampler2D map;
  uniform sampler2D alphaMap;
  uniform float useGradient;
  uniform float useMap;
  uniform float useAlphaMap;
  uniform float useDash;
  uniform float dashArray;
  uniform float dashOffset;
  uniform float dashRatio;
  uniform float visibility;
  uniform float alphaTest;
  uniform vec2 repeat;
  uniform vec3 gradient[2];
  
  varying vec2 vUV;
  varying vec4 vColor;
  varying float vCounters;
  
  void main() {
    #include <logdepthbuf_fragment>
    vec4 diffuseColor = vColor;
    if (useGradient == 1.) diffuseColor = vec4(mix(gradient[0], gradient[1], vCounters), 1.0);
    if (useMap == 1.) diffuseColor *= texture2D(map, vUV * repeat);
    if (useAlphaMap == 1.) diffuseColor.a *= texture2D(alphaMap, vUV * repeat).a;
    if (diffuseColor.a < alphaTest) discard;
    if (useDash == 1.) diffuseColor.a *= ceil(mod(vCounters + dashOffset, dashArray) - (dashArray * dashRatio));
    diffuseColor.a *= step(vCounters, visibility);
    #include <clipping_planes_fragment>
    gl_FragColor = diffuseColor;     
    #include <fog_fragment>
    #include <tonemapping_fragment>
    #include <${colorspace_fragment$1}>
  }
`;
	class MeshLineMaterial extends ShaderMaterial {
	  constructor(parameters) {
	    super({
	      uniforms: {
	        ...UniformsLib.fog,
	        lineWidth: { value: 1 },
	        map: { value: null },
	        useMap: { value: 0 },
	        alphaMap: { value: null },
	        useAlphaMap: { value: 0 },
	        color: { value: new Color(16777215) },
	        gradient: { value: [new Color(16711680), new Color(65280)] },
	        opacity: { value: 1 },
	        resolution: { value: new Vector2(1, 1) },
	        sizeAttenuation: { value: 1 },
	        dashArray: { value: 0 },
	        dashOffset: { value: 0 },
	        dashRatio: { value: 0.5 },
	        useDash: { value: 0 },
	        useGradient: { value: 0 },
	        visibility: { value: 1 },
	        alphaTest: { value: 0 },
	        repeat: { value: new Vector2(1, 1) }
	      },
	      vertexShader: vertexShader$4,
	      fragmentShader: fragmentShader$3
	    });
	    __publicField(this, "lineWidth");
	    __publicField(this, "map");
	    __publicField(this, "useMap");
	    __publicField(this, "alphaMap");
	    __publicField(this, "useAlphaMap");
	    __publicField(this, "color");
	    __publicField(this, "gradient");
	    __publicField(this, "resolution");
	    __publicField(this, "sizeAttenuation");
	    __publicField(this, "dashArray");
	    __publicField(this, "dashOffset");
	    __publicField(this, "dashRatio");
	    __publicField(this, "useDash");
	    __publicField(this, "useGradient");
	    __publicField(this, "visibility");
	    __publicField(this, "repeat");
	    this.type = "MeshLineMaterial";
	    Object.defineProperties(this, {
	      lineWidth: {
	        enumerable: true,
	        get() {
	          return this.uniforms.lineWidth.value;
	        },
	        set(value) {
	          this.uniforms.lineWidth.value = value;
	        }
	      },
	      map: {
	        enumerable: true,
	        get() {
	          return this.uniforms.map.value;
	        },
	        set(value) {
	          this.uniforms.map.value = value;
	        }
	      },
	      useMap: {
	        enumerable: true,
	        get() {
	          return this.uniforms.useMap.value;
	        },
	        set(value) {
	          this.uniforms.useMap.value = value;
	        }
	      },
	      alphaMap: {
	        enumerable: true,
	        get() {
	          return this.uniforms.alphaMap.value;
	        },
	        set(value) {
	          this.uniforms.alphaMap.value = value;
	        }
	      },
	      useAlphaMap: {
	        enumerable: true,
	        get() {
	          return this.uniforms.useAlphaMap.value;
	        },
	        set(value) {
	          this.uniforms.useAlphaMap.value = value;
	        }
	      },
	      color: {
	        enumerable: true,
	        get() {
	          return this.uniforms.color.value;
	        },
	        set(value) {
	          this.uniforms.color.value = value;
	        }
	      },
	      gradient: {
	        enumerable: true,
	        get() {
	          return this.uniforms.gradient.value;
	        },
	        set(value) {
	          this.uniforms.gradient.value = value;
	        }
	      },
	      opacity: {
	        enumerable: true,
	        get() {
	          return this.uniforms.opacity.value;
	        },
	        set(value) {
	          this.uniforms.opacity.value = value;
	        }
	      },
	      resolution: {
	        enumerable: true,
	        get() {
	          return this.uniforms.resolution.value;
	        },
	        set(value) {
	          this.uniforms.resolution.value.copy(value);
	        }
	      },
	      sizeAttenuation: {
	        enumerable: true,
	        get() {
	          return this.uniforms.sizeAttenuation.value;
	        },
	        set(value) {
	          this.uniforms.sizeAttenuation.value = value;
	        }
	      },
	      dashArray: {
	        enumerable: true,
	        get() {
	          return this.uniforms.dashArray.value;
	        },
	        set(value) {
	          this.uniforms.dashArray.value = value;
	          this.useDash = value !== 0 ? 1 : 0;
	        }
	      },
	      dashOffset: {
	        enumerable: true,
	        get() {
	          return this.uniforms.dashOffset.value;
	        },
	        set(value) {
	          this.uniforms.dashOffset.value = value;
	        }
	      },
	      dashRatio: {
	        enumerable: true,
	        get() {
	          return this.uniforms.dashRatio.value;
	        },
	        set(value) {
	          this.uniforms.dashRatio.value = value;
	        }
	      },
	      useDash: {
	        enumerable: true,
	        get() {
	          return this.uniforms.useDash.value;
	        },
	        set(value) {
	          this.uniforms.useDash.value = value;
	        }
	      },
	      useGradient: {
	        enumerable: true,
	        get() {
	          return this.uniforms.useGradient.value;
	        },
	        set(value) {
	          this.uniforms.useGradient.value = value;
	        }
	      },
	      visibility: {
	        enumerable: true,
	        get() {
	          return this.uniforms.visibility.value;
	        },
	        set(value) {
	          this.uniforms.visibility.value = value;
	        }
	      },
	      alphaTest: {
	        enumerable: true,
	        get() {
	          return this.uniforms.alphaTest.value;
	        },
	        set(value) {
	          this.uniforms.alphaTest.value = value;
	        }
	      },
	      repeat: {
	        enumerable: true,
	        get() {
	          return this.uniforms.repeat.value;
	        },
	        set(value) {
	          this.uniforms.repeat.value.copy(value);
	        }
	      }
	    });
	    this.setValues(parameters);
	  }
	  copy(source) {
	    super.copy(source);
	    this.lineWidth = source.lineWidth;
	    this.map = source.map;
	    this.useMap = source.useMap;
	    this.alphaMap = source.alphaMap;
	    this.useAlphaMap = source.useAlphaMap;
	    this.color.copy(source.color);
	    this.gradient = source.gradient;
	    this.opacity = source.opacity;
	    this.resolution.copy(source.resolution);
	    this.sizeAttenuation = source.sizeAttenuation;
	    this.dashArray = source.dashArray;
	    this.dashOffset = source.dashOffset;
	    this.dashRatio = source.dashRatio;
	    this.useDash = source.useDash;
	    this.useGradient = source.useGradient;
	    this.visibility = source.visibility;
	    this.alphaTest = source.alphaTest;
	    this.repeat.copy(source.repeat);
	    return this;
	  }
	}

	// Vertex Shader
	const vertexShader$5 = `
  varying vec2 vUv;
  void main() {
    vUv = uv;
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
  }
`;



	const fragmentShader$4 = `
  uniform float uTime;
  uniform vec2 uResolution;
  uniform vec2 uVariant;

  varying vec2 vUv;

  float hash11(float p) {
    p = fract(p * 0.1031);
    p *= p + 33.33;
    p *= p + p;
    return fract(p);
  }

  float hash12(vec2 p) {
    vec3 p3 = fract(vec3(p.xyx) * 0.1031);
    p3 += dot(p3, p3.yzx + 33.33);
    return fract((p3.x + p3.y) * p3.z);
  }

  mat2 rotate2d(float theta) {
    float c = cos(theta);
    float s = sin(theta);
    return mat2(c, -s, s, c);
  }

  float noise(vec2 p) {
    vec2 ip = floor(p);
    vec2 fp = fract(p);
    float a = hash12(ip);
    float b = hash12(ip + vec2(1.0, 0.0));
    float c = hash12(ip + vec2(0.0, 1.0));
    float d = hash12(ip + vec2(1.0, 1.0));
    
    vec2 t = smoothstep(0.0, 1.0, fp);
    return mix(mix(a, b, t.x), mix(c, d, t.x), t.y);
  }

  float fbm(vec2 p, int octaveCount) {
    float value = 0.0;
    float amplitude = 0.5;
    for (int i = 0; i < 10; ++i) {
      if (i >= octaveCount) break;
      value += amplitude * noise(p);
      p *= rotate2d(0.45);
      p *= 2.0;
      amplitude *= 0.5;
    }
    return value;
  }

  void main() {
    // Convert from Three.js UV coordinates to Shadertoy-style coordinates
    vec2 fragCoord = vUv * uResolution;
    
    // Normalized pixel coordinates (from 0 to 1)
    vec2 uv = fragCoord / uResolution.xy;
    uv = 2.0 * uv - 1.0;
    uv.x *= uResolution.x / uResolution.y;
    uv += 2.0 * fbm(uv + 0.2 * uTime, 40) - 1.0;
    
    float dist = abs(uv.x);
    vec3 col = vec3(0.2, 0.3, 0.8) * pow(mix(0.0, 0.07, hash11(uTime)) / dist, 1.0);
    
    col = pow(col, vec3(1.0));
    
    // Calculate alpha based on the lightning intensity
    float intensity = length(col);
    float alpha = smoothstep(0.0, 1.0, intensity);
    
    // Output to screen with transparency
    gl_FragColor = vec4(col, alpha);
  }`;




	// Create lightning bolt with subdivided plane geometry
	function createLightningBolt(params = {}) {

	    const { intensity = 1.0 } = params;

	    // Three.js Shader Material Setup
	    const lightningMaterial = new ShaderMaterial({
	    uniforms: {
	            color: { value: new Color(0.6, 0.8, 1.0) },
	            intensity: new Uniform(intensity),
	            uTime: { value: 0 },
	            uVariant: new Uniform(new Vector2(Math.random(), Math.Random * 20)),
	            uResolution: { value: new Vector2(800, 600) },
	        },
	        vertexShader: vertexShader$5,
	        fragmentShader: fragmentShader$4,
	        transparent: true,
	        side: DoubleSide
	    });


	  const geometry = new PlaneGeometry(4, 4); // High subdivisions for detail
	  const lightningBolt = new Mesh(geometry, lightningMaterial);

	  lightningBolt.scale.y = 15;
	  lightningBolt.scale.x = 10;
	  
	  //lightningBolt.rotation.x = Math.PI; // Rotate to make top wider (upside-down tree)
	  
	  return {
	    lightningBolt, lightningMaterial
	   };
	}


	function lightningBolt() {
	    let rate = Math.random() * 1.6;

	    const { lightningBolt, lightningMaterial } = createLightningBolt();

	    // Animation update
	    function tick(context) {

	        const analyser = context.analyser;
	        
	        let t = 1;
	        if (analyser) {
	          t = analyser.data.avg / 300;
	        }
	        
	        lightningMaterial.uniforms.uTime.value = context.clock.time * (rate * t);
	    }


	  return {
	    mesh: lightningBolt, material: lightningMaterial, tick
	  };
	}

	function heart(params) {

	        const {
	            scale = 1
	        } = params;

	        const geometryPoints = [];
	        for (let t = 0; t <= Math.PI * 2; t += 0.01) {
	        const x = 16 * Math.pow(Math.sin(t), 3);
	        const y =
	            13 * Math.cos(t) -
	            5 * Math.cos(2 * t) -
	            2 * Math.cos(3 * t) -
	            Math.cos(4 * t);
	        
	            geometryPoints.push(new Vector3(x * scale, y * scale, 0));
	        }

	        return geometryPoints;
	}



	const SHAPES = {
	    heart
	};



	function heartShape(params, program) {

	        const { 
	            width = 20,
	            height = 20,
	            color = 'red', 
	            lineWidth = 0.1, 
	            sizeAttenuation = 2, 
	            dashArray = 1  
	        } = params;


	        console.log("HEART SHAPE", color);

	                
	        const material = new MeshLineMaterial({
	            resolution: new Vector2(width, height),
	            lineWidth,
	            color: new Color(color),
	            sizeAttenuation,
	            dashArray,
	        });

	        material.transparent = true;
	        material.depthTest = false;


	        const geometry = new MeshLineGeometry({
	            widthCallback: (p) => {
	                //const w = p * Math.random();
	                console.log(":width callback", p);
	                return p;
	            }
	        });

	        const geometryPoints = SHAPES['heart'](params);
	        //geometry.setPoints(geometryPoints);
	        geometry.setPoints(geometryPoints); // (p) => 1 - (1 - p)

	        const mesh = new Mesh(geometry, material);


	        const tick = (context) => {
	            material.dashOffset -= 0.003;
	        };
	        
	        return {
	            tick, mesh, material
	        }
	}

	class LineGraph extends Shape$1 {
		
	    // default mesh
	    createMesh(program) {
	        
	        const container = new Group$1();
	        
	        

	        const color = new Color(...this.color);

	        const shapeParams = Object.assign({ color }, this.params);

	        const heart = heartShape(shapeParams);

	        const { 
	            innercolor = { hex: 'ff5900' }, outercolor = { hex: '243dff' }, dither = 2, power = 4,
	            particle_count = 2000, branches = 3, 
	            radius = 1, particleSize = 3.1, particleSizePow = 2,
	            blending = 'normal', particleType = 'disc',
	            innerRadius = 0, outerRadius = 1, amp = 0.1, spin = 1,
	         } = this.params || {};


	         console.log(">>>>>> >>> LINEGRAPOH PARAMS", this.params, innercolor, outercolor);

	        const params = {
	            count: particle_count,
	    //        size: 0.,
	            particleType,
	            innerRadius, // particle radius
	            outerRadius, // particle radius
	            radius, // simulation field radius
	            branches,
	            spin,
	            size: particleSize,
	            sizePow: particleSizePow,
	            randomness: dither,
	            randomnessPow: power,
	            sizeAttenuation: true,
	            depthWrite: false,
	            blending,
	            //texture: 'circle_01',
	            innerColor: new Color(`#${innercolor.hex}`),
	            outerColor: new Color(`#${outercolor.hex}`),
	        };
	        
	        const galaxy = galaxyParticles(params, program);

	        container.add(galaxy.mesh);
	        container.add(heart.mesh);

	        //this.controls = true;

	        const waveparams = {
	            count: particle_count,
	    //        size: 0.,
	            length,
	            radius,
	            branches,
	            spin: -5.5,
	            spacing: 0.2,
	            size: 4,
	            randomness: dither,
	            randomnessPow: power,
	            sizeAttenuation: true,
	            depthWrite: false,
	            blending: SubtractiveBlending,
	            //texture: 'circle_01',
	            innerColor: new Color(`#${innercolor.hex}`),
	            outerColor: new Color(`#${outercolor.hex}`),
	        };
	        

	        //const waves = waveParticleShader(waveparams, program)
	        //container.add(waves.mesh);

	        this.applyTransforms(container);


	        const lightning = lightningBolt();
	            container.add(lightning.mesh);

	        const lightning2 = lightningBolt();
	            container.add(lightning2.mesh);

	        lightning2.mesh.position.x = 0;
	        lightning2.mesh.position.z = 1;


	        const aObj = {x: 0};
	        const tl = animate(aObj, {
	            x: 1000,
	            ease: 'inout(4)',
	            duration: 1500,
	            autoplay: false, 
	            onUpdate: () => {
	                //console.log("animating model x", aObj.x)
	                galaxy.mesh.rotation.y = aObj.x / 100 * -Math.PI;
	                //mesh3.rotation.z = aObj.x / 100 * -Math.PI;

	                //bgMaterial.uniforms.uFrequency.value = aObj.x / 100;
	                //bgMaterial2.uniforms.uFrequency.value = aObj.x / 100;
	            }
	        });


	    
	         this.tick = (context) => {
	            heart.tick(context);
	            galaxy.tick(context);
	            lightning.tick(context);
	            lightning2.tick(context);

	            tl.seek(context.scroll.progress * 1500);
	            

	            //waves.tick(context)

	            //plasma.tick(context)
	            //blackhole.tick(context)

	            //mesh.rotation.y += 0.1;

	            //context.analyser.data
	        };

	        // applies styles from expressions
	        this.applyStyle = (key, prop) => {
	    		
			
	        };


	        return container;
	    }


	    getMaterial(program, geometry) {

	        return 
	    }



	}

	const _box$1 = new Box3();
	const _vector = new Vector3();

	/**
	 * A series of vertex pairs, forming line segments.
	 *
	 * This is used in {@link LineSegments2} to describe the shape.
	 *
	 * @augments InstancedBufferGeometry
	 * @three_import import { LineSegmentsGeometry } from 'three/addons/lines/LineSegmentsGeometry.js';
	 */
	class LineSegmentsGeometry extends InstancedBufferGeometry {

		/**
		 * Constructs a new line segments geometry.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineSegmentsGeometry = true;

			this.type = 'LineSegmentsGeometry';

			const positions = [ - 1, 2, 0, 1, 2, 0, - 1, 1, 0, 1, 1, 0, - 1, 0, 0, 1, 0, 0, - 1, - 1, 0, 1, - 1, 0 ];
			const uvs = [ - 1, 2, 1, 2, - 1, 1, 1, 1, - 1, - 1, 1, - 1, - 1, - 2, 1, - 2 ];
			const index = [ 0, 2, 1, 2, 3, 1, 2, 4, 3, 4, 5, 3, 4, 6, 5, 6, 7, 5 ];

			this.setIndex( index );
			this.setAttribute( 'position', new Float32BufferAttribute( positions, 3 ) );
			this.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );

		}

		/**
		 * Applies the given 4x4 transformation matrix to the geometry.
		 *
		 * @param {Matrix4} matrix - The matrix to apply.
		 * @return {LineSegmentsGeometry} A reference to this instance.
		 */
		applyMatrix4( matrix ) {

			const start = this.attributes.instanceStart;
			const end = this.attributes.instanceEnd;

			if ( start !== undefined ) {

				start.applyMatrix4( matrix );

				end.applyMatrix4( matrix );

				start.needsUpdate = true;

			}

			if ( this.boundingBox !== null ) {

				this.computeBoundingBox();

			}

			if ( this.boundingSphere !== null ) {

				this.computeBoundingSphere();

			}

			return this;

		}

		/**
		 * Sets the given line positions for this geometry. The length must be a multiple of six since
		 * each line segment is defined by a start end vertex in the pattern `(xyz xyz)`.
		 *
		 * @param {Float32Array|Array<number>} array - The position data to set.
		 * @return {LineSegmentsGeometry} A reference to this geometry.
		 */
		setPositions( array ) {

			let lineSegments;

			if ( array instanceof Float32Array ) {

				lineSegments = array;

			} else if ( Array.isArray( array ) ) {

				lineSegments = new Float32Array( array );

			}

			const instanceBuffer = new InstancedInterleavedBuffer( lineSegments, 6, 1 ); // xyz, xyz

			this.setAttribute( 'instanceStart', new InterleavedBufferAttribute( instanceBuffer, 3, 0 ) ); // xyz
			this.setAttribute( 'instanceEnd', new InterleavedBufferAttribute( instanceBuffer, 3, 3 ) ); // xyz

			this.instanceCount = this.attributes.instanceStart.count;

			//

			this.computeBoundingBox();
			this.computeBoundingSphere();

			return this;

		}

		/**
		 * Sets the given line colors for this geometry. The length must be a multiple of six since
		 * each line segment is defined by a start end color in the pattern `(rgb rgb)`.
		 *
		 * @param {Float32Array|Array<number>} array - The position data to set.
		 * @return {LineSegmentsGeometry} A reference to this geometry.
		 */
		setColors( array ) {

			let colors;

			if ( array instanceof Float32Array ) {

				colors = array;

			} else if ( Array.isArray( array ) ) {

				colors = new Float32Array( array );

			}

			const instanceColorBuffer = new InstancedInterleavedBuffer( colors, 6, 1 ); // rgb, rgb

			this.setAttribute( 'instanceColorStart', new InterleavedBufferAttribute( instanceColorBuffer, 3, 0 ) ); // rgb
			this.setAttribute( 'instanceColorEnd', new InterleavedBufferAttribute( instanceColorBuffer, 3, 3 ) ); // rgb

			return this;

		}

		/**
		 * Setups this line segments geometry from the given wireframe geometry.
		 *
		 * @param {WireframeGeometry} geometry - The geometry that should be used as a data source for this geometry.
		 * @return {LineSegmentsGeometry} A reference to this geometry.
		 */
		fromWireframeGeometry( geometry ) {

			this.setPositions( geometry.attributes.position.array );

			return this;

		}

		/**
		 * Setups this line segments geometry from the given edges geometry.
		 *
		 * @param {EdgesGeometry} geometry - The geometry that should be used as a data source for this geometry.
		 * @return {LineSegmentsGeometry} A reference to this geometry.
		 */
		fromEdgesGeometry( geometry ) {

			this.setPositions( geometry.attributes.position.array );

			return this;

		}

		/**
		 * Setups this line segments geometry from the given mesh.
		 *
		 * @param {Mesh} mesh - The mesh geometry that should be used as a data source for this geometry.
		 * @return {LineSegmentsGeometry} A reference to this geometry.
		 */
		fromMesh( mesh ) {

			this.fromWireframeGeometry( new WireframeGeometry( mesh.geometry ) );

			// set colors, maybe

			return this;

		}

		/**
		 * Setups this line segments geometry from the given line segments.
		 *
		 * @param {LineSegments} lineSegments - The line segments that should be used as a data source for this geometry.
		 * Assumes the source geometry is not using indices.
		 * @return {LineSegmentsGeometry} A reference to this geometry.
		 */
		fromLineSegments( lineSegments ) {

			const geometry = lineSegments.geometry;

			this.setPositions( geometry.attributes.position.array ); // assumes non-indexed

			// set colors, maybe

			return this;

		}

		computeBoundingBox() {

			if ( this.boundingBox === null ) {

				this.boundingBox = new Box3();

			}

			const start = this.attributes.instanceStart;
			const end = this.attributes.instanceEnd;

			if ( start !== undefined && end !== undefined ) {

				this.boundingBox.setFromBufferAttribute( start );

				_box$1.setFromBufferAttribute( end );

				this.boundingBox.union( _box$1 );

			}

		}

		computeBoundingSphere() {

			if ( this.boundingSphere === null ) {

				this.boundingSphere = new Sphere();

			}

			if ( this.boundingBox === null ) {

				this.computeBoundingBox();

			}

			const start = this.attributes.instanceStart;
			const end = this.attributes.instanceEnd;

			if ( start !== undefined && end !== undefined ) {

				const center = this.boundingSphere.center;

				this.boundingBox.getCenter( center );

				let maxRadiusSq = 0;

				for ( let i = 0, il = start.count; i < il; i ++ ) {

					_vector.fromBufferAttribute( start, i );
					maxRadiusSq = Math.max( maxRadiusSq, center.distanceToSquared( _vector ) );

					_vector.fromBufferAttribute( end, i );
					maxRadiusSq = Math.max( maxRadiusSq, center.distanceToSquared( _vector ) );

				}

				this.boundingSphere.radius = Math.sqrt( maxRadiusSq );

				if ( isNaN( this.boundingSphere.radius ) ) {

					console.error( 'THREE.LineSegmentsGeometry.computeBoundingSphere(): Computed radius is NaN. The instanced position data is likely to have NaN values.', this );

				}

			}

		}

		toJSON() {

			// todo

		}

	}

	UniformsLib.line = {

		worldUnits: { value: 1 },
		linewidth: { value: 1 },
		resolution: { value: new Vector2( 1, 1 ) },
		dashOffset: { value: 0 },
		dashScale: { value: 1 },
		dashSize: { value: 1 },
		gapSize: { value: 1 } // todo FIX - maybe change to totalSize

	};

	ShaderLib[ 'line' ] = {

		uniforms: UniformsUtils.merge( [
			UniformsLib.common,
			UniformsLib.fog,
			UniformsLib.line
		] ),

		vertexShader:
		/* glsl */`
		#include <common>
		#include <color_pars_vertex>
		#include <fog_pars_vertex>
		#include <logdepthbuf_pars_vertex>
		#include <clipping_planes_pars_vertex>

		uniform float linewidth;
		uniform vec2 resolution;

		attribute vec3 instanceStart;
		attribute vec3 instanceEnd;

		attribute vec3 instanceColorStart;
		attribute vec3 instanceColorEnd;

		#ifdef WORLD_UNITS

			varying vec4 worldPos;
			varying vec3 worldStart;
			varying vec3 worldEnd;

			#ifdef USE_DASH

				varying vec2 vUv;

			#endif

		#else

			varying vec2 vUv;

		#endif

		#ifdef USE_DASH

			uniform float dashScale;
			attribute float instanceDistanceStart;
			attribute float instanceDistanceEnd;
			varying float vLineDistance;

		#endif

		void trimSegment( const in vec4 start, inout vec4 end ) {

			// trim end segment so it terminates between the camera plane and the near plane

			// conservative estimate of the near plane
			float a = projectionMatrix[ 2 ][ 2 ]; // 3nd entry in 3th column
			float b = projectionMatrix[ 3 ][ 2 ]; // 3nd entry in 4th column
			float nearEstimate = - 0.5 * b / a;

			float alpha = ( nearEstimate - start.z ) / ( end.z - start.z );

			end.xyz = mix( start.xyz, end.xyz, alpha );

		}

		void main() {

			#ifdef USE_COLOR

				vColor.xyz = ( position.y < 0.5 ) ? instanceColorStart : instanceColorEnd;

			#endif

			#ifdef USE_DASH

				vLineDistance = ( position.y < 0.5 ) ? dashScale * instanceDistanceStart : dashScale * instanceDistanceEnd;
				vUv = uv;

			#endif

			float aspect = resolution.x / resolution.y;

			// camera space
			vec4 start = modelViewMatrix * vec4( instanceStart, 1.0 );
			vec4 end = modelViewMatrix * vec4( instanceEnd, 1.0 );

			#ifdef WORLD_UNITS

				worldStart = start.xyz;
				worldEnd = end.xyz;

			#else

				vUv = uv;

			#endif

			// special case for perspective projection, and segments that terminate either in, or behind, the camera plane
			// clearly the gpu firmware has a way of addressing this issue when projecting into ndc space
			// but we need to perform ndc-space calculations in the shader, so we must address this issue directly
			// perhaps there is a more elegant solution -- WestLangley

			bool perspective = ( projectionMatrix[ 2 ][ 3 ] == - 1.0 ); // 4th entry in the 3rd column

			if ( perspective ) {

				if ( start.z < 0.0 && end.z >= 0.0 ) {

					trimSegment( start, end );

				} else if ( end.z < 0.0 && start.z >= 0.0 ) {

					trimSegment( end, start );

				}

			}

			// clip space
			vec4 clipStart = projectionMatrix * start;
			vec4 clipEnd = projectionMatrix * end;

			// ndc space
			vec3 ndcStart = clipStart.xyz / clipStart.w;
			vec3 ndcEnd = clipEnd.xyz / clipEnd.w;

			// direction
			vec2 dir = ndcEnd.xy - ndcStart.xy;

			// account for clip-space aspect ratio
			dir.x *= aspect;
			dir = normalize( dir );

			#ifdef WORLD_UNITS

				vec3 worldDir = normalize( end.xyz - start.xyz );
				vec3 tmpFwd = normalize( mix( start.xyz, end.xyz, 0.5 ) );
				vec3 worldUp = normalize( cross( worldDir, tmpFwd ) );
				vec3 worldFwd = cross( worldDir, worldUp );
				worldPos = position.y < 0.5 ? start: end;

				// height offset
				float hw = linewidth * 0.5;
				worldPos.xyz += position.x < 0.0 ? hw * worldUp : - hw * worldUp;

				// don't extend the line if we're rendering dashes because we
				// won't be rendering the endcaps
				#ifndef USE_DASH

					// cap extension
					worldPos.xyz += position.y < 0.5 ? - hw * worldDir : hw * worldDir;

					// add width to the box
					worldPos.xyz += worldFwd * hw;

					// endcaps
					if ( position.y > 1.0 || position.y < 0.0 ) {

						worldPos.xyz -= worldFwd * 2.0 * hw;

					}

				#endif

				// project the worldpos
				vec4 clip = projectionMatrix * worldPos;

				// shift the depth of the projected points so the line
				// segments overlap neatly
				vec3 clipPose = ( position.y < 0.5 ) ? ndcStart : ndcEnd;
				clip.z = clipPose.z * clip.w;

			#else

				vec2 offset = vec2( dir.y, - dir.x );
				// undo aspect ratio adjustment
				dir.x /= aspect;
				offset.x /= aspect;

				// sign flip
				if ( position.x < 0.0 ) offset *= - 1.0;

				// endcaps
				if ( position.y < 0.0 ) {

					offset += - dir;

				} else if ( position.y > 1.0 ) {

					offset += dir;

				}

				// adjust for linewidth
				offset *= linewidth;

				// adjust for clip-space to screen-space conversion // maybe resolution should be based on viewport ...
				offset /= resolution.y;

				// select end
				vec4 clip = ( position.y < 0.5 ) ? clipStart : clipEnd;

				// back to clip space
				offset *= clip.w;

				clip.xy += offset;

			#endif

			gl_Position = clip;

			vec4 mvPosition = ( position.y < 0.5 ) ? start : end; // this is an approximation

			#include <logdepthbuf_vertex>
			#include <clipping_planes_vertex>
			#include <fog_vertex>

		}
		`,

		fragmentShader:
		/* glsl */`
		uniform vec3 diffuse;
		uniform float opacity;
		uniform float linewidth;

		#ifdef USE_DASH

			uniform float dashOffset;
			uniform float dashSize;
			uniform float gapSize;

		#endif

		varying float vLineDistance;

		#ifdef WORLD_UNITS

			varying vec4 worldPos;
			varying vec3 worldStart;
			varying vec3 worldEnd;

			#ifdef USE_DASH

				varying vec2 vUv;

			#endif

		#else

			varying vec2 vUv;

		#endif

		#include <common>
		#include <color_pars_fragment>
		#include <fog_pars_fragment>
		#include <logdepthbuf_pars_fragment>
		#include <clipping_planes_pars_fragment>

		vec2 closestLineToLine(vec3 p1, vec3 p2, vec3 p3, vec3 p4) {

			float mua;
			float mub;

			vec3 p13 = p1 - p3;
			vec3 p43 = p4 - p3;

			vec3 p21 = p2 - p1;

			float d1343 = dot( p13, p43 );
			float d4321 = dot( p43, p21 );
			float d1321 = dot( p13, p21 );
			float d4343 = dot( p43, p43 );
			float d2121 = dot( p21, p21 );

			float denom = d2121 * d4343 - d4321 * d4321;

			float numer = d1343 * d4321 - d1321 * d4343;

			mua = numer / denom;
			mua = clamp( mua, 0.0, 1.0 );
			mub = ( d1343 + d4321 * ( mua ) ) / d4343;
			mub = clamp( mub, 0.0, 1.0 );

			return vec2( mua, mub );

		}

		void main() {

			float alpha = opacity;
			vec4 diffuseColor = vec4( diffuse, alpha );

			#include <clipping_planes_fragment>

			#ifdef USE_DASH

				if ( vUv.y < - 1.0 || vUv.y > 1.0 ) discard; // discard endcaps

				if ( mod( vLineDistance + dashOffset, dashSize + gapSize ) > dashSize ) discard; // todo - FIX

			#endif

			#ifdef WORLD_UNITS

				// Find the closest points on the view ray and the line segment
				vec3 rayEnd = normalize( worldPos.xyz ) * 1e5;
				vec3 lineDir = worldEnd - worldStart;
				vec2 params = closestLineToLine( worldStart, worldEnd, vec3( 0.0, 0.0, 0.0 ), rayEnd );

				vec3 p1 = worldStart + lineDir * params.x;
				vec3 p2 = rayEnd * params.y;
				vec3 delta = p1 - p2;
				float len = length( delta );
				float norm = len / linewidth;

				#ifndef USE_DASH

					#ifdef USE_ALPHA_TO_COVERAGE

						float dnorm = fwidth( norm );
						alpha = 1.0 - smoothstep( 0.5 - dnorm, 0.5 + dnorm, norm );

					#else

						if ( norm > 0.5 ) {

							discard;

						}

					#endif

				#endif

			#else

				#ifdef USE_ALPHA_TO_COVERAGE

					// artifacts appear on some hardware if a derivative is taken within a conditional
					float a = vUv.x;
					float b = ( vUv.y > 0.0 ) ? vUv.y - 1.0 : vUv.y + 1.0;
					float len2 = a * a + b * b;
					float dlen = fwidth( len2 );

					if ( abs( vUv.y ) > 1.0 ) {

						alpha = 1.0 - smoothstep( 1.0 - dlen, 1.0 + dlen, len2 );

					}

				#else

					if ( abs( vUv.y ) > 1.0 ) {

						float a = vUv.x;
						float b = ( vUv.y > 0.0 ) ? vUv.y - 1.0 : vUv.y + 1.0;
						float len2 = a * a + b * b;

						if ( len2 > 1.0 ) discard;

					}

				#endif

			#endif

			#include <logdepthbuf_fragment>
			#include <color_fragment>

			gl_FragColor = vec4( diffuseColor.rgb, alpha );

			#include <tonemapping_fragment>
			#include <colorspace_fragment>
			#include <fog_fragment>
			#include <premultiplied_alpha_fragment>

		}
		`
	};

	/**
	 * A material for drawing wireframe-style geometries.
	 *
	 * Unlike {@link LineBasicMaterial}, it supports arbitrary line widths and allows using world units
	 * instead of screen space units. This material is used with {@link LineSegments2} and {@link Line2}.
	 *
	 * This module can only be used with {@link WebGLRenderer}. When using {@link WebGPURenderer},
	 * use {@link Line2NodeMaterial}.
	 *
	 * @augments ShaderMaterial
	 * @three_import import { LineMaterial } from 'three/addons/lines/LineMaterial.js';
	 */
	class LineMaterial extends ShaderMaterial {

		/**
		 * Constructs a new line segments geometry.
		 *
		 * @param {Object} [parameters] - An object with one or more properties
		 * defining the material's appearance. Any property of the material
		 * (including any property from inherited materials) can be passed
		 * in here. Color values can be passed any type of value accepted
		 * by {@link Color#set}.
		 */
		constructor( parameters ) {

			super( {

				type: 'LineMaterial',
				uniforms: UniformsUtils.clone( ShaderLib[ 'line' ].uniforms ),

				vertexShader: ShaderLib[ 'line' ].vertexShader,
				fragmentShader: ShaderLib[ 'line' ].fragmentShader,

				clipping: true // required for clipping support

			} );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineMaterial = true;

			this.setValues( parameters );

		}

		/**
		 * The material's color.
		 *
		 * @type {Color}
		 * @default (1,1,1)
		 */
		get color() {

			return this.uniforms.diffuse.value;

		}

		set color( value ) {

			this.uniforms.diffuse.value = value;

		}

		/**
		 * Whether the material's sizes (width, dash gaps) are in world units.
		 *
		 * @type {boolean}
		 * @default false
		 */
		get worldUnits() {

			return 'WORLD_UNITS' in this.defines;

		}

		set worldUnits( value ) {

			if ( value === true ) {

				this.defines.WORLD_UNITS = '';

			} else {

				delete this.defines.WORLD_UNITS;

			}

		}

		/**
		 * Controls line thickness in CSS pixel units when `worldUnits` is `false` (default),
		 * or in world units when `worldUnits` is `true`.
		 *
		 * @type {number}
		 * @default 1
		 */
		get linewidth() {

			return this.uniforms.linewidth.value;

		}

		set linewidth( value ) {

			if ( ! this.uniforms.linewidth ) return;
			this.uniforms.linewidth.value = value;

		}

		/**
		 * Whether the line is dashed, or solid.
		 *
		 * @type {boolean}
		 * @default false
		 */
		get dashed() {

			return 'USE_DASH' in this.defines;

		}

		set dashed( value ) {

			if ( ( value === true ) !== this.dashed ) {

				this.needsUpdate = true;

			}

			if ( value === true ) {

				this.defines.USE_DASH = '';

			} else {

				delete this.defines.USE_DASH;

			}

		}

		/**
		 * The scale of the dashes and gaps.
		 *
		 * @type {number}
		 * @default 1
		 */
		get dashScale() {

			return this.uniforms.dashScale.value;

		}

		set dashScale( value ) {

			this.uniforms.dashScale.value = value;

		}

		/**
		 * The size of the dash.
		 *
		 * @type {number}
		 * @default 1
		 */
		get dashSize() {

			return this.uniforms.dashSize.value;

		}

		set dashSize( value ) {

			this.uniforms.dashSize.value = value;

		}

		/**
		 * Where in the dash cycle the dash starts.
		 *
		 * @type {number}
		 * @default 0
		 */
		get dashOffset() {

			return this.uniforms.dashOffset.value;

		}

		set dashOffset( value ) {

			this.uniforms.dashOffset.value = value;

		}

		/**
		 * The size of the gap.
		 *
		 * @type {number}
		 * @default 0
		 */
		get gapSize() {

			return this.uniforms.gapSize.value;

		}

		set gapSize( value ) {

			this.uniforms.gapSize.value = value;

		}

		/**
		 * The opacity.
		 *
		 * @type {number}
		 * @default 1
		 */
		get opacity() {

			return this.uniforms.opacity.value;

		}

		set opacity( value ) {

			if ( ! this.uniforms ) return;
			this.uniforms.opacity.value = value;

		}

		/**
		 * The size of the viewport, in screen pixels. This must be kept updated to make
		 * screen-space rendering accurate.The `LineSegments2.onBeforeRender` callback
		 * performs the update for visible objects.
		 *
		 * @type {Vector2}
		 */
		get resolution() {

			return this.uniforms.resolution.value;

		}

		set resolution( value ) {

			this.uniforms.resolution.value.copy( value );

		}

		/**
		 * Whether to use alphaToCoverage or not. When enabled, this can improve the
		 * anti-aliasing of line edges when using MSAA.
		 *
		 * @type {boolean}
		 */
		get alphaToCoverage() {

			return 'USE_ALPHA_TO_COVERAGE' in this.defines;

		}

		set alphaToCoverage( value ) {

			if ( ! this.defines ) return;

			if ( ( value === true ) !== this.alphaToCoverage ) {

				this.needsUpdate = true;

			}

			if ( value === true ) {

				this.defines.USE_ALPHA_TO_COVERAGE = '';

			} else {

				delete this.defines.USE_ALPHA_TO_COVERAGE;

			}

		}

	}

	const _viewport = new Vector4();

	const _start$1 = new Vector3();
	const _end$1 = new Vector3();

	const _start4 = new Vector4();
	const _end4 = new Vector4();

	const _ssOrigin = new Vector4();
	const _ssOrigin3 = new Vector3();
	const _mvMatrix = new Matrix4();
	const _line = new Line3();
	const _closestPoint = new Vector3();

	const _box$5 = new Box3();
	const _sphere$2 = new Sphere();
	const _clipToWorldVector = new Vector4();

	let _ray$5, _lineWidth;

	// Returns the margin required to expand by in world space given the distance from the camera,
	// line width, resolution, and camera projection
	function getWorldSpaceHalfWidth( camera, distance, resolution ) {

		// transform into clip space, adjust the x and y values by the pixel width offset, then
		// transform back into world space to get world offset. Note clip space is [-1, 1] so full
		// width does not need to be halved.
		_clipToWorldVector.set( 0, 0, - distance, 1.0 ).applyMatrix4( camera.projectionMatrix );
		_clipToWorldVector.multiplyScalar( 1.0 / _clipToWorldVector.w );
		_clipToWorldVector.x = _lineWidth / resolution.width;
		_clipToWorldVector.y = _lineWidth / resolution.height;
		_clipToWorldVector.applyMatrix4( camera.projectionMatrixInverse );
		_clipToWorldVector.multiplyScalar( 1.0 / _clipToWorldVector.w );

		return Math.abs( Math.max( _clipToWorldVector.x, _clipToWorldVector.y ) );

	}

	function raycastWorldUnits( lineSegments, intersects ) {

		const matrixWorld = lineSegments.matrixWorld;
		const geometry = lineSegments.geometry;
		const instanceStart = geometry.attributes.instanceStart;
		const instanceEnd = geometry.attributes.instanceEnd;
		const segmentCount = Math.min( geometry.instanceCount, instanceStart.count );

		for ( let i = 0, l = segmentCount; i < l; i ++ ) {

			_line.start.fromBufferAttribute( instanceStart, i );
			_line.end.fromBufferAttribute( instanceEnd, i );

			_line.applyMatrix4( matrixWorld );

			const pointOnLine = new Vector3();
			const point = new Vector3();

			_ray$5.distanceSqToSegment( _line.start, _line.end, point, pointOnLine );
			const isInside = point.distanceTo( pointOnLine ) < _lineWidth * 0.5;

			if ( isInside ) {

				intersects.push( {
					point,
					pointOnLine,
					distance: _ray$5.origin.distanceTo( point ),
					object: lineSegments,
					face: null,
					faceIndex: i,
					uv: null,
					uv1: null,
				} );

			}

		}

	}

	function raycastScreenSpace( lineSegments, camera, intersects ) {

		const projectionMatrix = camera.projectionMatrix;
		const material = lineSegments.material;
		const resolution = material.resolution;
		const matrixWorld = lineSegments.matrixWorld;

		const geometry = lineSegments.geometry;
		const instanceStart = geometry.attributes.instanceStart;
		const instanceEnd = geometry.attributes.instanceEnd;
		const segmentCount = Math.min( geometry.instanceCount, instanceStart.count );

		const near = - camera.near;

		//

		// pick a point 1 unit out along the ray to avoid the ray origin
		// sitting at the camera origin which will cause "w" to be 0 when
		// applying the projection matrix.
		_ray$5.at( 1, _ssOrigin );

		// ndc space [ - 1.0, 1.0 ]
		_ssOrigin.w = 1;
		_ssOrigin.applyMatrix4( camera.matrixWorldInverse );
		_ssOrigin.applyMatrix4( projectionMatrix );
		_ssOrigin.multiplyScalar( 1 / _ssOrigin.w );

		// screen space
		_ssOrigin.x *= resolution.x / 2;
		_ssOrigin.y *= resolution.y / 2;
		_ssOrigin.z = 0;

		_ssOrigin3.copy( _ssOrigin );

		_mvMatrix.multiplyMatrices( camera.matrixWorldInverse, matrixWorld );

		for ( let i = 0, l = segmentCount; i < l; i ++ ) {

			_start4.fromBufferAttribute( instanceStart, i );
			_end4.fromBufferAttribute( instanceEnd, i );

			_start4.w = 1;
			_end4.w = 1;

			// camera space
			_start4.applyMatrix4( _mvMatrix );
			_end4.applyMatrix4( _mvMatrix );

			// skip the segment if it's entirely behind the camera
			const isBehindCameraNear = _start4.z > near && _end4.z > near;
			if ( isBehindCameraNear ) {

				continue;

			}

			// trim the segment if it extends behind camera near
			if ( _start4.z > near ) {

				const deltaDist = _start4.z - _end4.z;
				const t = ( _start4.z - near ) / deltaDist;
				_start4.lerp( _end4, t );

			} else if ( _end4.z > near ) {

				const deltaDist = _end4.z - _start4.z;
				const t = ( _end4.z - near ) / deltaDist;
				_end4.lerp( _start4, t );

			}

			// clip space
			_start4.applyMatrix4( projectionMatrix );
			_end4.applyMatrix4( projectionMatrix );

			// ndc space [ - 1.0, 1.0 ]
			_start4.multiplyScalar( 1 / _start4.w );
			_end4.multiplyScalar( 1 / _end4.w );

			// screen space
			_start4.x *= resolution.x / 2;
			_start4.y *= resolution.y / 2;

			_end4.x *= resolution.x / 2;
			_end4.y *= resolution.y / 2;

			// create 2d segment
			_line.start.copy( _start4 );
			_line.start.z = 0;

			_line.end.copy( _end4 );
			_line.end.z = 0;

			// get closest point on ray to segment
			const param = _line.closestPointToPointParameter( _ssOrigin3, true );
			_line.at( param, _closestPoint );

			// check if the intersection point is within clip space
			const zPos = MathUtils.lerp( _start4.z, _end4.z, param );
			const isInClipSpace = zPos >= - 1 && zPos <= 1;

			const isInside = _ssOrigin3.distanceTo( _closestPoint ) < _lineWidth * 0.5;

			if ( isInClipSpace && isInside ) {

				_line.start.fromBufferAttribute( instanceStart, i );
				_line.end.fromBufferAttribute( instanceEnd, i );

				_line.start.applyMatrix4( matrixWorld );
				_line.end.applyMatrix4( matrixWorld );

				const pointOnLine = new Vector3();
				const point = new Vector3();

				_ray$5.distanceSqToSegment( _line.start, _line.end, point, pointOnLine );

				intersects.push( {
					point: point,
					pointOnLine: pointOnLine,
					distance: _ray$5.origin.distanceTo( point ),
					object: lineSegments,
					face: null,
					faceIndex: i,
					uv: null,
					uv1: null,
				} );

			}

		}

	}

	/**
	 * A series of lines drawn between pairs of vertices.
	 *
	 * This adds functionality beyond {@link LineSegments}, like arbitrary line width and changing width
	 * to be in world units. {@link Line2} extends this object, forming a polyline instead of individual
	 * segments.
	 *
	 * This module can only be used with {@link WebGLRenderer}. When using {@link WebGPURenderer},
	 * import the class from `lines/webgpu/LineSegments2.js`.
	 *
	 *  ```js
	 * const geometry = new LineSegmentsGeometry();
	 * geometry.setPositions( positions );
	 * geometry.setColors( colors );
	 *
	 * const material = new LineMaterial( { linewidth: 5, vertexColors: true } };
	 *
	 * const lineSegments = new LineSegments2( geometry, material );
	 * scene.add( lineSegments );
	 * ```
	 *
	 * @augments Mesh
	 * @three_import import { LineSegments2 } from 'three/addons/lines/LineSegments2.js';
	 */
	class LineSegments2 extends Mesh {

		/**
		 * Constructs a new wide line.
		 *
		 * @param {LineSegmentsGeometry} [geometry] - The line geometry.
		 * @param {LineMaterial} [material] - The line material.
		 */
		constructor( geometry = new LineSegmentsGeometry(), material = new LineMaterial( { color: Math.random() * 0xffffff } ) ) {

			super( geometry, material );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineSegments2 = true;

			this.type = 'LineSegments2';

		}

		/**
		 * Computes an array of distance values which are necessary for rendering dashed lines.
		 * For each vertex in the geometry, the method calculates the cumulative length from the
		 * current point to the very beginning of the line.
		 *
		 * @return {LineSegments2} A reference to this instance.
		 */
		computeLineDistances() {

			// for backwards-compatibility, but could be a method of LineSegmentsGeometry...

			const geometry = this.geometry;

			const instanceStart = geometry.attributes.instanceStart;
			const instanceEnd = geometry.attributes.instanceEnd;
			const lineDistances = new Float32Array( 2 * instanceStart.count );

			for ( let i = 0, j = 0, l = instanceStart.count; i < l; i ++, j += 2 ) {

				_start$1.fromBufferAttribute( instanceStart, i );
				_end$1.fromBufferAttribute( instanceEnd, i );

				lineDistances[ j ] = ( j === 0 ) ? 0 : lineDistances[ j - 1 ];
				lineDistances[ j + 1 ] = lineDistances[ j ] + _start$1.distanceTo( _end$1 );

			}

			const instanceDistanceBuffer = new InstancedInterleavedBuffer( lineDistances, 2, 1 ); // d0, d1

			geometry.setAttribute( 'instanceDistanceStart', new InterleavedBufferAttribute( instanceDistanceBuffer, 1, 0 ) ); // d0
			geometry.setAttribute( 'instanceDistanceEnd', new InterleavedBufferAttribute( instanceDistanceBuffer, 1, 1 ) ); // d1

			return this;

		}

		/**
		 * Computes intersection points between a casted ray and this instance.
		 *
		 * @param {Raycaster} raycaster - The raycaster.
		 * @param {Array<Object>} intersects - The target array that holds the intersection points.
		 */
		raycast( raycaster, intersects ) {

			const worldUnits = this.material.worldUnits;
			const camera = raycaster.camera;

			if ( camera === null && ! worldUnits ) {

				console.error( 'LineSegments2: "Raycaster.camera" needs to be set in order to raycast against LineSegments2 while worldUnits is set to false.' );

			}

			const threshold = ( raycaster.params.Line2 !== undefined ) ? raycaster.params.Line2.threshold || 0 : 0;

			_ray$5 = raycaster.ray;

			const matrixWorld = this.matrixWorld;
			const geometry = this.geometry;
			const material = this.material;

			_lineWidth = material.linewidth + threshold;

			// check if we intersect the sphere bounds
			if ( geometry.boundingSphere === null ) {

				geometry.computeBoundingSphere();

			}

			_sphere$2.copy( geometry.boundingSphere ).applyMatrix4( matrixWorld );

			// increase the sphere bounds by the worst case line screen space width
			let sphereMargin;
			if ( worldUnits ) {

				sphereMargin = _lineWidth * 0.5;

			} else {

				const distanceToSphere = Math.max( camera.near, _sphere$2.distanceToPoint( _ray$5.origin ) );
				sphereMargin = getWorldSpaceHalfWidth( camera, distanceToSphere, material.resolution );

			}

			_sphere$2.radius += sphereMargin;

			if ( _ray$5.intersectsSphere( _sphere$2 ) === false ) {

				return;

			}

			// check if we intersect the box bounds
			if ( geometry.boundingBox === null ) {

				geometry.computeBoundingBox();

			}

			_box$5.copy( geometry.boundingBox ).applyMatrix4( matrixWorld );

			// increase the box bounds by the worst case line width
			let boxMargin;
			if ( worldUnits ) {

				boxMargin = _lineWidth * 0.5;

			} else {

				const distanceToBox = Math.max( camera.near, _box$5.distanceToPoint( _ray$5.origin ) );
				boxMargin = getWorldSpaceHalfWidth( camera, distanceToBox, material.resolution );

			}

			_box$5.expandByScalar( boxMargin );

			if ( _ray$5.intersectsBox( _box$5 ) === false ) {

				return;

			}

			if ( worldUnits ) {

				raycastWorldUnits( this, intersects );

			} else {

				raycastScreenSpace( this, camera, intersects );

			}

		}

		onBeforeRender( renderer ) {

			const uniforms = this.material.uniforms;

			if ( uniforms && uniforms.resolution ) {

				renderer.getViewport( _viewport );
				this.material.uniforms.resolution.value.set( _viewport.z, _viewport.w );

			}

		}

	}

	/**
	 * A chain of vertices, forming a polyline.
	 *
	 * This is used in {@link Line2} to describe the shape.
	 *
	 * ```js
	 * const points = [
	 * 	new THREE.Vector3( - 10, 0, 0 ),
	 * 	new THREE.Vector3( 0, 5, 0 ),
	 * 	new THREE.Vector3( 10, 0, 0 ),
	 * ];
	 *
	 * const geometry = new LineGeometry();
	 * geometry.setFromPoints( points );
	 * ```
	 *
	 * @augments LineSegmentsGeometry
	 * @three_import import { LineLineGeometry2 } from 'three/addons/lines/LineGeometry.js';
	 */
	class LineGeometry extends LineSegmentsGeometry {

		/**
		 * Constructs a new line geometry.
		 */
		constructor() {

			super();

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLineGeometry = true;

			this.type = 'LineGeometry';

		}

		/**
		 * Sets the given line positions for this geometry.
		 *
		 * @param {Float32Array|Array<number>} array - The position data to set.
		 * @return {LineGeometry} A reference to this geometry.
		 */
		setPositions( array ) {

			// converts [ x1, y1, z1,  x2, y2, z2, ... ] to pairs format

			const length = array.length - 3;
			const points = new Float32Array( 2 * length );

			for ( let i = 0; i < length; i += 3 ) {

				points[ 2 * i ] = array[ i ];
				points[ 2 * i + 1 ] = array[ i + 1 ];
				points[ 2 * i + 2 ] = array[ i + 2 ];

				points[ 2 * i + 3 ] = array[ i + 3 ];
				points[ 2 * i + 4 ] = array[ i + 4 ];
				points[ 2 * i + 5 ] = array[ i + 5 ];

			}

			super.setPositions( points );

			return this;

		}

		/**
		 * Sets the given line colors for this geometry.
		 *
		 * @param {Float32Array|Array<number>} array - The position data to set.
		 * @return {LineGeometry} A reference to this geometry.
		 */
		setColors( array ) {

			// converts [ r1, g1, b1,  r2, g2, b2, ... ] to pairs format

			const length = array.length - 3;
			const colors = new Float32Array( 2 * length );

			for ( let i = 0; i < length; i += 3 ) {

				colors[ 2 * i ] = array[ i ];
				colors[ 2 * i + 1 ] = array[ i + 1 ];
				colors[ 2 * i + 2 ] = array[ i + 2 ];

				colors[ 2 * i + 3 ] = array[ i + 3 ];
				colors[ 2 * i + 4 ] = array[ i + 4 ];
				colors[ 2 * i + 5 ] = array[ i + 5 ];

			}

			super.setColors( colors );

			return this;

		}

		/**
		 * Setups this line segments geometry from the given sequence of points.
		 *
		 * @param {Array<Vector3|Vector2>} points - An array of points in 2D or 3D space.
		 * @return {LineGeometry} A reference to this geometry.
		 */
		setFromPoints( points ) {

			// converts a vector3 or vector2 array to pairs format

			const length = points.length - 1;
			const positions = new Float32Array( 6 * length );

			for ( let i = 0; i < length; i ++ ) {

				positions[ 6 * i ] = points[ i ].x;
				positions[ 6 * i + 1 ] = points[ i ].y;
				positions[ 6 * i + 2 ] = points[ i ].z || 0;

				positions[ 6 * i + 3 ] = points[ i + 1 ].x;
				positions[ 6 * i + 4 ] = points[ i + 1 ].y;
				positions[ 6 * i + 5 ] = points[ i + 1 ].z || 0;

			}

			super.setPositions( positions );

			return this;

		}

		/**
		 * Setups this line segments geometry from the given line.
		 *
		 * @param {Line} line - The line that should be used as a data source for this geometry.
		 * @return {LineGeometry} A reference to this geometry.
		 */
		fromLine( line ) {

			const geometry = line.geometry;

			this.setPositions( geometry.attributes.position.array ); // assumes non-indexed

			// set colors, maybe

			return this;

		}

	}

	/**
	 * A polyline drawn between vertices.
	 *
	 * This adds functionality beyond {@link Line}, like arbitrary line width and changing width to
	 * be in world units.It extends {@link LineSegments2}, simplifying constructing segments from a
	 * chain of points.
	 *
	 * This module can only be used with {@link WebGLRenderer}. When using {@link WebGPURenderer},
	 * import the class from `lines/webgpu/Line2.js`.
	 *
	 * ```js
	 * const geometry = new LineGeometry();
	 * geometry.setPositions( positions );
	 * geometry.setColors( colors );
	 *
	 * const material = new LineMaterial( { linewidth: 5, vertexColors: true } };
	 *
	 * const line = new Line2( geometry, material );
	 * scene.add( line );
	 * ```
	 *
	 * @augments LineSegments2
	 * @three_import import { Line2 } from 'three/addons/lines/Line2.js';
	 */
	class Line2 extends LineSegments2 {

		/**
		 * Constructs a new wide line.
		 *
		 * @param {LineGeometry} [geometry] - The line geometry.
		 * @param {LineMaterial} [material] - The line material.
		 */
		constructor( geometry = new LineGeometry(), material = new LineMaterial( { color: Math.random() * 0xffffff } ) ) {

			super( geometry, material );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isLine2 = true;

			this.type = 'Line2';

		}

	}

	const D = (
	  /* glsl */
	  `
    
#ifdef IS_VERTEX
    vec3 csm_Position;
    vec4 csm_PositionRaw;
    vec3 csm_Normal;

    // csm_PointSize
    #ifdef IS_POINTSMATERIAL
        float csm_PointSize;
    #endif
#else
    vec4 csm_DiffuseColor;
    vec4 csm_FragColor;
    float csm_UnlitFac;

    // csm_Emissive, csm_Roughness, csm_Metalness
    #if defined IS_MESHSTANDARDMATERIAL || defined IS_MESHPHYSICALMATERIAL
        vec3 csm_Emissive;
        float csm_Roughness;
        float csm_Metalness;
        float csm_Iridescence;
        
        #if defined IS_MESHPHYSICALMATERIAL
            float csm_Clearcoat;
            float csm_ClearcoatRoughness;
            vec3 csm_ClearcoatNormal;
            float csm_Transmission;
            float csm_Thickness;
        #endif
    #endif

    // csm_AO
    #if defined IS_MESHSTANDARDMATERIAL || defined IS_MESHPHYSICALMATERIAL || defined IS_MESHBASICMATERIAL || defined IS_MESHLAMBERTMATERIAL || defined IS_MESHPHONGMATERIAL || defined IS_MESHTOONMATERIAL
        float csm_AO;
    #endif

    // csm_Bump
    #if defined IS_MESHLAMBERTMATERIAL || defined IS_MESHMATCAPMATERIAL || defined IS_MESHNORMALMATERIAL || defined IS_MESHPHONGMATERIAL || defined IS_MESHPHYSICALMATERIAL || defined IS_MESHSTANDARDMATERIAL || defined IS_MESHTOONMATERIAL || defined IS_SHADOWMATERIAL 
        vec3 csm_Bump;
        vec3 csm_FragNormal;
    #endif

    float csm_DepthAlpha;
#endif
`
	), H = (
	  /* glsl */
	  `

#ifdef IS_VERTEX
    // csm_Position & csm_PositionRaw
    #ifdef IS_UNKNOWN
        csm_Position = vec3(0.0);
        csm_PositionRaw = vec4(0.0);
        csm_Normal = vec3(0.0);
    #else
        csm_Position = position;
        csm_PositionRaw = projectionMatrix * modelViewMatrix * vec4(position, 1.);
        csm_Normal = normal;
    #endif

    // csm_PointSize
    #ifdef IS_POINTSMATERIAL
        csm_PointSize = size;
    #endif
#else
    csm_UnlitFac = 0.0;

    // csm_DiffuseColor & csm_FragColor
    #if defined IS_UNKNOWN || defined IS_SHADERMATERIAL || defined IS_MESHDEPTHMATERIAL || defined IS_MESHDISTANCEMATERIAL || defined IS_MESHNORMALMATERIAL || defined IS_SHADOWMATERIAL
        csm_DiffuseColor = vec4(1.0, 0.0, 1.0, 1.0);
        csm_FragColor = vec4(1.0, 0.0, 1.0, 1.0);
    #else
        #ifdef USE_MAP
            vec4 _csm_sampledDiffuseColor = texture2D(map, vMapUv);

            #ifdef DECODE_VIDEO_TEXTURE
            // inline sRGB decode (TODO: Remove this code when https://crbug.com/1256340 is solved)
            _csm_sampledDiffuseColor = vec4(mix(pow(_csm_sampledDiffuseColor.rgb * 0.9478672986 + vec3(0.0521327014), vec3(2.4)), _csm_sampledDiffuseColor.rgb * 0.0773993808, vec3(lessThanEqual(_csm_sampledDiffuseColor.rgb, vec3(0.04045)))), _csm_sampledDiffuseColor.w);
            #endif

            csm_DiffuseColor = vec4(diffuse, opacity) * _csm_sampledDiffuseColor;
            csm_FragColor = vec4(diffuse, opacity) * _csm_sampledDiffuseColor;
        #else
            csm_DiffuseColor = vec4(diffuse, opacity);
            csm_FragColor = vec4(diffuse, opacity);
        #endif
    #endif

    // csm_Emissive, csm_Roughness, csm_Metalness
    #if defined IS_MESHSTANDARDMATERIAL || defined IS_MESHPHYSICALMATERIAL
        csm_Emissive = emissive;
        csm_Roughness = roughness;
        csm_Metalness = metalness;

        #ifdef USE_IRIDESCENCE
            csm_Iridescence = iridescence;
        #else
            csm_Iridescence = 0.0;
        #endif

        #if defined IS_MESHPHYSICALMATERIAL
            #ifdef USE_CLEARCOAT
                csm_Clearcoat = clearcoat;
                csm_ClearcoatRoughness = clearcoatRoughness;
            #else
                csm_Clearcoat = 0.0;
                csm_ClearcoatRoughness = 0.0;
            #endif

            #ifdef USE_TRANSMISSION
                csm_Transmission = transmission;
                csm_Thickness = thickness;
            #else
                csm_Transmission = 0.0;
                csm_Thickness = 0.0;
            #endif
        #endif
    #endif

    // csm_AO
    #if defined IS_MESHSTANDARDMATERIAL || defined IS_MESHPHYSICALMATERIAL || defined IS_MESHBASICMATERIAL || defined IS_MESHLAMBERTMATERIAL || defined IS_MESHPHONGMATERIAL || defined IS_MESHTOONMATERIAL
        csm_AO = 0.0;
    #endif

    // csm_Bump
    #if defined IS_MESHLAMBERTMATERIAL || defined IS_MESHMATCAPMATERIAL || defined IS_MESHNORMALMATERIAL || defined IS_MESHPHONGMATERIAL || defined IS_MESHPHYSICALMATERIAL || defined IS_MESHSTANDARDMATERIAL || defined IS_MESHTOONMATERIAL || defined IS_SHADOWMATERIAL 
        csm_Bump = vec3(0.0);
        #ifdef FLAT_SHADED
            vec3 fdx = dFdx( vViewPosition );
            vec3 fdy = dFdy( vViewPosition );
            csm_FragNormal = normalize( cross( fdx, fdy ) );
        #else
            csm_FragNormal = normalize(vNormal);
            #ifdef DOUBLE_SIDED
                csm_FragNormal *= gl_FrontFacing ? 1.0 : - 1.0;
            #endif
        #endif
    #endif

    csm_DepthAlpha = 1.0;
#endif
`
	), y = (
	  /* glsl */
	  `
    varying mat4 csm_internal_vModelViewMatrix;
`
	), O = (
	  /* glsl */
	  `
    csm_internal_vModelViewMatrix = modelViewMatrix;
`
	), b = (
	  /* glsl */
	  `
    varying mat4 csm_internal_vModelViewMatrix;
`
	), x = (
	  /* glsl */
	  `
    
`
	), e = {
	  // PBR (frag)
	  diffuse: "csm_DiffuseColor",
	  // Color + alpha
	  roughness: "csm_Roughness",
	  // Roughness
	  metalness: "csm_Metalness",
	  // Metalness
	  emissive: "csm_Emissive",
	  // Emissive
	  ao: "csm_AO",
	  // AO
	  bump: "csm_Bump",
	  // Bump
	  fragNormal: "csm_FragNormal",
	  // Fragment Normal
	  clearcoat: "csm_Clearcoat",
	  // Clearcoat factor
	  clearcoatRoughness: "csm_ClearcoatRoughness",
	  // Clearcoat roughness
	  clearcoatNormal: "csm_ClearcoatNormal",
	  // Clearcoat normals
	  transmission: "csm_Transmission",
	  // Transmission
	  thickness: "csm_Thickness",
	  // Thickness
	  iridescence: "csm_Iridescence",
	  // Iridescence
	  // Extras
	  pointSize: "csm_PointSize",
	  // gl_PointSize (Frag)
	  fragColor: "csm_FragColor",
	  // gl_FragColor (Frag)
	  depthAlpha: "csm_DepthAlpha",
	  // Depth (MeshDepthMaterial)
	  unlitFac: "csm_UnlitFac",
	  // Unlit factor (mix between csm_FragColor and csm_DiffuseColor)
	  // Vert
	  position: "csm_Position",
	  // gl_Position
	  positionRaw: "csm_PositionRaw",
	  // gl_Position (without projection)
	  normal: "csm_Normal"
	  // Vertex Normal
	}, F = {
	  [`${e.position}`]: "*",
	  [`${e.positionRaw}`]: "*",
	  [`${e.normal}`]: "*",
	  [`${e.depthAlpha}`]: "*",
	  [`${e.pointSize}`]: ["PointsMaterial"],
	  [`${e.diffuse}`]: "*",
	  [`${e.fragColor}`]: "*",
	  [`${e.fragNormal}`]: "*",
	  [`${e.unlitFac}`]: "*",
	  [`${e.emissive}`]: ["MeshStandardMaterial", "MeshPhysicalMaterial"],
	  [`${e.roughness}`]: ["MeshStandardMaterial", "MeshPhysicalMaterial"],
	  [`${e.metalness}`]: ["MeshStandardMaterial", "MeshPhysicalMaterial"],
	  [`${e.iridescence}`]: [
	    "MeshStandardMaterial",
	    "MeshPhysicalMaterial"
	  ],
	  [`${e.ao}`]: [
	    "MeshStandardMaterial",
	    "MeshPhysicalMaterial",
	    "MeshBasicMaterial",
	    "MeshLambertMaterial",
	    "MeshPhongMaterial",
	    "MeshToonMaterial"
	  ],
	  [`${e.bump}`]: [
	    "MeshLambertMaterial",
	    "MeshMatcapMaterial",
	    "MeshNormalMaterial",
	    "MeshPhongMaterial",
	    "MeshPhysicalMaterial",
	    "MeshStandardMaterial",
	    "MeshToonMaterial",
	    "ShadowMaterial"
	  ],
	  [`${e.clearcoat}`]: ["MeshPhysicalMaterial"],
	  [`${e.clearcoatRoughness}`]: ["MeshPhysicalMaterial"],
	  [`${e.clearcoatNormal}`]: ["MeshPhysicalMaterial"],
	  [`${e.transmission}`]: ["MeshPhysicalMaterial"],
	  [`${e.thickness}`]: ["MeshPhysicalMaterial"]
	}, k = {
	  // VERT
	  "*": {
	    "#include <lights_physical_fragment>": ShaderChunk.lights_physical_fragment,
	    "#include <transmission_fragment>": ShaderChunk.transmission_fragment
	  },
	  [`${e.normal}`]: {
	    "#include <beginnormal_vertex>": `
    vec3 objectNormal = ${e.normal};
    #ifdef USE_TANGENT
	    vec3 objectTangent = vec3( tangent.xyz );
    #endif
    `
	  },
	  [`${e.position}`]: {
	    "#include <begin_vertex>": `
    vec3 transformed = ${e.position};
  `
	  },
	  [`${e.positionRaw}`]: {
	    "#include <project_vertex>": `
    #include <project_vertex>
    gl_Position = ${e.positionRaw};
  `
	  },
	  [`${e.pointSize}`]: {
	    "gl_PointSize = size;": `
    gl_PointSize = ${e.pointSize};
    `
	  },
	  // FRAG
	  [`${e.diffuse}`]: {
	    "#include <color_fragment>": `
    #include <color_fragment>
    diffuseColor = ${e.diffuse};
  `
	  },
	  [`${e.fragColor}`]: {
	    "#include <opaque_fragment>": `
    #include <opaque_fragment>
    gl_FragColor = mix(gl_FragColor, ${e.fragColor}, ${e.unlitFac});
  `
	  },
	  [`${e.emissive}`]: {
	    "vec3 totalEmissiveRadiance = emissive;": `
    vec3 totalEmissiveRadiance = ${e.emissive};
    `
	  },
	  [`${e.roughness}`]: {
	    "#include <roughnessmap_fragment>": `
    #include <roughnessmap_fragment>
    roughnessFactor = ${e.roughness};
    `
	  },
	  [`${e.metalness}`]: {
	    "#include <metalnessmap_fragment>": `
    #include <metalnessmap_fragment>
    metalnessFactor = ${e.metalness};
    `
	  },
	  [`${e.ao}`]: {
	    "#include <aomap_fragment>": `
    #include <aomap_fragment>
    reflectedLight.indirectDiffuse *= 1. - ${e.ao};
    `
	  },
	  [`${e.bump}`]: {
	    "#include <normal_fragment_maps>": `
    #include <normal_fragment_maps>

    vec3 csm_internal_orthogonal = ${e.bump} - (dot(${e.bump}, normal) * normal);
    vec3 csm_internal_projectedbump = mat3(csm_internal_vModelViewMatrix) * csm_internal_orthogonal;
    normal = normalize(normal - csm_internal_projectedbump);
    `
	  },
	  [`${e.fragNormal}`]: {
	    "#include <normal_fragment_maps>": `
      #include <normal_fragment_maps>
      normal = ${e.fragNormal};
    `
	  },
	  [`${e.depthAlpha}`]: {
	    "gl_FragColor = vec4( vec3( 1.0 - fragCoordZ ), opacity );": `
      gl_FragColor = vec4( vec3( 1.0 - fragCoordZ ), opacity * 1.0 - ${e.depthAlpha} );
    `,
	    "gl_FragColor = packDepthToRGBA( fragCoordZ );": `
      if(${e.depthAlpha} < 1.0) discard;
      gl_FragColor = packDepthToRGBA( dist );
    `,
	    "gl_FragColor = packDepthToRGBA( dist );": `
      if(${e.depthAlpha} < 1.0) discard;
      gl_FragColor = packDepthToRGBA( dist );
    `
	  },
	  [`${e.clearcoat}`]: {
	    "material.clearcoat = clearcoat;": `material.clearcoat = ${e.clearcoat};`
	  },
	  [`${e.clearcoatRoughness}`]: {
	    "material.clearcoatRoughness = clearcoatRoughness;": `material.clearcoatRoughness = ${e.clearcoatRoughness};`
	  },
	  [`${e.clearcoatNormal}`]: {
	    "#include <clearcoat_normal_fragment_begin>": `
      vec3 csm_coat_internal_orthogonal = csm_ClearcoatNormal - (dot(csm_ClearcoatNormal, nonPerturbedNormal) * nonPerturbedNormal);
      vec3 csm_coat_internal_projectedbump = mat3(csm_internal_vModelViewMatrix) * csm_coat_internal_orthogonal;
      vec3 clearcoatNormal = normalize(nonPerturbedNormal - csm_coat_internal_projectedbump);
    `
	  },
	  [`${e.transmission}`]: {
	    "material.transmission = transmission;": `
      material.transmission = ${e.transmission};
    `
	  },
	  [`${e.thickness}`]: {
	    "material.thickness = thickness;": `
      material.thickness = ${e.thickness};
    `
	  },
	  [`${e.iridescence}`]: {
	    "material.iridescence = iridescence;": `
      material.iridescence = ${e.iridescence};
    `
	  }
	}, w = {
	  clearcoat: [
	    e.clearcoat,
	    e.clearcoatNormal,
	    e.clearcoatRoughness
	  ],
	  transmission: [e.transmission],
	  iridescence: [e.iridescence]
	};
	function z(u) {
	  let i = 0;
	  for (let m = 0; m < u.length; m++)
	    i = u.charCodeAt(m) + (i << 6) + (i << 16) - i;
	  const _ = i >>> 0;
	  return String(_);
	}
	function U(u) {
	  try {
	    new u();
	  } catch (i) {
	    if (i.message.indexOf("is not a constructor") >= 0)
	      return !1;
	  }
	  return !0;
	}
	function P(u) {
	  return u.replace(/\/\*[\s\S]*?\*\/|\/\/.*/g, "");
	}
	class B extends Material {
	  constructor({
	    baseMaterial: i,
	    vertexShader: _,
	    fragmentShader: h,
	    uniforms: m,
	    patchMap: I,
	    cacheKey: M,
	    ...d
	  }) {
	    if (!i)
	      throw new Error("CustomShaderMaterial: baseMaterial is required.");
	    let s;
	    if (U(i)) {
	      const t = Object.keys(d).length === 0;
	      s = new i(t ? void 0 : d);
	    } else
	      s = i, Object.assign(s, d);
	    if (["ShaderMaterial", "RawShaderMaterial"].includes(s.type))
	      throw new Error(
	        `CustomShaderMaterial does not support ${s.type} as a base material.`
	      );
	    super(), this.uniforms = {}, this.vertexShader = "", this.fragmentShader = "";
	    const o = s;
	    o.name = `CustomShaderMaterial<${s.name || s.type}>`, o.update = this.update, o.__csm = {
	      prevOnBeforeCompile: s.onBeforeCompile,
	      baseMaterial: s,
	      vertexShader: _,
	      fragmentShader: h,
	      uniforms: m,
	      patchMap: I,
	      cacheKey: M
	    };
	    const n = { ...o.uniforms || {}, ...m || {} };
	    o.uniforms = this.uniforms = n, o.vertexShader = this.vertexShader = _ || "", o.fragmentShader = this.fragmentShader = h || "", o.update({
	      fragmentShader: o.fragmentShader,
	      vertexShader: o.vertexShader,
	      uniforms: o.uniforms,
	      patchMap: I,
	      cacheKey: M
	    }), Object.assign(this, o);
	    const f = Object.getOwnPropertyDescriptors(
	      Object.getPrototypeOf(o)
	    );
	    for (const t in f) {
	      const l = f[t];
	      (l.get || l.set) && Object.defineProperty(this, t, l);
	    }
	    return Object.defineProperty(this, "type", {
	      get() {
	        return s.type;
	      },
	      set(t) {
	        s.type = t;
	      }
	    }), this;
	  }
	  update({
	    fragmentShader: i,
	    vertexShader: _,
	    uniforms: h,
	    cacheKey: m,
	    patchMap: I
	  }) {
	    const M = P(_ || ""), d = P(i || ""), s = this;
	    h && (s.uniforms = h), _ && (s.vertexShader = _), i && (s.fragmentShader = i), Object.entries(w).forEach(([a, n]) => {
	      for (const f in n) {
	        const t = n[f];
	        (d && d.includes(t) || M && M.includes(t)) && (s[a] || (s[a] = 1));
	      }
	    });
	    const R = s.__csm.prevOnBeforeCompile, o = (a, n, f) => {
	      let t, l = "";
	      if (n) {
	        const r = n.search(/void\s+main\s*\(\s*\)\s*{/);
	        if (r !== -1) {
	          l = n.slice(0, r);
	          let c = 0, g = -1;
	          for (let S = r; S < n.length; S++)
	            if (n[S] === "{" && c++, n[S] === "}" && (c--, c === 0)) {
	              g = S;
	              break;
	            }
	          if (g !== -1) {
	            const S = n.slice(r, g + 1);
	            t = S.slice(S.indexOf("{") + 1, -1);
	          }
	        } else
	          l = n;
	      }
	      if (f && (n && n.includes(e.fragColor)) && t && (t = `csm_UnlitFac = 1.0;
` + t), a.includes("//~CSM_DEFAULTS")) {
	        a = a.replace(
	          "void main() {",
	          `
          // THREE-CustomShaderMaterial by Faraz Shaikh: https://github.com/FarazzShaikh/THREE-CustomShaderMaterial
  
          ${l}
          
          void main() {
          `
	        );
	        const r = a.lastIndexOf("//~CSM_MAIN_END");
	        if (r !== -1) {
	          const c = `
            ${t ? `${t}` : ""}
            //~CSM_MAIN_END
          `;
	          a = a.slice(0, r) + c + a.slice(r);
	        }
	      } else {
	        const r = /void\s*main\s*\(\s*\)\s*{/gm;
	        a = a.replace(
	          r,
	          `
          // THREE-CustomShaderMaterial by Faraz Shaikh: https://github.com/FarazzShaikh/THREE-CustomShaderMaterial
  
          //~CSM_DEFAULTS
          ${f ? b : y}
          ${D}
  
          ${l}
          
          void main() {
            {
              ${H}
            }
            ${f ? x : O}

            ${t ? `${t}` : ""}
            //~CSM_MAIN_END
          `
	        );
	      }
	      return a;
	    };
	    s.onBeforeCompile = (a, n) => {
	      R == null || R(a, n);
	      const f = I || {}, t = s.type, l = t ? `#define IS_${t.toUpperCase()};
` : `#define IS_UNKNOWN;
`;
	      a.vertexShader = l + `#define IS_VERTEX
` + a.vertexShader, a.fragmentShader = l + `#define IS_FRAGMENT
` + a.fragmentShader;
	      const T = (r) => {
	        for (const c in r) {
	          const g = c === "*" || M && M.includes(c);
	          if (c === "*" || d && d.includes(c) || g) {
	            const p = F[c];
	            if (p && p !== "*" && (Array.isArray(p) ? !p.includes(t) : p !== t)) {
	              console.error(
	                `CustomShaderMaterial: ${c} is not available in ${t}. Shader cannot compile.`
	              );
	              return;
	            }
	            const $ = r[c];
	            for (const E in $) {
	              const A = $[E];
	              if (typeof A == "object") {
	                const N = A.type, L = A.value;
	                N === "fs" ? a.fragmentShader = a.fragmentShader.replace(
	                  E,
	                  L
	                ) : N === "vs" && (a.vertexShader = a.vertexShader.replace(
	                  E,
	                  L
	                ));
	              } else A && (a.vertexShader = a.vertexShader.replace(
	                E,
	                A
	              ), a.fragmentShader = a.fragmentShader.replace(
	                E,
	                A
	              ));
	            }
	          }
	        }
	      };
	      T(k), T(f), a.vertexShader = o(
	        a.vertexShader,
	        M,
	        !1
	      ), a.fragmentShader = o(
	        a.fragmentShader,
	        d,
	        !0
	      ), h && (a.uniforms = { ...a.uniforms, ...s.uniforms }), s.uniforms = a.uniforms;
	    };
	    const C = s.customProgramCacheKey;
	    s.customProgramCacheKey = () => ((m == null ? void 0 : m()) || z((M || "") + (d || ""))) + (C == null ? void 0 : C.call(s)), s.needsUpdate = !0;
	  }
	  clone() {
	    const i = this;
	    return new i.constructor({
	      baseMaterial: i.__csm.baseMaterial.clone(),
	      vertexShader: i.__csm.vertexShader,
	      fragmentShader: i.__csm.fragmentShader,
	      uniforms: i.__csm.uniforms,
	      patchMap: i.__csm.patchMap,
	      cacheKey: i.__csm.cacheKey
	    });
	  }
	}
	//# sourceMappingURL=three-custom-shader-material.es.js.map

	function heartShape$1() {
	    const geometryPoints = [];
	    for (let t = 0; t <= Math.PI * 2; t += 0.01) {
	    const x = 16 * Math.pow(Math.sin(t), 3);
	    const y =
	        13 * Math.cos(t) -
	        5 * Math.cos(2 * t) -
	        2 * Math.cos(3 * t) -
	        Math.cos(4 * t);
	    
	        geometryPoints.push(new Vector3(x/10, y/10, 0));
	    }

	    return geometryPoints;
	}









	function basicShape() {
	    const geometry = new MeshLineGeometry({
	        widthCallback: (p) => {
	            const w = p * Math.random();
	            console.log(":width callback", w);
	            return w;
	        }
	    });

	    const geometryPoints = heartShape$1();

	    geometry.setPoints(geometryPoints);

	    const tick = () => {
	        
	    };

	    return {
	        geometry,
	        tick
	    };
	}














	/*
	function _____createLine() {

	    const positions = [];
	    const colors = [];

	    const points = pointsOnALine({ x: -2, y: 0, z: 10}, { x: 10, y: -15, z: -1 }, 10);
	    const spline = new THREE.CatmullRomCurve3( points );
	    const divisions = Math.round( 12 * 10 );
	    const point = new THREE.Vector3();
	    const color = new THREE.Color();

	    for ( let i = 0, l = divisions; i < l; i ++ ) {

	        const t = i / l;

	        spline.getPoint( t, point );
	        positions.push( point.x, point.y, point.z );

	        color.setHSL( t, 1.0, 0.5, THREE.SRGBColorSpace );
	        colors.push( color.r, color.g, color.b );
	    }


	    // Line2 ( LineGeometry, LineMaterial )

	    const geometry = new LineGeometry();
	    geometry.setPositions( positions );
	    geometry.setColors( colors );

	    const matLine = new LineMaterial( {
	        color: 0xffffff,
	        linewidth: 5, // in world units with size attenuation, pixels otherwise
	        vertexColors: true,
	        dashed: false,
	        alphaToCoverage: true,
	    } );



	    const line = new Line2( geometry, material );
	    line.computeLineDistances();
	    line.scale.set( 1, 1, 1 );
	    
	    const tick = (context) => {

	    }

	    return {
	        geometry,
	        mesh: line,
	        material,
	        tick
	    }

	    
	}



	function graphPoints() {
	        const points = GeometryUtils.hilbert3D( new THREE.Vector3( 0, 0, 0 ), 20.0, 1, 0, 1, 2, 3, 4, 5, 6, 7 );
	        return points;
	    }


	function splineGraph(beginning, end, shiftRatio = 2) {

	    let ySign = Math.sign((end.y + beginning.y)/2)

	    let appliedRatio = -shiftRatio * Math.abs(beginning.y)

	    let midVector = new THREE.Vector3( 0, (end.y+beginning.y)/2, (end.z+beginning.z)/2 )
	    let positionVector = new THREE.Vector3(0,end.y-beginning.y,end.z-beginning.z)

	    let orthogVector = new THREE.Vector3(0,positionVector.z,-positionVector.y).normalize() 

	    // Compute the curve passing by the three points
	    var curve = new THREE.CatmullRomCurve3( [
	        new THREE.Vector3( beginning.x, beginning.y, beginning.z ),
	        midVector.clone().addScaledVector(orthogVector, ySign*appliedRatio),
	        new THREE.Vector3( end.x, end.y, end.z ),
	    ]);

	    var points = curve.getPoints( 20 );

	    return points;
	}



	function pointsOnALine() {
	    return (new Array(20)).fill(0).map((n, i) => {
	        return new THREE.Vector3( i * 0.2, 0, 0 )
	    })
	}

	*/











	const vertexShader$6 = /* glsl */`
        uniform vec2 uPlaneResolution;
        uniform vec2 uTextureSize;
        varying vec2 vUv;

        uniform float uTime;
        uniform float uVolume;

        void main() { 

            float time = uTime * 2.0;

            csm_Position.x += smoothstep(- 1.0, 1.0, sin((csm_Position.y * 5.5 * (uVolume * 0.1) + time) + uVolume) * uVolume) * 0.1;

            vUv = uv;
            //gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }   
`;

	const fragmentShader$5 = /* glsl */`
            varying vec2 vUv;

            uniform sampler2D uTexture;
            uniform vec2 uPlaneResolution;
            uniform vec2 uTextureSize;

            uniform vec3 uColor;

            void main()	{

                vec3 color = uColor;

                csm_FragColor.rgb = vec3(color);

                //vec2 scaledUV = vUv; //calcUV(vUv, uTextureSize, uPlaneResolution);

                //vec4 image = texture2D(uTexture, scaledUV);
                //gl_FragColor = image; // vec4(vUv, 1.0, 1.0);
                //gl_FragColor =  vec4(1.0, 0.1, 1.0, 1.0);

                //#include <tonemapping_fragment>
                //#include <colorspace_fragment>
            }
`;



	function createLineMaterial(params = {}) {

	    const uniforms = {
	        uTime: new Uniform(0),
	        uColor: new Uniform(params.color),
	        uVolume: new Uniform(0),
	    };

	    // Vanilla
	    const material = new B({
	        baseMaterial: MeshBasicMaterial,
	        vertexShader: vertexShader$6,
	        fragmentShader: fragmentShader$5,
	        vertexColors: true,
	        uniforms
	    });

	    return material
	}





	function createLine(params, program) {

	    // Line2 ( LineGeometry, LineMaterial )

	    //geometry.setPositions( positions );
	    //geometry.setColors( colors );

	//    CylinderGeometry(radiusTop : Float, radiusBottom : Float, height : Float, radialSegments : Integer, heightSegments : Integer, openEnded : Boolean, thetaStart : Float, thetaLength : Float)

	    const {
	        radiusTop = 0.02,
	        radiusBottom = 0.02,
	        height = 1,
	        radialSegments = 8,
	        heightSegments = 20,
	        openEnded = false,
	        thetaStart = 0,
	        thetaLength = 2 * Math.PI,
	        graph = {}
	    } = params;

	    const {
	        innercolor = { hex: 'ffcc22' }
	    } = graph;


	    const geometry = new CylinderGeometry( 
	        radiusTop, 
	        radiusBottom, 
	        height, 
	        radialSegments, 
	        heightSegments, 
	        openEnded,
	        thetaStart, 
	        thetaLength 
	    ); 

	    const material = createLineMaterial( { 
	        color: new Color(`#${innercolor.hex}`),
	        wireframe: false
	    } );

	    const mesh = new Mesh(geometry, material);
	    mesh.rotation.z = Math.PI / 2;

	    

	    // console.log("CHART MESH", material, params, innercolor)

	    const tick = (context) => {
	        material.uniforms.uTime.value = context.clock.time;
	        material.uniforms.uVolume.value = context.analyser.data.average;
	    };

	    return {
	        geometry,
	        mesh,
	        material,
	        tick
	    }

	}










	class LineGraph$1 extends Shape$1 {
		getGeometry(program) {
			//let plane = new THREE.PlaneGeometry(this.params.width, this.params.height, 32);

	        return basicShape();
		}

	    // default mesh
	    createMesh(program) {		
	        //const geo = this.getGeometry(program)
	        //const mat = this.getMaterial(program, geo.geometry)

	        //const mesh = new THREE.Mesh(geo.geometry, mat.material)
	        const container = new Group$1();
	        

	        const { innercolor, outercolor, dither = 2, power = 4,
	            particle_count = 2000, branches = 3,
	            length = 1,
	         } = this.params.graph || {};

	        const chartParams = Object.assign({
	            count: particle_count,
	    //        size: 0.,
	            length,
	            radius: 4,
	            branches,
	            spin: -5.5,
	            spacing: 0.2,
	            randomness: dither,
	            randomnessPow: power,
	            sizeAttenuation: true,
	            depthWrite: false,
	            blending: SubtractiveBlending,
	            //texture: 'circle_01',
	            innerColor: new Color(`#${innercolor.hex}`),
	            outerColor: new Color(`#${outercolor.hex}`),
	        }, this.params);

	        console.log("CHART::::::   chartParams", chartParams, program);
	        
	        //const waves = waveParticleShader(waveparams, program)
	        //container.add(waves.mesh);



	        const lines = createLine(this.params);
	        container.add(lines.mesh);

	        console.log("CHART PARAMS", this.params);

	        this.applyTransforms(container);

	        this.tick = (context) => {
	            //geo.tick(context)
	            //mat.tick(context)
	            lines.tick(context);

	            //console.log("meter volume", context.meter.data.channels[0].volume)
	            //console.log("analyser avg", context.analyser.data.average)

	        };

	        return container;
	    }


	    getMaterial(program, geometry) {

	        const color = new Color(...this.color);
	        const { params } = this;

	        return lineMaterial(program, Object.assign({ color }, params))
	    }



	}

	function rand(min, max) {
	   return  Math.floor(Math.random() * (max - min + 1)) + min;
	}

	const SHAPES$1 = {
	    sparkle: (params) => {
	        return /* glsl */`
            strength = 0.15 / (distance(vec2(pointCoord.x, (pointCoord.y - 0.5) * 5.0 + 0.5), vec2(0.5)));
            strength *= 0.15 / (distance(vec2(pointCoord.y, (pointCoord.x - 0.5) * 5.0 + 0.5), vec2(0.5)));
            strength *= 1.0;
            strength = pow(strength, 1.0);
        `
	    },
	    photon: () => {
	        return /* glsl */`
            // photon
            strength *= distance(pointCoord, vec2(0.5)); // distance to center
            //strength *= 2.0; //smoothstep(0. 0.5, dist);
            strength = 1.0 - strength;
            strength = pow(strength, 10.0);
        `
	    },
	    disc: () => {
	        return /* glsl */`
            // disc
            strength = distance(pointCoord, vec2(0.5)); // distance to center
            strength = 1.0 - step(0.5, strength); //smoothstep(0. 0.5, dist);
        `
	    }
	};


	const vertex$r = /* glsl */`
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;
uniform float uPointSize;
uniform float uTime;
uniform sampler2D uPerlinTex;
uniform vec2 waveFreq;
uniform float noiseMapSize;
uniform float twistAmp;
uniform float twistFreq;
uniform float uFrequency;
uniform float uDir;


uniform vec2 uRandom; // random limits

attribute vec3 aScale;
attribute vec4 aRand;
attribute vec3 aOriginalPosition;
attribute vec3 aRadius;

varying vec2 vUv;
varying vec3 vColor;
varying float vIntensity;
varying vec3 vPointCoord;

${defs}
${perlin3d}

 vec2 rotate2D(vec2 value, float angle)
        {
            float s = sin(angle);
            float c = cos(angle);
            mat2 m = mat2(c, s, -s, c);
            return m * value;
    }

float remap(float value, float min1, float max1, float min2, float max2) {
        return min2 + (value - min1) * (max2 - min2) / (max1 - min1);
}


void main() { 
    vUv = uv;
    vColor = color;

    vec4 modelPosition = modelMatrix * vec4(position, 1.0);
    

    //gl_Position = projectedPosition;
    
    //gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);

    
    float spinSpeed = 0.5;
    float time = uTime;

    float angle = atan(modelPosition.x, modelPosition.z); // assumes model is at 0,0
    float distToCenter = length(modelPosition.yz);
    float angleOffset = (1.0 / distToCenter) * time * spinSpeed;

    angle += angleOffset; // speed based on distance to center

    //modelPosition.z = modelPosition.z + sin(uTime) * 2.0;
    //modelPosition.x += sin(uTime * modelPosition.y) * 1.0;
    //modelPosition.z += sin(uTime) * 1.0;

    vec3 newPosition = aOriginalPosition.xyz;

    //time = (uTime + (uRandom.x * 37.0)) * uFrequency;

    // low radius
    // float noise = abs(cnoise(vec3(modelPosition.xz * 3.0, uTime * 0.42))) * 0.05;
    
    float radius = aRadius.x;
    float windEffect = 0.7 * radius;
    float blastRadius = 1.0;

    float noiseX = abs(cnoise(vec3(modelPosition.xz * aRadius.x, uTime * 0.42)));
    float noiseY = abs(cnoise(vec3(modelPosition.xz * aRadius.y, uTime * 0.22)));

    /*
    float noisePerlin = texture(uPerlinTex,
            vec2(0.1 + uv.x * noiseMapSize - time, 
                0.1 + uv.y * noiseMapSize - time)
    ).r;
    */

    // noisePerlin = smoothstep(0.1, 0.9, noisePerlin);

    // float twist = (noisePerlin + (time * twistFreq)) * twistAmp;
    
    /*
    vec2 windOffset = vec2(
        (texture(uPerlinTex, vec2(0.25, time * 0.03)).r - 0.5 ) * pow(noise, 2.0),
        (texture(uPerlinTex, vec2(0.75, time * 0.03)).r - 0.5 ) * pow(noise, 2.0)
    );
    */

    time = uTime; // reset time

    modelPosition.x = (sin(angle) * distToCenter) + noiseX * aRadius.x; // sin(twist * aRand.x) *  windOffset.x; 
    modelPosition.z = (cos(angle) * distToCenter) + noiseY * aRadius.z;  //cos(twist * aRand.y) *  windOffset.y; 

    float oY = modelPosition.y;
    modelPosition.y =  oY + (time * aRand.y) ;

    //modelPosition.y = oY + twist;
    
    //modelPosition.y = mod( modelPosition.y, oY + noisePerlin);
    float height = (aRand.z * aRadius.y);
    modelPosition.y = mod( modelPosition.y, height);

    //float remap(float value, float min1, float max1, float min2, float max2) {
    float decay = remap(modelPosition.y, 0.0, height, 0.0, 1.0);

    // snow = uDir = 0
    modelPosition.y = oY + pow( modelPosition.y, uDir + oY) ;

    vec4 viewPosition = viewMatrix * modelPosition;
    vec4 projectedPosition = projectionMatrix * viewPosition;

    gl_Position = projectedPosition;

    gl_PointSize = uPointSize * aScale.x;

    vIntensity = smoothstep(0.0, 0.5,  modelPosition.y);

    vPointCoord = modelPosition.xyz;

    // size attenuation
    gl_PointSize *= (1.0 / - viewPosition.z) * (1.0 - decay);

}   
  `;

	const fragment$r = /* glsl */`

uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;

uniform vec3 uColor1;
uniform vec3 uColor2;

varying vec2 vUv;
varying vec3 vColor;
varying float vIntensity;

void main()	{

	//vec2 scaledUV = vUv; //calcUV(vUv, uTextureSize, uPlaneResolution);

	//vec4 image = texture2D(uTexture, scaledUV);
    //gl_FragColor = image; // vec4(vUv, 1.0, 1.0);
    vec2 pointCoord = gl_PointCoord;
    float strength = 1.0;

    ${SHAPES$1.disc()}
   
    vec3 color = mix(uColor1, uColor2, vIntensity);
    color = mix(vColor, color, smoothstep(0.0, 0.5, vIntensity));
    color = mix(vec3(0.0), color, strength);

    //color = vec3(1.0);

    gl_FragColor =  vec4(color, 1.0);

    #include <tonemapping_fragment>
    #include <colorspace_fragment>
}
`;


	function generateParticles(params) {

	    // console.log("GENERATING PARTICLES", params)

	    const {
	        x = 0,
	        y = 0,
	        z = 0,
	        rx = 1,
	        ry = 1,
	        rz = 1,
	        width = 1, 
	        height = 1,
	        depth = 1,        
	        particle_count = 1500,
	        count = particle_count,
	        particleSize = 6.0,
	        map,
	        dir = 2.0,
	        
	        innercolor = { hex: 'FF9419' },
	        outercolor = { hex: 'FF9419' },
	        color1 = innercolor,
	        color2 = outercolor,
	        color3 = { hex: '140CFF' },
	    } = params;


	    const geometry = new BufferGeometry();

	    const positions = new Float32Array(count * 3);
	    const originalPositions = new Float32Array(count * 3);
	    const colors = new Float32Array(count * 3);
	    const scales = new Float32Array(count * 3);
	    const radius = new Float32Array(count * 3);

	    const randomness = new Float32Array(count * 4);

	    const _colors = [
	        new Color(`#${color1.hex}`),
	        new Color(`#${color2.hex}`),
	        new Color(`#${color3.hex}`)
	    ];

	    for (let i = 0; i < particle_count; i++) {
	        const i3 = i * 3;

	        positions[i3 + 0] = x + (Math.random() - 0.5) * width;
	        positions[i3 + 1] = y + (Math.random() - 0.5) * height;
	        positions[i3 + 2] = z + (Math.random() - 0.5) * depth;

	        originalPositions[i3 + 0] = positions[i3 + 0];
	        originalPositions[i3 + 1] = positions[i3 + 1];
	        originalPositions[i3 + 2] = positions[i3 + 2];

	        const color = _colors[rand(0, _colors.length - 1)];

	        colors[i3 + 0] = color.r;
	        colors[i3 + 1] = color.g;
	        colors[i3 + 2] = color.b;

	        radius[i3 + 0] = rx;
	        radius[i3 + 1] = ry;
	        radius[i3 + 2] = rz;

	        scales[i3 + 0] = Math.random() * 3;
	        scales[i3 + 1] = Math.random() * 3;
	        scales[i3 + 2] = Math.random() * 3;

	        randomness[i3 + 0] = Math.random();
	        randomness[i3 + 1] = Math.random();
	        randomness[i3 + 2] = Math.random();
	        randomness[i3 + 3] = Math.random(); // alpha
	    }

	    geometry.setAttribute('position', 
	        new BufferAttribute(positions, 3)
	    );

	    geometry.setAttribute('aOriginalPosition', 
	        new BufferAttribute(originalPositions, 3)
	    );

	    geometry.setAttribute('color', 
	        new BufferAttribute(colors, 3)
	    );

	    geometry.setAttribute('aScale', 
	        new BufferAttribute(scales, 3)
	    );

	    geometry.setAttribute('aRand', 
	        new BufferAttribute(randomness, 4)
	    );

	    geometry.setAttribute('aRadius', 
	        new BufferAttribute(radius, 3)
	    );

	    return {
	        geometry
	    }
	}



	function emitter(params, program) {


	    const {
	        pointSize = 6.0,
	        particleSize = pointSize,
	        map,
	        dir = 2.0,
	        innercolor = { hex: 'FF9419' },
	        outercolor = { hex: 'FF9419' },
	        color1 = innercolor,
	        color2 = outercolor,
	        color3 = { hex: '140CFF' },
	        fragmentShader = fragment$r,
	        vertexShader = vertex$r
	    } = params;

	    const { renderer } = program;

	    let texture;
	    
	    
	    console.log("PARTICLE EMITTER TEXTURE", map, pointSize);

	    if (typeof map === 'string') {
	        const textureLoader = new TextureLoader();
	        texture = textureLoader.load(map, function() {
	             console.log("PARTICLE: texture loaded", map, texture);
	        });
	    } else {
	        texture = map;
	    }

	    const uniforms = {
	        uTime: new Uniform(0),
	        uPointSize:  new Uniform(particleSize * Math.min(renderer.getPixelRatio(), 2)),
	        uFreq: new Uniform(1),
	        uTexture: new Uniform(texture),
	        uTextureSize:  new Uniform(new Vector2(256, 256)),
	        uPlaneResolution: new Uniform(new Vector2(1, 1)),
	        uPerlinTex: new Uniform(texture),
	        waveFreq: new Uniform(new Vector2(1.4, 1)),
	        noiseMapSize: new Uniform(0.5),
	        twistAmp: new Uniform(1.2),
	        twistFreq: new Uniform(3.2),
	        uFrequency: new Uniform(1.2),
	        uDir:  new Uniform(dir), // 0 for snow, 2 for fire, 4 for rise
	        uRandom: new Uniform(new Vector2(1, 1)),
	        uColor1: new Uniform(new Color(`#${color1.hex}`)),
	        uColor2: new Uniform(new Color(`#${color2.hex}`)),
	        uColor3: new Uniform(new Color(`#${color3.hex}`)),
	        ...(params.uniforms || {})
	    };
	    
	    const material = new ShaderMaterial({
	        //side: THREE.DoubleSide,
	        alphaTest: 0.01,
	        vertexColors: true,
	        depthTest: true,
	        depthWrite: false,
	        transparent: true,
	        blending: AdditiveBlending,
	        fragmentShader,
	        vertexShader,
	        uniforms,
	    });


	   // const geometry = new THREE.SphereGeometry(width, 32, 32);

	    const { geometry } = generateParticles(params);

	    const mesh = new Points(geometry, material);

	    function tick(context) {
	        const { time } = context.clock;
	        // mesh.rotation.y = time / 2

	        uniforms.uTime.value = time;  
	    }

	    return {
	        mesh, material, geometry, uniforms, tick
	    }

	}

	function matrix(params, program) {
	    // prevent rendering
	    const mesh = new Group();

	    const tick = () => {

	    };

	    return {
	        mesh, tick
	    };
	}

	function warp(params, program) {


	    console.log("WRAP", params);

	    const {
	        map
	    } = params;

	    const radiusTop = 16;
	    const radiusBottom = 15;
	    const height = 64;
	    const radialSegments = 32; 
	    const heightSegments = 1; 
	    const openEnded = true;
	    const thetaStart = 2;
	    const thetaLength = 4;

	    const geometry = new CylinderGeometry(
	        radiusTop, radiusBottom, height, 
	        radialSegments, heightSegments, openEnded,
	        thetaStart, thetaLength
	    );

	    map.repeat.set(-1, 1);
	    map.center.set(0.5, 0.5);

	    const material = new MeshStandardMaterial({
	        color: 'red',
	        map,
	        side: BackSide
	    });


	    const mesh = new Mesh(geometry, material);


	    const tick = (context) => {

	    };

	    return {
	        mesh, tick
	    };
	}



	var EFFECTS = /*#__PURE__*/Object.freeze({
		__proto__: null,
		matrix: matrix,
		warp: warp
	});

	class TextEffect extends Shape$1 {

	    
		getGeometry(program) {
			let plane = new PlaneGeometry(1, 5, 32, 32);

	        //console.log("PLANE CREATED FOR TEXT", plane)
	        plane.scale.y = 5;
	       
			return plane
		}


	   

	    // default mesh
	    createMesh(program) {		
	        const color = new Color(...this.color);
	        const container = new Group$1();

	        const { 
	            effectType = 'warp',
	            debug = 0
	        } = this.params;

	        const renderTarget = new WebGLRenderTarget( 1024, 1024 );

	         const params = {
	            ...this.params,
	            map: renderTarget.texture, // overrides the default texture
	            color
	        };

	        const createEffect = EFFECTS[effectType] || warp;
	        const effect = createEffect(params, { renderTarget, ...program });
	        
	        container.add(effect.mesh);

	        const textItems = program.context.main_titles;

	        function sowDebug() {
	            if (!debug) return;

	            const plane = new PlaneGeometry(1, 1, 12);
	            const material = new MeshBasicMaterial({
	                map: renderTarget.texture
	            });
	            const mesh = new Mesh(plane, material);

	            mesh.position.z = 2;
	            mesh.position.x = 0.2;

	            container.add(mesh);
	        }

	        sowDebug();



	        // setup rendertarget for texture
	        const camera = new PerspectiveCamera(75, 256 / 256, 0.1, 100);
	        camera.position.set( 0, 0, 4 );

	        const { renderer } = program;

	        // scene for the texture
	        const scene = new Scene();

	        let textGroup = null;

	        const init = (group) => {
	            textGroup = group;
	        };

	        //const text = createTextNode("test", this.params)
	        //scene.add(text)

	        const textNodes = textItems.map((item, i) => {
	            const node = createTextNode(item.text, this.params);

	            node.position.y += 0.5 + i * 0.2;

	            scene.add(node);
	            return node
	        });



	        this.textNodes = textNodes;
	        this.renderTarget = renderTarget;
	        renderer.setClearColor(0x000000, 0.0);


	        const renderTexture = (context) => {
	            

	            const { time } = context.clock;

	            //uniforms.uTime.value = time;

	            if (textGroup) {
	                textGroup.children.forEach((child, i) => {
	                    //child.position.x = Math.sin(time / 2) * 3.2;
	                    //child.position.y = i * 0.5 + Math.sin(time / 2) * 1.2
	                });
	            }

	            renderer.setRenderTarget( renderTarget );
	            renderer.clear();
	            
	            renderer.render( scene, camera );
	        };

	        const tick = (context) => {

	            //text.sync()
	            textNodes.forEach(node => node.sync());

	            // save the original camera properties
	            const currentRenderTarget = renderer.getRenderTarget();
	            const currentXrEnabled = renderer.xr.enabled;
	            const currentShadowAutoUpdate = renderer.shadowMap.autoUpdate;
	            renderer.xr.enabled = false; // Avoid camera modification
	            renderer.shadowMap.autoUpdate = false; // Avoid re-computing shadows

	            // render the effect
	            renderTexture( context);
	            
	            // restore the original rendering properties
	            renderer.xr.enabled = currentXrEnabled;
	            renderer.shadowMap.autoUpdate = currentShadowAutoUpdate;
	            renderer.setRenderTarget( currentRenderTarget );

	            // once the texture is rendered, 
	            // tick the effect
	            effect.tick(context);
	        };


	        this.applyTransforms(container);


	        this.init = init;
	        this.tick = tick;

	        return container;
	    }

	    // override to create a renderTarget
	    getChildNodes(program, parent) {

	        // special case for this one
	        // when we need an array of textnodes to 
	        // render into a renderTarget
	        // create a fake parent object
	        const par = {
	            add: (group)  => {
	                // group.children contans an array of textnodes
	                // send the text node group to the effect function
	                // 
	                this.init(group);
	            }
	        };

	        if (this.children) {
	            for (let child of this.children) {
	                child.node(program, par);
	            }
	        }
	    }

	    createNode(program, parent) {
	        if (!this.mesh) {
	            this.mesh = this.createMesh(program);
	            parent.add(this.mesh);
	        }
			//console.log("drawing webgl mesh", mesh, this)
			return this.mesh
		}

	    removeNodes() {
	        // implement this
	    }


	    getMaterial(program, geometry) {
	        return; 
	    }

	    


	}

	const vertexShader$7 = /* glsl */`
    uniform vec2 uResolution;
    uniform vec2 uTextureSize;
    uniform float uTime;

    varying vec2 vUv;
    varying vec4 vPosition;
    varying float time;

    void main() { 
        vUv = uv;
        time = uTime;

        vec4 position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);

        vPosition = position;

        gl_Position = position;
    }   
`;


	const fragmentShader$6 = /* glsl */`

        uniform float uTime;
        uniform sampler2D uPerlinTex;
        uniform sampler2D uTexture;
        uniform float uColorMixFactor;
        uniform vec3 uColor;
        uniform vec2 uCursor;
        uniform float uVolume;
        //uniform float uTime;

        varying float time;
        varying vec2 vUv;

       void main() {
            vec2 scaledUv = vUv;
            vec2 scaledUv2 = vUv;

            scaledUv.x *= 0.082;
            scaledUv.y *= 0.052;

            scaledUv.y -= time * 0.02;
            scaledUv.x -= time * 0.03;

            scaledUv2.y += sin(time * 0.02);
            scaledUv2.x -= cos(time * 0.02);

            vec4 vertexPosition = vec4(gl_PointCoord, 1.0, 1.0);

            float lum = texture(uPerlinTex, scaledUv).r; // red channel
            lum = smoothstep(0.1, 0.9, lum);

            float lum2 = texture(uPerlinTex, scaledUv2).r; // red channel

            // vignette
            //lum = 1.0;
            //lum *= smoothstep(0.0, 0.1, vUv.x);
            //lum *= smoothstep(1.0, 0.9, vUv.x);
            //lum *= smoothstep(0.0, 0.1, vUv.y);
            //lum *= smoothstep(1.0, 0.9, vUv.y);


            float x = abs(sin(vUv.x + time * 0.3));
            float y = abs(cos(vUv.y + time * 0.6));
            float z = abs(smoothstep(0.0, 1.0, sin(time) * 0.6));

            float x2 = abs(sin(vUv.x + time * 0.4));
            float y2 = abs(cos(vUv.y + time * 0.7));
            float z2 = abs(smoothstep(0.0, 1.0, sin(time) * 0.7));


            vec3 mixedColor = mix(vec3(x,y,z), uColor, 0.5);

            //vec3 mixedColor = mix(vec3(x,y,z), uColor, uColorMixFactor);
            //mixedColor = mix(mixedColor, vec3(x2,y2,z2), vertexPosition.z);
            //mixedColor = mix(mixedColor, vec3(x2,y2,z2), vertexPosition.z);

            //lum = smoothstep(0.0, 0.5, lum);
            //gl_FragColor = vec4(mixedColor, lum);
            //gl_FragColor =  vec4(mixedColor, lum);

            vec4 tcolor = texture(uTexture, scaledUv2); // red channel

            gl_FragColor = mix(tcolor, vec4(mixedColor, lum), lum);
       }
    `;




	function cloudEffect(params, program) {

	    console.log("Cloud params", params);

	    const {
	        width = 1, height = 1,
	        widthSegments = 1,
	        heightSegments = 1,
	        innerColor = {
	            hex: 'A7D0F9'
	        }

	    } = params;





	    const displacementMapUrl = params.displacement;

	    const textureLoader2 = new TextureLoader();
	    const displaceTexture = textureLoader2.load(displacementMapUrl, function() {
	            console.log("CLOUD displaceTexture loaded", displacementMapUrl, displaceTexture, params);
	        });

	    displaceTexture.wrapS = MirroredRepeatWrapping;
	    displaceTexture.wrapT = MirroredRepeatWrapping;

	    const textureLoader3 = new TextureLoader();
	    const textureMapUrl = params.map;
	    const textureMap = textureLoader3.load(textureMapUrl, function() {
	            console.log("CLOUD textureMap loaded", textureMapUrl, textureMap);
	        });

	    textureMap.wrapS = MirroredRepeatWrapping;
	    textureMap.wrapT = MirroredRepeatWrapping;

	    const uniforms = {
	            uTime: { value: new Uniform(0) },
	            uVolume: { value: new Uniform(0) },
	            uColor: { value: new Color(`#${innerColor.hex}`) },
	            uCursor: { value: new Vector2(0, 0) },
	            uColorMixFactor: { value: 0.5 },
	            uRandom: { value: Math.random() },
	            uFrequency: { value: 1 },
	            //uTexture: { value: texture },
	            uPerlinTex: { value: displaceTexture },
	            uTexture: { value: textureMap },
	            uTextureSize: {value: new Vector2(1024, 1024)},
	            uPlaneResolution: {value: new Vector2(width, height)}
	    };


	    const geometry = new PlaneGeometry(width, height, widthSegments, heightSegments);
	    geometry.scale(1, 1, 1);

	    const material = new ShaderMaterial({
	            //wireframe: params.materialRendering === 'wireframe',
	            transparent: false,
	            //side: THREE.DoubleSide,
	            fragmentShader: fragmentShader$6,
	           
	            vertexShader: vertexShader$7,
	            //depthTest: false,
	            uniforms,
	    });


	    const mesh = new Mesh(geometry, material);

	    const tick = (context) => {

	        const { clock, cursor } = context;

	        //console.log('scroll', context.scroll);
	        
	        //uniforms.uTime.value = context.scroll.progress * 10;

	        uniforms.uTime.value = clock.time;

	        uniforms.uCursor.value.x = cursor.x;
	        uniforms.uCursor.value.y = cursor.y;

	        //uniforms.uColorMixFactor.value = context.mouse.y;
	        //console.log(context.cursor.x)
	    };


	    return { mesh, geometry, material, tick, uniforms }
	}

	const vertexShader$8 = /* glsl */`
    uniform vec2 uResolution;
    uniform vec2 uTextureSize;
    uniform float uTime;

    varying vec2 vUv;
    varying vec4 vPosition;
    varying float time;

    void main() { 
        vUv = uv;
        time = uTime;

        vec4 position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);

        vPosition = position;

        gl_Position = position;
    }   
`;


	const fragmentShader$7 = /* glsl */`

uniform float uTime;
uniform vec2 uResolution;
uniform vec3 uColor;
uniform float uFrequency;
uniform float uRotate;
uniform float uRadius;


varying vec2 vUv;
varying vec4 vPosition;
varying float time;

void main() {
    //Iterator and attenuation (distance-squared)
    float i = .2, a;
    //Resolution for scaling and centering
    vec2 r = uResolution.xy,
         //Centered ratio-corrected coordinates
         p = ( vPosition.xy - r ) / r.y / .7,
         //Diagonal vector for skewing
         d = vec2(-1, 1),
         //Blackhole center
         b = p - i * d,
         //Rotate and apply perspective
         c = p * mat2(1, 1, d / (uRotate + i/dot(b, b))),
         //Rotate into spiraling coordinates
         v = c * mat2(cos(uFrequency * log(a=dot(c,c)) + time * i + vec4(0,33,11,0)))/i,
         //Waves cumulative total for coloring
         w;

    //Loop through waves
    for(; i++<9.; w += 1.+sin(v) )
        v += .7* sin(v.yx * i +time) / i + .5;

    //Acretion disk radius
    i = length( sin(v / .3) * uRadius + c*(3.+d) );

    //Red/blue gradient
    vec4 clr = 1. - exp( -exp( c.x * vec4(.6,-.4,-1,0) )
                   //Wave coloring
                   /  w.xyyx
                   //Acretion disk brightness
                   / ( 2. + i*i/4. - i )
                   //Center darkness
                   / ( .5 + 1. / a )
                   //Rim highlight
                   / ( .03 + abs( length(p)-.7 ) )
             );
             
    
    gl_FragColor = clr;

}`;








	function blackHoleEffect(params, program) {

	    console.log("blackHoleEffect params", params);

	    const {
	        width = 1, height = 1,
	        widthSegments = 1,
	        heightSegments = 1,
	        innerColor = {
	            hex: 'A7D0F9'
	        }

	    } = params;


	    const uniforms = {
	            uTime: { value: new Uniform(0) },
	            uColor: { value: new Color(`#${innerColor.hex}`) },
	            uFrequency: { value: 1 },
	            uRotate: { value: 0.5 },
	            uRadius: new Uniform(0.641),
	            uResolution: {value: new Vector2(14, 14)}
	    };


	    const geometry = new PlaneGeometry(width, height, widthSegments, heightSegments);
	    geometry.scale(1, 1, 1);

	    const material = new ShaderMaterial({
	            //wireframe: params.materialRendering === 'wireframe',
	            transparent: false,
	            //side: THREE.DoubleSide,
	            fragmentShader: fragmentShader$7,
	           
	            vertexShader: vertexShader$8,
	            //depthTest: false,
	            uniforms,
	    });


	    const mesh = new Mesh(geometry, material);

	    const tick = (context) => {

	        const { clock, cursor } = context;
	        uniforms.uTime.value = clock.time / 2;
	    };


	    return { mesh, geometry, material, tick, uniforms }
	}

	const EFFECTS$1 = {
	    cloud: cloudEffect,
	    blackhole: blackHoleEffect,
	    ragingSea
	};


	class BackgroundEffects extends Shape$1 {
		

	    // default mesh
	    createMesh(program) {		
	        
	        const { 
	            effectType = 'FluidShader' 
	        } = this.params;

	        const { camera } = program;

	        const createEffect = EFFECTS$1['blackhole'];

	        const container = new Group$1();
	        let effect;

	        if (createEffect) {
	            effect = createEffect(this.params, program);

	            planeFitPerspectiveCamera(effect.mesh, camera);            
	            container.add(effect.mesh);
	        }

	        this.applyTransforms(container);

	        this.tick = (context) => {
	            if (effect)
	                effect.tick(context);
	        };

	        return container;
	    }


	}

	const vertexShader$9 = /* glsl */`
${simplexNoise4d$1}

attribute vec4 tangent;

uniform float uTime;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;

uniform float uPositionFrequency;
uniform float uTimeFrequency;
uniform float uStrength;

uniform float uWarpPositionFrequency;
uniform float uWarpTimeFrequency;
uniform float uWarpStrength;

varying float vWobble;
varying vec2 vUv;

float getWobble(vec3 position)
{
    vec3 warpedPosition = position;
    warpedPosition += simplexNoise4d(vec4(
        position * uWarpPositionFrequency,
        uTime * uWarpTimeFrequency
    )) * uWarpStrength;
    
    return simplexNoise4d(vec4(
        warpedPosition * uPositionFrequency, // XYZ
        uTime * uTimeFrequency       // W
    )) * uStrength;

}


void main() { 
    vUv = uv;
    vec3 biTangent = cross(normal, tangent.xyz);

    float shift = 0.01;
    vec3 positionA = csm_Position + tangent.xyz * shift;
    vec3 positionB = csm_Position + biTangent * shift;

    float wobble = getWobble(csm_Position);
    csm_Position += wobble * normal;

    positionA    += getWobble(positionA) * normal;
    positionB    += getWobble(positionB) * normal;

    // Compute normal
    vec3 toA = normalize(positionA - csm_Position);
    vec3 toB = normalize(positionB - csm_Position);
    csm_Normal = cross(toA, toB);

    vWobble = wobble / uStrength;

    //csm_Position.y += 2.0;
    //csm_Position.y += sin(csm_Position.z * 3.0) * 0.5;

    //gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}   
  `;

	const fragmentShader$8 = /* glsl */`

varying vec2 vUv;

uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;

uniform vec3 uColorA;
uniform vec3 uColorB;

varying float vWobble;

void main()	{


    // remap from -1.0, 1.0 => 0.0, 1.0 
    float colormix = smoothstep(-1.0, 1.0, vWobble);
    
    csm_DiffuseColor.rgb = mix(uColorA, uColorB, colormix);

    // mirror effect
    //csm_Metalness = step(0.25, vWobble);
    //csm_Roughness = 1.0 - csm_Metalness;

    // shiny tips
    csm_Roughness = 1.0 - colormix;


    //csm_Metalness = step(0.0, sin(vUv.x * 100.0 + 0.5));
    //csm_Roughness = 1.0 - csm_Metalness;
    //csm_FragColor.rgb = vec3(1.0, 0.5, 0.5);

	//vec2 scaledUV = vUv; //calcUV(vUv, uTextureSize, uPlaneResolution);

	//vec4 image = texture2D(uTexture, scaledUV);
    //gl_FragColor = image; // vec4(vUv, 1.0, 1.0);
    //gl_FragColor =  vec4(vUv, 1.0, 1.0);
    //#include <tonemapping_fragment>
    //#include <colorspace_fragment>
}
`;








	class BlobShape extends Shape$1 {
		getGeometry(program) {
	        const {
	            shape = 'sphere', 
	            width = 1,
	            height = 1,
	        } = this.params;

	        let geometry = null;

	        switch(shape) {
	            case 'icosahedron':
	                geometry = new IcosahedronGeometry(2.5, 50);                
	            break;
	            case 'sphere':
	                geometry = new SphereGeometry( width, 128, 128 ); 
	            break;
	            default:
	                geometry = new PlaneGeometry(width, height, 32);
	            break;
	        }
			
	        geometry = mergeVertices(geometry);
	        geometry.computeTangents();

			return geometry
		}

	    // default mesh
	    createMesh(program) {	
	        
	        const {
	            shape = 'sphere',
	            warpPositionFrequency = 0.001,
	            warpTimeFrequency = 0.001,
	            warpStrength = 0.001
	            
	        } = this.params;


	        console.log(">>>> BLOB CREATE", this.params);

	        const geometry = this.getGeometry(program);
	        const { material, depthMaterial, tick } = this.getMaterial(program, geometry);

	        const mesh = new Mesh(geometry, material);
	        mesh.customDepthMaterial = depthMaterial;

	        const container = new Group$1();
	        container.add(mesh);

	        this.applyTransforms(container);

	        this.tick = (context) => {
	            tick(context);
	        };

	        return container;
	    }

	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);

	        const {
	            warpPositionFrequency = 0.5,
	            warpTimeFrequency = 0.4,
	            warpStrength = 0.3,

	            positionFrequency = 0.5,
	            timeFrequency = 0.4,
	            strength = 0.3 , 
	            
	            innercolor = { hex: 'ff5900' }, 
	            outercolor = { hex: '243dff' },
	        } = this.params;
	        const texFile = this.params.map;

	        const textureLoader = new TextureLoader();
	        const texture = textureLoader.load(texFile, function() {
	            console.log("BLOB: texture loaded");
	        });

	        const uniforms = {
	            uTexture: new Uniform(texture),
	            uTextureSize: new Uniform(new Vector2(1024, 1024)),
	            uPlaneResolution: new Uniform(new Vector2(1, 1)),
	            uTime: new Uniform(0),

	            uPositionFrequency: new Uniform(positionFrequency),
	            uTimeFrequency: new Uniform(timeFrequency),
	            uStrength: new Uniform(strength),

	            uWarpPositionFrequency: new Uniform(warpPositionFrequency),
	            uWarpTimeFrequency: new Uniform(warpTimeFrequency),
	            uWarpStrength: new Uniform(warpStrength),

	            uColorA: new Uniform(new Color(`#${innercolor.hex}`)),
	            uColorB: new Uniform(new Color(`#${outercolor.hex}`)),
	        };

	        const material = new B({
	                    color,
	                    fragmentShader: fragmentShader$8,
	                    vertexShader: vertexShader$9,
	                    uniforms,
	                    // CSM
	                    baseMaterial: MeshPhysicalMaterial,
	                    // MeshPhysicalMaterial
	                    metalness: 0,
	                    roughness: 0.1,
	                    transmission: 0,
	                    ior: 1.5,
	                    thickness: 1.5,
	                    transparent: true,
	                    wireframe: false,
	                    
	            });

	        const depthMaterial = new B({
	                // CSM
	                baseMaterial: MeshDepthMaterial,
	                vertexShader: vertexShader$9,

	                uniforms: uniforms,

	                // MeshDepthMaterial
	                depthPacking: RGBADepthPacking
	                    
	            });
	        
	        const tick = (context) => {
	            uniforms.uTime.value = context.clock.time;
	        };

	        return {
	            material,
	            depthMaterial,
	            tick
	        }
	    }



	}

	const vertexShader$a = /* glsl */`

struct colordata {
    vec3 point;
    vec3 binormal;
    vec3 normal;
};


uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;

uniform sampler2D uTexture;

uniform float uPositionFrequency;
uniform float uElevPow;
uniform float uStrength;

uniform float uTime;

uniform float uWarpFrequency;
uniform float uWarpStrength;

varying vec2 vUv;
varying vec3 vPosition;

${simplexNoise2d}


float getElevation(vec2 position) {
    float elevation = 0.0;

    vec2 warpedPosition = position;
    warpedPosition += uTime;

    warpedPosition += simplexNoise2d(warpedPosition * uPositionFrequency * uWarpFrequency) * uWarpStrength;

    // keep evelation betwen 0 and 1;
    elevation += simplexNoise2d(warpedPosition * uPositionFrequency ) / 2.0;
    elevation += simplexNoise2d(warpedPosition * uPositionFrequency * 2.0)  / 4.0;
    elevation += simplexNoise2d(warpedPosition * uPositionFrequency * 4.0)  / 8.0 ;

    float elevSign = sign(elevation);
    elevation = pow(abs(elevation), uElevPow) * elevSign;
    elevation *= uStrength;

    return elevation;
}

void main() { 
   

    //vec4 color = texture(uTexture, aColorsUv);

    // neighbor positions
    float shift = 0.01;
    vec3 posA = position.xyz + vec3(shift, 0.0, 0.0);
    vec3 posB = position + vec3(0.0, 0.0, - shift);

    float elevation = getElevation(csm_Position.xz);

    csm_Position.y += elevation;

    posA.y = getElevation(posA.xz);
    posB.y = getElevation(posB.xz);

    // compute the normal between neighbors
    vec3 toA = normalize(posA - csm_Position);
    vec3 toB = normalize(posB - csm_Position);

    csm_Normal = cross(toA, toB);

    vUv = uv;
    vPosition = csm_Position;

}   
`;




	const fragmentShader$9 = /* glsl */`


uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;

uniform float uNoOfColors;

uniform float uTime;

uniform vec3 uColor1;
uniform vec3 uColor2;
uniform vec3 uColor3; // sand
uniform vec3 uColor4; // grass
uniform vec3 uColor5; // snow
uniform vec3 uColor6;
uniform vec3 uColor7;

varying vec2 vUv;
varying vec3 vPosition;

${simplexNoise2d}

void main()	{
    //  mix(uColorA, uColorB, colormix)

    vec3 color = vec3(0.0);

    float alpha = 1.0;

    vec4 c1 = vec4(uColor1, 0.6);
    vec4 c2 = vec4(uColor2, 1.0);
    vec4 c3 = vec4(uColor3, 0.4);
    vec4 c4 = vec4(uColor4, 0.3);
    vec4 c5 = vec4(uColor5, 0.5);
    vec4 c6 = vec4(uColor6, 0.5);
    vec4 c7 = vec4(uColor7, 0.5);

    // Water
    float surfaceWaterMix = smoothstep(- 1.0, - 0.1, vPosition.y);
    color = mix(uColor1.rgb, uColor2.rgb, surfaceWaterMix);

    alpha = alpha * c2.a;

    // Sand
    float sandMix = step(- 0.1, vPosition.y);
    color = mix(color, uColor3.rgb, sandMix);

    alpha = alpha * c3.a;

    // Grass
    float grassMix = step(- 0.06, vPosition.y);
    color = mix(color, uColor4, grassMix);

    // Snow
    // float snowMix = step(0.45, vPosition.y);
    float snowThreshold = 0.45;

    snowThreshold += simplexNoise2d(vPosition.xz * 15.0) * 0.1;

    float snowMix = step(snowThreshold, vPosition.y);
    color = mix(color, uColor5, snowMix);

    csm_DiffuseColor.rgb = color.rgb;
    csm_DiffuseColor.a = alpha;
}
`;








	class Terrain extends Shape$1 {
		getGeometry(program) {
			let plane = new PlaneGeometry(this.params.width, this.params.height, 512, 512);

	        // remove these for performance
	        plane.deleteAttribute('uv');
	        plane.deleteAttribute('normal');

	        plane.rotateX(-Math.PI * 0.5);

	    
			return plane
		}

	    // default mesh
	    createMesh(program) {		
	        const geometry = this.getGeometry(program);
	        const { material, depthMaterial, tick } = this.getMaterial(program, geometry);

	        const mesh = new Mesh(geometry, material);
	        mesh.castShadow = true;
	        mesh.receiveShadow = true;
	        mesh.customDepthMaterial = depthMaterial;

	        //const frame = rectangleBoxFrame();

	        const container = new Group$1();
	        container.add(mesh);

	        //container.add(frame.mesh);

	        this.applyTransforms(container);

	        this.tick = (context) => {
	            // updqate materals
	            tick(context);
	        };


	        return container;
	    }




	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);

	        const {
	            
	            elevPow = 3.0,
	            strength = 0.5,
	            positionFrequency = 0.2,
	            warpFrequency = 5.0,
	            warpStrength = 0.5,
	            texture = [],
	            
	            color1 = { hex: '002b3d' } ,
	            color2 = { hex: '66a8ff' } ,
	            color3 = { hex: 'ffe894' } ,
	            color4 = { hex: '021C49' } ,
	            color5 = { hex: '021C49' } ,
	            color6 = { hex: 'bfbd8d' } ,
	            color7 = { hex: 'bfbd8d' } ,

	        } = this.params;
	        
	        console.log("TERRAIN", this.params);

	        // get colors from a linear gradient 
	        // and create a data texture
	        const gradient = texture[0]?.image?.stops || [];
	        const len = gradient.length;

	        const width = 16;
	        const height = 16;
	        const size = width * height;
	        
	        //const size = width * height;
	        const data = new Uint8Array( 4 * size );
	        const colorsUv = new Float32Array(len * 2);
	        
	        
	        for (let i=0; i < len;i++) {
	            const i4 = i * 4;

	            const { color, at } = gradient[i];
	            const clr = new Color(`#${color.hex}`);


	            for (let y = 0; y < size; y++) {
	            for (let x = 0; x < size; x++) {
	                const j2 = (y * size) + x;
	                const { color, at } = gradient[i];

	                const uvX = (x + 0.5) / len;
	                const uvY = (y + 0.5) / len;

	                colorsUv[j2 + 0] = uvX;
	                colorsUv[j2 + 1] = uvY;

	                }
	            }
	            
	            const r = Math.floor( clr.r * 255 );
	            const g = Math.floor( clr.g * 255 );
	            const b = Math.floor( clr.b * 255 );

	            data[i4 +0] = r;
	            data[i4 +1] = g;
	            data[i4 +2] = b;
	            data[i4 +3] = color.a * 255;

	        }



	        // used the buffer to create a DataTexture
	        const dataTexture = new DataTexture( data, width, height );
	        dataTexture.format = RGBAFormat;
	        dataTexture.minFilter = LinearFilter;
	        dataTexture.magFilter = LinearFilter;
	        dataTexture.type = UnsignedByteType;
	        dataTexture.needsUpdate = true;


	        //console.log("gradient", gradient,  dataTexture, colorsUv, paramsArray);

	        
	        //geometry.setAttribute('aColorsUv', new THREE.BufferAttribute(colorsUv, 2))
	        //geometry.setAttribute('aParams', new THREE.BufferAttribute(colorsUv, 2))

	        //const texFile = this.params.map

	        //const textureLoader = new THREE.TextureLoader()
	        //const texture = textureLoader.load(texFile, function() {
	        //    console.log("EVBAR: texture loaded")
	        //})








	    
	        const uniforms = {
	            uTime:  new Uniform(0),
	            
	            uPlaneResolution: new Uniform(new Vector2(1.4, 1)),
	            uElevPow: new Uniform(elevPow),

	            uPositionFrequency: new Uniform(positionFrequency),
	            uStrength: new Uniform(strength),
	            
	            uWarpFrequency: new Uniform(warpFrequency),
	            uWarpStrength: new Uniform(warpStrength),

	            uColor1: new Uniform(new Color(`#${color1.hex}`)),
	            uColor2: new Uniform(new Color(`#${color2.hex}`)),
	            uColor3: new Uniform(new Color(`#${color3.hex}`)),
	            uColor4: new Uniform(new Color(`#${color4.hex}`)),
	            uColor5: new Uniform(new Color(`#${color5.hex}`)),
	            uColor6: new Uniform(new Color(`#${color6.hex}`)),
	            uColor7: new Uniform(new Color(`#${color7.hex}`)),

	        };
	        
	        const material = new B({
	            baseMaterial: MeshBasicMaterial,
	            color,
	            // MeshPhysicalMaterial
	            metalness: 0,
	            roughness: 0.5,
	            transmission: 1,
	            ior: 1.5,
	            thickness: 1.5,
	            transparent: true,
	            wireframe: false,

	            fragmentShader: fragmentShader$9,
	            vertexShader: vertexShader$a,
	            uniforms,      
	        });


	        const depthMaterial = new B({
	            baseMaterial: LineBasicMaterial,
	            
	            vertexShader: vertexShader$a,
	            uniforms,   
	            
	            depthPacking: RGBADepthPacking
	        });


	        const tick = (context) => {
	            uniforms.uTime.value = context.clock.time;

	            //console.log(context.analyser.data.avg)

	            uniforms.uStrength.value = context.analyser.data.avg * 0.2;
	        };

	        return {
	            uniforms, material, depthMaterial, tick
	        }
	    }




	}

	function Visualizer(params, program) {

	    const {context} = program;

	    const { 
	      color1 = { hex: 'FF9419' },
	      color2 = { hex: '140CFF' },
	      color3 = { hex: '140CFF' },
	    } = params;

	    const colors = [color1, color2, color3].map(c => new Color(`#${c.hex}`));

	    function generateParticles() {


	        const count = context.analyser.data.length;

	        const particles = emitter({
	            ...params,
	            count,
	            //vertexShader(count),
	            //fragmentShader: fragmentShader(shaderParams)
	        }, program);

	        return particles;
	    }
	    
	    const particles = generateParticles();


	    const { mesh, material, geometry, uniforms } = particles;

	    const tick = (context) => {

	          //console.log(context.analyser.data);

	          // note: update audio data
	          //analyser.getByteFrequencyData(dataArray);

	          // note: update uniforms
	          uniforms.uTime.value = context.clock.time;
	          //uniforms.u_data_arr.value = dataArray;
	      };
	      
	      return {
	          mesh, material, geometry, tick
	      }

	}

	class TextEffect$1 extends Shape$1 {
	    // default mesh
	    createMesh(program) {		
	        const container = new Group$1();

	        console.log(":::::::::: VISUALIZER", this.params);
	        
	        const visual = Visualizer(this.params, program);
	        container.add(visual.mesh);

	        
	        this.applyTransforms(container);

	        this.updateMaterials = (context) => {
	            visual.tick(context);
	        };

	        return container;
	    }

	    tick(context) {
	        if (context) {
	            if (this.updateMaterials) {
	                //this.bgMaterial.tick(context)
	                this.updateMaterials(context);
	            }
	            //console.log("lockscreen tick", context.clock.time)
	        }
	        
	    }

	    getMaterial(program, geometry) {}
	}

	class Environment extends Shape$1 {
		getGeometry(program) {
		}

	    // default mesh
	    createMesh(program, parent) {		


	        const color = new Color(...this.color);
	        

	    }

	        

	        

	    getMaterial(program, geometry) {
	        
	    }

	    tick(context) {
	        //console.log("lockscreen tick", context)
	    }


	}

	function waveLines(params, program) {
	    const { renderer } = program; 


	        // modelMatrix 
	        // viewMatrix 
	        // projectionMatrix
	    
	    const innerColor = new Color(params.innerColor);
	    const outerColor = new Color(params.outerColor);

	    const {branches = 3, spin = 0.4, 
	        length = 2,
	        lineThickness = 0.04,
	        freq = 2,
	        width = 2,
	        height = 2,
	        radius = 1.5, 
	        randomnessPow = 8, 
	        spacing = 10.5, // spacing between graphs
	        randomness: randomnessFreq = 0.5 
	    } = params;




	    const material = new LineMaterial({
	        color: 0xffffff,
	        linewidth: 5, // in world units with size attenuation, pixels otherwise
	        vertexColors: true,

	        dashed: false,
	        alphaToCoverage: true,
	    });

	    const points = [];
	    points.push( new Vector3( 0, 1, 0 ) );
	    points.push( new Vector3( 0, -1, 0 ) );
	    points.push( new Vector3( 0, 0, 0 ) );

	    const geometry = new BufferGeometry().setFromPoints( points );

	    const lineMesh = new Line2( geometry, material );

	    console.log("geometry", geometry);

	    const uniforms = {
	            uSize: { value: 80 * renderer.getPixelRatio() }, //
	            uTime: { value: 0 },
	            uResolution: new Uniform(new Vector2(
	                width,
		            height
	            ))
	        };

	    const tick = (context) => {
	        //console.log("wave tick")
	        uniforms.uTime.value = context.clock.time;
	    };

	    return { geometry, mesh: lineMesh, material, tick }
	}

	class LineGraph$2 extends Shape$1 {
		
	    // default mesh
	    createMesh(program) {
	        
	        const container = new Group$1();
	        
	        console.log(">>>>>> >>> WAVE LINES PARAMS", this.params);

	        const color = new Color(...this.color);

	        const { 
	            innercolor = { hex: 'ff5900' }, 
	            outercolor = { hex: '243dff' }, 
	            dither = 2, 
	            power = 4,
	            particle_count = 2000, 
	            branches = 3, 
	            radius = 1,
	            particleSize = 3.1,
	            particleSizePow = 2,
	            blending = 'normal', 
	            particleType = 'disc',
	            innerRadius = 0,
	            outerRadius = 1,
	            amp = 0.1,
	            spin = 1,
	            width = 1, height = 1,
	        } = this.params || {};

	        const params = {
	            color, width, height,
	        };
	        
	        const effect = waveLines(params, program);
	        container.add(effect.mesh);

	        console.log("effect", effect);


	        this.applyTransforms(container);

	    
	        this.tick = (context) => {
	            effect.tick(context);
	        };

	        // applies styles from expressions
	        this.applyStyle = (key, prop) => {
	    		
			
	        };

	        return container;
	    }


	    getMaterial(program, geometry) {

	        return 
	    }



	}

	/**
	 * A loader for the RGBE HDR texture format.
	 *
	 * ```js
	 * const loader = new RGBELoader();
	 * const envMap = await loader.loadAsync( 'textures/equirectangular/blouberg_sunrise_2_1k.hdr' );
	 * envMap.mapping = THREE.EquirectangularReflectionMapping;
	 *
	 * scene.environment = envMap;
	 * ```
	 *
	 * @augments DataTextureLoader
	 * @three_import import { RGBELoader } from 'three/addons/loaders/RGBELoader.js';
	 */
	class RGBELoader extends DataTextureLoader {

		/**
		 * Constructs a new RGBE loader.
		 *
		 * @param {LoadingManager} [manager] - The loading manager.
		 */
		constructor( manager ) {

			super( manager );

			/**
			 * The texture type.
			 *
			 * @type {(HalfFloatType|FloatType)}
			 * @default HalfFloatType
			 */
			this.type = HalfFloatType;

		}

		/**
		 * Parses the given RGBE texture data.
		 *
		 * @param {ArrayBuffer} buffer - The raw texture data.
		 * @return {DataTextureLoader~TexData} An object representing the parsed texture data.
		 */
		parse( buffer ) {

			// adapted from http://www.graphics.cornell.edu/~bjw/rgbe.html

			const
				/* default error routine.  change this to change error handling */
				rgbe_read_error = 1,
				rgbe_write_error = 2,
				rgbe_format_error = 3,
				rgbe_memory_error = 4,
				rgbe_error = function ( rgbe_error_code, msg ) {

					switch ( rgbe_error_code ) {

						case rgbe_read_error: throw new Error( 'THREE.RGBELoader: Read Error: ' + ( msg || '' ) );
						case rgbe_write_error: throw new Error( 'THREE.RGBELoader: Write Error: ' + ( msg || '' ) );
						case rgbe_format_error: throw new Error( 'THREE.RGBELoader: Bad File Format: ' + ( msg || '' ) );
						default:
						case rgbe_memory_error: throw new Error( 'THREE.RGBELoader: Memory Error: ' + ( msg || '' ) );

					}

				},

				/* offsets to red, green, and blue components in a data (float) pixel */
				//RGBE_DATA_RED = 0,
				//RGBE_DATA_GREEN = 1,
				//RGBE_DATA_BLUE = 2,

				/* number of floats per pixel, use 4 since stored in rgba image format */
				//RGBE_DATA_SIZE = 4,

				/* flags indicating which fields in an rgbe_header_info are valid */
				RGBE_VALID_PROGRAMTYPE = 1,
				RGBE_VALID_FORMAT = 2,
				RGBE_VALID_DIMENSIONS = 4,

				NEWLINE = '\n',

				fgets = function ( buffer, lineLimit, consume ) {

					const chunkSize = 128;

					lineLimit = ! lineLimit ? 1024 : lineLimit;
					let p = buffer.pos,
						i = - 1, len = 0, s = '',
						chunk = String.fromCharCode.apply( null, new Uint16Array( buffer.subarray( p, p + chunkSize ) ) );

					while ( ( 0 > ( i = chunk.indexOf( NEWLINE ) ) ) && ( len < lineLimit ) && ( p < buffer.byteLength ) ) {

						s += chunk; len += chunk.length;
						p += chunkSize;
						chunk += String.fromCharCode.apply( null, new Uint16Array( buffer.subarray( p, p + chunkSize ) ) );

					}

					if ( - 1 < i ) {

						/*for (i=l-1; i>=0; i--) {
							byteCode = m.charCodeAt(i);
							if (byteCode > 0x7f && byteCode <= 0x7ff) byteLen++;
							else if (byteCode > 0x7ff && byteCode <= 0xffff) byteLen += 2;
							if (byteCode >= 0xDC00 && byteCode <= 0xDFFF) i--; //trail surrogate
						}*/
						if ( false !== consume ) buffer.pos += len + i + 1;
						return s + chunk.slice( 0, i );

					}

					return false;

				},

				/* minimal header reading.  modify if you want to parse more information */
				RGBE_ReadHeader = function ( buffer ) {


					// regexes to parse header info fields
					const magic_token_re = /^#\?(\S+)/,
						gamma_re = /^\s*GAMMA\s*=\s*(\d+(\.\d+)?)\s*$/,
						exposure_re = /^\s*EXPOSURE\s*=\s*(\d+(\.\d+)?)\s*$/,
						format_re = /^\s*FORMAT=(\S+)\s*$/,
						dimensions_re = /^\s*\-Y\s+(\d+)\s+\+X\s+(\d+)\s*$/,

						// RGBE format header struct
						header = {

							valid: 0, /* indicate which fields are valid */

							string: '', /* the actual header string */

							comments: '', /* comments found in header */

							programtype: 'RGBE', /* listed at beginning of file to identify it after "#?". defaults to "RGBE" */

							format: '', /* RGBE format, default 32-bit_rle_rgbe */

							gamma: 1.0, /* image has already been gamma corrected with given gamma. defaults to 1.0 (no correction) */

							exposure: 1.0, /* a value of 1.0 in an image corresponds to <exposure> watts/steradian/m^2. defaults to 1.0 */

							width: 0, height: 0 /* image dimensions, width/height */

						};

					let line, match;

					if ( buffer.pos >= buffer.byteLength || ! ( line = fgets( buffer ) ) ) {

						rgbe_error( rgbe_read_error, 'no header found' );

					}

					/* if you want to require the magic token then uncomment the next line */
					if ( ! ( match = line.match( magic_token_re ) ) ) {

						rgbe_error( rgbe_format_error, 'bad initial token' );

					}

					header.valid |= RGBE_VALID_PROGRAMTYPE;
					header.programtype = match[ 1 ];
					header.string += line + '\n';

					while ( true ) {

						line = fgets( buffer );
						if ( false === line ) break;
						header.string += line + '\n';

						if ( '#' === line.charAt( 0 ) ) {

							header.comments += line + '\n';
							continue; // comment line

						}

						if ( match = line.match( gamma_re ) ) {

							header.gamma = parseFloat( match[ 1 ] );

						}

						if ( match = line.match( exposure_re ) ) {

							header.exposure = parseFloat( match[ 1 ] );

						}

						if ( match = line.match( format_re ) ) {

							header.valid |= RGBE_VALID_FORMAT;
							header.format = match[ 1 ];//'32-bit_rle_rgbe';

						}

						if ( match = line.match( dimensions_re ) ) {

							header.valid |= RGBE_VALID_DIMENSIONS;
							header.height = parseInt( match[ 1 ], 10 );
							header.width = parseInt( match[ 2 ], 10 );

						}

						if ( ( header.valid & RGBE_VALID_FORMAT ) && ( header.valid & RGBE_VALID_DIMENSIONS ) ) break;

					}

					if ( ! ( header.valid & RGBE_VALID_FORMAT ) ) {

						rgbe_error( rgbe_format_error, 'missing format specifier' );

					}

					if ( ! ( header.valid & RGBE_VALID_DIMENSIONS ) ) {

						rgbe_error( rgbe_format_error, 'missing image size specifier' );

					}

					return header;

				},

				RGBE_ReadPixels_RLE = function ( buffer, w, h ) {

					const scanline_width = w;

					if (
						// run length encoding is not allowed so read flat
						( ( scanline_width < 8 ) || ( scanline_width > 0x7fff ) ) ||
						// this file is not run length encoded
						( ( 2 !== buffer[ 0 ] ) || ( 2 !== buffer[ 1 ] ) || ( buffer[ 2 ] & 0x80 ) )
					) {

						// return the flat buffer
						return new Uint8Array( buffer );

					}

					if ( scanline_width !== ( ( buffer[ 2 ] << 8 ) | buffer[ 3 ] ) ) {

						rgbe_error( rgbe_format_error, 'wrong scanline width' );

					}

					const data_rgba = new Uint8Array( 4 * w * h );

					if ( ! data_rgba.length ) {

						rgbe_error( rgbe_memory_error, 'unable to allocate buffer space' );

					}

					let offset = 0, pos = 0;

					const ptr_end = 4 * scanline_width;
					const rgbeStart = new Uint8Array( 4 );
					const scanline_buffer = new Uint8Array( ptr_end );
					let num_scanlines = h;

					// read in each successive scanline
					while ( ( num_scanlines > 0 ) && ( pos < buffer.byteLength ) ) {

						if ( pos + 4 > buffer.byteLength ) {

							rgbe_error( rgbe_read_error );

						}

						rgbeStart[ 0 ] = buffer[ pos ++ ];
						rgbeStart[ 1 ] = buffer[ pos ++ ];
						rgbeStart[ 2 ] = buffer[ pos ++ ];
						rgbeStart[ 3 ] = buffer[ pos ++ ];

						if ( ( 2 != rgbeStart[ 0 ] ) || ( 2 != rgbeStart[ 1 ] ) || ( ( ( rgbeStart[ 2 ] << 8 ) | rgbeStart[ 3 ] ) != scanline_width ) ) {

							rgbe_error( rgbe_format_error, 'bad rgbe scanline format' );

						}

						// read each of the four channels for the scanline into the buffer
						// first red, then green, then blue, then exponent
						let ptr = 0, count;

						while ( ( ptr < ptr_end ) && ( pos < buffer.byteLength ) ) {

							count = buffer[ pos ++ ];
							const isEncodedRun = count > 128;
							if ( isEncodedRun ) count -= 128;

							if ( ( 0 === count ) || ( ptr + count > ptr_end ) ) {

								rgbe_error( rgbe_format_error, 'bad scanline data' );

							}

							if ( isEncodedRun ) {

								// a (encoded) run of the same value
								const byteValue = buffer[ pos ++ ];
								for ( let i = 0; i < count; i ++ ) {

									scanline_buffer[ ptr ++ ] = byteValue;

								}
								//ptr += count;

							} else {

								// a literal-run
								scanline_buffer.set( buffer.subarray( pos, pos + count ), ptr );
								ptr += count; pos += count;

							}

						}


						// now convert data from buffer into rgba
						// first red, then green, then blue, then exponent (alpha)
						const l = scanline_width; //scanline_buffer.byteLength;
						for ( let i = 0; i < l; i ++ ) {

							let off = 0;
							data_rgba[ offset ] = scanline_buffer[ i + off ];
							off += scanline_width; //1;
							data_rgba[ offset + 1 ] = scanline_buffer[ i + off ];
							off += scanline_width; //1;
							data_rgba[ offset + 2 ] = scanline_buffer[ i + off ];
							off += scanline_width; //1;
							data_rgba[ offset + 3 ] = scanline_buffer[ i + off ];
							offset += 4;

						}

						num_scanlines --;

					}

					return data_rgba;

				};

			const RGBEByteToRGBFloat = function ( sourceArray, sourceOffset, destArray, destOffset ) {

				const e = sourceArray[ sourceOffset + 3 ];
				const scale = Math.pow( 2.0, e - 128.0 ) / 255.0;

				destArray[ destOffset + 0 ] = sourceArray[ sourceOffset + 0 ] * scale;
				destArray[ destOffset + 1 ] = sourceArray[ sourceOffset + 1 ] * scale;
				destArray[ destOffset + 2 ] = sourceArray[ sourceOffset + 2 ] * scale;
				destArray[ destOffset + 3 ] = 1;

			};

			const RGBEByteToRGBHalf = function ( sourceArray, sourceOffset, destArray, destOffset ) {

				const e = sourceArray[ sourceOffset + 3 ];
				const scale = Math.pow( 2.0, e - 128.0 ) / 255.0;

				// clamping to 65504, the maximum representable value in float16
				destArray[ destOffset + 0 ] = DataUtils.toHalfFloat( Math.min( sourceArray[ sourceOffset + 0 ] * scale, 65504 ) );
				destArray[ destOffset + 1 ] = DataUtils.toHalfFloat( Math.min( sourceArray[ sourceOffset + 1 ] * scale, 65504 ) );
				destArray[ destOffset + 2 ] = DataUtils.toHalfFloat( Math.min( sourceArray[ sourceOffset + 2 ] * scale, 65504 ) );
				destArray[ destOffset + 3 ] = DataUtils.toHalfFloat( 1 );

			};

			const byteArray = new Uint8Array( buffer );
			byteArray.pos = 0;
			const rgbe_header_info = RGBE_ReadHeader( byteArray );

			const w = rgbe_header_info.width,
				h = rgbe_header_info.height,
				image_rgba_data = RGBE_ReadPixels_RLE( byteArray.subarray( byteArray.pos ), w, h );


			let data, type;
			let numElements;

			switch ( this.type ) {

				case FloatType:

					numElements = image_rgba_data.length / 4;
					const floatArray = new Float32Array( numElements * 4 );

					for ( let j = 0; j < numElements; j ++ ) {

						RGBEByteToRGBFloat( image_rgba_data, j * 4, floatArray, j * 4 );

					}

					data = floatArray;
					type = FloatType;
					break;

				case HalfFloatType:

					numElements = image_rgba_data.length / 4;
					const halfArray = new Uint16Array( numElements * 4 );

					for ( let j = 0; j < numElements; j ++ ) {

						RGBEByteToRGBHalf( image_rgba_data, j * 4, halfArray, j * 4 );

					}

					data = halfArray;
					type = HalfFloatType;
					break;

				default:

					throw new Error( 'THREE.RGBELoader: Unsupported type: ' + this.type );

			}

			return {
				width: w, height: h,
				data: data,
				header: rgbe_header_info.string,
				gamma: rgbe_header_info.gamma,
				exposure: rgbe_header_info.exposure,
				type: type
			};

		}

		/**
		 * Sets the texture type.
		 *
		 * @param {(HalfFloatType|FloatType)} value - The texture type to set.
		 * @return {RGBELoader} A reference to this loader.
		 */
		setDataType( value ) {

			this.type = value;
			return this;

		}

		load( url, onLoad, onProgress, onError ) {

			function onLoadCallback( texture, texData ) {

				switch ( texture.type ) {

					case FloatType:
					case HalfFloatType:

						texture.colorSpace = LinearSRGBColorSpace;
						texture.minFilter = LinearFilter;
						texture.magFilter = LinearFilter;
						texture.generateMipmaps = false;
						texture.flipY = true;

						break;

				}

				if ( onLoad ) onLoad( texture, texData );

			}

			return super.load( url, onLoadCallback, onProgress, onError );

		}

	}

	/**
	 * @webxr-input-profiles/motion-controllers 1.0.0 https://github.com/immersive-web/webxr-input-profiles
	 */

	const Constants = {
	  Handedness: Object.freeze({
	    NONE: 'none',
	    LEFT: 'left',
	    RIGHT: 'right'
	  }),

	  ComponentState: Object.freeze({
	    DEFAULT: 'default',
	    TOUCHED: 'touched',
	    PRESSED: 'pressed'
	  }),

	  ComponentProperty: Object.freeze({
	    BUTTON: 'button',
	    X_AXIS: 'xAxis',
	    Y_AXIS: 'yAxis',
	    STATE: 'state'
	  }),

	  ComponentType: Object.freeze({
	    TRIGGER: 'trigger',
	    SQUEEZE: 'squeeze',
	    TOUCHPAD: 'touchpad',
	    THUMBSTICK: 'thumbstick',
	    BUTTON: 'button'
	  }),

	  ButtonTouchThreshold: 0.05,

	  AxisTouchThreshold: 0.1,

	  VisualResponseProperty: Object.freeze({
	    TRANSFORM: 'transform',
	    VISIBILITY: 'visibility'
	  })
	};

	/**
	 * @description Static helper function to fetch a JSON file and turn it into a JS object
	 * @param {string} path - Path to JSON file to be fetched
	 */
	async function fetchJsonFile(path) {
	  const response = await fetch(path);
	  if (!response.ok) {
	    throw new Error(response.statusText);
	  } else {
	    return response.json();
	  }
	}

	async function fetchProfilesList(basePath) {
	  if (!basePath) {
	    throw new Error('No basePath supplied');
	  }

	  const profileListFileName = 'profilesList.json';
	  const profilesList = await fetchJsonFile(`${basePath}/${profileListFileName}`);
	  return profilesList;
	}

	async function fetchProfile(xrInputSource, basePath, defaultProfile = null, getAssetPath = true) {
	  if (!xrInputSource) {
	    throw new Error('No xrInputSource supplied');
	  }

	  if (!basePath) {
	    throw new Error('No basePath supplied');
	  }

	  // Get the list of profiles
	  const supportedProfilesList = await fetchProfilesList(basePath);

	  // Find the relative path to the first requested profile that is recognized
	  let match;
	  xrInputSource.profiles.some((profileId) => {
	    const supportedProfile = supportedProfilesList[profileId];
	    if (supportedProfile) {
	      match = {
	        profileId,
	        profilePath: `${basePath}/${supportedProfile.path}`,
	        deprecated: !!supportedProfile.deprecated
	      };
	    }
	    return !!match;
	  });

	  if (!match) {
	    if (!defaultProfile) {
	      throw new Error('No matching profile name found');
	    }

	    const supportedProfile = supportedProfilesList[defaultProfile];
	    if (!supportedProfile) {
	      throw new Error(`No matching profile name found and default profile "${defaultProfile}" missing.`);
	    }

	    match = {
	      profileId: defaultProfile,
	      profilePath: `${basePath}/${supportedProfile.path}`,
	      deprecated: !!supportedProfile.deprecated
	    };
	  }

	  const profile = await fetchJsonFile(match.profilePath);

	  let assetPath;
	  if (getAssetPath) {
	    let layout;
	    if (xrInputSource.handedness === 'any') {
	      layout = profile.layouts[Object.keys(profile.layouts)[0]];
	    } else {
	      layout = profile.layouts[xrInputSource.handedness];
	    }
	    if (!layout) {
	      throw new Error(
	        `No matching handedness, ${xrInputSource.handedness}, in profile ${match.profileId}`
	      );
	    }

	    if (layout.assetPath) {
	      assetPath = match.profilePath.replace('profile.json', layout.assetPath);
	    }
	  }

	  return { profile, assetPath };
	}

	/** @constant {Object} */
	const defaultComponentValues = {
	  xAxis: 0,
	  yAxis: 0,
	  button: 0,
	  state: Constants.ComponentState.DEFAULT
	};

	/**
	 * @description Converts an X, Y coordinate from the range -1 to 1 (as reported by the Gamepad
	 * API) to the range 0 to 1 (for interpolation). Also caps the X, Y values to be bounded within
	 * a circle. This ensures that thumbsticks are not animated outside the bounds of their physical
	 * range of motion and touchpads do not report touch locations off their physical bounds.
	 * @param {number} x The original x coordinate in the range -1 to 1
	 * @param {number} y The original y coordinate in the range -1 to 1
	 */
	function normalizeAxes(x = 0, y = 0) {
	  let xAxis = x;
	  let yAxis = y;

	  // Determine if the point is outside the bounds of the circle
	  // and, if so, place it on the edge of the circle
	  const hypotenuse = Math.sqrt((x * x) + (y * y));
	  if (hypotenuse > 1) {
	    const theta = Math.atan2(y, x);
	    xAxis = Math.cos(theta);
	    yAxis = Math.sin(theta);
	  }

	  // Scale and move the circle so values are in the interpolation range.  The circle's origin moves
	  // from (0, 0) to (0.5, 0.5). The circle's radius scales from 1 to be 0.5.
	  const result = {
	    normalizedXAxis: (xAxis * 0.5) + 0.5,
	    normalizedYAxis: (yAxis * 0.5) + 0.5
	  };
	  return result;
	}

	/**
	 * Contains the description of how the 3D model should visually respond to a specific user input.
	 * This is accomplished by initializing the object with the name of a node in the 3D model and
	 * property that need to be modified in response to user input, the name of the nodes representing
	 * the allowable range of motion, and the name of the input which triggers the change. In response
	 * to the named input changing, this object computes the appropriate weighting to use for
	 * interpolating between the range of motion nodes.
	 */
	class VisualResponse {
	  constructor(visualResponseDescription) {
	    this.componentProperty = visualResponseDescription.componentProperty;
	    this.states = visualResponseDescription.states;
	    this.valueNodeName = visualResponseDescription.valueNodeName;
	    this.valueNodeProperty = visualResponseDescription.valueNodeProperty;

	    if (this.valueNodeProperty === Constants.VisualResponseProperty.TRANSFORM) {
	      this.minNodeName = visualResponseDescription.minNodeName;
	      this.maxNodeName = visualResponseDescription.maxNodeName;
	    }

	    // Initializes the response's current value based on default data
	    this.value = 0;
	    this.updateFromComponent(defaultComponentValues);
	  }

	  /**
	   * Computes the visual response's interpolation weight based on component state
	   * @param {Object} componentValues - The component from which to update
	   * @param {number} xAxis - The reported X axis value of the component
	   * @param {number} yAxis - The reported Y axis value of the component
	   * @param {number} button - The reported value of the component's button
	   * @param {string} state - The component's active state
	   */
	  updateFromComponent({
	    xAxis, yAxis, button, state
	  }) {
	    const { normalizedXAxis, normalizedYAxis } = normalizeAxes(xAxis, yAxis);
	    switch (this.componentProperty) {
	      case Constants.ComponentProperty.X_AXIS:
	        this.value = (this.states.includes(state)) ? normalizedXAxis : 0.5;
	        break;
	      case Constants.ComponentProperty.Y_AXIS:
	        this.value = (this.states.includes(state)) ? normalizedYAxis : 0.5;
	        break;
	      case Constants.ComponentProperty.BUTTON:
	        this.value = (this.states.includes(state)) ? button : 0;
	        break;
	      case Constants.ComponentProperty.STATE:
	        if (this.valueNodeProperty === Constants.VisualResponseProperty.VISIBILITY) {
	          this.value = (this.states.includes(state));
	        } else {
	          this.value = this.states.includes(state) ? 1.0 : 0.0;
	        }
	        break;
	      default:
	        throw new Error(`Unexpected visualResponse componentProperty ${this.componentProperty}`);
	    }
	  }
	}

	class Component {
	  /**
	   * @param {Object} componentId - Id of the component
	   * @param {Object} componentDescription - Description of the component to be created
	   */
	  constructor(componentId, componentDescription) {
	    if (!componentId
	     || !componentDescription
	     || !componentDescription.visualResponses
	     || !componentDescription.gamepadIndices
	     || Object.keys(componentDescription.gamepadIndices).length === 0) {
	      throw new Error('Invalid arguments supplied');
	    }

	    this.id = componentId;
	    this.type = componentDescription.type;
	    this.rootNodeName = componentDescription.rootNodeName;
	    this.touchPointNodeName = componentDescription.touchPointNodeName;

	    // Build all the visual responses for this component
	    this.visualResponses = {};
	    Object.keys(componentDescription.visualResponses).forEach((responseName) => {
	      const visualResponse = new VisualResponse(componentDescription.visualResponses[responseName]);
	      this.visualResponses[responseName] = visualResponse;
	    });

	    // Set default values
	    this.gamepadIndices = Object.assign({}, componentDescription.gamepadIndices);

	    this.values = {
	      state: Constants.ComponentState.DEFAULT,
	      button: (this.gamepadIndices.button !== undefined) ? 0 : undefined,
	      xAxis: (this.gamepadIndices.xAxis !== undefined) ? 0 : undefined,
	      yAxis: (this.gamepadIndices.yAxis !== undefined) ? 0 : undefined
	    };
	  }

	  get data() {
	    const data = { id: this.id, ...this.values };
	    return data;
	  }

	  /**
	   * @description Poll for updated data based on current gamepad state
	   * @param {Object} gamepad - The gamepad object from which the component data should be polled
	   */
	  updateFromGamepad(gamepad) {
	    // Set the state to default before processing other data sources
	    this.values.state = Constants.ComponentState.DEFAULT;

	    // Get and normalize button
	    if (this.gamepadIndices.button !== undefined
	        && gamepad.buttons.length > this.gamepadIndices.button) {
	      const gamepadButton = gamepad.buttons[this.gamepadIndices.button];
	      this.values.button = gamepadButton.value;
	      this.values.button = (this.values.button < 0) ? 0 : this.values.button;
	      this.values.button = (this.values.button > 1) ? 1 : this.values.button;

	      // Set the state based on the button
	      if (gamepadButton.pressed || this.values.button === 1) {
	        this.values.state = Constants.ComponentState.PRESSED;
	      } else if (gamepadButton.touched || this.values.button > Constants.ButtonTouchThreshold) {
	        this.values.state = Constants.ComponentState.TOUCHED;
	      }
	    }

	    // Get and normalize x axis value
	    if (this.gamepadIndices.xAxis !== undefined
	        && gamepad.axes.length > this.gamepadIndices.xAxis) {
	      this.values.xAxis = gamepad.axes[this.gamepadIndices.xAxis];
	      this.values.xAxis = (this.values.xAxis < -1) ? -1 : this.values.xAxis;
	      this.values.xAxis = (this.values.xAxis > 1) ? 1 : this.values.xAxis;

	      // If the state is still default, check if the xAxis makes it touched
	      if (this.values.state === Constants.ComponentState.DEFAULT
	        && Math.abs(this.values.xAxis) > Constants.AxisTouchThreshold) {
	        this.values.state = Constants.ComponentState.TOUCHED;
	      }
	    }

	    // Get and normalize Y axis value
	    if (this.gamepadIndices.yAxis !== undefined
	        && gamepad.axes.length > this.gamepadIndices.yAxis) {
	      this.values.yAxis = gamepad.axes[this.gamepadIndices.yAxis];
	      this.values.yAxis = (this.values.yAxis < -1) ? -1 : this.values.yAxis;
	      this.values.yAxis = (this.values.yAxis > 1) ? 1 : this.values.yAxis;

	      // If the state is still default, check if the yAxis makes it touched
	      if (this.values.state === Constants.ComponentState.DEFAULT
	        && Math.abs(this.values.yAxis) > Constants.AxisTouchThreshold) {
	        this.values.state = Constants.ComponentState.TOUCHED;
	      }
	    }

	    // Update the visual response weights based on the current component data
	    Object.values(this.visualResponses).forEach((visualResponse) => {
	      visualResponse.updateFromComponent(this.values);
	    });
	  }
	}

	/**
	  * @description Builds a motion controller with components and visual responses based on the
	  * supplied profile description. Data is polled from the xrInputSource's gamepad.
	  * @author Nell Waliczek / https://github.com/NellWaliczek
	*/
	class MotionController {
	  /**
	   * @param {Object} xrInputSource - The XRInputSource to build the MotionController around
	   * @param {Object} profile - The best matched profile description for the supplied xrInputSource
	   * @param {string} assetUrl
	   */
	  constructor(xrInputSource, profile, assetUrl) {
	    if (!xrInputSource) {
	      throw new Error('No xrInputSource supplied');
	    }

	    if (!profile) {
	      throw new Error('No profile supplied');
	    }

	    this.xrInputSource = xrInputSource;
	    this.assetUrl = assetUrl;
	    this.id = profile.profileId;

	    // Build child components as described in the profile description
	    this.layoutDescription = profile.layouts[xrInputSource.handedness];
	    this.components = {};
	    Object.keys(this.layoutDescription.components).forEach((componentId) => {
	      const componentDescription = this.layoutDescription.components[componentId];
	      this.components[componentId] = new Component(componentId, componentDescription);
	    });

	    // Initialize components based on current gamepad state
	    this.updateFromGamepad();
	  }

	  get gripSpace() {
	    return this.xrInputSource.gripSpace;
	  }

	  get targetRaySpace() {
	    return this.xrInputSource.targetRaySpace;
	  }

	  /**
	   * @description Returns a subset of component data for simplified debugging
	   */
	  get data() {
	    const data = [];
	    Object.values(this.components).forEach((component) => {
	      data.push(component.data);
	    });
	    return data;
	  }

	  /**
	   * @description Poll for updated data based on current gamepad state
	   */
	  updateFromGamepad() {
	    Object.values(this.components).forEach((component) => {
	      component.updateFromGamepad(this.xrInputSource.gamepad);
	    });
	  }
	}

	const DEFAULT_PROFILES_PATH = 'https://cdn.jsdelivr.net/npm/@webxr-input-profiles/assets@1.0/dist/profiles';
	const DEFAULT_PROFILE = 'generic-trigger';

	/**
	 * Represents a XR controller model.
	 *
	 * @augments Object3D
	 */
	class XRControllerModel extends Object3D {

		/**
		 * Constructs a new XR controller model.
		 */
		constructor() {

			super();

			/**
			 * The motion controller.
			 *
			 * @type {?MotionController}
			 * @default null
			 */
			this.motionController = null;

			/**
			 * The controller's environment map.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.envMap = null;

		}

		/**
		 * Sets an environment map that is applied to the controller model.
		 *
		 * @param {?Texture} envMap - The environment map to apply.
		 * @return {XRControllerModel} A reference to this instance.
		 */
		setEnvironmentMap( envMap ) {

			if ( this.envMap == envMap ) {

				return this;

			}

			this.envMap = envMap;
			this.traverse( ( child ) => {

				if ( child.isMesh ) {

					child.material.envMap = this.envMap;
					child.material.needsUpdate = true;

				}

			} );

			return this;

		}

		/**
		 * Overwritten with a custom implementation. Polls data from the XRInputSource and updates the
		 * model's components to match the real world data.
		 *
		 * @param {boolean} [force=false] - When set to `true`, a recomputation of world matrices is forced even
		 * when {@link Object3D#matrixWorldAutoUpdate} is set to `false`.
		 */
		updateMatrixWorld( force ) {

			super.updateMatrixWorld( force );

			if ( ! this.motionController ) return;

			// Cause the MotionController to poll the Gamepad for data
			this.motionController.updateFromGamepad();

			// Update the 3D model to reflect the button, thumbstick, and touchpad state
			Object.values( this.motionController.components ).forEach( ( component ) => {

				// Update node data based on the visual responses' current states
				Object.values( component.visualResponses ).forEach( ( visualResponse ) => {

					const { valueNode, minNode, maxNode, value, valueNodeProperty } = visualResponse;

					// Skip if the visual response node is not found. No error is needed,
					// because it will have been reported at load time.
					if ( ! valueNode ) return;

					// Calculate the new properties based on the weight supplied
					if ( valueNodeProperty === Constants.VisualResponseProperty.VISIBILITY ) {

						valueNode.visible = value;

					} else if ( valueNodeProperty === Constants.VisualResponseProperty.TRANSFORM ) {

						valueNode.quaternion.slerpQuaternions(
							minNode.quaternion,
							maxNode.quaternion,
							value
						);

						valueNode.position.lerpVectors(
							minNode.position,
							maxNode.position,
							value
						);

					}

				} );

			} );

		}

	}

	/**
	 * Walks the model's tree to find the nodes needed to animate the components and
	 * saves them to the motionController components for use in the frame loop. When
	 * touchpads are found, attaches a touch dot to them.
	 *
	 * @private
	 * @param {MotionController} motionController
	 * @param {Object3D} scene
	 */
	function findNodes( motionController, scene ) {

		// Loop through the components and find the nodes needed for each components' visual responses
		Object.values( motionController.components ).forEach( ( component ) => {

			const { type, touchPointNodeName, visualResponses } = component;

			if ( type === Constants.ComponentType.TOUCHPAD ) {

				component.touchPointNode = scene.getObjectByName( touchPointNodeName );
				if ( component.touchPointNode ) {

					// Attach a touch dot to the touchpad.
					const sphereGeometry = new SphereGeometry( 0.001 );
					const material = new MeshBasicMaterial( { color: 0x0000FF } );
					const sphere = new Mesh( sphereGeometry, material );
					component.touchPointNode.add( sphere );

				} else {

					console.warn( `Could not find touch dot, ${component.touchPointNodeName}, in touchpad component ${component.id}` );

				}

			}

			// Loop through all the visual responses to be applied to this component
			Object.values( visualResponses ).forEach( ( visualResponse ) => {

				const { valueNodeName, minNodeName, maxNodeName, valueNodeProperty } = visualResponse;

				// If animating a transform, find the two nodes to be interpolated between.
				if ( valueNodeProperty === Constants.VisualResponseProperty.TRANSFORM ) {

					visualResponse.minNode = scene.getObjectByName( minNodeName );
					visualResponse.maxNode = scene.getObjectByName( maxNodeName );

					// If the extents cannot be found, skip this animation
					if ( ! visualResponse.minNode ) {

						console.warn( `Could not find ${minNodeName} in the model` );
						return;

					}

					if ( ! visualResponse.maxNode ) {

						console.warn( `Could not find ${maxNodeName} in the model` );
						return;

					}

				}

				// If the target node cannot be found, skip this animation
				visualResponse.valueNode = scene.getObjectByName( valueNodeName );
				if ( ! visualResponse.valueNode ) {

					console.warn( `Could not find ${valueNodeName} in the model` );

				}

			} );

		} );

	}

	function addAssetSceneToControllerModel( controllerModel, scene ) {

		// Find the nodes needed for animation and cache them on the motionController.
		findNodes( controllerModel.motionController, scene );

		// Apply any environment map that the mesh already has set.
		if ( controllerModel.envMap ) {

			scene.traverse( ( child ) => {

				if ( child.isMesh ) {

					child.material.envMap = controllerModel.envMap;
					child.material.needsUpdate = true;

				}

			} );

		}

		// Add the glTF scene to the controllerModel.
		controllerModel.add( scene );

	}

	/**
	 * Allows to create controller models for WebXR controllers that can be added as a visual
	 * representation to your scene. `XRControllerModelFactory` will automatically fetch controller
	 * models that match what the user is holding as closely as possible. The models should be
	 * attached to the object returned from getControllerGrip in order to match the orientation of
	 * the held device.
	 *
	 * This module depends on the [motion-controllers]{@link https://github.com/immersive-web/webxr-input-profiles/blob/main/packages/motion-controllers/README.md}
	 * third-part library.
	 *
	 * ```js
	 * const controllerModelFactory = new XRControllerModelFactory();
	 *
	 * const controllerGrip = renderer.xr.getControllerGrip( 0 );
	 * controllerGrip.add( controllerModelFactory.createControllerModel( controllerGrip ) );
	 * scene.add( controllerGrip );
	 * ```
	 *
	 * @three_import import { XRControllerModelFactory } from 'three/addons/webxr/XRControllerModelFactory.js';
	 */
	class XRControllerModelFactory {

		/**
		 * Constructs a new XR controller model factory.
		 *
		 * @param {?GLTFLoader} [gltfLoader=null] - A glTF loader that is used to load controller models.
		 * @param {?Function} [onLoad=null] - A callback that is executed when a controller model has been loaded.
		 */
		constructor( gltfLoader = null, onLoad = null ) {

			/**
			 * A glTF loader that is used to load controller models.
			 *
			 * @type {?GLTFLoader}
			 * @default null
			 */
			this.gltfLoader = gltfLoader;

			/**
			 * The path to the model repository.
			 *
			 * @type {string}
			 */
			this.path = DEFAULT_PROFILES_PATH;
			this._assetCache = {};

			/**
			 * A callback that is executed when a controller model has been loaded.
			 *
			 * @type {?Function}
			 * @default null
			 */
			this.onLoad = onLoad;

			// If a GLTFLoader wasn't supplied to the constructor create a new one.
			if ( ! this.gltfLoader ) {

				this.gltfLoader = new GLTFLoader();

			}

		}

		/**
		 * Sets the path to the model repository.
		 *
		 * @param {string} path - The path to set.
		 * @return {XRControllerModelFactory} A reference to this instance.
		 */
		setPath( path ) {

			this.path = path;

			return this;

		}

		/**
		 * Creates a controller model for the given WebXR controller.
		 *
		 * @param {Group} controller - The controller.
		 * @return {XRControllerModel} The XR controller model.
		 */
		createControllerModel( controller ) {

			const controllerModel = new XRControllerModel();
			let scene = null;

			controller.addEventListener( 'connected', ( event ) => {

				const xrInputSource = event.data;

				if ( xrInputSource.targetRayMode !== 'tracked-pointer' || ! xrInputSource.gamepad || xrInputSource.hand ) return;

				fetchProfile( xrInputSource, this.path, DEFAULT_PROFILE ).then( ( { profile, assetPath } ) => {

					controllerModel.motionController = new MotionController(
						xrInputSource,
						profile,
						assetPath
					);

					const cachedAsset = this._assetCache[ controllerModel.motionController.assetUrl ];
					if ( cachedAsset ) {

						scene = cachedAsset.scene.clone();

						addAssetSceneToControllerModel( controllerModel, scene );

						if ( this.onLoad ) this.onLoad( scene );

					} else {

						if ( ! this.gltfLoader ) {

							throw new Error( 'GLTFLoader not set.' );

						}

						this.gltfLoader.setPath( '' );
						this.gltfLoader.load( controllerModel.motionController.assetUrl, ( asset ) => {

							this._assetCache[ controllerModel.motionController.assetUrl ] = asset;

							scene = asset.scene.clone();

							addAssetSceneToControllerModel( controllerModel, scene );

							if ( this.onLoad ) this.onLoad( scene );

						},
						null,
						() => {

							throw new Error( `Asset ${controllerModel.motionController.assetUrl} missing or malformed.` );

						} );

					}

				} ).catch( ( err ) => {

					console.warn( err );

				} );

			} );

			controller.addEventListener( 'disconnected', () => {

				controllerModel.motionController = null;
				controllerModel.remove( scene );
				scene = null;

			} );

			return controllerModel;

		}

	}

	const DEFAULT_HAND_PROFILE_PATH = 'https://cdn.jsdelivr.net/npm/@webxr-input-profiles/assets@1.0/dist/profiles/generic-hand/';

	/**
	 * Represents one of the hand model types {@link XRHandModelFactory} might produce
	 * depending on the selected profile. `XRHandMeshModel` represents a hand with a
	 * custom asset.
	 *
	 * @three_import import { XRHandMeshModel } from 'three/addons/webxr/XRHandMeshModel.js';
	 */
	class XRHandMeshModel {

		/**
		 * Constructs a new XR hand mesh model.
		 *
		 * @param {XRHandModel} handModel - The hand model.
		 * @param {Group} controller - The WebXR controller.
		 * @param {?string} path - The model path.
		 * @param {XRHandedness} handedness - The handedness of the XR input source.
		 * @param {?Loader} [loader=null] - The loader. If not provided, an instance of `GLTFLoader` will be used to load models.
		 * @param {?Function} [onLoad=null] - A callback that is executed when a controller model has been loaded.
		 */
		constructor( handModel, controller, path, handedness, loader = null, onLoad = null ) {

			/**
			 * The WebXR controller.
			 *
			 * @type {Group}
			 */
			this.controller = controller;

			/**
			 * The hand model.
			 *
			 * @type {XRHandModel}
			 */
			this.handModel = handModel;

			/**
			 * An array of bones representing the bones
			 * of the hand skeleton.
			 *
			 * @type {Array<Bone>}
			 */
			this.bones = [];

			if ( loader === null ) {

				loader = new GLTFLoader();
				loader.setPath( path || DEFAULT_HAND_PROFILE_PATH );

			}

			loader.load( `${handedness}.glb`, gltf => {

				const object = gltf.scene.children[ 0 ];
				this.handModel.add( object );

				const mesh = object.getObjectByProperty( 'type', 'SkinnedMesh' );
				mesh.frustumCulled = false;
				mesh.castShadow = true;
				mesh.receiveShadow = true;

				const joints = [
					'wrist',
					'thumb-metacarpal',
					'thumb-phalanx-proximal',
					'thumb-phalanx-distal',
					'thumb-tip',
					'index-finger-metacarpal',
					'index-finger-phalanx-proximal',
					'index-finger-phalanx-intermediate',
					'index-finger-phalanx-distal',
					'index-finger-tip',
					'middle-finger-metacarpal',
					'middle-finger-phalanx-proximal',
					'middle-finger-phalanx-intermediate',
					'middle-finger-phalanx-distal',
					'middle-finger-tip',
					'ring-finger-metacarpal',
					'ring-finger-phalanx-proximal',
					'ring-finger-phalanx-intermediate',
					'ring-finger-phalanx-distal',
					'ring-finger-tip',
					'pinky-finger-metacarpal',
					'pinky-finger-phalanx-proximal',
					'pinky-finger-phalanx-intermediate',
					'pinky-finger-phalanx-distal',
					'pinky-finger-tip',
				];

				joints.forEach( jointName => {

					const bone = object.getObjectByName( jointName );

					if ( bone !== undefined ) {

						bone.jointName = jointName;

					} else {

						console.warn( `Couldn't find ${jointName} in ${handedness} hand mesh` );

					}

					this.bones.push( bone );

				} );

				if ( onLoad ) onLoad( object );

			} );

		}

		/**
		 * Updates the mesh based on the tracked XR joints data.
		 */
		updateMesh() {

			// XR Joints
			const XRJoints = this.controller.joints;

			for ( let i = 0; i < this.bones.length; i ++ ) {

				const bone = this.bones[ i ];

				if ( bone ) {

					const XRJoint = XRJoints[ bone.jointName ];

					if ( XRJoint.visible ) {

						const position = XRJoint.position;

						bone.position.copy( position );
						bone.quaternion.copy( XRJoint.quaternion );
						// bone.scale.setScalar( XRJoint.jointRadius || defaultRadius );

					}

				}

			}

		}

	}

	const log = (...args) => {
	    console.log(...args);
	};

	const _matrix$1 = new Matrix4();
	const _vector$1 = new Vector3();

	/**
	 * Represents one of the hand model types {@link XRHandModelFactory} might produce
	 * depending on the selected profile. `XRHandPrimitiveModel` represents a hand
	 * with sphere or box primitives according to the selected `primitive` option.
	 *
	 * @three_import import { XRHandPrimitiveModel } from 'three/addons/webxr/XRHandPrimitiveModel.js';
	 */
	class XRHandPrimitiveModel {

		/**
		 * Constructs a new XR hand primitive model.
		 *
		 * @param {XRHandModel} handModel - The hand model.
		 * @param {Group} controller - The WebXR controller.
		 * @param {string} path - The model path.
		 * @param {XRHandedness} handedness - The handedness of the XR input source.
		 * @param {XRHandPrimitiveModel~Options} options - The model options.
		 */
		constructor( handModel, controller, path, handedness, options ) {

			/**
			 * The WebXR controller.
			 *
			 * @type {Group}
			 */
			this.controller = controller;

			/**
			 * The hand model.
			 *
			 * @type {XRHandModel}
			 */
			this.handModel = handModel;

			/**
			 * The model's environment map.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.envMap = null;

			let geometry;

			if ( ! options || ! options.primitive || options.primitive === 'sphere' ) {

				geometry = new SphereGeometry( 1, 10, 10 );

			} else if ( options.primitive === 'box' ) {

				geometry = new BoxGeometry( 1, 1, 1 );

			}

			const material = new MeshStandardMaterial();

			this.handMesh = new InstancedMesh( geometry, material, 30 );
			this.handMesh.frustumCulled = false;
			this.handMesh.instanceMatrix.setUsage( DynamicDrawUsage ); // will be updated every frame
			this.handMesh.castShadow = true;
			this.handMesh.receiveShadow = true;
			this.handModel.add( this.handMesh );

			this.joints = [
				'wrist',
				'thumb-metacarpal',
				'thumb-phalanx-proximal',
				'thumb-phalanx-distal',
				'thumb-tip',
				'index-finger-metacarpal',
				'index-finger-phalanx-proximal',
				'index-finger-phalanx-intermediate',
				'index-finger-phalanx-distal',
				'index-finger-tip',
				'middle-finger-metacarpal',
				'middle-finger-phalanx-proximal',
				'middle-finger-phalanx-intermediate',
				'middle-finger-phalanx-distal',
				'middle-finger-tip',
				'ring-finger-metacarpal',
				'ring-finger-phalanx-proximal',
				'ring-finger-phalanx-intermediate',
				'ring-finger-phalanx-distal',
				'ring-finger-tip',
				'pinky-finger-metacarpal',
				'pinky-finger-phalanx-proximal',
				'pinky-finger-phalanx-intermediate',
				'pinky-finger-phalanx-distal',
				'pinky-finger-tip'
			];

		}

		/**
		 * Updates the mesh based on the tracked XR joints data.
		 */
		updateMesh() {

			const defaultRadius = 0.008;
			const joints = this.controller.joints;

			let count = 0;

			for ( let i = 0; i < this.joints.length; i ++ ) {

				const joint = joints[ this.joints[ i ] ];

				if ( joint.visible ) {

					_vector$1.setScalar( joint.jointRadius || defaultRadius );
					_matrix$1.compose( joint.position, joint.quaternion, _vector$1 );
					this.handMesh.setMatrixAt( i, _matrix$1 );

					count ++;

				}

			}

			this.handMesh.count = count;
			this.handMesh.instanceMatrix.needsUpdate = true;

		}

	}

	/**
	 * Represents a XR hand model.
	 *
	 * @augments Object3D
	 */
	class XRHandModel extends Object3D {

		/**
		 * Constructs a new XR hand model.
		 *
		 * @param {Group} controller - The hand controller.
		 */
		constructor( controller ) {

			super();

			/**
			 * The hand controller.
			 *
			 * @type {Group}
			 */
			this.controller = controller;

			/**
			 * The motion controller.
			 *
			 * @type {?MotionController}
			 * @default null
			 */
			this.motionController = null;

			/**
			 * The controller's environment map.
			 *
			 * @type {?Texture}
			 * @default null
			 */
			this.envMap = null;

			/**
			 * The model mesh.
			 *
			 * @type {Mesh}
			 * @default null
			 */
			this.mesh = null;

		}

		/**
		 * Overwritten with a custom implementation. Makes sure the motion controller updates the mesh.
		 *
		 * @param {boolean} [force=false] - When set to `true`, a recomputation of world matrices is forced even
		 * when {@link Object3D#matrixWorldAutoUpdate} is set to `false`.
		 */
		updateMatrixWorld( force ) {

			super.updateMatrixWorld( force );

			if ( this.motionController ) {

				this.motionController.updateMesh();

			}

		}

	}

	/**
	 * Similar to {@link XRControllerModelFactory}, this class allows to create hand models
	 * for WebXR controllers that can be added as a visual representation to your scene.
	 *
	 * ```js
	 * const handModelFactory = new XRHandModelFactory();
	 *
	 * const hand = renderer.xr.getHand( 0 );
	 * hand.add( handModelFactory.createHandModel( hand ) );
	 * scene.add( hand );
	 * ```
	 *
	 * @three_import import { XRHandModelFactory } from 'three/addons/webxr/XRHandModelFactory.js';
	 */
	class XRHandModelFactory {

		/**
		 * Constructs a new XR hand model factory.
		 *
		 * @param {?GLTFLoader} [gltfLoader=null] - A glTF loader that is used to load hand models.
		 * @param {?Function} [onLoad=null] - A callback that is executed when a hand model has been loaded.
		 */
		constructor( gltfLoader = null, onLoad = null ) {

			/**
			 * A glTF loader that is used to load hand models.
			 *
			 * @type {?GLTFLoader}
			 * @default null
			 */
			this.gltfLoader = gltfLoader;

			/**
			 * The path to the model repository.
			 *
			 * @type {?string}
			 * @default null
			 */
			this.path = null;

			/**
			 * A callback that is executed when a hand model has been loaded.
			 *
			 * @type {?Function}
			 * @default null
			 */
			this.onLoad = onLoad;

		}

		/**
		 * Sets the path to the hand model repository.
		 *
		 * @param {string} path - The path to set.
		 * @return {XRHandModelFactory} A reference to this instance.
		 */
		setPath( path ) {

			this.path = path;

			return this;

		}

		/**
		 * Creates a controller model for the given WebXR hand controller.
		 *
		 * @param {Group} controller - The hand controller.
		 * @param {('spheres'|'boxes'|'mesh')} [profile] - The model profile that defines the model type.
		 * @return {XRHandModel} The XR hand model.
		 */
		createHandModel( controller, profile ) {

			const handModel = new XRHandModel( controller );

			controller.addEventListener( 'connected', ( event ) => {

				const xrInputSource = event.data;

				if ( xrInputSource.hand && ! handModel.motionController ) {

					handModel.xrInputSource = xrInputSource;

					// @todo Detect profile if not provided
					if ( profile === undefined || profile === 'spheres' ) {

						handModel.motionController = new XRHandPrimitiveModel( handModel, controller, this.path, xrInputSource.handedness, { primitive: 'sphere' } );

					} else if ( profile === 'boxes' ) {

						handModel.motionController = new XRHandPrimitiveModel( handModel, controller, this.path, xrInputSource.handedness, { primitive: 'box' } );

					} else if ( profile === 'mesh' ) {

						handModel.motionController = new XRHandMeshModel( handModel, controller, this.path, xrInputSource.handedness, this.gltfLoader, this.onLoad );

					}

				}

				controller.visible = true;

			} );

			controller.addEventListener( 'disconnected', () => {

				controller.visible = false;
				// handModel.motionController = null;
				// handModel.remove( scene );
				// scene = null;

			} );

			return handModel;

		}

	}

	class Skybox extends Shape$1 {
		

	    // default mesh
	    createMesh(program) {	
	        
	        

	        const { 
	            map = '' // url
	        } = this.params;

	        const { scene, renderer } = program;

	        const loader = new RGBELoader();

	        const container = new Group$1();

	        let geometry;
	        let mesh;
	        let material;
	        let texture;
	        
	        let textureLoader = new TextureLoader();

	        const sphereSkyBox = () => {

	            geometry = new SphereGeometry(90, 60, 60);
	                    //tex.colorSpace = THREE.SRGBColorSpace;

	            texture = textureLoader.load(map, (tex) => {
	                 // let planetGeometry = new THREE.SphereGeometry(1, 60, 60);                    
	                //planetMesh = new THREE.Mesh(planetGeometry, skySphereMaterial);
	                //planetMesh.position.z = -1;
	                //container.add(planetMesh);
	            });
	                   
	            material = new MeshBasicMaterial({
	                map: texture,
	                transparent: true, // Enable transparency
	                opacity: 1.0, // Start fully opaque
	            });
	        
	            material.side = BackSide;

	            mesh = new Mesh(geometry, material);
	            
	            container.add(mesh);
	                
	        };

	        //normalSkyBox()
	        sphereSkyBox();

	        

	        //const innerMap = context.files.envmaps.children.filter((f) => f.conf.extn === 'png');
	        //    console.log("available maps", innerMap);


	        const innerMap = [];
	        
	        let innerSky;


	        if (innerMap[0]) {
	            textureLoader.load(innerMap[0].url, (tex) => {

	                log("innermesh loaded", tex);

	                scene.environment = tex;
	                
	                let innerSphereGeometry = new SphereGeometry(40, 60, 60);
	                //tex.colorSpace = THREE.SRGBColorSpace;
	                
	                const skySphereMaterial = new MeshBasicMaterial({
	                    map: tex,
	                    transparent: true, // Enable transparency
	                    opacity: 1, // Start fully opaque
	                    blending: NormalBlending
	                });
	            
	                skySphereMaterial.side = BackSide;

	                const skymesh = new Mesh(innerSphereGeometry, skySphereMaterial);
	                
	                
	                //container.add(skymesh);

	                innerSky = skymesh;
	                innerSky.rotation.y = Math.PI;

	                // let planetGeometry = new THREE.SphereGeometry(1, 60, 60);                    
	                //planetMesh = new THREE.Mesh(planetGeometry, skySphereMaterial);
	                //planetMesh.position.z = -1;
	                //container.add(planetMesh);


	            });
	        }
	        
	        
	        

	        this.tick = (context) => {
	            const { time  } = context.clock;

	            // interact.tick(context)
	            if (mesh) {
	                mesh.rotation.y += 0.00025;
	                
	            }
	            if (innerSky) {
	                 innerSky.rotation.y += 0.00030;
	                 
	            }
	            // cubeCamera.update(renderer, scene);
	        };



	        this.destroy = () => {
	            if (texture) {
	                log("DISPOSED TEXTURE");
	                texture.dispose();
	            }
	            if (mesh) {
	                geometry.dispose();
	                material.dispose();
	                mesh.removeFromParent();
	            }

	            container.clear();
	            container.removeFromParent();

	            log("DESTROY SKY MESH", mesh, material, texture);
	        };


	        return container;
	        
	    }   


	}

	const EMITTERS = {
	    fire: (params, program) => {
	        // set some defaults for fire
	        return emitter(params, program)
	    }
	};



	class ParticleEmitter extends Shape$1 {
	    getGeometry(program) {
			
		}
	    // default mesh
	    createMesh(program) {		
	        
	        const { 
	            particleType = 'fire' 
	        } = this.params;

	//        console.log("PARTICLE EMITTER", this.params)

	        const createParticleEmitter = EMITTERS[particleType];

	        const emitter = createParticleEmitter(this.params, program); // ;

	        const container = new Group$1();        
	        container.add(emitter.mesh);

	        this.applyTransforms(container);

	        this.tick = (context) => {
	            emitter.tick(context);
	        };

	        return container;
	    }


	}

	function e$1(e,t,r,n){return new(r||(r=Promise))((function(o,a){function i(e){try{d(n.next(e));}catch(e){a(e);}}function c(e){try{d(n.throw(e));}catch(e){a(e);}}function d(e){var t;e.done?o(e.value):(t=e.value,t instanceof r?t:new r((function(e){e(t);}))).then(i,c);}d((n=n.apply(e,t||[])).next());}))}"function"==typeof SuppressedError&&SuppressedError;const t=["geforce 320m","geforce 8600","geforce 8600m gt","geforce 8800 gs","geforce 8800 gt","geforce 9400","geforce 9400m g","geforce 9400m","geforce 9600m gt","geforce 9600m","geforce fx go5200","geforce gt 120","geforce gt 130","geforce gt 330m","geforce gtx 285","google swiftshader","intel g41","intel g45","intel gma 4500mhd","intel gma x3100","intel hd 3000","intel q45","legacy","mali-2","mali-3","mali-4","quadro fx 1500","quadro fx 4","quadro fx 5","radeon hd 2400","radeon hd 2600","radeon hd 4670","radeon hd 4850","radeon hd 4870","radeon hd 5670","radeon hd 5750","radeon hd 6290","radeon hd 6300","radeon hd 6310","radeon hd 6320","radeon hd 6490m","radeon hd 6630m","radeon hd 6750m","radeon hd 6770m","radeon hd 6970m","sgx 543","sgx543"];function r(e){return e=e.toLowerCase().replace(/.*angle ?\((.+)\)(?: on vulkan [0-9.]+)?$/i,"$1").replace(/\s(\d{1,2}gb|direct3d.+$)|\(r\)| \([^)]+\)$/g,"").replace(/(?:vulkan|opengl) \d+\.\d+(?:\.\d+)?(?: \((.*)\))?/,"$1")}const n="undefined"==typeof window,o=(()=>{if(n)return;const{userAgent:e,platform:t,maxTouchPoints:r}=window.navigator,o=/(iphone|ipod|ipad)/i.test(e),a="iPad"===t||"MacIntel"===t&&r>0&&!window.MSStream;return {isIpad:a,isMobile:/android/i.test(e)||o||a,isSafari12:/Version\/12.+Safari/.test(e),isFirefox:/Firefox/.test(e)}})();function a(e,t,r){if(!r)return [t];const n=function(e){const t="\n    precision highp float;\n    attribute vec3 aPosition;\n    varying float vvv;\n    void main() {\n      vvv = 0.31622776601683794;\n      gl_Position = vec4(aPosition, 1.0);\n    }\n  ",r="\n    precision highp float;\n    varying float vvv;\n    void main() {\n      vec4 enc = vec4(1.0, 255.0, 65025.0, 16581375.0) * vvv;\n      enc = fract(enc);\n      enc -= enc.yzww * vec4(1.0 / 255.0, 1.0 / 255.0, 1.0 / 255.0, 0.0);\n      gl_FragColor = enc;\n    }\n  ",n=e.createShader(35633),o=e.createShader(35632),a=e.createProgram();if(!(o&&n&&a))return;e.shaderSource(n,t),e.shaderSource(o,r),e.compileShader(n),e.compileShader(o),e.attachShader(a,n),e.attachShader(a,o),e.linkProgram(a),e.detachShader(a,n),e.detachShader(a,o),e.deleteShader(n),e.deleteShader(o),e.useProgram(a);const i=e.createBuffer();e.bindBuffer(34962,i),e.bufferData(34962,new Float32Array([-1,-1,0,3,-1,0,-1,3,0]),35044);const c=e.getAttribLocation(a,"aPosition");e.vertexAttribPointer(c,3,5126,!1,0,0),e.enableVertexAttribArray(c),e.clearColor(1,1,1,1),e.clear(16384),e.viewport(0,0,1,1),e.drawArrays(4,0,3);const d=new Uint8Array(4);return e.readPixels(0,0,1,1,6408,5121,d),e.deleteProgram(a),e.deleteBuffer(i),d.join("")}(e),a="801621810",i="8016218135",c="80162181161",d=(null==o?void 0:o.isIpad)?[["a7",c,12],["a8",i,15],["a8x",i,15],["a9",i,15],["a9x",i,15],["a10",i,15],["a10x",i,15],["a12",a,15],["a12x",a,15],["a12z",a,15],["a14",a,15],["a15",a,15],["m1",a,15],["m2",a,15]]:[["a7",c,12],["a8",i,12],["a9",i,15],["a10",i,15],["a11",a,15],["a12",a,15],["a13",a,15],["a14",a,15],["a15",a,15],["a16",a,15],["a17",a,15]];let l;"80162181255"===n?l=d.filter((([,,e])=>e>=14)):(l=d.filter((([,e])=>e===n)),l.length||(l=d));return l.map((([e])=>`apple ${e} gpu`))}class i extends Error{constructor(e){super(e),Object.setPrototypeOf(this,new.target.prototype);}}const c=[],d=[];function l(e,t){if(e===t)return 0;const r=e;e.length>t.length&&(e=t,t=r);let n=e.length,o=t.length;for(;n>0&&e.charCodeAt(~-n)===t.charCodeAt(~-o);)n--,o--;let a,i=0;for(;i<n&&e.charCodeAt(i)===t.charCodeAt(i);)i++;if(n-=i,o-=i,0===n)return o;let l,s,f=0,u=0,g=0;for(;u<n;)d[u]=e.charCodeAt(i+u),c[u]=++u;for(;g<o;)for(a=t.charCodeAt(i+g),l=g++,f=g,u=0;u<n;u++)s=a===d[u]?l:l+1,l=c[u],f=c[u]=l>f?s>f?f+1:s:s>l?l+1:s;return f}function s(e){return null!=e}const f=({mobileTiers:c=[0,15,30,60],desktopTiers:d=[0,15,30,60],override:f={},glContext:u,failIfMajorPerformanceCaveat:g=!1,benchmarksURL:h="https://unpkg.com/detect-gpu@5.0.70/dist/benchmarks"}={})=>e$1(void 0,void 0,void 0,(function*(){const p={};if(n)return {tier:0,type:"SSR"};const{isIpad:m=!!(null==o?void 0:o.isIpad),isMobile:v=!!(null==o?void 0:o.isMobile),screenSize:w=window.screen,loadBenchmarks:x=(t=>e$1(void 0,void 0,void 0,(function*(){const e=yield fetch(`${h}/${t}`).then((e=>e.json()));if(parseInt(e.shift().split(".")[0],10)<4)throw new i("Detect GPU benchmark data is out of date. Please update to version 4x");return e})))}=f;let{renderer:A}=f;const P=(e,t,r,n,o)=>({device:o,fps:n,gpu:r,isMobile:v,tier:e,type:t});let S,b="";if(A)A=r(A),S=[A];else {const e=u||function(e,t=!1){const r={alpha:!1,antialias:!1,depth:!1,failIfMajorPerformanceCaveat:t,powerPreference:"high-performance",stencil:!1};e&&delete r.powerPreference;const n=window.document.createElement("canvas"),o=n.getContext("webgl",r)||n.getContext("experimental-webgl",r);return null!=o?o:void 0}(null==o?void 0:o.isSafari12,g);if(!e)return P(0,"WEBGL_UNSUPPORTED");const t=(null==o?void 0:o.isFirefox)?null:e.getExtension("WEBGL_debug_renderer_info");if(A=t?e.getParameter(t.UNMASKED_RENDERER_WEBGL):e.getParameter(e.RENDERER),!A)return P(1,"FALLBACK");b=A,A=r(A),S=function(e,t,r){return "apple gpu"===t?a(e,t,r):[t]}(e,A,v);}const E=(yield Promise.all(S.map((function(t){var r;return e$1(this,void 0,void 0,(function*(){const e=(e=>{const t=v?["adreno","apple","mali-t","mali","nvidia","powervr","samsung"]:["intel","apple","amd","radeon","nvidia","geforce","adreno"];for(const r of t)if(e.includes(r))return r})(t);if(!e)return;const n=`${v?"m":"d"}-${e}${m?"-ipad":""}.json`,o=p[n]=null!==(r=p[n])&&void 0!==r?r:x(n);let a;try{a=yield o;}catch(e){if(e instanceof i)throw e;return}const c=function(e){var t;const r=(e=e.replace(/\([^)]+\)/,"")).match(/\d+/)||e.match(/(\W|^)([A-Za-z]{1,3})(\W|$)/g);return null!==(t=null==r?void 0:r.join("").replace(/\W|amd/g,""))&&void 0!==t?t:""}(t);let d=a.filter((([,e])=>e===c));d.length||(d=a.filter((([e])=>e.includes(t))));const s=d.length;if(0===s)return;const f=t.split(/[.,()\[\]/\s]/g).sort().filter(((e,t,r)=>0===t||e!==r[t-1])).join(" ");let u,[g,,,,h]=s>1?d.map((e=>[e,l(f,e[2])])).sort((([,e],[,t])=>e-t))[0][0]:d[0],A=Number.MAX_VALUE;const{devicePixelRatio:P}=window,S=w.width*P*w.height*P;for(const e of h){const[t,r]=e,n=t*r,o=Math.abs(S-n);o<A&&(A=o,u=e);}if(!u)return;const[,,b,E]=u;return [A,b,g,E]}))})))).filter(s).sort((([e=Number.MAX_VALUE,t],[r=Number.MAX_VALUE,n])=>e===r?t-n:e-r));if(!E.length){const e=t.find((e=>A.includes(e)));return e?P(0,"BLOCKLISTED",e):P(1,"FALLBACK",`${A} (${b})`)}const[,y,C,L]=E[0];if(-1===y)return P(0,"BLOCKLISTED",C,y,L);const M=v?c:d;let $=0;for(let e=0;e<M.length;e++)y>=M[e]&&($=e);return P($,"BENCHMARK",C,y,L)}));//# sourceMappingURL=detect-gpu.esm.js.map

	/**
	 * Can be used to create a flat, reflective surface like a mirror.
	 *
	 * Note that this class can only be used with {@link WebGLRenderer}.
	 * When using {@link WebGPURenderer}, use {@link ReflectorNode}.
	 *
	 * ```js
	 * const geometry = new THREE.PlaneGeometry( 100, 100 );
	 *
	 * const reflector = new Reflector( geometry, {
	 * 	clipBias: 0.003,
	 * 	textureWidth: window.innerWidth * window.devicePixelRatio,
	 * 	textureHeight: window.innerHeight * window.devicePixelRatio,
	 * 	color: 0xc1cbcb
	 * } );
	 *
	 * scene.add( reflector );
	 * ```
	 *
	 * @augments Mesh
	 * @three_import import { Reflector } from 'three/addons/objects/Reflector.js';
	 */
	class Reflector extends Mesh {

		/**
		 * Constructs a new reflector.
		 *
		 * @param {BufferGeometry} geometry - The reflector's geometry.
		 * @param {Reflector~Options} [options] - The configuration options.
		 */
		constructor( geometry, options = {} ) {

			super( geometry );

			/**
			 * This flag can be used for type testing.
			 *
			 * @type {boolean}
			 * @readonly
			 * @default true
			 */
			this.isReflector = true;

			this.type = 'Reflector';

			/**
			 * Whether to force an update, no matter if the reflector
			 * is in view or not.
			 *
			 * @type {boolean}
			 * @default false
			 */
			this.forceUpdate = false;

			/**
			 * The reflector's virtual camera. This is used to render
			 * the scene from the mirror's point of view.
			 *
			 * @type {PerspectiveCamera}
			 */
			this.camera = new PerspectiveCamera();

			const scope = this;

			const color = ( options.color !== undefined ) ? new Color( options.color ) : new Color( 0x7F7F7F );
			const textureWidth = options.textureWidth || 512;
			const textureHeight = options.textureHeight || 512;
			const clipBias = options.clipBias || 0;
			const shader = options.shader || Reflector.ReflectorShader;
			const multisample = ( options.multisample !== undefined ) ? options.multisample : 4;

			//

			const reflectorPlane = new Plane();
			const normal = new Vector3();
			const reflectorWorldPosition = new Vector3();
			const cameraWorldPosition = new Vector3();
			const rotationMatrix = new Matrix4();
			const lookAtPosition = new Vector3( 0, 0, - 1 );
			const clipPlane = new Vector4();

			const view = new Vector3();
			const target = new Vector3();
			const q = new Vector4();

			const textureMatrix = new Matrix4();
			const virtualCamera = this.camera;

			const renderTarget = new WebGLRenderTarget( textureWidth, textureHeight, { samples: multisample, type: HalfFloatType } );

			const material = new ShaderMaterial( {
				name: ( shader.name !== undefined ) ? shader.name : 'unspecified',
				uniforms: UniformsUtils.clone( shader.uniforms ),
				fragmentShader: shader.fragmentShader,
				vertexShader: shader.vertexShader
			} );

			material.uniforms[ 'tDiffuse' ].value = renderTarget.texture;
			material.uniforms[ 'color' ].value = color;
			material.uniforms[ 'textureMatrix' ].value = textureMatrix;

			this.material = material;

			this.onBeforeRender = function ( renderer, scene, camera ) {

				reflectorWorldPosition.setFromMatrixPosition( scope.matrixWorld );
				cameraWorldPosition.setFromMatrixPosition( camera.matrixWorld );

				rotationMatrix.extractRotation( scope.matrixWorld );

				normal.set( 0, 0, 1 );
				normal.applyMatrix4( rotationMatrix );

				view.subVectors( reflectorWorldPosition, cameraWorldPosition );

				// Avoid rendering when reflector is facing away unless forcing an update
				const isFacingAway = view.dot( normal ) > 0;

				if ( isFacingAway === true && this.forceUpdate === false ) return;

				view.reflect( normal ).negate();
				view.add( reflectorWorldPosition );

				rotationMatrix.extractRotation( camera.matrixWorld );

				lookAtPosition.set( 0, 0, - 1 );
				lookAtPosition.applyMatrix4( rotationMatrix );
				lookAtPosition.add( cameraWorldPosition );

				target.subVectors( reflectorWorldPosition, lookAtPosition );
				target.reflect( normal ).negate();
				target.add( reflectorWorldPosition );

				virtualCamera.position.copy( view );
				virtualCamera.up.set( 0, 1, 0 );
				virtualCamera.up.applyMatrix4( rotationMatrix );
				virtualCamera.up.reflect( normal );
				virtualCamera.lookAt( target );

				virtualCamera.far = camera.far; // Used in WebGLBackground

				virtualCamera.updateMatrixWorld();
				virtualCamera.projectionMatrix.copy( camera.projectionMatrix );

				// Update the texture matrix
				textureMatrix.set(
					0.5, 0.0, 0.0, 0.5,
					0.0, 0.5, 0.0, 0.5,
					0.0, 0.0, 0.5, 0.5,
					0.0, 0.0, 0.0, 1.0
				);
				textureMatrix.multiply( virtualCamera.projectionMatrix );
				textureMatrix.multiply( virtualCamera.matrixWorldInverse );
				textureMatrix.multiply( scope.matrixWorld );

				// Now update projection matrix with new clip plane, implementing code from: http://www.terathon.com/code/oblique.html
				// Paper explaining this technique: http://www.terathon.com/lengyel/Lengyel-Oblique.pdf
				reflectorPlane.setFromNormalAndCoplanarPoint( normal, reflectorWorldPosition );
				reflectorPlane.applyMatrix4( virtualCamera.matrixWorldInverse );

				clipPlane.set( reflectorPlane.normal.x, reflectorPlane.normal.y, reflectorPlane.normal.z, reflectorPlane.constant );

				const projectionMatrix = virtualCamera.projectionMatrix;

				q.x = ( Math.sign( clipPlane.x ) + projectionMatrix.elements[ 8 ] ) / projectionMatrix.elements[ 0 ];
				q.y = ( Math.sign( clipPlane.y ) + projectionMatrix.elements[ 9 ] ) / projectionMatrix.elements[ 5 ];
				q.z = - 1.0;
				q.w = ( 1.0 + projectionMatrix.elements[ 10 ] ) / projectionMatrix.elements[ 14 ];

				// Calculate the scaled plane vector
				clipPlane.multiplyScalar( 2.0 / clipPlane.dot( q ) );

				// Replacing the third row of the projection matrix
				projectionMatrix.elements[ 2 ] = clipPlane.x;
				projectionMatrix.elements[ 6 ] = clipPlane.y;
				projectionMatrix.elements[ 10 ] = clipPlane.z + 1.0 - clipBias;
				projectionMatrix.elements[ 14 ] = clipPlane.w;

				// Render
				scope.visible = false;

				const currentRenderTarget = renderer.getRenderTarget();

				const currentXrEnabled = renderer.xr.enabled;
				const currentShadowAutoUpdate = renderer.shadowMap.autoUpdate;

				renderer.xr.enabled = false; // Avoid camera modification
				renderer.shadowMap.autoUpdate = false; // Avoid re-computing shadows

				renderer.setRenderTarget( renderTarget );

				renderer.state.buffers.depth.setMask( true ); // make sure the depth buffer is writable so it can be properly cleared, see #18897

				if ( renderer.autoClear === false ) renderer.clear();
				renderer.render( scene, virtualCamera );

				renderer.xr.enabled = currentXrEnabled;
				renderer.shadowMap.autoUpdate = currentShadowAutoUpdate;

				renderer.setRenderTarget( currentRenderTarget );

				// Restore viewport

				const viewport = camera.viewport;

				if ( viewport !== undefined ) {

					renderer.state.viewport( viewport );

				}

				scope.visible = true;
				this.forceUpdate = false;

			};

			/**
			 * Returns the reflector's internal render target.
			 *
			 * @return {WebGLRenderTarget} The internal render target
			 */
			this.getRenderTarget = function () {

				return renderTarget;

			};

			/**
			 * Frees the GPU-related resources allocated by this instance. Call this
			 * method whenever this instance is no longer used in your app.
			 */
			this.dispose = function () {

				renderTarget.dispose();
				scope.material.dispose();

			};

		}

	}

	Reflector.ReflectorShader = {

		name: 'ReflectorShader',

		uniforms: {

			'color': {
				value: null
			},

			'tDiffuse': {
				value: null
			},

			'textureMatrix': {
				value: null
			}

		},

		vertexShader: /* glsl */`
		uniform mat4 textureMatrix;
		varying vec4 vUv;

		#include <common>
		#include <logdepthbuf_pars_vertex>

		void main() {

			vUv = textureMatrix * vec4( position, 1.0 );

			gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );

			#include <logdepthbuf_vertex>

		}`,

		fragmentShader: /* glsl */`
		uniform vec3 color;
		uniform sampler2D tDiffuse;
		varying vec4 vUv;

		#include <logdepthbuf_pars_fragment>

		float blendOverlay( float base, float blend ) {

			return( base < 0.5 ? ( 2.0 * base * blend ) : ( 1.0 - 2.0 * ( 1.0 - base ) * ( 1.0 - blend ) ) );

		}

		vec3 blendOverlay( vec3 base, vec3 blend ) {

			return vec3( blendOverlay( base.r, blend.r ), blendOverlay( base.g, blend.g ), blendOverlay( base.b, blend.b ) );

		}

		void main() {

			#include <logdepthbuf_fragment>

			vec4 base = texture2DProj( tDiffuse, vUv );
			gl_FragColor = vec4( blendOverlay( base.rgb, color ), 1.0 );

			#include <tonemapping_fragment>
			#include <colorspace_fragment>

		}`
	};

	const vertexShader$b = /* glsl */`
		uniform mat4 textureMatrix;
		varying vec4 vUv;

		#include <common>
		#include <logdepthbuf_pars_vertex>

		void main() {

			vUv = textureMatrix * vec4( position, 1.0 );

			gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );

			#include <logdepthbuf_vertex>

}`;

	const fragmentShader$a = /* glsl */`
		uniform vec3 color;
		uniform sampler2D tDiffuse;
        uniform sampler2D tDudv;

        uniform float uTime;

		varying vec4 vUv;

		#include <logdepthbuf_pars_fragment>

        /*

		float blendOverlay( float base, float blend ) {

			return( base < 0.5 ? ( 2.0 * base * blend ) : ( 1.0 - 2.0 * ( 1.0 - base ) * ( 1.0 - blend ) ) );

		}

		vec3 blendOverlay( vec3 base, vec3 blend ) {

			return vec3( blendOverlay( base.r, blend.r ), blendOverlay( base.g, blend.g ), blendOverlay( base.b, blend.b ) );

		}
        */

		void main() {

			#include <logdepthbuf_fragment>

            float time = uTime;

            float waveStrength = 0.01;
		    float waveSpeed = 0.03;

			// simple distortion (ripple) via dudv map (see https://www.youtube.com/watch?v=6B7IF6GOu7s)

			vec2 distortedUv = texture2D( tDudv, vec2( vUv.x + time * waveSpeed, vUv.y ) ).rg * waveStrength;
			distortedUv = vUv.xy + vec2( distortedUv.x, distortedUv.y + time * waveSpeed );
			
            vec2 distortion = ( texture2D( tDudv, distortedUv ).rg * 2.0 - 1.0 ) * waveStrength;

			// new uv coords

			vec4 uv = vec4( vUv );
			uv.xy += distortion;


			vec4 base = texture2DProj( tDiffuse, uv );
			gl_FragColor = vec4( mix( base.rgb, color, 0.8 ), 1.0 );

			#include <tonemapping_fragment>
			#include <colorspace_fragment>

}`;





	class Mirror extends Shape$1 {

	    getGeometry() {
	        const { 
	            width = 1, height = 1
	        } = this.params;
	        const geometry = new CircleGeometry( width, 12 ); 
	        // const geometry = new THREE.PlaneGeometry(width, height, 2);
	        return geometry;
	    }
		
	    // default mesh
	    createMesh(program) {
	        
	        const container = new Group$1();

	        const { renderer } = program;
	        const pixelRatio = Math.min(renderer.getPixelRatio(), 2);
	        
	        // console.log(">>>>>> >>> MIRROR REFLECTOR", this.params);

	        const color = new Color(...this.color);

	        const { 
	            dither = 2, 
	            power = 4,
	            particle_count = 2000, 
	            branches = 3, 
	            radius = 1,
	            particleSize = 3.1,
	            particleSizePow = 2,
	            blending = 'normal', 
	            particleType = 'disc',
	            innerRadius = 0,
	            outerRadius = 1,
	            amp = 0.1,
	            spin = 1,
	            width = 1, height = 1,
	            displacement = ""
	        } = this.params || {};

	        let shader;

	        const enableMirror = () => {


	            const geometry = this.getGeometry(program);


	            const textureLoader = new TextureLoader();
	            const displacementMap = textureLoader.load(displacement, function() {
	                console.log("texture loaded", displacement);
	            });
	            displacementMap.wrapS = displacementMap.wrapT = RepeatWrapping;


	            const customShader = Reflector.ReflectorShader;

	            customShader.fragmentShader = fragmentShader$a;
	            customShader.vertexShader = vertexShader$b;
	            customShader.uniforms.tDudv = new Uniform(displacementMap);
	            customShader.uniforms.uTime = new Uniform(0);

	            shader = customShader;

	            // reflector mesh
	            const mirror = new Reflector(geometry, {
	                shader: customShader,
	                clipBias: 0.003,
	                textureWidth: 1024 * pixelRatio,
	                textureHeight: 1024 * pixelRatio,
	                color
	            });

	            container.add(mirror);

	        };

	        


	        
	        const gpuDetector = async () => {

	            // we have AR
	            if (navigator.xr) {
	                enableMirror();
	                console.log("MIRROR - HAS XR", navigator.xr);
	                return
	            }

	            const gpuTier = await f();
	            console.log("MIRROR", gpuTier, navigator.xr);

	            if (!gpuTier.isMobile) {
	                enableMirror();
	                return   
	            }

	            console.log("DISABLING MIRROR MOBILE");

	            // Example output:
	            // {
	            //   "tier": 1,
	            //   "isMobile": false,
	            //   "type": "BENCHMARK",
	            //   "fps": 21,
	            //   "gpu": "intel iris graphics 6100"
	            // }
	        };

	        gpuDetector();



	        
	        this.applyTransforms(container);
	    
	        this.tick = (context) => {
	            const { time } = context.clock;

	            if (shader) {
	                shader.uniforms.uTime.value = time;
	            }
	        };

	        return container;
	    }


	    getMaterial(program, geometry) {

	        
	    }



	}

	const BUTTONS = {
	    'glass': glassButton
	};


	const vertexShader$c = /* glsl */`
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;
varying vec2 vUv;

void main() { 
    vUv = uv;
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}   
  `;

	const fragmentShader$b = /* glsl */`
varying vec2 vUv;

uniform sampler2D uTexture;
uniform vec2 uPlaneResolution;
uniform vec2 uTextureSize;

void main()	{

	//vec2 scaledUV = vUv; //calcUV(vUv, uTextureSize, uPlaneResolution);

	//vec4 image = texture2D(uTexture, scaledUV);
    //gl_FragColor = image; // vec4(vUv, 1.0, 1.0);
    gl_FragColor =  vec4(vUv, 1.0, 1.0);
    #include <tonemapping_fragment>
    #include <colorspace_fragment>
}
`;






	class Button extends Shape$1 {
		getGeometry(program) {
			let plane = new PlaneGeometry(this.params.width, this.params.height, 32);
	       
			return plane
		}

	    // default mesh
	    createMesh(program) {	
	        

	        const {
	            type = 'glass'
	        } = this.params;

	        //const geometry = this.getGeometry(program)
	        //const material = this.getMaterial(program, geometry)

	        //const mesh = new THREE.Mesh(geometry, material)

	        const container = new Group$1();
	        //container.add(mesh)

	        // console.log("----------- >>>>>>>>>>>>>>>>> BUTTON", this.params)

	        const createButton = BUTTONS['glass'];

	        const button = createButton(this.params, program);
	        container.add(button.mesh);

	        // keep the mesh behund the text
	        button.mesh.position.z = -0.2;
	        button.mesh.position.y = -0.05;

	        this.applyTransforms(container);

	        this.tick = (context) => {
	            button.tick(context);
	        };


	        return container;
	    }


	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);
	        const texFile = this.params.map;

	        const textureLoader = new TextureLoader();
	        const texture = textureLoader.load(texFile, function() {
	            console.log("EVBAR: texture loaded");
	        });

	        const uniforms = {
	            time: {value: 0},
	            uTexture: { value: texture },
	            uTextureSize: {value: new Vector2(1024, 1024)},
	            uPlaneResolution: {value: new Vector2(1.4, 1)}
	        };
	        
	        const material = new ShaderMaterial({
	                    color,
	                    wireframe: false,
	                    side: DoubleSide,
	                    fragmentShader: fragmentShader$b,
	                    vertexShader: vertexShader$c,
	                    uniforms,
	                    
	            });

	        return material
	    }

	   


	}

	function createFlower(params, program) {
	    const { count } = params;
	    const shape = new Shape(heart({ scale: 0.001 }));

	    const geometry = new ShapeGeometry( shape, 3 );

	    const material = new MeshBasicMaterial( { 
	        side: DoubleSide
	     } );

	    const dummy = new Object3D();
	    const matrix = new Matrix4();

	    let mesh = new InstancedMesh(geometry, material, count);



	    return {
	        mesh, geometry, material, dummy, matrix,
	        evolve: {
	            x: Math.random(),
	            y: Math.random(),
	            z: Math.random()
	        }
	    }

	}










	function createPlants(params, program) {
	    
	    const radiusTop = 0.0005;
	    const radiusBottom =  0.003;
	    const radialSegments = 5;
	    const heightSegments = 1;
	    const openEnded = true;
	    const thetaStart = 0;
	    const thetaLength = Math.PI * 2;

	    const {
	        count = 20,
	        height = 1,
	        radius = 8
	    } = params;



	    const geometry = new CylinderGeometry(
	        radiusTop, radiusBottom, height, 
	        radialSegments, heightSegments, openEnded,
	        thetaStart, thetaLength
	    );

	    const material = new MeshBasicMaterial({
	        color: 0x00ff00 // green stem
	        //color: 'red',
	        //emissive: new THREE.Color('#red'),
	        //emissiveIntensity: 0.1,
	        //side: THREE.BackSide
	    });

	    const container = new Group$1();

	    const dummy = new Object3D();
	    
	    //const createFlower = flowerGenerator(params, program)

	    let mesh;
	    let flower; 

	    function createInstances() {

	        flower = createFlower(params);
	        mesh = new InstancedMesh(geometry, material, count);
	        
	        //mesh.castShadow = true;
	        //mesh.receiveShadow = true;

	        for (let i = 0; i < count; i++) {
	            
	            dummy.position.x = (Math.random() - 0.5) * radius;
	            dummy.position.y = 0.5;
	            dummy.position.z = (Math.random() - 0.5) * radius;

	            flower.dummy.position.x = dummy.position.x;
	            flower.dummy.position.y = 0;
	            flower.dummy.position.z = dummy.position.z;

	            dummy.updateMatrix();
	            flower.dummy.updateMatrix();

	            mesh.setMatrixAt(i, dummy.matrix);
	            flower.mesh.setMatrixAt(i, flower.dummy.matrix);

	            const color = new Color(Math.random() * 0xFFFFFF);

	            mesh.setColorAt(i, color);
	            flower.mesh.setColorAt(i, color);
	        }

	        container.add(mesh);
	        container.add(flower.mesh);
	    }


	    createInstances();

	    
	    const matrix = new Matrix4();

	    const tick = (context) => {
	        if (!mesh) {
	            return;
	        }
	        const { analyser } = context;
	        const { time } = context.clock;


	        for (let i = 0; i<count; i++) { 

	            const d = analyser.data[i];
	            const p = analyser.peaks[i];

	            mesh.getMatrixAt(i, matrix);
	            flower.mesh.getMatrixAt(i, flower.matrix);

	            matrix.decompose(dummy.position, dummy.rotation, dummy.scale);
	            flower.matrix.decompose(flower.dummy.position, flower.dummy.rotation, flower.dummy.scale);

	            //dummy.position.z = (i + 1) / 10 * Math.sin(time) * 2
	            
	            // stems
	            const scale = 0.01 + d / 100;
	            const ypos = 0.01 + p / 100;
	            const flowerScale = 0.1 + d / 10;

	            dummy.position.y = 0.18 + (scale / 2);
	            dummy.scale.set(1, scale, 1);

	            flower.dummy.position.y = 0.18 + ypos; //+ (scale / 2);
	            flower.dummy.rotation.y = (time / 10) + flower.evolve.y; //+ (scale / 2);
	            flower.dummy.scale.set(flowerScale, flowerScale, 1);

	            // flowers

	            dummy.updateMatrix();
	            flower.dummy.updateMatrix();

	            mesh.setMatrixAt(i, dummy.matrix);
	            flower.mesh.setMatrixAt(i, flower.dummy.matrix);
	        }

	        mesh.instanceMatrix.needsUpdate = true;
	        flower.mesh.instanceMatrix.needsUpdate = true;
	    };

	    return {
	        mesh: container, tick
	    };

	}










	function floweringGarden(params, program) {

	    const { 
	      color1 = { hex: 'FF9419' },
	      color2 = { hex: '140CFF' },
	      color3 = { hex: '140CFF' },
	    } = params;

	    const colors = [color1, color2, color3].map(c => new Color(`#${c.hex}`));

	    const bars = createPlants(params);

	    // the big heart
	    const heart = heartShape({  scale: 0.05, lineWidth: 0.03, ...params, color: 'red', });
	    heart.mesh.position.y = 1.5;
	    heart.mesh.position.z = 0.5;

	    const { mesh, material, geometry, uniforms } = bars;

	    const container = new Group$1();
	    container.add(heart.mesh);
	    container.add(mesh);


	    const tick = (context) => {
	        bars.tick(context);
	        heart.tick(context);
	          //console.log(context.analyser.data);

	          // note: update audio data
	          //analyser.getByteFrequencyData(dataArray);

	          // note: update uniforms
	          // uniforms.uTime.value = context.clock.time;
	          //uniforms.u_data_arr.value = dataArray;
	      };
	      
	      return {
	          mesh:container, material, geometry, tick
	      }

	}

	const vertexShader$d = /* glsl */`
    uniform vec2 uPlaneResolution;
    uniform vec2 uTextureSize;
    varying vec2 vUv;

    void main() { 
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
    }   
  `;

	const fragmentShader$c = /* glsl */`
    varying vec2 vUv;

    uniform sampler2D uTexture;
    uniform vec2 uPlaneResolution;
    uniform vec2 uTextureSize;

    void main()	{

        //vec2 scaledUV = vUv; //calcUV(vUv, uTextureSize, uPlaneResolution);

        //vec4 image = texture2D(uTexture, scaledUV);
        //gl_FragColor = image; // vec4(vUv, 1.0, 1.0);
        gl_FragColor =  vec4(vUv, 1.0, 1.0);
        #include <tonemapping_fragment>
        #include <colorspace_fragment>
    }
`;



	function createCage(params, program) {
	    
	    const radiusTop = 0.02;
	    const radiusBottom = 0.02;
	    const height = 8;
	    const radialSegments = 4;
	    const heightSegments = 1;
	    const openEnded = true;
	    const thetaStart = 0;
	    const thetaLength = Math.PI * 2;
	    const barCount = 20;

	    const cageRadius = 4.5;

	    const geometry = new CylinderGeometry(
	        radiusTop, radiusBottom, height, 
	        radialSegments, heightSegments, openEnded,
	        thetaStart, thetaLength
	    );

	    const material = new MeshStandardMaterial({
	        color: '#222222',
	        //side: THREE.BackSide
	    });

	    const container = new Group$1();

	    // for (let i = 0; i < barCount; i++) {
	    //     const mesh = new THREE.Mesh(geometry, material)
	    //     mesh.position.x = Math.sin(i) * cageRadius
	    //     mesh.position.z = Math.cos(i) * cageRadius
	    //     group.add(mesh)

	    //     mesh.castShadow = true;
	    // }




	    const dummy = new Object3D();
	    let mesh;

	    function createInstances() {
	       
	        mesh = new InstancedMesh(geometry, material, barCount);
	        mesh.castShadow = true;
	        mesh.receiveShadow = true;

	        for (let i = 0; i < barCount; i++) {
	            
	            dummy.position.x = Math.sin(i) * cageRadius;
	            dummy.position.z = Math.cos(i) * cageRadius;

	            dummy.updateMatrix();
	            mesh.setMatrixAt(i, dummy.matrix);
	            //mesh.setColorAt(i, new THREE.Color(Math.random() * 0xFFFFFF));
	        }

	        container.add(mesh);
	    }


	    createInstances();


	    const matrix = new Matrix4();

	    const tick = (context) => {
	        if (!mesh) {
	            return;
	        }

	        const { time } = context.clock;
	        //mesh.instanceMatrix.needsUpdate = true;
	    };

	    return {
	        mesh: container, tick
	    };

	}




	function createTrees(params, program, parent) {
	    const { context } = program;
	    const { site } = context;

	    //const treeNode = site.findElement('tree1')
	    //const treeGroup = treeNode.nodes[0].mesh; // this will be a group
	    //const treeMesh = treeGroup.children

	    //const treeData = context.treedata;

	    const treeData = [
	        { x: -4.5, y: 0, z: -7, rx: 0, ry: 0, rz: 0.2 }, 
	        { x: 6, y: 0, z: 7, rx: 0, ry: 1.2, rz: 0 },
	        { x: 4, y: -1, z: 0, rx: -0.6, ry: 0.8, rz: 0.2 },
	        { x: -1.5, y: -0.6, z: 1, rx: 0.1, ry: -1.4, rz: -0.3, s: 0.6 },
	        { x: -0.5, y: 0, z: 3, rx: 0.1, ry: 0.2, rz: 1.2, s: 0.3 },
	        { x: 1.4, y: -0, z: -2, rx: -0.6, ry: -0.8, rz: -0.2, s: 0.2 },
	    ];

	    console.log("LOADING TREES", context);
	    console.log("treeData", treeData);

	    const {
	        count = treeData.length
	    } = params;

	    const treeModel = site.files.models.files.find(f => f.name === 'tree.glb');

	    const container = new Group$1();
	    const dummy = new Object3D();

	    let mesh;

	    function createInstances(geometry, material) {
	        geometry.computeVertexNormals();

	        const mat = new MeshStandardMaterial({
	            color: 'red',
	            metalness: 0,
	            roughness: 1
	        });

	        mesh = new InstancedMesh(geometry, mat, count);
	        mesh.castShadow = true;
	        mesh.receiveShadow = true;
	        
	        for (let i = 0; i < count; i++) {
	            const data = treeData[i];

	            dummy.position.x = data.x;
	            dummy.position.y = data.y;
	            dummy.position.z = data.z;

	            dummy.rotation.x = data.rx;
	            dummy.rotation.y = data.ry;
	            dummy.rotation.z = data.rz;

	            /*
	            dummy.position.x = ( 0.5 - Math.random()) * 8;
	            dummy.position.y = 0.5 - ( Math.random()) * 0.5;
	            dummy.position.z =( 0.5 - Math.random()) * 8;

	            dummy.rotation.set(
	                (0.5 - Math.random()) * Math.PI * 2,
	                (0.5 - Math.random()) * Math.PI * 2,
	                (0.5 - Math.random()) * Math.PI / 4,
	            );
	            */

	            const scale = data.s || 1; //0.3 * (Math.random() + 0.5);
	            dummy.scale.set(scale, scale, scale);

	            dummy.updateMatrix();
	            mesh.setMatrixAt(i, dummy.matrix);
	            mesh.setColorAt(i, new Color(Math.random() * 0xFFFFFF));

	        }

	        container.add(mesh);
	    }


	    parent.loadGLTF(treeModel.url, program).then((model) => {
	        const { material, geometry} = model.scene.children[0];
	        createInstances(geometry);
	    });


	    const matrix = new Matrix4();

	    const tick = (context) => {
	        if (!mesh) {
	            return;
	        }

	        const { time } = context.clock;
	        for (let i = 0; i<count; i++) { 
	            mesh.getMatrixAt(i, matrix);
	            matrix.decompose(dummy.position, dummy.rotation, dummy.scale);

	            //dummy.position.z = (i + 1) / 10 * Math.sin(time) * 2
	            //dummy.rotation.y += 0.15 // i / 100 * time / 10;

	            dummy.updateMatrix();
	            mesh.setMatrixAt(i, dummy.matrix);
	        }
	        mesh.instanceMatrix.needsUpdate = true;
	    };

	    return {
	        mesh: container, tick
	    };

	    


	}




	class ChapterOne extends Shape$1 {
		getGeometry(program) {

	        const { width = 1, height = 1 } = this.params;

			let plane = new PlaneGeometry(width, height, 1);
	       
			return plane
		}

	    // default mesh
	    createMesh(program) {
	        const container = new Group$1();
	        
	        
	        const geometry = this.getGeometry(program);
	        const material = this.getMaterial(program, geometry);

	        const mesh = new Mesh(geometry, material);

	        
	        //container.add(mesh)


	        const cage = createCage(this.params);
	        cage.mesh.position.z = -10;
	        cage.mesh.position.y = 3;

	        container.add(cage.mesh);


	        const trees = createTrees(this.params, program, this);
	        trees.mesh.position.y = -1;
	        container.add(trees.mesh);

	        const lightning = lightningBolt(this.params);
	        container.add(lightning.mesh);
	        lightning.mesh.position.y = 25;
	        lightning.mesh.position.z = 2.5;


	        const garden = floweringGarden({
	            ...this.params,
	            count: 100,
	        });

	        container.add(garden.mesh);
	        garden.mesh.position.y = -1;
	        garden.mesh.position.z = -10;


	        this.tick = (context) => {
	            cage.tick(context);
	            trees.tick(context);
	            lightning.tick(context);
	            garden.tick(context);

	                //console.log("lockscreen tick", context)
	        };

	        return container;
	    }

	    getMaterial(program, geometry) {
	        const color = new Color(...this.color);
	        const texFile = this.params.map;

	        const textureLoader = new TextureLoader();
	        const texture = textureLoader.load(texFile, function() {
	            console.log("EVBAR: texture loaded");
	        });

	        const uniforms = {
	            time: {value: 0},
	            uTexture: { value: texture },
	            uTextureSize: {value: new Vector2(1024, 1024)},
	            uPlaneResolution: {value: new Vector2(1.4, 1)}
	        };
	        
	        const material = new ShaderMaterial({
	                //color,
	                wireframe: false,
	                side: DoubleSide,
	                fragmentShader: fragmentShader$c,
	                vertexShader: vertexShader$d,
	                uniforms,      
	        });

	        return material
	    }




	}

	var chapters = {
	    chapterOne: ChapterOne,
	    'webgl-chapterone': ChapterOne
	};

	const ACTIONS = new WeakMap();

	function pointerInteractions(tracked, params, { context, camera, raycaster }) {
	    let currentIntersect = null;

	    const {
	        hoverColor = "blue",
	        normalColor = "black",
	        doClick, onEnter, onLeave
	    } = params;

	    function getIntersections( ) {
	        raycaster.setFromCamera(context.mouse, camera);
	        return raycaster.intersectObjects( tracked );
	    }

	    function intersect() {
	        const intersects = getIntersections();
	        
	        if (intersects.length) {
	            const target = intersects[0];
	            const object = target.object;

	            if (currentIntersect === null) {
	                // mouse enter event
	                onEnter(target);                
	            } else if (currentIntersect.object === object) ; else if (currentIntersect.object !== object) {
	                // mouse leave
	                onLeave(currentIntersect);
	                onEnter(target);
	            }
	            
	            currentIntersect = target;

	        } else {
	            if (currentIntersect !== null) {
	                onLeave(currentIntersect);
	            }
	            currentIntersect = null;
	        }
	    }

	    function onCLick(e) {
	        if (currentIntersect !== null) {
	            doClick(currentIntersect.object, currentIntersect);
	        }   
	    }

	    document.addEventListener('click', onCLick);

	    return {
	        click: doClick,
	        intersect
	    }
	}






	function controllerInteractions(tracked, params, program) {
	    
	    let currentIntersect = null;
	    

	    const {
	        doClick, onEnter, onLeave
	    } = params;

	    const { renderer, dolly, stage, raycaster, camera, sceme } = program;


	    const controller1 = renderer.xr.getController(0);
	    const controller2 = renderer.xr.getController(1);


	    // line 
	    const geometry = new BufferGeometry().setFromPoints(
	        [new Vector3(0, 0, 0), new Vector3(0, 0, - 1)]
	    );

	    const line = new Line(geometry);
	    line.name = 'line';
	    line.scale.z = 5;

	    
	    function getIntersections(controller ) {
	        raycaster.setFromXRController(controller);
	        const intersects = raycaster.intersectObjects(tracked);
	        return intersects
	    }

	    function onSelect(event) {

	        const controller = event.target;

	        console.log("ON CONTROLLER SELECT", event, controller);

	        controller1.userData.active = false;
	        controller2.userData.active = false;

	        if (controller === controller1) {
	            controller1.userData.active = true;
	            controller1.add(line);
	        }

	        if (controller === controller2) {
	            controller2.userData.active = true;
	            controller2.add(line);
	        }

	        const intersects = getIntersections(controller);

	        if (intersects.length > 0) {
	            const target = intersects[0];
	            doClick(target.object, target);
	            // controls.attach(intersects[0].object);
	        }

	    }


	    function intersect(controller) {
	        const intersects = getIntersections(controller);
	        
	        if (intersects.length) {
	            const target = intersects[0];
	            const object = target.object;

	            if (currentIntersect === null) {
	                // mouse enter event
	                onEnter(target);                
	            } else if (currentIntersect.object === object) ; else if (currentIntersect.object !== object) {
	                // mouse leave
	                onLeave(currentIntersect);
	                onEnter(target);
	            }
	            
	            currentIntersect = target;

	        } else {
	            if (currentIntersect !== null) {
	                onLeave(currentIntersect);
	            }
	            currentIntersect = null;
	        }
	    }


	    function onControllerEvent(event) {

	        const controller = event.target;

	        if (controller.userData.active === false) return;

	        // 
	        
	        switch (event.type) {

	            case 'selectstart':
	                // currentIntersect = null
	                // controls.pointerDown(null);
	                break;

	            case 'selectend':
	                currentIntersect = null;
	                // controls.pointerUp(null);
	                break;

	            case 'move':
	                intersect(controller);
	                break;

	        }

	    }
	    

	    
	    controller1.addEventListener('select', onSelect);
	    controller1.addEventListener('selectstart', onControllerEvent);
	    controller1.addEventListener('selectend', onControllerEvent);
	    controller1.addEventListener('move', onControllerEvent);
	    controller1.userData.active = false;
	    dolly.add(controller1);

	    
	    controller2.addEventListener('select', onSelect);
	    controller2.addEventListener('selectstart', onControllerEvent);
	    controller2.addEventListener('selectend', onControllerEvent);
	    controller2.addEventListener('move', onControllerEvent);
	    controller2.userData.active = true;
	    dolly.add(controller2);

	    const controllerModelFactory = new XRControllerModelFactory();
	    const handModelFactory = new XRHandModelFactory();

	    const controllerGrip1 = renderer.xr.getControllerGrip(0);
	    controllerGrip1.add(controllerModelFactory.createControllerModel(controllerGrip1));
	    dolly.add(controllerGrip1);

	    const hand1 = renderer.xr.getHand(0);
	    hand1.add( handModelFactory.createHandModel( hand1 ) );

	    dolly.add( hand1 );

	    const controllerGrip2 = renderer.xr.getControllerGrip(1);
	    controllerGrip2.add(controllerModelFactory.createControllerModel(controllerGrip2));
	    dolly.add(controllerGrip2);

	    const hand2 = renderer.xr.getHand( 1 );
	    hand2.add( handModelFactory.createHandModel( hand2 ) );
	    dolly.add( hand2 );

	    //

	    function tick() {

	    }

	    return {
	        controller1, controller2,
	        hand1, hand2,
	        intersect: tick
	    }

	}




	function Interactive(params, program) {

	    const tracked = [];
	    

	    const {
	        name,
	        hoverColor = "blue",
	        normalColor = "black",
	        selectedColor = "yellow"
	    } = params;

	    const { renderer, scene, stage } = program;

	    const raycaster = new Raycaster();

	    function doClick(object, event) {
	        const actions = ACTIONS.get(object);
	        // console.log("click registered", currentIntersect)
	        if (actions.click) {
	            actions.click(event);
	        }
	        object.material.color.set(new Color(selectedColor));
	    }

	    
	    function onLeave(target) {
	        const object = target.object;
	        const actions = ACTIONS.get(object);
	        // console.log("pointer leave")
	        // mouse leave event
	        if (actions.leave) {
	            actions.leave(target);
	        }
	        object.material.color.set(new Color(normalColor));
	    }

	    function onEnter(target) {
	        const object = target.object;
	        const actions = ACTIONS.get(object);

	        if (actions.enter) {
	            actions.enter(target);
	        }
	        object.material.color.set(new Color(hoverColor));
	    }

	    
	    const pointer = pointerInteractions(tracked, 
	        { doClick, onEnter, onLeave },
	        {raycaster, ...program}
	    );

	    const spatial = controllerInteractions(tracked, 
	        { doClick, onEnter, onLeave },
	        {raycaster, ...program}
	    );
	    

	    function add(obj, actions) {
	        ACTIONS.set(obj, actions);
	        tracked.push(obj);
	    }

	    function remove(obj, actions) {
	        ACTIONS.delete(obj);

	        const idx = tracked.indexOf(obj);
	        tracked.splice(idx, 1);
	    }

	    function tick(context) {
	        if (renderer.xr.isPresenting) {
	            spatial.intersect();
	        } else {
	            pointer.intersect();
	        }
	    }   

	    return {
	        add, remove, 
	        track: add, untrack: remove, 
	        tick
	    }


	}

	const isAppleVisionPro = () => {
	  try {
	    // Check if the user agent string includes "Macintosh"
	    const isMacintosh = navigator.userAgent.includes("Macintosh");

	    // Check if the device has exactly five touch points
	    const hasFiveTouchPoints = navigator.maxTouchPoints === 5;

	    // Return true if both conditions are met
	    return isMacintosh && hasFiveTouchPoints;

	  } catch (error) {
	    console.error(
	      "Error determining if the device is an Apple Vision Pro: ",
	      error,
	    );
	    return false;
	  }
	};




	function createAssetManager(ctxt) {
	    const manager = new LoadingManager();
	            const events = {};

	            // set this to the parent context
	            ctxt.assetManager = manager;

	            manager.addEvent = (name, handler) => {
	                console.log("ADDING EVENT", name);
	                if (!events[name]) {
	                    events[name] = []; 
	                }
	                events[name].push(handler);
	            };

	            manager.onStart = function ( url, itemsLoaded, itemsTotal ) {
	                // console.log( 'Started loading file: ' + url + '.\nLoaded ' + itemsLoaded + ' of ' + itemsTotal + ' files.' );
	            };

	            manager.onProgress = function ( url, itemsLoaded, itemsTotal ) {
	                // console.log( 'Loading file: ' + url + '.\nLoaded ' + itemsLoaded + ' of ' + itemsTotal + ' files.' );
	            };

	            manager.onLoad = function () {
	                // console.log( 'Loading complete!' );
	                // Code to execute after all assets are loaded
	                
	                const evs = events['onComplete'] || [];
	                for (let handler of evs) {
	                    handler("LOADED");
	                }
	            };

	            manager.onError = function ( url ) {
	                // console.log( 'There was an error loading ' + url );
	            };

	            manager.setURLModifier( ( url ) => {
	                // console.log("LOADING URL", url)
	                return url;
	            } );


	            return manager;
	}






	function initializeContext(context, { canvas } = {}) {

	    const webglContext = context.$new("webgl", 0);

	    const canvasSizes = {
	        width: canvas.width,
	        height: canvas.height,
	    };

	    const sizes = {
	        width: window.innerWidth,
	        height: window.innerHeight,
	    };

	    webglContext.assign({         
	        cursor: new Vector2(0,0),
	        mouse: new Vector2(0,0),
	        sizes,
	        canvasSize: canvasSizes,
	        clock: {
	            time: 0,
	            delta: 0
	        },
	        get time() {
	            this.clock;
	        }
	        
	    });

	    const TICKS = [];

	    context.addTick = (fn) => {
	        TICKS.push(fn);
	    };


	        window.addEventListener('mousemove', (event) =>
	        {

	            webglContext.cursor.x = (event.clientX / sizes.width) - 0.5;
	            webglContext.cursor.y = (event.clientY / sizes.height) - 0.5;

	            webglContext.mouse.x = (event.clientX / sizes.width) * 2 - 1;
	            webglContext.mouse.y = -(event.clientY / sizes.height )* 2 + 1;

	            // context.mouse.set(context.cursor)
	        });

	        /*
	        window.addEventListener('scroll', (e) => {
	            webglContext.scroll.y = window.scrollY;
	            webglContext.scroll.x = window.scrollX;
	            webglContext.scroll.page = Math.round(webglContext.scroll.y / webglContext.window.height);
	        }, { passive: true })
	        */


	        const resize = () => {
	            sizes.width = window.innerWidth,
	            sizes.height = window.innerHeight;
	        };


	        const clock = new Clock();
	        let previousTime = 0;
	        
	        const tick = () => {
	            const elapsedTime = clock.getElapsedTime();
	            const deltaTime = elapsedTime - previousTime;
	            previousTime = elapsedTime;

	            // mutates the context clock!
	            webglContext.clock.time = elapsedTime;
	            webglContext.clock.elapsed = elapsedTime;
	            webglContext.clock.delta = deltaTime;

	            for (let tickfn of TICKS) {
	                tickfn(webglContext);
	            }


	        };

	        return { context: webglContext, tick, clock, resize }
	}








	function createControls(params, program) {
		const { camera, renderer } = program;

		const controls = new OrbitControls( camera, renderer.domElement );
		controls.listenToKeyEvents( window ); // optional

		//controls.addEventListener( 'change', render ); // call this only in static scenes (i.e., if there is no animation loop)

		controls.enableDamping = true; // an animation loop is required when either damping or auto-rotation are enabled
		controls.dampingFactor = 0.05;

		controls.target.set( 0, 0, 0 );
		controls.update();

		controls.enableZoom = true; 


		controls.screenSpacePanning = true;

		//controls.minDistance = 300;
		//controls.maxDistance = 500;

		controls.maxPolarAngle = Math.PI * 3;

		function tick(context) {
			controls.update();
		}

		return {
			controls, tick
		}
			
	}




	function initVR(canvas, program) {



	    let container;
	    let controls;

	    let camera, scene, renderer;

	    let ticker;

	    container = document.createElement( 'div' );
	    document.body.appendChild( container );

	    camera = new PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 );
	    camera.position.set( 0, 0, 4 );
	    
	    controls = new OrbitControls( camera, container );
	    controls.target.set( 0, 1.6, 0 );
	    controls.update();
	    //

	    
	    renderer = new WebGLRenderer( { 
	        antialias: true, 
	        canvas, 
	        alpha: true  
	    } );

	    renderer.setPixelRatio( window.devicePixelRatio );
	    renderer.setSize( window.innerWidth, window.innerHeight );

	    renderer.xr.enabled = true;
	    renderer.autoClear = false;
	    renderer.setClearColor( 0x000000, 0 );
	    
	    // renderer.shadowMap.enabled = true;

	    //renderer.toneMappingExposure = 1;
	    //renderer.toneMapping = THREE.ACESFilmicToneMapping;
	    renderer.toneMapping = 1;
	    renderer.toneMappingExposure = 1;
	    renderer.useLegacyLights  = false;
	    //renderer.toneMapping = THREE.NoToneMapping;
	    //renderer.setClearColor(0xffffff, 0);
	    renderer.toneMapping = ACESFilmicToneMapping;
	    //renderer.outputColorSpace = THREE.SRGBColorSpace;
	    //renderer.outputEncoding = THREE.sRGBEncoding;


	    renderer.xr.setReferenceSpaceType( 'local' );
	    

	    
	    

	    // container.appendChild( renderer.domElement );

	    const sessionInit = {
	        // handtracking prevents select events from firing in avp       
	       // requiredFeatures: [ 'hand-tracking' ]
	    };

	    const vrButton = VRButton.createButton( renderer, sessionInit );

	    const btnCtr = document.querySelector('.vrbutton_ctr') || document.body;

	    vrButton.addEventListener('mousedown', () => {
	        console.log("BUTTON CLICKED");
	    });

	    btnCtr.appendChild( vrButton );


	    function onWindowResize() {

	        camera.aspect = window.innerWidth / window.innerHeight;
	        camera.updateProjectionMatrix();

	        renderer.setSize( window.innerWidth, window.innerHeight );

	    }


	    function animate() {
	        if (ticker) {
	             ticker();
	        }
	       
	    }

	    renderer.setAnimationLoop( animate );


	    window.addEventListener( 'resize', onWindowResize );

	    function setTicker(fn) {
	        
	        ticker = fn;
	    }


	    return { ...program, canvas, camera, scene, renderer, setTicker }

	}




	function initScene(params, program) {
	    
	    const scene = new Scene();
	    //scene.background = new THREE.Color( 0x444444 );
	    scene.background = null;
	    scene.add( new HemisphereLight( 0xbcbcbc, 0xa5a5a5, 3 ) );

	    const light = new DirectionalLight( 0xffffff, 3 );
	    light.position.set( 0, 6, 0 );
	    light.castShadow = true;
	    light.shadow.camera.top = 2;
	    light.shadow.camera.bottom = - 2;
	    light.shadow.camera.right = 2;
	    light.shadow.camera.left = - 2;
	    //light.shadow.mapSize.set( 4096, 4096 );
	    scene.add( light );

	    return { scene }
	}



	function createStage(params, program) {

	    const { camera, scene } = program;

	    const stage = new Group$1();

	    const floorGeometry = new PlaneGeometry( 4, 4 );
	    const floorMaterial = new MeshStandardMaterial( { color: 0xffcc00 } );
	    const floor = new Mesh( floorGeometry, floorMaterial );
	    floor.rotation.x = - Math.PI / 2;
	    floor.position.y = -2;

	    stage.position.y = 0;

	    floor.receiveShadow = true;
	    //stage.add(floor)

	    const empty = new Object3D();
	    empty.position.y = 0;
	    empty.position.z = -4;

	    scene.add(empty);
	    
	    camera.lookAt(empty.position);


	    return { stage }
	}









	function init(canvas, { render, context }) {


	    const gl = initializeContext(context, { canvas });

	    const { site } = context;
		const devMode = site.runtimeMode === 'dev';


	    const program = initVR(canvas, { context: gl.context });
	    const { renderer, camera } = program;

	    const { scene } = initScene();
	    
	    const { stage } = createStage({}, { ...program, scene });
	    
	    const dolly = new Group$1();
	    dolly.position.set( 0, 0, 0 );
	    
	    dolly.add( camera );
	    scene.add( dolly );

	    renderer.xr.addEventListener('sessionstart', (e) => {
	        console.log("VR SESSION STARTED", e);
	        //camera.position.set( 0, 0, 4 );
	        //dolly.position.set( 0, 0, 8 );
	        // You can update camera properties here if needed.
	        // renderer.xr.getCamera().near = 0.01;
	        // renderer.xr.getCamera().updateProjectionMatrix();
	        // const vrcam = renderer.xr.getCamera()

	        const isAvp = isAppleVisionPro();

	        stage.position.z = -6;
	        stage.position.y = isAvp ? 1.2 : 0;

	        // console.log("camera", vrcam)

	        //dolly.position.set( 0, 3, 3 );

	    });


	    renderer.xr.addEventListener('sessionend', (ev) => {
	        console.log("SESSION ENDED");

	        window.location.reload();

	        vrMode = false;
	        context.vrMode = false;

	        resetCamera();

	        camera.position.set(0, 0, 0);

	        stage.position.set(0, 0, 0);

	        window.scrollTo(0,0);

	        window.location.reload();

	        // when vr session end, hide the button
	        // so user had to refresh before beginning the next session
	        // this is because once ended, the next vr session is just black.
	        // until I figure out why this is... this is how it'll be.
	        document.body.dispatchEvent(new CustomEvent('vrended', {
	            bubbles: true,
	            detail: {
	                vr: true,
	            }
	        }));



	    });

	    const assetManager = createAssetManager(context);

	    const interact = Interactive({
	            // hand tracking is disabled for now 
	            // it causes select event to not fire in avp
	            profile: 'mesh', 
	        },
	        { ...program, scene, dolly }
	    );


	    context.assign({
	        renderer, camera , scene, stage, 
	        assetManager, interaction: interact, interact
	    });


	    //const balls = createModels({}, { stage, ...program })
	    const mainStage = render({ 
	        ...program, scene, stage, 
	        assetManager, interact, context: gl.context 
	    });

	    let controls;

	    if (devMode) {
	        controls = createControls({ }, { ...program, camera });
	    }

	    gl.context.controls = controls;



	    site.setAnimationLoop((mainSiteTicker) => {
	        renderer.setAnimationLoop(mainSiteTicker);
	    });


	    function tick() {

	        if (controls) {
	            controls.tick(context);
	        }

	        if (interact) {
	            interact.tick(gl.context);
	        }
	        
	        mainStage.tick(gl.context);

	        gl.tick();
	        
	        renderer.render(scene, camera);
	    }


	    // grabs the main animation loop from site
	    // hooks it into the renderer's anim loop
	    // to support vr/xr 

	    // site.setAnimationLoop((mainSiteTicker) => {
	    //    renderer.setAnimationLoop(mainSiteTicker);
	    //})

	    //renderer.setAnimationLoop(tick)
	    scene.add(stage);
	    program.setTicker(tick);


	    return {
	        scene, renderer, camera, stage, 
	        interact, context: gl.context, tick
	    }

	}

	const classes = {
	    shape: Shape$1,
		scene: Scene$1,
	    plane: Plane$1,
	    cube: Cube,
	    lockscreen: LockScreen,
	    shiphud: ShipHud,
	    shipui: ShipUI,
	    evbar: EVBottomBar,
	    evstatusbar: EVStatusBar,
	    island: EVBottomBar$1,
	    text2d: TroikaTextShape,
	    text3d: Text3D,
	    gpuparticles: GPGPUParticles,
	    linegraph: LineGraph,
	    chart: LineGraph$1,
	    texteffect: TextEffect,
	    effects: BackgroundEffects,
	    blob: BlobShape,
	    visualizer: TextEffect$1,
	    environment: Environment,
	    waves: LineGraph$2,
	    skybox: Skybox,
	    light: Light$1,
	    particles: ParticleEmitter,
	    group: Group$2,
	    mirror: Mirror,
	    empty: Empty,
	    button: Button,
	    mesh: GenericMesh,
	    tree: Tree,

	    'webgl-lockscreen': LockScreen,
		'webgl-cube': Cube,
	    'webgl-plane': Plane$1,
		'webgl-model': Model,
	    'webgl-scene': Scene$1,
	    'webgl-shiphud': ShipHud,
	    'webgl-shipui': ShipUI,
	    'webgl-evbar': EVBottomBar,
	    'webgl-evstatusbar': EVStatusBar,
	    'webgl-island': EVBottomBar$1,
	    'webgl-text2d': TroikaTextShape,
	    'webgl-text3d': Text3D,
	    'webgl-gpuparticles': GPGPUParticles,
	    'webgl-linegraph': LineGraph,
	    'webgl-chart': LineGraph$1,
	    'webgl-texteffect': TextEffect,
	    'webgl-effects': BackgroundEffects,
	    'webgl-blob': BlobShape,
	    'webgl-terrain': Terrain,
	    'webgl-visualizer': TextEffect$1,
	    'webgl-environment': Environment,
	    'webgl-waves': LineGraph$2,
	    'webgl-skybox': Skybox,
	    'webgl-light': Light$1,
	    'webgl-particles': ParticleEmitter,
	    'webgl-group': Group$2,
	    'webgl-mirror': Mirror,
	    'webgl-button': Button,
	    'webgl-mesh': GenericMesh,

	    'webgl-tree': Tree,

	    ...chapters
	};


	var DOM = [];







	function createScene(root, canvas, ctxt, entity) {

	    const renderScene = (program) => {
	        // always start a scene by default?
	        // this is the default scene
	        const node = root.node(program, { 
	            name: "Default Scene", fog: true, 
	            root: true 
	        });

	        console.log("GOT ROOT NODE", node);

	        program.stage.add(node);

	        return {
	            node,
	            tick(context) {
	                root.tick(context);
	            }
	        }

	    };

	    return init(canvas, { root, render: renderScene, context: ctxt })
	}





	const WebglDoc = {
	    createElement(tag) {
	        const Klass = classes[tag] || Empty;
	        var obj =  new Klass(tag);
	        DOM.push(obj);
	        return obj
	    },
	    createTextNode(...args) {
	        // console.log("webgl doc create text node", ...args)
	        //return [{ node: ''}]
	        return new TextNode(...args)
	    },
	    getElements(classname) {
			var nodeList = [];
	        for (let obj of DOM) {
	            if (obj.attrs.class.trim() === classname.trim()) {
	                nodeList.push(obj);
	            }
	        }
	        return nodeList
	    },
		getElementById(id) {
			for (let obj of DOM) {
				const eid = obj.attrs['data-eid'] || '';
	            if (eid.trim() === id.trim()) {
	                return obj
	            }
	        }
		},
		createScene,
		nodes
	};

	return WebglDoc;

}());
